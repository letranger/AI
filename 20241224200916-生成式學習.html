<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-02-14 Fri 15:54 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>生成式學習</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script src="../css/copy_code.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">生成式學習</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgb145d05">1. 生成式學習</a></li>
<li><a href="#orgc76ce46">2. 生成式AI相關理論</a></li>
<li><a href="#orgd73b039">3. 自然語言生成</a></li>
<li><a href="#orgbd1baf9">4. 影像與多模態生成</a></li>
<li><a href="#org2d991aa">5. 生成式 AI 的相關議題</a></li>
<li><a href="#orga7e5065">6. Resource</a></li>
</ul>
</div>
</div>
<a href="https://hits.sh/letranger.github.io/AI//20241224200916-生成式學習.html/"><img alt="Hits" align="right" src="https://hits.sh/letranger.github.io/AI//20241224200916-生成式學習.html.svg"/></a>
<div id="outline-container-orgb145d05" class="outline-2">
<h2 id="orgb145d05"><span class="section-number-2">1.</span> 生成式學習</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org9a23f05" class="outline-3">
<h3 id="org9a23f05"><span class="section-number-3">1.1.</span> 生成是一件複雜的事</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>以256種顏色隨機生成一張長寛均為16像素（pixel）的小圖，這張隨機生成的圖將有(16×16)^256=256^256種可能性，大約是10^1229種 。<br /></li>
<li>以1000個基礎英文單字隨機生成一篇100字的英文作文，這篇作文的可能結果將來到100^1000=10^2000種。<br /></li>
<li>可觀測宇宙中有10^24顆恒星<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup><br /></li>
<li>宇宙中原子總數：10^82<sup><a id="fnr.1.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org68b7b70" class="outline-3">
<h3 id="org68b7b70"><span class="section-number-3">1.2.</span> 生成式AI的發展與演進</h3>
<div class="outline-text-3" id="text-1-2">
<ol class="org-ol">
<li>早期的文字生成與對話模<br />
1966 年，麻省理工學院的約瑟夫·韋森鮑姆（Joseph Weizenbaum）開發了一個有趣的程式： ELIZA （如圖 ‎1.2 1），該程式試圖扮演一個心理治療師的角色來與人類交談。雖然ELIZA的回應僅基於一套簡單的模式匹配規則，並無法真正理解語意，但它成功地開啟了人類與機器對話的可能性，也為後來的生成式AI模型奠定了基礎。<br />
<ul class="org-ul">
<li><a href="https://letranger.github.io/AI/eliza.html">ELIZA</a><br /></li>
<li><a href="https://github.com/letranger/GAI-Textbook/blob/main/eliza.html">ELIZA原始碼</a><br /></li>
</ul></li>
<li>從規則系統到統計方法<br />
<ul class="org-ul">
<li>規則式翻譯：以條件判斷來處理自然語言翻譯，容易出現如下結果：Can you feel my world?  / 罐頭您了解我的世界嗎？<br /></li>
<li><p>
統計式翻譯：IBM於1990 年代提出了基於統計式機器翻譯（Statistical Machine Translation, SMT），這種方法使用雙語對照資料庫 來學習來源語言和目標語言之間的對應關係，利用機率的計算進行翻譯選擇。例如資料庫中有以下的語言對應關係：<br />
</p>
<ul class="org-ul">
<li>「I want a coffee」對應「我想要一杯咖啡」<br /></li>
<li>「Can I get a sandwich」對應「我可以點個三明治嗎」<br /></li>
</ul>
<p>
電腦會從這些雙語句子中找出「I」通常對應「我」，「want」對應「想要」…「sandwich」對應「三明治」這些對應關係。<br />
</p></li>
</ul></li>
<li>機器學習的興起<br />
<ul class="org-ul">
<li>語言是有順序關係的，每一個詞的意思通常會受到前後詞語的影響。因此，處理語言、語音這類有時序關係的資料時，我們需要一種能夠記住先前資訊的模型來協助理解整體上下文。<br /></li>
<li>循環神經網路（Recurrent Neural Network, RNN）的出現解決了這一問題，不同於CNN只專注處理當前的資料（例如擷取某張影像的特徵），RNN能夠將先前輸入的資料一併傳遞到當前的分析步驟中，使模型能「記住」先前的輸入，因此更適合處理文章、語音等時間序列資料。<br /></li>
<li><p>
RNN<br />
</p>

<div id="orgf660cde" class="figure">
<p><img src="file:///Users/letranger/Dropbox/Working/[202410]南大生成式AI教材/rnn-animate.gif" alt="rnn-animate.gif" width="500" /><br />
</p>
</div>


<div id="org89b7e47" class="figure">
<p><img src="images/CNN-RNN-3.png" alt="CNN-RNN-3.png" width="500px" /><br />
</p>
</div></li>
<li>RNN 也存在一定的限制，在處理較長的句子或序列時，RNN 容易出現「長期依賴問題」，即模型會逐漸「遺忘」先前的資訊，導致上下文理解不完整。這使得 RNN 難以處理長篇的文本或長時間的語音。<br /></li>
<li>為了解決 RNN 的長期依賴問題，長短期記憶網路（Long Short-Term Memory, LSTM） 應運而生<br /></li>
</ul></li>
<li>從文字生成到影像生成<br />
<ul class="org-ul">
<li>由 Ian Goodfellow 及其團隊於 2014 年提出的生成對抗網路（Generative Adversarial Networks,   ） 是生成式AI領域的另一個重要里程碑，生成對抗網路一問世便在影像生成領域引發了廣泛的關注，成為生成式AI的核心技術之一。<br /></li>
<li><p>
GAN<br />
</p>

<div id="org16b2b7a" class="figure">
<p><img src="images/圖4.3 1.png" alt="圖4.3 1.png" width="500px" /><br />
</p>
</div></li>
<li><a href="https://thispersondoesnotexist.com/">thispersondoesnotexist</a><br /></li>
</ul></li>
<li>從影像生成到影像理解<br />
<ul class="org-ul">
<li>014年，Google開發了一個名為Show and Tell（如圖 ‎1.2 5）的影像理解模型，這是一個能夠為照片生成簡單文字描述（Image Captioning）的系統， Show and Tell展示了人工智慧「看懂」一張照片的能力，<br /></li>
<li><p>
Show and Tell<br />
</p>

<div id="org76ebaa9" class="figure">
<p><img src="images/圖1.2-5.png" alt="圖1.2-5.png" width="500px" /><br />
</p>
</div></li>
</ul></li>
<li><p>
Transformer 架構的突破<br />
Transformer 的自注意力機制具備了下列兩項優勢：<br />
</p>
<ol class="org-ol">
<li>全局關聯：自注意力機制讓模型在處理句子中的每個詞時，可以同時參考其他所有詞語的資訊，這樣即使上文文章開頭的「賈伯斯」、「離開蘋果」與文末的「他」、「回到蘋果」之間距離較遠，自注意力機制仍能輕鬆找到這種關聯，從而理解「他」指的就是「賈伯斯」，也能對賈伯斯的整個行動脈絡有所掌握，知道他曾離開，後來又回到蘋果。如果使用RNN 或 LSTM，在處理到文末的「他再次回到蘋果」時，文章開頭的「賈伯斯」與「離開蘋果」可能已被模型遺忘。<br /></li>
<li>平行處理：自注意力機制允許 Transformer 同時處理句子中的所有詞語，這比 RNN 和 LSTM 的逐句循序處理要快很多，每個詞都能同時接收來自其他詞的資訊，大幅提高了處理效率。<br /></li>
</ol>
<p>
How a transformer models work:<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup><br />
</p>

<div id="org5b06d30" class="figure">
<p><img src="images/transformer-models.png" alt="transformer-models.png" width="500px" /><br />
</p>
</div></li>
<li>大語言模型與多模態生成時代<br />
<ul class="org-ul">
<li>2019年2月，OpenAI發布了第二代的語言模型產品GPT-2，該模型具有15億個參數<br /></li>
<li>2020年推出具有1750億個參數的GPT-3 ，至此，生成式AI正式進入了大語言模型（Large Language Model, LLM）時代<br /></li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-orga331b55" class="outline-3">
<h3 id="orga331b55"><span class="section-number-3">1.3.</span> 生成式AI的類型與應用</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-orga8ee37a" class="outline-4">
<h4 id="orga8ee37a"><span class="section-number-4">1.3.1.</span> 類型</h4>
<div class="outline-text-4" id="text-1-3-1">
<ol class="org-ol">
<li>文字生成<br />
<ul class="org-ul">
<li><a href="https://chatgpt.com/">ChatGPT</a><br /></li>
<li><a href="https://claude.ai/">Claude</a><br /></li>
<li><a href="https://copilot.microsoft.com/chats/oacf53dNrrczskuUqA2Xp">Microsoft Copilot</a><br /></li>
<li><a href="https://gemini.google.com/app?hl=zh-TW">Google Gemini</a><br /></li>
<li><a href="https://huggingface.co/chat/">HuggingChat</a><br /></li>
</ul></li>
<li>影像生成<br />
<ul class="org-ul">
<li><a href="https://firefly.adobe.com/">Adobe Firefly</a><br /></li>
<li><a href="https://www.midjourney.com">Midjourney</a><br /></li>
<li><a href="https://stablediffusionweb.com">Stable Diffusion</a><br /></li>
</ul></li>
<li>程式生成<br />
<ul class="org-ul">
<li>GitHub Copilot<br /></li>
<li>Colab + Gemini<br /></li>
</ul></li>
<li>其他模態生成<br />
<ul class="org-ul">
<li><a href="https://suno.com">Suno AI</a><br /></li>
<li><a href="https://www.hedra.com/">Hedra AI</a><br /></li>
<li><a href="https://runwayml.com/">Runway</a><br /></li>
<li><a href="https://gamma.app/">Gamma</a><br /></li>
<li><a href="https://mapify.so/">Mapify</a><br /></li>
<li><a href="https://www.napkin.ai/">Napkin</a><br /></li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org4271146" class="outline-4">
<h4 id="org4271146"><span class="section-number-4">1.3.2.</span> 應用</h4>
<div class="outline-text-4" id="text-1-3-2">
<ol class="org-ol">
<li>教育: 自主學習、筆記、語言學習、教師備課、評量<br /></li>
<li>媒體/內容生成<br /></li>
<li>商業：貼文、廣告、客服<br /></li>
</ol>
</div>
</div>
</div>
</div>
<div id="outline-container-orgc76ce46" class="outline-2">
<h2 id="orgc76ce46"><span class="section-number-2">2.</span> 生成式AI相關理論</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orgfc14bea" class="outline-3">
<h3 id="orgfc14bea"><span class="section-number-3">2.1.</span> AI 的本質：函數</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>人工智慧本質上就是在找出一個特定函數。<br />
<ul class="org-ul">
<li><p>
成績預測<br />
</p>

<div id="orga2b9a38" class="figure">
<p><img src="images/2025-02-14_14-21-45.png" alt="2025-02-14_14-21-45.png" width="400" /><br />
</p>
</div>
<ul class="org-ul">
<li>期末成績= 0.4 × 期中考成績 + 0.6 × 期末考成績<br /></li>
</ul></li>
<li><p>
影像辨識<br />
</p>

<div id="orgd8bc248" class="figure">
<p><img src="images/screenshot.png" alt="screenshot.png" width="300" /><br />
</p>
</div></li>
<li><p>
語音辨識<br />
</p>

<div id="org5333f9a" class="figure">
<p><img src="./images/screenshot-20250214-143244.png" alt="screenshot-20250214-143244.png" width="300" /><br />
</p>
</div></li>
<li><p>
五子椣<br />
</p>

<div id="orgf30e93c" class="figure">
<p><img src="./images/screenshot-20250214-153704.png" alt="screenshot-20250214-153704.png" width="500" /><br />
</p>
</div></li>
<li><p>
文字生成<br />
</p>

<div id="org8a7077e" class="figure">
<p><img src="./images/screenshot-20250214-153755.png" alt="screenshot-20250214-153755.png" width="500" /><br />
</p>
</div></li>
<li><p>
影像生成<br />
</p>

<div id="org4de1ebd" class="figure">
<p><img src="./images/screenshot-20250214-153835.png" alt="screenshot-20250214-153835.png" width="500" /><br />
</p>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orge0bb13e" class="outline-3">
<h3 id="orge0bb13e"><span class="section-number-3">2.2.</span> 模型訓練</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-orgc3f98a5" class="outline-4">
<h4 id="orgc3f98a5"><span class="section-number-4">2.2.1.</span> 以函數參數尋找最佳模型</h4>
<div class="outline-text-4" id="text-2-2-1">

<div id="orgd9091c0" class="figure">
<p><img src="./images/screenshot-20250214-154827.png" alt="screenshot-20250214-154827.png" width="500" /><br />
</p>
</div>
<ol class="org-ol">
<li><p>
蒐集歷屆學長姐的成績資料（包括兩次段考平均成績與學期總成績），這些資料稱之為訓練資料（training data）<br />
</p>

<div id="org137dd6f" class="figure">
<p><img src="./images/screenshot-20250214-155002.png" alt="screenshot-20250214-155002.png" width="500" /><br />
</p>
</div></li>
<li><p>
將訓練資料視覺化, 初步猜測二者可能存在線性關係<br />
</p>

<div id="org27d5159" class="figure">
<p><img src="./images/screenshot-20250214-155110.png" alt="screenshot-20250214-155110.png" width="500" /><br />
</p>
</div></li>
<li>接下來的任務就是畫出一條能儘量接近圖上所有資料點的線，也就是找出最佳的參數 a（即這條迴歸線的斜率）<br /></li>
<li></li>
</ol>
</div>
</div>
<div id="outline-container-org270b817" class="outline-4">
<h4 id="org270b817"><span class="section-number-4">2.2.2.</span> 利用梯度下降法與損失函數（如 MSE）來優化模型</h4>
</div>
<div id="outline-container-org77c9826" class="outline-4">
<h4 id="org77c9826"><span class="section-number-4">2.2.3.</span> 神經網路的概念與其參數調整方式</h4>
</div>
</div>
<div id="outline-container-org8b69a0c" class="outline-3">
<h3 id="org8b69a0c"><span class="section-number-3">2.3.</span> 探討活動 1</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>Python 任務<br />
<ol class="org-ol">
<li>比較不同類型的種損失函數、繪製損失函數曲線<br /></li>
<li>設計一個函數來量化模型的準確性<br /></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org20d713f" class="outline-3">
<h3 id="org20d713f"><span class="section-number-3">2.4.</span> 生成式 AI： 一種會接龍的函數</h3>
<div class="outline-text-3" id="text-2-4">
<ul class="org-ul">
<li>簡介文字生成的接龍機制<br /></li>
<li>Token 概念 與不同 GPT 版本的 token 處理方式<br /></li>
<li>自迴歸模型 (AR) 與非自迴歸模型 (NAR) 比較<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgc6c32d0" class="outline-3">
<h3 id="orgc6c32d0"><span class="section-number-3">2.5.</span> 探討活動 2</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li>測試不同的中英文輸入，分析 Token 的劃分方式<br /></li>
<li>比較 GPT-3 和 GPT-4 的 Token 分割方式<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org1df9574" class="outline-3">
<h3 id="org1df9574"><span class="section-number-3">2.6.</span> 文字、圖形與向量：先理解才能生成</h3>
<div class="outline-text-3" id="text-2-6">
<ul class="org-ul">
<li>AI模型如何理解影像資料<br /></li>
<li>AI模型如何理解文字資料<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org769778f" class="outline-3">
<h3 id="org769778f"><span class="section-number-3">2.7.</span> 探討活動 3</h3>
<div class="outline-text-3" id="text-2-7">
<ul class="org-ul">
<li>以 Python 撰寫卷積核程式，分析影像特徵擷取<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org428cd7b" class="outline-3">
<h3 id="org428cd7b"><span class="section-number-3">2.8.</span> 探討活動 4</h3>
<div class="outline-text-3" id="text-2-8">
<ul class="org-ul">
<li>文字轉換向量的實作與探究<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgc3402f1" class="outline-3">
<h3 id="orgc3402f1"><span class="section-number-3">2.9.</span> 2.5 編碼與解碼：邁向生成的一小步</h3>
<div class="outline-text-3" id="text-2-9">
<ul class="org-ul">
<li>簡介自動編碼器運作原理<br /></li>
<li>簡介自動編碼器的應用<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org6db2341" class="outline-3">
<h3 id="org6db2341"><span class="section-number-3">2.10.</span> 探討活動 5</h3>
<div class="outline-text-3" id="text-2-10">
<ul class="org-ul">
<li>體驗 VAE（變分自動編碼器）的影像漸變<br /></li>
<li>設計並測試不同數字間的影像漸變<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd73b039" class="outline-2">
<h2 id="orgd73b039"><span class="section-number-2">3.</span> 自然語言生成</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org544940b" class="outline-3">
<h3 id="org544940b"><span class="section-number-3">3.1.</span> 見樹也見林：從單詞到全句</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>探討 NLP 如何理解句子與文件<br /></li>
<li>簡介BoW、TF-IDF、N-Gram<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org18ecde8" class="outline-3">
<h3 id="org18ecde8"><span class="section-number-3">3.2.</span> 探討活動 1</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>以實作體驗BoW、TF-IDF的運作並分析結果<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org63c7777" class="outline-3">
<h3 id="org63c7777"><span class="section-number-3">3.3.</span> RNN/LSTM：時間序列資料的解決方案</h3>
<div class="outline-text-3" id="text-3-3">
<ul class="org-ul">
<li>簡介RNN，LSTM、GRU運作原理<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org3d407a9" class="outline-3">
<h3 id="org3d407a9"><span class="section-number-3">3.4.</span> 探討活動 2</h3>
<div class="outline-text-3" id="text-3-4">
<ol class="org-ol">
<li>比較 RNN、LSTM、GRU 的結構與應用<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org0a1d3ec" class="outline-3">
<h3 id="org0a1d3ec"><span class="section-number-3">3.5.</span> 注意力機制與 Transformer</h3>
<div class="outline-text-3" id="text-3-5">
<ul class="org-ul">
<li>簡Seq2Seq 模型<br /></li>
<li>簡介Transformer及自注意力機制<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org63671f1" class="outline-3">
<h3 id="org63671f1"><span class="section-number-3">3.6.</span> 探討活動 3</h3>
<div class="outline-text-3" id="text-3-6">
<ol class="org-ol">
<li>實作以 Transformer 進行文字翻譯<br /></li>
<li>觀察並解釋程式生成之注意力矩陣<br /></li>
</ol>
</div>
</div>
<div id="outline-container-orge0a2201" class="outline-3">
<h3 id="orge0a2201"><span class="section-number-3">3.7.</span> 從 LM 到 LLM</h3>
<div class="outline-text-3" id="text-3-7">
<ul class="org-ul">
<li>簡介LM與LLM<br /></li>
<li>介紹幾種常見的LLM<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orga99ff16" class="outline-3">
<h3 id="orga99ff16"><span class="section-number-3">3.8.</span> 探討活動 4</h3>
<div class="outline-text-3" id="text-3-8">
<ol class="org-ol">
<li>搜尋並介紹一款 LLM<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org12015a3" class="outline-3">
<h3 id="org12015a3"><span class="section-number-3">3.9.</span> 語言模型的訓練與微調</h3>
<div class="outline-text-3" id="text-3-9">
<ol class="org-ol">
<li>介紹語言模型的建置、訓練與微調<br /></li>
</ol>
</div>
</div>
<div id="outline-container-orgc9682f4" class="outline-3">
<h3 id="orgc9682f4"><span class="section-number-3">3.10.</span> 探討活動 5</h3>
<div class="outline-text-3" id="text-3-10">
<ol class="org-ol">
<li>訓練一個簡單的語言模型<br /></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgbd1baf9" class="outline-2">
<h2 id="orgbd1baf9"><span class="section-number-2">4.</span> 影像與多模態生成</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orgb0e565f" class="outline-3">
<h3 id="orgb0e565f"><span class="section-number-3">4.1.</span> 影像與多模態生成概述</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>簡介 AI 在影像與影片生成的發展<br /></li>
<li>介紹不同類型的多模態生成<br />
<ol class="org-ol">
<li>文字生成影像、文字生成影片（Text-to-Image / Text-to-Video）<br /></li>
<li>影像生成文字、影片生成文字（Image-to-Text / Video-to-Text）<br /></li>
<li>影像生成影像、影片生成影片（Image-to-Image / Video-to-Video）<br /></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-orga946a68" class="outline-3">
<h3 id="orga946a68"><span class="section-number-3">4.2.</span> 探討活動 1</h3>
<div class="outline-text-3" id="text-4-2">
<ol class="org-ol">
<li>選擇兩種多模態生成技術<br /></li>
<li>比較不同工具的生成品質與操作便利性<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org7030179" class="outline-3">
<h3 id="org7030179"><span class="section-number-3">4.3.</span> VAE：生成模型的開端</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>變分自動編碼器（VAE）的概念與原理<br /></li>
<li>應用VAE進行風格轉換與圖片漸變<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orga6129bf" class="outline-3">
<h3 id="orga6129bf"><span class="section-number-3">4.4.</span> 探討活動 2</h3>
<div class="outline-text-3" id="text-4-4">
<ol class="org-ol">
<li>使用 VAE 進行圖片風格轉換<br /></li>
<li>測試不同的 <b><b>潛在向量（Latent Code）</b></b> 設定，分析結果<br /></li>
</ol>
</div>
</div>
<div id="outline-container-orgab3f0af" class="outline-3">
<h3 id="orgab3f0af"><span class="section-number-3">4.5.</span> GAN：在對抗中學習</h3>
<div class="outline-text-3" id="text-4-5">
<ul class="org-ul">
<li>介紹 <b><b>生成對抗網路（GAN）</b></b> 的概念<br /></li>
<li>GAN 在 <b><b>圖片生成、風格轉換、Deepfake</b></b> 等領域的應用<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgab33f72" class="outline-3">
<h3 id="orgab33f72"><span class="section-number-3">4.6.</span> 探討活動 3</h3>
<div class="outline-text-3" id="text-4-6">
<ol class="org-ol">
<li>訓練一個簡單的 GAN 來生成手寫數字<br /></li>
<li>體驗 GAN 風格轉換，將照片轉換為卡通風格<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org7e551bf" class="outline-3">
<h3 id="org7e551bf"><span class="section-number-3">4.7.</span> Diffusion Models：擴散模型的崛起</h3>
<div class="outline-text-3" id="text-4-7">
<ul class="org-ul">
<li>介紹擴散模型（Diffusion Models）的原理<br /></li>
<li>介紹幾種代表性的擴散模型應用<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgd298167" class="outline-3">
<h3 id="orgd298167"><span class="section-number-3">4.8.</span> 探討活動 4</h3>
<div class="outline-text-3" id="text-4-8">
<ol class="org-ol">
<li>嘗試不同的提示詞（Prompt），比較生成結果<br /></li>
<li>利用Gradio 或 Streamlit實作一個簡單的文生圖介面<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org00ac74a" class="outline-3">
<h3 id="org00ac74a"><span class="section-number-3">4.9.</span> 從單模態到多模態生成</h3>
<div class="outline-text-3" id="text-4-9">
<ul class="org-ul">
<li>簡介多模態生成（Multimodal Generation）的概念<br /></li>
<li>介紹 CLIP、Sora、ViT（Vision Transformer） 的應用<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org6e0436a" class="outline-3">
<h3 id="org6e0436a"><span class="section-number-3">4.10.</span> 探討活動 5</h3>
<div class="outline-text-3" id="text-4-10">
<ol class="org-ol">
<li>使用 CLIP 進行圖文匹配<br /></li>
<li>嘗試以 Sora 生成短影片<br /></li>
<li>討論多模態 AI 的應用與未來發展<br /></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org2d991aa" class="outline-2">
<h2 id="org2d991aa"><span class="section-number-2">5.</span> 生成式 AI 的相關議題</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgff88838" class="outline-3">
<h3 id="orgff88838"><span class="section-number-3">5.1.</span> 法律議題</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>探討生成式 AI 在法律層面的影響<br /></li>
<li>探討生成式AI主要法律爭議<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org16bd082" class="outline-3">
<h3 id="org16bd082"><span class="section-number-3">5.2.</span> 探討活動 1</h3>
<div class="outline-text-3" id="text-5-2">
<ol class="org-ol">
<li>討論兩起生成式 AI 相關的判決案例<br /></li>
<li>分析 AI 生成內容的法律地位與影響<br /></li>
</ol>
</div>
</div>
<div id="outline-container-orgfcb7906" class="outline-3">
<h3 id="orgfcb7906"><span class="section-number-3">5.3.</span> 倫理議題</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>討論生成式 AI 可能引發的倫理問題：<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org164f19d" class="outline-3">
<h3 id="org164f19d"><span class="section-number-3">5.4.</span> 探討活動 2</h3>
<div class="outline-text-3" id="text-5-4">
<ol class="org-ol">
<li>測試不同 AI 聊天機器人的倫理邊界<br /></li>
<li>討論如何設計更符合倫理規範的 AI<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org3f7ce31" class="outline-3">
<h3 id="org3f7ce31"><span class="section-number-3">5.5.</span> 教育議題</h3>
<div class="outline-text-3" id="text-5-5">
<ul class="org-ul">
<li>探討生成式 AI 對學校教育的影響<br /></li>
<li>討論 AI 在學習輔助與評量中的角色<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org3881e5e" class="outline-3">
<h3 id="org3881e5e"><span class="section-number-3">5.6.</span> 探討活動 3</h3>
<div class="outline-text-3" id="text-5-6">
<ol class="org-ol">
<li>一組使用 AI 撰寫報告，另一組傳統方式撰寫<br /></li>
<li>實驗比較「有/無以AI輔助學習」在學習內容完整性與學習體驗上的差異<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org1a453d2" class="outline-3">
<h3 id="org1a453d2"><span class="section-number-3">5.7.</span> 其他議題</h3>
<div class="outline-text-3" id="text-5-7">
<ul class="org-ul">
<li>環保議題：生成式 AI 的電力與水資源消耗<br /></li>
<li>壟斷與反壟斷：科技巨頭如何主導 AI 發展<br /></li>
<li>就業市場影響：AI 取代與創造的新職業<br /></li>
<li>國防與安全風險：AI 在戰爭與資訊戰中的應用<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org8555c23" class="outline-3">
<h3 id="org8555c23"><span class="section-number-3">5.8.</span> 探討活動 4</h3>
<div class="outline-text-3" id="text-5-8">
<ol class="org-ol">
<li>計算、分析個人 AI 使用的電力消耗<br /></li>
<li>討論 AI 節能技術與環保策略<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org088ee53" class="outline-3">
<h3 id="org088ee53"><span class="section-number-3">5.9.</span> 探討活動 5</h3>
<div class="outline-text-3" id="text-5-9">
<ol class="org-ol">
<li>列舉 AI 可能取代的職業、可能創造的新職業<br /></li>
<li>制定 AI 時代的職業發展策略<br /></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orga7e5065" class="outline-2">
<h2 id="orga7e5065"><span class="section-number-2">6.</span> Resource</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li><a href="https://www.techbang.com/posts/114202-8-google-employees-invented-modern-artificial-intelligence">8 名Google員工發明了現代人工智慧，這是那篇論文的內幕故事</a><br /></li>
</ul>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/zh-tw/%E5%AE%87%E5%AE%99">維基百科:宇宙</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://datasciencedojo.com/blog/transformer-models/">Transformer models: the future of natural language processing</a><br />
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2025-02-14 Fri 15:54</p>
</div>
</body>
</html>
