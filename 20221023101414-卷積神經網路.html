<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-05-03 Fri 09:22 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>卷積神經網路</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">卷積神經網路</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgdf9afb7">1. CNN 卷積神經網路</a>
<ul>
<li><a href="#org563a644">1.1. CNN v.s. MLP</a></li>
<li><a href="#orgf53c688">1.2. 卷積運算</a></li>
<li><a href="#orgefcc246">1.3. 池化層(Pooling Layer)</a></li>
</ul>
</li>
<li><a href="#org1ab9f24">2. 神經網路解題步驟</a>
<ul>
<li><a href="#orgaee7e8d">2.1. 收集資料</a></li>
<li><a href="#org1bb86d3">2.2. 準備數據</a></li>
<li><a href="#org1e1082e">2.3. 選擇模型</a></li>
<li><a href="#org1751695">2.4. 訓練機器</a></li>
<li><a href="#orgd88acc4">2.5. 評估分析</a></li>
<li><a href="#orgba30f6b">2.6. 調整參數</a></li>
<li><a href="#orgca3b249">2.7. 預測推論</a></li>
</ul>
</li>
<li><a href="#org7af808c">3. 實作1</a></li>
<li><a href="#Hi-MNIST">4. 實作2: MNIST</a>
<ul>
<li><a href="#org6500c8b">4.1. MNIST資料集</a></li>
<li><a href="#org4cc6218">4.2. 準備 MNIST 資料</a></li>
<li><a href="#org36327df">4.3. 建立CNN模型</a></li>
<li><a href="#orgb7618ad">4.4. 訓練CNN模型</a></li>
<li><a href="#orgfb2c7e2">4.5. 評估CNN模型</a></li>
<li><a href="#org2a681a6">4.6. 預測結果</a></li>
<li><a href="#org4efdaac">4.7. Crosstab</a></li>
</ul>
</li>
<li><a href="#orgfbb3a34">5. 實作3: Regression</a>
<ul>
<li><a href="#orge6da0e5">5.1. 產生數據</a></li>
<li><a href="#orge62a43d">5.2. scikit learn的線性迴歸模組</a></li>
<li><a href="#org33fb14f">5.3. 建立model來畫迴歸線</a></li>
<li><a href="#org3302773">5.4. 訓練model</a></li>
<li><a href="#orgc948c09">5.5. 查看訓練過程</a></li>
<li><a href="#orgbcf783d">5.6. 評估model</a></li>
<li><a href="#orgc926fa6">5.7. 預測結果</a></li>
<li><a href="#org9878384">5.8. 調整model/參數</a></li>
</ul>
</li>
<li><a href="#org2adb815">6. 實作4[回家踹]: Cifar-10</a>
<ul>
<li><a href="#orgd22d9b0">6.1. 資料集下載/預處理</a></li>
<li><a href="#orgdfab358">6.2. 建模</a></li>
<li><a href="#org28fe402">6.3. 訓練、評估</a></li>
<li><a href="#orge5feb75">6.4. 查看結果</a></li>
<li><a href="#org8c83a69">6.5. 儲存模型</a></li>
</ul>
</li>
<li><a href="#org6d6e6e2">7. [課堂練習][作業]&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></a>
<ul>
<li><a href="#orgaec65dc">7.1. [課堂練習]Regression&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></a></li>
<li><a href="#HomeWork-2">7.2. [作業]病例預測&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></a></li>
<li><a href="#org4846abf">7.3. [作業]照片分類&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></a></li>
</ul>
</li>
<li><a href="#org28d8281">8. 實作4: 真實世界圖片辨識</a>
<ul>
<li><a href="#org24c815d">8.1. 深度學習與少量資料的相關性</a></li>
<li><a href="#orgdcbe932">8.2. 實作</a></li>
<li><a href="#org9d4e4c4">8.3. 改善#1: 資料擴增</a></li>
<li><a href="#orgb8c22b0">8.4. 改善 2: Pretrained network</a></li>
</ul>
</li>
<li><a href="#orgd8c4110">9. 視覺化呈現 CNN 的學習內容</a>
<ul>
<li><a href="#org6064357">9.1. 中間層輸出視覺化</a></li>
<li><a href="#orgc47b435">9.2. 查看新圖</a></li>
<li><a href="#orgfecd2cd">9.3. 第一層卷積層效果</a></li>
<li><a href="#org8af9aee">9.4. 各層的輸出結果</a></li>
</ul>
</li>
</ul>
</div>
</div>
<a href="https://letranger.github.io/AI/20221023101414-卷積神經網路.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023101414-卷積神經網路.html.svg"/></a>
<div id="outline-container-orgdf9afb7" class="outline-2">
<h2 id="orgdf9afb7"><span class="section-number-2">1.</span> CNN 卷積神經網路</h2>
<div class="outline-text-2" id="text-1">
<p>
卷積神經網路(CNN)由Yann LeCun(法國電腦科學家，2018年圖靈獎得主)所提出，此人在機器學習、計算機視覺、計算機神經科學等領域都有很多貢獻。<br />
</p>


<div id="orgc816aba" class="figure">
<p><img src="images/AI的發展沿革/2024-01-29_14-26-12_2024-01-29_14-21-23.png" alt="2024-01-29_14-26-12_2024-01-29_14-21-23.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 1: </span>Yann LeCun</p>
</div>

<p>
CNN的想法源自於對人類大腦認知方式的模仿，當我們辨識一個圖像，會先注意到顏色鮮明的點、線、面，之後將它們構成一個個不同的形狀(眼睛、鼻子、嘴巴 &#x2026;)，這種抽象化的過程就是 CNN 演算法建立模型的方式。卷積層(Convolution Layer) 就是由點的比對轉成局部的比對，透過一塊塊的特徵研判，逐步堆疊綜合比對結果，就可以得到比較好的辨識結果，過程如下圖<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>。<br />
</p>


<div id="orgce7f2c0" class="figure">
<p><img src="images/CNN-1.png" alt="CNN-1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 2: </span>CNN 概念</p>
</div>

<p>
那麼，CNN與之前我們介紹的神經網路(DNN)有什麼差異呢？<br />
</p>
</div>
<div id="outline-container-org563a644" class="outline-3">
<h3 id="org563a644"><span class="section-number-3">1.1.</span> CNN v.s. MLP</h3>
<div class="outline-text-3" id="text-1-1">
<p>
CNN 與<a href="20221025104603-神經網路.html#ID-d6daa102-05bb-475d-b619-db8b61e86030">神經網路</a>所提及之DNN(或是MLP, Multilayer Perceptron, 多層感知器) 的主要差異可由下圖看出，即，CNN 在輪入層中多了卷積層與池化層，而DNN中的每一層都是Dense Layer，也就是Fully Connected Layer。<br />
</p>

<div id="org82cbfc1" class="figure">
<p><img src="images/cnnmlp.png" alt="cnnmlp.png" width="400" /><br />
</p>
<p><span class="figure-number">Figure 3: </span>CNN 與 DNNA 之差異</p>
</div>

<p>
更進一步來看MPL與CNN的架構差異，我們同樣以圖形識別為例，在讀入一張圖片後，MLP的做法如下：<br />
</p>


<div id="orge449767" class="figure">
<p><img src="images/CNN_卷積神經網路/2024-04-17_09-06-44_2024-04-17_09-03-45.png" alt="2024-04-17_09-06-44_2024-04-17_09-03-45.png" width="400" /><br />
</p>
<p><span class="figure-number">Figure 4: </span>DNN原理</p>
</div>

<p>
就是將2維圖片矩陣「攤平」為1維矩陣(也就會損失了圖片的空間特徵)，然後每個矩陣的值搭配一個權重往下一層傳送進行運算，可以想像，如果第二層有100個神經元，就代表會有100*(36+1)個參數，其中+1為bias。而CNN的做法則如下圖:<br />
</p>


<div id="orgacaa28f" class="figure">
<p><img src="images/CNN_卷積神經網路/2024-04-17_09-18-53_2024-04-17_09-11-28.png" alt="2024-04-17_09-18-53_2024-04-17_09-11-28.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 5: </span>CNN原理</p>
</div>

<p>
而CNN則是透過卷積核(kernel, 即圖<a href="#orgacaa28f">5</a>中的filter)對整張圖做卷積，部份的保留了圖片的空間特徵，同時也減少了參數數量。<br />
</p>

<p>
由此看來，較之CNN，DNN有兩個缺點<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup><sup>, </sup><sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>：<br />
</p>
<ol class="org-ol">
<li>需要大量記憶體:<br />
在處理 256x256 大小的彩色圖片時，會需要用到 256 * 256 * 3 =196,608 個 Input Neuron，如果中間的隱藏層有 1000 個 Neuron，每個神經元需要一個浮點數的權重值 (8 bytes)，那麼總共需要 196,608 * 1001 * 8 = 1.47 GB 的記憶體才夠。更何況這還只是個簡單的模型。<br /></li>
<li>多層感知器只針對圖片中每個單一像素去作判斷，完全捨棄重要的影像特徵。人類在判斷所看到的物體時，會從不同部位的特徵先作個別判斷，例如當你看到一架飛機，會先從機翼、機鼻、機艙體等這些特徵，再跟記憶中的印象來判斷是否為一架飛機，甚至再進一步判斷為客機還是戰鬥機。但是多層感知器沒有利用這些特徵，所以在影像的判讀上準確率就沒有接下來要討論的 CNN 來得好。<br /></li>
</ol>


<div id="org21cefaa" class="figure">
<p><img src="images/CNN_卷積神經網路/2024-02-26_12-34-58_1*4_BDTvgB6WoYVXyxO8lDGA.png" alt="2024-02-26_12-34-58_1*4_BDTvgB6WoYVXyxO8lDGA.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 6: </span>DNN神經網路架構</p>
</div>


<div id="org98890da" class="figure">
<p><img src="images/CNN-arch-1.jpg" alt="CNN-arch-1.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 7: </span>CNN架構</p>
</div>

<p>
與 DNN 相比，CNN多了卷積層與池化層，卷積層用來強調圖案(資料)特徵，池化層則可以縮減取樣，減少 overfitting 問題。二者的比較如下圖<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup>所示：<br />
</p>


<div id="org294a039" class="figure">
<p><img src="images/CNN_卷積神經網路/2024-04-17_09-54-39_2024-04-17_09-54-28.png" alt="2024-04-17_09-54-39_2024-04-17_09-54-28.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 8: </span>DNN v.s. CNN</p>
</div>
</div>
</div>
<div id="outline-container-orgf53c688" class="outline-3">
<h3 id="orgf53c688"><span class="section-number-3">1.2.</span> 卷積運算</h3>
<div class="outline-text-3" id="text-1-2">
<p>
想具體的了解卷積核的功能，可以先到<a href="https://setosa.io/ev/image-kernels/">這裡</a>來體驗一下。<br />
</p>

<p>
在<a href="20221025104603-神經網路.html#ID-d6daa102-05bb-475d-b619-db8b61e86030">神經網路</a>中，我們曾經提出如下的卷積運算例子：<br />
</p>
<blockquote>
<p>
經由如下的矩陣計算，我們可以初步擬定一條分類規則：若是運算所得值大於0，則此圖像為＼；若是運算所得值小於0，則判定為／。<br />
</p>

<div id="orgc450d94" class="figure">
<p><img src="images/How_machine_recognize_image/2024-02-17_09-56-41_2024-02-17_09-56-25.png" alt="2024-02-17_09-56-41_2024-02-17_09-56-25.png" width="500" /><br />
</p>
</div>

<p>
在上述範例中：<br />
</p>
<ul class="org-ul">
<li>矩陣K對矩陣A、B所進行的運算即為卷積(convolution)，矩陣K在<a href="20221023101414-卷積神經網路.html#ID-20221023T101414.457264">卷積神經網路</a>中稱之為卷積核(convolution kernel)，其作用即在於萃取出資料特徵。藉此，我們達成了利用數學運算來擷取圖像特徵，也可以理解到為何深度學習能夠過濾資料雜訊而完成圖像識別。<br /></li>
<li>計算得到結果後，我們私自擬定一條分類規則：若是運算所得值大於0，則此圖像為＼；若是運算所得值小於0，則判定為／。在神經網路中，這就是<a href="20240215153606-activationfunction.html#ID-d3bcc30a-3d94-4a3c-8e66-baaac7325c75">激勵函數</a>(<a href="20240215153606-activationfunction.html#ID-d3bcc30a-3d94-4a3c-8e66-baaac7325c75">Activation Function</a>)。<br /></li>
</ul>
</blockquote>

<p>
以全連接層來處理神經網路的問題在於：全連接層會忽略資料的「形狀」。例如，假設輸入資料為影像，則通常會包含水平、垂直、色版方向的三維形狀，然而當這些資料輸入全連接層時，三維資料就必須變為平面（一維資料），如前述的 MNist 資料集，輸入為(1, 28, 28)，即，一種顏色、28*28 像素，輸入全連接層後會變成一行的 784 個資料。<br />
</p>

<p>
三維形狀的影像包含了許多重要的空間資料，例如，類似的空間有著相似的象素值、RGB 各色版間有緊密連接的關連性，距離較遠的像素彼此沒有關連&#x2026;等特質，這些特質會在全連接層中被忽略掉。卷積層（Convolution layer）則能維持這些形狀，我們把 CNN 的卷積層輸出入資料稱作特徵圖（input / output feature map），而在卷積層中執行的處理則稱為卷積運算，若以影像處理來比喻卷積運算，則相當於「濾鏡效果」。卷積層的意義即是將原本一個影像經由卷積運算產生多個影像，每個影像均代表不同特徵。卷積運算方式如下：<br />
</p>

<p>
典型的卷積運算如圖<a href="#org9eb860f">9</a>，此處特徵圖為(4,4)，濾鏡為(3,3)，輸出為(2,2)，這裡所謂的濾鏡就是CNN中的卷積核(convolution kernel)，其初始值由隨機方式產生。此外，在全連接網路層中，除了權重參數(weight)之外，還有偏權值(bias)，其結果如圖<a href="#orgc136b08">10</a>。<br />
</p>

<div id="org9eb860f" class="figure">
<p><img src="images/CNN-struc1.png" alt="CNN-struc1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 9: </span>卷積運算</p>
</div>


<div id="orgc136b08" class="figure">
<p><img src="images/CNN-struc2.png" alt="CNN-struc2.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 10: </span>卷積運算 2</p>
</div>

<p>
由圖<a href="#org9eb860f">9</a>、<a href="#orgc136b08">10</a>的卷積運算可以看出，輸入特徵值在經過運算後，其大小會縮小，可以預見的結果是，在經過多層神經網路反複進行卷積運算後，輸出特徵值大小很快就會縮小為 1，而無法再進行卷積運算。為了避免這種情況發生，在進行卷積運算前，可以針對輸入資料周圍補上一圈固定的資料（例如 0），這個動作稱為填補(padding)，如果我們對在卷積運算前對於圖<a href="#org9eb860f">9</a>中的輸入特徵值進行寬度 1 的填補，則其結果如圖<a href="#org2fc58dd">11</a>所示。<br />
</p>


<div id="org2fc58dd" class="figure">
<p><img src="images/CNN-struc3.png" alt="CNN-struc3.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 11: </span>卷積運算 3</p>
</div>

<p>
進行上述卷積運算時，每次自左而右、自上而下，自輸入特徵值取出一個與核大小相同的子矩陣與核進行運算，而每個取出的子矩陣的間隔稱為步幅(stride)，上述範例中的stride均為 1，若 stride 設為 2，則一個(7,7)的輸入特徵值與一個(3,3)的核進行運算後，其輸出特徵值大小只剩(3,3)。<br />
</p>

<p>
上述範例中的特徵值均為二維矩陣，亦即，僅能表示水平與垂直方向的單色點陣圖，若輸入中包含色彩資料(RGB)，則輸入特徵圖將升及為三維矩陣（三層二維矩陣，每層表示一種 RGB 值），核的結構也是三維矩陣，但輸出特徵值則為二維矩陣。 以 MNist 資料集為例，將數字 7 的 28*28 影像以隨機產生的 5*5 濾鏡(或稱 filter weight、kernel)對其進行卷積，其結果如圖<a href="#orgecdaa9a">12</a>所示，這種效果有助於提取輸入影像的不同特徵，例如邊緣、線條&#x2026;等。<br />
</p>

<div id="orgecdaa9a" class="figure">
<p><img src="images/CNN-FW-1.jpg" alt="CNN-FW-1.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 12: </span>卷積運算 4</p>
</div>

<p>
實際建構模型時，不會只進行單一 kenrel 的卷積，圖<a href="#org954028a">13</a>即是隨機產生 16 個 kernel 對輸入影像提取不同特徵。<br />
</p>

<div id="org954028a" class="figure">
<p><img src="images/CNN-FW-2.jpg" alt="CNN-FW-2.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 13: </span>卷積運算 5</p>
</div>

<p>
全連接層(又稱密集層, dense layer)和卷積層之間的根本區別在於：全連接層會由輸入的特徵空間中學習全域的 pattern，而卷積層則是學習局部的 pattern。以影像辨識為例，卷積層會把輸入分解成小小的 2D 窗格，然後從中找出 pattern。這個關鍵特性為 CNN 提供了兩個有趣的特質：<br />
</p>

<ul class="org-ul">
<li>學習到的 pattern 具平移不變性(translation invariant)：在影像的右下角學習到的某個 pattern，CNN 可以在任何位置識別這樣的 pattern(如左上角)，相對的，當全連接層連接神經網路看到 pattern 出現在新位置時，就必須重新學習，這使的 CNN 可以更有效率地處理影像資料。<br /></li>
<li>學習到 pattern 的空間層次結構(spatial hierarchies of patterns)：第一層卷積層會學習到諸如邊邊角角的小局部圖案，第二層卷積層則會基於第一層學到的特徵(小圖案)來學習較大的圖案，這使得 CNN 能夠有效地學習越來越複雜和抽象的視覺概念。<br /></li>
</ul>

<p>
CNN 所運算的 3D 張量稱為特徵映射圖(feature maps，簡稱特徵圖)，特徵圖有 2 個空間軸(height, width)以及 1 個色深度軸(depth / channel)，對於 RGB 影像來說，depth 值為 3。卷積運算會從輸入特徵中萃取出各種小區塊 pattern，當它對整張影像都做完萃取之後，就會產生輸出特徵映射圖(output feature map)。輸出特徵映射圖仍是 3D 張量，具有寬度和高度，但此時其深度軸已不再代表 RGB 顏色值，此時它代表過濾器(filter)，每一種 filter 會對輸入資料進行特定面向的編碼、萃取出結果，例如，filter 可以萃取到「在輸入資料中出現一張臉」這種高階抽象的概念，將不是臉的都過濾掉。<br />
</p>
</div>
</div>
<div id="outline-container-orgefcc246" class="outline-3">
<h3 id="orgefcc246"><span class="section-number-3">1.3.</span> 池化層(Pooling Layer)</h3>
<div class="outline-text-3" id="text-1-3">
<p>
卷積層之間通常會加一個池化層(Pooling Layer)，它是一個壓縮圖片並保留重要資訊的方法，取樣的方法一樣是採滑動視窗，但是通常取最大值(Max-Pooling)，而非加權總和，若滑動視窗大小設為 2，『滑動步長』(Stride) 也為 2，則資料量就降為原本的四分之一，但因為取最大值，它還是保留局部範圍比對的最大可能性。也就是說，池化後的資訊更專注於圖片中是否存在相符的特徵，而非圖片中『哪裡』存在這些特徵，幫助 CNN 判斷圖片中是否包含某項特徵，而不必關心特徵所在的位置，這樣圖像偏移，一樣可以辨識出來。其架構如圖<a href="#org6ef9e79">14</a>所示。<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup><br />
</p>

<div id="org6ef9e79" class="figure">
<p><img src="images/CNN-Pooling.png" alt="CNN-Pooling.png" /><br />
</p>
<p><span class="figure-number">Figure 14: </span>CNN 之池化層</p>
</div>

<p>
池化層以縮減取樣(downsampling)的方式縮小影像可以帶來以下優點：<br />
</p>
<ol class="org-ol">
<li>減少需要處理的資料點：減少後續運算所需時間。<br /></li>
<li>讓影像位置差異變小：影像要辨識的目標（如 MNist 資料集的數字）可能因為在影像中的位置不同而影響辦識，減小影像可以讓數字的位置差異變小。<br /></li>
<li>參數的數量程計算量下降：同時也能控制 overfitting。<br /></li>
</ol>

<p>
圖<a href="#org7512982">15</a>即為使用 Max-Pool 對 16 個卷積影像進行縮減取樣(downsampling)的效果，將 16 個 28*28 個影像縮小為 16 個 14*14 的影像，但仍保持其特徵。MaxPooling 主要是由輸入特徵圖中做採樣並輸出樣本的最大值，它在概念上類似於卷積層操作，但並不是用卷積核(convolution kernel)張量積的方式來轉換局部區塊，而是經由手動編碼的 max 張量操作進行轉換。與卷積層操作的很大區別是 MaxPooling 通常用 2&times;2 窗格和步長(strides)2 來完成，以便將特徵圖每一軸的採樣減少到原來的 1/2，而卷積層操作通常使用 3&times;3 窗格且不指定步長(即使用預設步長 1)。<br />
</p>


<div id="org7512982" class="figure">
<p><img src="images/CNN-PL-1.jpg" alt="CNN-PL-1.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 15: </span>池化效果</p>
</div>

<p>
為什麼要採用這種方式來縮小採樣特徵圖而不用原來的特徵圖尺寸一路執行下去？假設一個有不加入 MaxPooling 而是以全卷積層的模型設計如下：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">model_no_max_pool</span> = models.Sequential()
<span class="linenr">2: </span>model_no_max_pool.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">32</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>),
<span class="linenr">3: </span>                      input_shape=(<span style="color: #da8548; font-weight: bold;">28</span>, <span style="color: #da8548; font-weight: bold;">28</span>, <span style="color: #da8548; font-weight: bold;">1</span>))
<span class="linenr">4: </span>model_no_max_pool.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">64</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>),)
<span class="linenr">5: </span>model_no_max_pool.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">64</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>),)
</pre>
</div>

<p>
上述設計的問題可以從以下兩個面向來看：<sup><a id="fnr.6" class="footref" href="#fn.6" role="doc-backlink">6</a></sup><br />
</p>
<ul class="org-ul">
<li>不利於學習特徵的空間層次結構。當 strides=1，第二層的 3&times;3 窗格要走過 5&times;5 的區域才能包含第一層的 7&times;7 區城，進而生成下一層的完整 3&times;3 區域，依此類推，第三層的 3&times;3 窗格也要走過 5&times;5 的區域才能包含第二層的 5&times;5 區域。也就是說，第三層的 3&times;3 窗格實際上僅包含來自原始輸入的 7&times;7 區城的資訊。相對於初始輸入，由卷積神經網路學習的高階 pattern 仍然進展很小，不足以學習分類數字。我們希望的是：最後一個卷積層的輸出特徵已經能提供有關輸入資料的總體訊息。<br /></li>
<li>最終特徵圖的每個樣本總係數為 22&times;22&times;64=3-976，這是相當巨大的 model，如果要將其展平以在頂部連接大小為 512 的 Dense 層，則該層將會有 1580 萬個參數，這對小 model 而言實在是太大，而且會導致 overfitting。<br /></li>
</ul>

<p>
雖然 MaxPooling 並不是縮小探樣特徵圖的唯一方法（也可以透過卷積層的 strides 來調整，或是使用平均池化而非 MaxPooling）,不過就經驗來看，MaxPooling 往往比這些方案好。主要原因是：特徵通常是源自於空間某些有特色的 pattern，因此要取其最大值才更具訊息性，若採用平均值，則特色就被掩蓋了。<br />
</p>
</div>
</div>
</div>
<div id="outline-container-org1ab9f24" class="outline-2">
<h2 id="org1ab9f24"><span class="section-number-2">2.</span> 神經網路解題步驟</h2>
<div class="outline-text-2" id="text-2">
<p>
使用神經網路解決問題可大致分為兩個步驟：「學習」與「推論」。<br />
</p>
<ul class="org-ul">
<li>學習指使用訓練資料進行權重參數的學習<br /></li>
<li>推論指使用學習過的參數進行資料分類CNN<br /></li>
</ul>
<p>
而實際的動手實作可再細分為以下幾個步驟<br />
</p>
<ol class="org-ol">
<li>收集資料 (Gathering data)<br /></li>
<li>準備數據 (Preparing that data)<br /></li>
<li>選擇模型 (Choosing a model)<br /></li>
<li>訓練機器 (Training)<br /></li>
<li>評估分析 (Evaluation)<br /></li>
<li>調整參數 (Hyperparameter tuning)<br /></li>
<li>預測推論 (Prediction)<br /></li>
</ol>
<p>
實際動手玩一下神經網路架構: <a href="https://playground.tensorflow.org">Tensorflow Playground</a><br />
</p>
</div>
<div id="outline-container-orgaee7e8d" class="outline-3">
<h3 id="orgaee7e8d"><span class="section-number-3">2.1.</span> 收集資料</h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-org8432726" class="outline-4">
<h4 id="org8432726"><span class="section-number-4">2.1.1.</span> 資料類型</h4>
<div class="outline-text-4" id="text-2-1-1">
</div>
<div id="outline-container-orgaa63391" class="outline-5">
<h5 id="orgaa63391"><span class="section-number-5">2.1.1.1.</span> 人工收集</h5>
<div class="outline-text-5" id="text-2-1-1-1">
<ul class="org-ul">
<li>預測股市股價: 開盤、收盤、成交量、技術指標、財務指標、籌碼指標等等<br /></li>
<li>以物品識別:大量物品照片並給予名稱(label)<br /></li>
<li>以注音符號手寫辨識: 大量手寫照片及其對應答案(label)<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org97a41a9" class="outline-5">
<h5 id="org97a41a9"><span class="section-number-5">2.1.1.2.</span> 現成資料集</h5>
<div class="outline-text-5" id="text-2-1-1-2">
</div>
<ol class="org-ol">
<li><a id="orgbf695b8"></a>MNIST<br />
<div class="outline-text-6" id="text-2-1-1-2-1">
<p>
資料集由 0~9 的數字影像構成(如圖<a href="#org7e6eb31">16</a>)，共計 60000 張訓練影像、10000 張測試影像。<br />
</p>

<div id="org7e6eb31" class="figure">
<p><img src="images/MNIST.jpg" alt="MNIST.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 16: </span>MNIST 資料集內容範例</p>
</div>
</div>
</li>
<li><a id="org496d5e7"></a>Boston housing<br />
<div class="outline-text-6" id="text-2-1-1-2-2">
<p>
Boston Housing數據集包含有關波士頓不同房屋的數據(數據，如年份、面積)，本資料集中有506個樣本和13個特徵變量，目標是使用給定的特徵預測房屋價格的價值。<br />
</p>
</div>
</li>
<li><a id="org508d8ed"></a>Iris<br />
<div class="outline-text-6" id="text-2-1-1-2-3">
<p>
鳶尾花資料集是非常著名的生物資訊資料集之一，由英國統計學家 Ronald Fisher 在1936年時，對加斯帕半島上的鳶尾屬花朵所提取的花瓣花萼的長寬數據資料，依照山鳶尾，變色鳶尾，維吉尼亞鳶尾三類進行標示，共150筆資料<sup><a id="fnr.7" class="footref" href="#fn.7" role="doc-backlink">7</a></sup>。每筆資料有五個欄位：花萼長度(Sepal Length)、花萼寬度(Sepal Width)、花瓣長度(Petal Length) 、花瓣寬度(Petal Width)、類別(Class)，其中類有Setosa，Versicolor和Virginica三個品種。<br />
</p>

<div id="org726a183" class="figure">
<p><img src="images/cqy409dEexm96zavyuw.png" alt="cqy409dEexm96zavyuw.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 17: </span>Iris資料集</p>
</div>
</div>
</li>
<li><a id="orgab8800f"></a>Cifar-10<br />
<div class="outline-text-6" id="text-2-1-1-2-4">
<p>
由深度學習大師 Geoffrey Hinton 教授與其在加拿大多倫多大學的學生 Alex Krixhevsky 與 Vinoid Nair 所整理之影像資料集, 包含 6 萬筆 32*32 低解析度之彩色圖片, 其中 5 萬筆為訓練集; 1 萬筆為測試集, 是機器學習中常用的圖片辨識資料集<br />
</p>

<div id="org5e81187" class="figure">
<p><img src="images/cifar10-ten-categories.jpg" alt="cifar10-ten-categories.jpg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 18: </span>Cifar-10</p>
</div>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org703be01" class="outline-4">
<h4 id="org703be01"><span class="section-number-4">2.1.2.</span> DEMO</h4>
<div class="outline-text-4" id="text-2-1-2">
<p>
以keras為例，我們可以利用mnist.load_data()自網路下載手寫辨識資料集，資料集內容包含 <b>資料(x)</b> 和 <b>標籤(y)</b> 兩部份，load_data()這個function會把整份資料集分割成兩個子集合：訓練集(training set)和測試集(testing set)。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr">2: </span>(X_train, y_Train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_Test</span>) = mnist.load_data()
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org1bb86d3" class="outline-3">
<h3 id="org1bb86d3"><span class="section-number-3">2.2.</span> 準備數據</h3>
<div class="outline-text-3" id="text-2-2">
<p>
當我們在比較分析兩組數據資料時，可能會遭遇因單位的不同(例如：身高與體重)，或數字大小的代表性不同(例如：粉專1萬人與滿足感0.8)，造成各自變化的程度不一，進而影響統計分析的結果<sup><a id="fnr.8" class="footref" href="#fn.8" role="doc-backlink">8</a></sup>，即：那些變化量最大的因素（特徵）會主導分析結果。<br />
</p>

<p>
正式將資料送至模型訓練前，資料應進行相應的缺漏值處理以及資料正規化，詳細處理方式可參考<a href="20221023130936-資料預處理.html#ID-82e219c3-6ca0-43b0-bb11-e3a8454f089d">資料預處理</a>。<br />
</p>
</div>
<div id="outline-container-orgade0731" class="outline-4">
<h4 id="orgade0731"><span class="section-number-4">2.2.1.</span> DEMO範例</h4>
<div class="outline-text-4" id="text-2-2-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">x_train</span> = x_train.reshape(<span style="color: #da8548; font-weight: bold;">60000</span>, <span style="color: #da8548; font-weight: bold;">784</span>)
<span class="linenr">2: </span><span style="color: #dcaeea;">x_test</span> = x_test.reshape(<span style="color: #da8548; font-weight: bold;">10000</span>, <span style="color: #da8548; font-weight: bold;">784</span>)
<span class="linenr">3: </span><span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">4: </span><span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">5: </span><span style="color: #dcaeea;">x_train</span> /= <span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">6: </span><span style="color: #dcaeea;">x_test</span> /= <span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">7: </span>
<span class="linenr">8: </span><span style="color: #dcaeea;">y_TrainOneHot</span> = np_utils.to_categorical(y_Train)
<span class="linenr">9: </span><span style="color: #dcaeea;">y_TestOneHot</span> = np_utils.to_categorical(y_Test)
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org1e1082e" class="outline-3">
<h3 id="org1e1082e"><span class="section-number-3">2.3.</span> 選擇模型</h3>
<div class="outline-text-3" id="text-2-3">
<p>
整理完資料集後，接下來就是要選擇訓練用的模型，像是決策樹、LSTM、RNN等等都是機器學習中常使用的訓練模型，其中目前較常拿來訓練股市的是「LSTM」，中文叫做長短期記憶，是屬於深度學習中的一個模型。另一種CNN模型則適合處理圖形資料。<br />
</p>
</div>
<div id="outline-container-orgca022c3" class="outline-4">
<h4 id="orgca022c3"><span class="section-number-4">2.3.1.</span> 語法</h4>
<div class="outline-text-4" id="text-2-3-1">
<p>
<a href="https://keras.io/api/models/model_training_apis/">Keras API reference / Models API / Model training APIs </a><br />
</p>
</div>
</div>
<div id="outline-container-orgd56fd59" class="outline-4">
<h4 id="orgd56fd59"><span class="section-number-4">2.3.2.</span> DEMO</h4>
<div class="outline-text-4" id="text-2-3-2">
</div>
<div id="outline-container-org1a0742e" class="outline-5">
<h5 id="org1a0742e"><span class="section-number-5">2.3.2.1.</span> CNN模型示例</h5>
<div class="outline-text-5" id="text-2-3-2-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr"> 2: </span>model.add(Conv2D(<span style="color: #da8548; font-weight: bold;">32</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), padding=<span style="color: #98be65;">"same"</span>, activation=<span style="color: #98be65;">"relu"</span>))
<span class="linenr"> 3: </span>model.add(MaxPooling2D(pool_size=(<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 4: </span>model.add(Conv2D(<span style="color: #da8548; font-weight: bold;">64</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), padding=<span style="color: #98be65;">"same"</span>, activation=<span style="color: #98be65;">"relu"</span>))
<span class="linenr"> 5: </span>model.add(MaxPooling2D(pool_size=(<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 6: </span>model.add(Conv2D(<span style="color: #da8548; font-weight: bold;">128</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), padding=<span style="color: #98be65;">"same"</span>, activation=<span style="color: #98be65;">"relu"</span>))
<span class="linenr"> 7: </span>model.add(MaxPooling2D(pool_size=(<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 8: </span>model.add(Activation(<span style="color: #98be65;">"softmax"</span>))
<span class="linenr"> 9: </span>model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">128</span>,
<span class="linenr">10: </span>                input_dim=<span style="color: #da8548; font-weight: bold;">784</span>,
<span class="linenr">11: </span>                kernel_initializer=<span style="color: #98be65;">'normal'</span>,
<span class="linenr">12: </span>                activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">13: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">64</span>, activation=<span style="color: #98be65;">'relu'</span>)
<span class="linenr">14: </span>model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">10</span>,
<span class="linenr">15: </span>                kernel_initializer=<span style="color: #98be65;">'normal'</span>,
<span class="linenr">16: </span>                activation=<span style="color: #98be65;">'softmax'</span>))
</pre>
</div>

<div id="org1b8520e" class="figure">
<p><img src="images/MNIST-CNN.png" alt="MNIST-CNN.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 19: </span>MNIST-NeuralNet</p>
</div>
</div>
</div>
<div id="outline-container-orgbc128fb" class="outline-5">
<h5 id="orgbc128fb"><span class="section-number-5">2.3.2.2.</span> LSTM模型示例</h5>
<div class="outline-text-5" id="text-2-3-2-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr"> 2: </span>model.add(LSTM(<span style="color: #da8548; font-weight: bold;">128</span>,
<span class="linenr"> 3: </span>               input_shape=(x_train.shape[<span style="color: #da8548; font-weight: bold;">1</span>:]),
<span class="linenr"> 4: </span>               activation=<span style="color: #98be65;">'relu'</span>,
<span class="linenr"> 5: </span>               return_sequences=<span style="color: #a9a1e1;">True</span>))
<span class="linenr"> 6: </span>model.add(Dropout(<span style="color: #da8548; font-weight: bold;">0.2</span>))
<span class="linenr"> 7: </span>model.add(LSTM(<span style="color: #da8548; font-weight: bold;">128</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 8: </span>model.add(Dropout(<span style="color: #da8548; font-weight: bold;">0.1</span>))
<span class="linenr"> 9: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">32</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">10: </span>model.add(Dropout(<span style="color: #da8548; font-weight: bold;">0.2</span>))
<span class="linenr">11: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">10</span>, activation=<span style="color: #98be65;">'softmax'</span>))
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org1751695" class="outline-3">
<h3 id="org1751695"><span class="section-number-3">2.4.</span> 訓練機器</h3>
<div class="outline-text-3" id="text-2-4">
<p>
選擇好訓練模型後，再來要將訓練集資料丟進去模型中做訓練，每層要放多少神經元、要跑幾層等等都會影響模型訓練出來的結果，這部分只能靠經驗跟不斷嘗試去學習，或是上網多爬文看別人怎麼撰寫訓練模型。<br />
</p>

<p>
在真正訓練前應該再設定好模型的loss function, optimizer。<br />
</p>
</div>
<div id="outline-container-orge21128f" class="outline-4">
<h4 id="orge21128f"><span class="section-number-4">2.4.1.</span> 語法</h4>
<div class="outline-text-4" id="text-2-4-1">
<p>
<a href="https://keras.io/api/models/model_training_apis/">Keras API reference / Models API / Model training APIs </a><br />
</p>
</div>
</div>
<div id="outline-container-org36a9c09" class="outline-4">
<h4 id="org36a9c09"><span class="section-number-4">2.4.2.</span> DEMO</h4>
<div class="outline-text-4" id="text-2-4-2">
</div>
<div id="outline-container-orgc4e910d" class="outline-5">
<h5 id="orgc4e910d"><span class="section-number-5">2.4.2.1.</span> CNN</h5>
<div class="outline-text-5" id="text-2-4-2-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">optimizer, loss function</span>
<span class="linenr">2: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'categorical_crossentropy'</span>,
<span class="linenr">3: </span>              optimizer=<span style="color: #98be65;">'adam'</span>, metrics=[<span style="color: #98be65;">'accuracy'</span>])
<span class="linenr">4: </span>
<span class="linenr">5: </span>model.fit(x=x_Train,
<span class="linenr">6: </span>          y=y_TrainOneHot,
<span class="linenr">7: </span>          validation_split=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">8: </span>          epochs=<span style="color: #da8548; font-weight: bold;">5</span>, batch_size=<span style="color: #da8548; font-weight: bold;">30</span>, verbose=<span style="color: #da8548; font-weight: bold;">2</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-org8bcb705" class="outline-5">
<h5 id="org8bcb705"><span class="section-number-5">2.4.2.2.</span> LSTM</h5>
<div class="outline-text-5" id="text-2-4-2-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">ptimizer, loss function</span>
<span class="linenr">2: </span>model.<span style="color: #c678dd;">compile</span>(optimizer=Adam(lr=<span style="color: #da8548; font-weight: bold;">0.001</span>),
<span class="linenr">3: </span>              loss=<span style="color: #98be65;">'categorical_crossentropy'</span>,
<span class="linenr">4: </span>              metrics=[<span style="color: #98be65;">'accuracy'</span>])
<span class="linenr">5: </span>
<span class="linenr">6: </span>model.fit(x_train, y_train,
<span class="linenr">7: </span>          e pochs=<span style="color: #da8548; font-weight: bold;">3</span>,
<span class="linenr">8: </span>          validation_data=(x_test, y_test))
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd88acc4" class="outline-3">
<h3 id="orgd88acc4"><span class="section-number-3">2.5.</span> 評估分析</h3>
<div class="outline-text-3" id="text-2-5">
<p>
當模型訓練完成後，接下來就是判斷該模型是否有過度擬合(overfitting)，這裡就是帶入測試集的資料進行評估，也可以嘗試利用交叉驗證的方式進行模型的擬合性判斷，以及利用RESM、MSE等統計計算來判斷模型的準確度<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">scores</span> = model.evaluate(x_Train, y_TestOneHot)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgba30f6b" class="outline-3">
<h3 id="orgba30f6b"><span class="section-number-3">2.6.</span> 調整參數</h3>
<div class="outline-text-3" id="text-2-6">
<p>
到這大致上模型已經完成了50%，最後的一步就是進行參數的微調，我們也稱為「超參數 (Hyperparamters)」，讓整個模型更加的精準，但也不能過度的調整，因為會造成overfitting的結果，這個取捨就只能依照無窮盡的反覆迭帶去尋找了，這部分也是相對較耗時間的地方<br />
</p>
</div>
<div id="outline-container-orgba9b5bc" class="outline-4">
<h4 id="orgba9b5bc"><span class="section-number-4">2.6.1.</span> model參數</h4>
<div class="outline-text-4" id="text-2-6-1">
<ul class="org-ul">
<li>調整model架構: <a href="https://medium.com/%E9%9B%9E%E9%9B%9E%E8%88%87%E5%85%94%E5%85%94%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%B8%96%E7%95%8C/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-ml-note-cnn%E6%BC%94%E5%8C%96%E5%8F%B2-alexnet-vgg-inception-resnet-keras-coding-668f74879306">[機器學習 ML NOTE] CNN演化史(AlexNet、VGG、Inception、ResNet)+Keras Coding</a><br /></li>
<li>loss function: <a href="https://keras.io/api/losses/">https://keras.io/api/losses/</a><br /></li>
<li>optimizers: <a href="https://keras.io/api/optimizers/">https://keras.io/api/optimizers/</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org5e5c339" class="outline-4">
<h4 id="org5e5c339"><span class="section-number-4">2.6.2.</span> Hyperparameters</h4>
<div class="outline-text-4" id="text-2-6-2">
<ul class="org-ul">
<li>batch size：一次迭代放入進行訓練或測試的影像數量。<br /></li>
<li>epoch：一種單位，所有影像皆被計算過1次後即為1 epoch<br /></li>
<li><a href="http://elmer-storage.blogspot.com/2018/06/cnn-hyperparamters.html">CNN筆記 - 超參數 (Hyperparamters) </a><br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgca3b249" class="outline-3">
<h3 id="orgca3b249"><span class="section-number-3">2.7.</span> 預測推論</h3>
<div class="outline-text-3" id="text-2-7">
<p>
到此，模型已經正式完成。那，怎麼知道這個模型夠不夠優秀？能不能正常運作？最簡單的評估方式是以一筆新的資料來測試。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">prediction</span> = model.predict_classes(x_Test4D_normalize)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(prediction[:<span style="color: #da8548; font-weight: bold;">10</span>])
</pre>
</div>
<p>
以MNIST手寫數字辨識為例，我們可以自已寫一個數字餵給模型，看看模型是否能正確預測。<br />
</p>

<p>
對於模型來說，這類全新的數據則是一個未知數，如果我們在訓練與測試階段都用同一批資料，這就好像上課與考試的內容都一樣，這會導致學生其實沒有學到真正的知識，而考試得到的分數也不會太準確。這種訓練資料與測試資料過於雷同而導致模型對新型別的資料欠缺處理能力的問題即為 <b>過度擬合(overfitting)</b> ；反之，如果我們的模型對於各種新型態資料都能辨識，則這個模型就具有 <b>泛化（Generalization）</b> 的預測能力。<br />
</p>
</div>
</div>
</div>
<div id="outline-container-org7af808c" class="outline-2">
<h2 id="org7af808c"><span class="section-number-2">3.</span> 實作1</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li><a href="20221211165455-cnn實作.html#ID-31d6a744-f7f7-47e4-ae33-3f9fa91c33bb">CNN實作</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-Hi-MNIST" class="outline-2">
<h2 id="Hi-MNIST"><span class="section-number-2">4.</span> 實作2: MNIST</h2>
<div class="outline-text-2" id="text-Hi-MNIST">
</div>
<div id="outline-container-org6500c8b" class="outline-3">
<h3 id="org6500c8b"><span class="section-number-3">4.1.</span> MNIST資料集</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>MNIST 是機器學習領域中相當著名的資料集，號稱機器學習領域的「Hello world.」，其重要性不言可喻。<br /></li>
<li>MNIST 資料集由 0~9 的數字影像構成(如圖<a href="#org7e6eb31">16</a>)，共計 60000 張訓練影像、10000 張測試影像。<br /></li>
<li>一般的 MMIST 資料集的用法為：使用訓練影像進行學習，再利用學習後的模型預測能否正確分類測試影像。<br /></li>
</ul>

<p>
準備資料是訓練模型的第一步，基礎資料可以是網上公開的資料集，也可以是自己的資料集。視覺、語音、語言等各種型別的資料在網上都能找到相應的資料集。<br />
</p>
</div>
</div>
<div id="outline-container-org4cc6218" class="outline-3">
<h3 id="org4cc6218"><span class="section-number-3">4.2.</span> 準備 MNIST 資料</h3>
<div class="outline-text-3" id="text-4-2">
<p>
MNIST 數據集來自美國國家標準與技術研究所, National Institute of Standards and Technology (NIST). 訓練集 (training set) 由來自 250 個不同人手寫的數字構成, 其中 50% 是高中學生, 50% 來自人口普查局 (the Census Bureau) 的工作人員. 測試集(test set) 也是同樣比例的手寫數字數據。MNIST 數據集可在 <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 獲取, 它包含了四個部分:<br />
</p>
<ol class="org-ol">
<li>Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解壓後 47 MB, 包含 60,000 個樣本)<br /></li>
<li>Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解壓後 60 KB, 包含 60,000 個標籤)<br /></li>
<li>Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解壓後 7.8 MB, 包含 10,000 個樣本)<br /></li>
<li>Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解壓後 10 KB, 包含 10,000 個標籤)<br /></li>
</ol>

<p>
雖然自己手動下載是個不錯的主意，可以讓你練習如何從網路抓檔案、解壓、設定這些檔案的下載路徑、然後再讀進來變成numpy的array或是pandas的dataframe，再把這些資料餵給tensorflow模組去建模型&#x2026;..不過這對初學者來說著實是一件很麻煩的事，所以多數的套件都很貼心的幫你準備好了直接從網路抓下資料集的function，像tensorflow的load_data。<br />
</p>
</div>
<div id="outline-container-org5bf5390" class="outline-4">
<h4 id="org5bf5390"><span class="section-number-4">4.2.1.</span> load data</h4>
<div class="outline-text-4" id="text-4-2-1">
<p>
MNIST 資料集是一個適合拿來當作 TensotFlow 的練習素材，在 Tensorflow 的現有套件中，也已經有內建好的 MNIST 資料集，我們只要在安裝好 TensorFlow 的 Python 環境中執行以下程式碼，即可將 MNIST 資料成功讀取進來。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr">2: </span><span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span id="coderef-get-keras-mnist" class="coderef-off"><span class="linenr">3: </span>(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()</span>
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(x_train.shape)
</pre>
</div>

<pre class="example">
(60000, 28, 28)
</pre>


<p>
在訓練模型之前，需要將樣本資料劃分為訓練集、測試集，有些情況下還會劃分為訓練集、測試集、驗證集。由上述程式第<a href="#coderef-get-keras-mnist" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-get-keras-mnist');" onmouseout="CodeHighlightOff(this, 'coderef-get-keras-mnist');">3</a>行可知，下載後的 MNIST 資料分成訓練資料(training data)與測試資料(testing data)，其中 x 為圖片、y為所對應數字。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21028;&#26039;&#36039;&#26009;&#24418;&#29376;</span>
<span class="linenr"> 2: </span><span style="color: #c678dd;">print</span>(x_train.shape)
<span class="linenr"> 3: </span><span style="color: #c678dd;">print</span>(x_test.shape)
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31532;&#19968;&#20491;label&#30340;&#20839;&#23481;</span>
<span class="linenr"> 5: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#24433;&#20687;&#20839;&#23481;</span>
<span class="linenr"> 7: </span><span style="color: #51afef;">import</span> matplotlib.pylab <span style="color: #51afef;">as</span> plt
<span class="linenr"> 8: </span><span style="color: #dcaeea;">img</span> = x_train[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr"> 9: </span>plt.imshow(img)
<span class="linenr">10: </span>plt.savefig(<span style="color: #98be65;">"MNIST-Image.png"</span>)
</pre>
</div>
<pre class="example">
(60000, 28, 28)
(10000, 28, 28)
5
</pre>


<p>
由上述程式輸出結果可以看到載入的 x 為大小為 28*28 的圖片共 60000 張，每一筆 MNIST 資料的照片(x)由 784 個 pixels 組成（28*28），照片內容如圖<a href="#orgffbdf0a">20</a>，訓練集的標籤(y)則為其對應的數字(0～9)，此例為 5。<br />
</p>

<div id="orgffbdf0a" class="figure">
<p><img src="images/MNIST-Image.png" alt="MNIST-Image.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 20: </span>MNIST 影像示例</p>
</div>

<p>
x 的影像資料為灰階影像，每個像素的數值介於 0~255 之間，矩陣裡每一項的資料則是代表每個 pixel 顏色深淺的數值，如下圖<a href="#orgf84efdf">21</a>所示：<br />
</p>

<div id="orgf84efdf" class="figure">
<p><img src="images/MNIST-Matrix.png" alt="MNIST-Matrix.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 21: </span>MNIST 資料矩陣</p>
</div>
</div>
</div>
<div id="outline-container-orgb9ed68a" class="outline-4">
<h4 id="orgb9ed68a"><span class="section-number-4">4.2.2.</span> 資料預處理</h4>
<div class="outline-text-4" id="text-4-2-2">
</div>
<div id="outline-container-orgc48d767" class="outline-5">
<h5 id="orgc48d767"><span class="section-number-5">4.2.2.1.</span> 影像數值資料的<a href="https://aifreeblog.herokuapp.com/posts/54/data_science_203/">正規化</a></h5>
<div class="outline-text-5" id="text-4-2-2-1">
<p>
此例中每張圖被存成28X28個0~255的數值，分別代表影像中每個點(pixel)的灰階深度，在把影像丟進模型前，最好先將數值資料做正規化或標準化，讓數值都變為介於0到1間的數值。<br />
</p>

<p>
以此狀況為例，把所有的數值除上255是個不錯的解決方案。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"====&#31532;0&#24373;&#22294;&#30340;&#31532;&#19971;&#21015;&#21407;&#22987;&#20839;&#23481;==="</span>)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(x_train[<span style="color: #da8548; font-weight: bold;">0</span>][<span style="color: #da8548; font-weight: bold;">7</span>])
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #dcaeea;">X_train</span> = x_train / <span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">5: </span><span style="color: #dcaeea;">X_test</span> = x_test / <span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">6: </span>
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"====&#31532;0&#24373;&#22294;&#30340;&#31532;&#19971;&#21015;&#27491;&#35215;&#21270;&#24460;&#30340;&#20839;&#23481;==="</span>)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(X_train[<span style="color: #da8548; font-weight: bold;">0</span>][<span style="color: #da8548; font-weight: bold;">7</span>])
</pre>
</div>

<pre class="example">
====第0張圖的第七列原始內容===
[  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251
  93  82  82  56  39   0   0   0   0   0]
====第0張圖的第七列正規化後的內容===
[0.         0.         0.         0.         0.         0.
 0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686
 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373
 0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.
 0.         0.         0.         0.        ]
</pre>
</div>
</div>
<div id="outline-container-orgb028254" class="outline-5">
<h5 id="orgb028254"><span class="section-number-5">4.2.2.2.</span> Label的格式轉換</h5>
<div class="outline-text-5" id="text-4-2-2-2">
<p>
載入的 y 為所對應的數字 0~9，在這我們要運用 keras 中的 np_under_utils.to_under_categorical 將 y 轉成 one-hot 的形式，將他轉為一個 10 維的 vector，例如：我們所拿到的資料為 y=3，經過 np_utils.to_categorical，會轉換為 y=[0,0,0,1,0,0,0,0,0,0]。這部份的轉換程式碼如下：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">2: </span><span style="color: #51afef;">from</span> tensorflow.keras.utils <span style="color: #51afef;">import</span> to_categorical
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">5: </span><span style="color: #dcaeea;">Y_train</span> = to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">6: </span><span style="color: #dcaeea;">Y_test</span> = to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(y_Train[<span style="color: #da8548; font-weight: bold;">0</span>])
</pre>
</div>

<pre class="example">
5
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</pre>


<p>
結果可以看出第0張圖的label為5，表示這張圖不管寫的好或不好，像或不像，其真正的答案為5。<br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org36327df" class="outline-3">
<h3 id="org36327df"><span class="section-number-3">4.3.</span> 建立CNN模型</h3>
<div class="outline-text-3" id="text-4-3">
<ul class="org-ul">
<li>在這個模型中，第一層(同時也身兼輸入層)有32個卷積核，也就是有32個神經元<br /></li>
<li>第一層的每個神經元有10個參數\(3*3+1\)，因為卷積核大小為\(3*3\)，還有一個bias<br /></li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 3: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr"> 4: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">32</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">28</span>, <span style="color: #da8548; font-weight: bold;">28</span>, <span style="color: #da8548; font-weight: bold;">1</span>)))
<span class="linenr"> 5: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 6: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">64</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 7: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 8: </span>model.add(layers.Flatten())
<span class="linenr"> 9: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">512</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">10: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">10</span>, activation=<span style="color: #98be65;">'softmax'</span>))
<span class="linenr">11: </span>model.summary()  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26597;&#30475;&#27169;&#22411;&#25688;&#35201;</span>
</pre>
</div>

<pre class="example" id="orga6e78d6">
Model: "sequential_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_32 (Conv2D)          (None, 26, 26, 32)        320

 max_pooling2d_25 (MaxPooli  (None, 13, 13, 32)        0
 ng2D)

 conv2d_33 (Conv2D)          (None, 11, 11, 64)        18496

 max_pooling2d_26 (MaxPooli  (None, 5, 5, 64)          0
 ng2D)

 flatten_7 (Flatten)         (None, 1600)              0

 dense_26 (Dense)            (None, 512)               819712

 dense_27 (Dense)            (None, 10)                5130

=================================================================
Total params: 843658 (3.22 MB)
Trainable params: 843658 (3.22 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre>

<p>
在編譯時，以adim優化器，由於使用 softmax 單元結束神經網路，所以配合使用 categorical_crossentropy 為損失基準。<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="orgb2f7b78"><span class="linenr">1: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'categorical_crossentropy'</span>,
<span class="linenr">2: </span>              optimizer=<span style="color: #98be65;">'adam'</span>,
<span class="linenr">3: </span>              metrics=[<span style="color: #98be65;">'accuracy'</span>])
</pre>
</div>
</div>
</div>
<div id="outline-container-orgb7618ad" class="outline-3">
<h3 id="orgb7618ad"><span class="section-number-3">4.4.</span> 訓練CNN模型</h3>
<div class="outline-text-3" id="text-4-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> os
<span class="linenr">2: </span>os.<span style="color: #dcaeea;">environ</span>[<span style="color: #98be65;">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span style="color: #98be65;">'2'</span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35774;&#32622; Tensorflow &#26085;&#24535;&#32423;&#21035;&#20026; ERROR</span>
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #dcaeea;">history</span> = model.fit(X_train, Y_train,  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35757;&#32451;&#25968;&#25454;&#21644;&#26631;&#31614;</span>
<span class="linenr">5: </span>                    batch_size=<span style="color: #da8548; font-weight: bold;">128</span>,     <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25209;&#27425;&#22823;&#23567;</span>
<span class="linenr">6: </span>                    epochs=<span style="color: #da8548; font-weight: bold;">10</span>,          <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35757;&#32451;&#36718;&#25968;</span>
<span class="linenr">7: </span>                    validation_split=<span style="color: #da8548; font-weight: bold;">0.2</span>)  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39564;&#35777;&#38598;&#27604;&#20363;&#65288;&#21487;&#36873;&#65289;</span>
</pre>
</div>

<pre class="example" id="orgd1621ee">
Epoch 1/10
375/375 [==============================] - 7s 18ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0429 - val_accuracy: 0.9900
Epoch 2/10
375/375 [==============================] - 7s 19ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0458 - val_accuracy: 0.9904
Epoch 3/10
375/375 [==============================] - 7s 19ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0543 - val_accuracy: 0.9887
Epoch 4/10
375/375 [==============================] - 7s 19ms/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.0456 - val_accuracy: 0.9905
Epoch 5/10
375/375 [==============================] - 7s 19ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0428 - val_accuracy: 0.9911
Epoch 6/10
375/375 [==============================] - 7s 19ms/step - loss: 9.6022e-04 - accuracy: 0.9997 - val_loss: 0.0503 - val_accuracy: 0.9912
Epoch 7/10
375/375 [==============================] - 7s 19ms/step - loss: 1.9383e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9917
Epoch 8/10
375/375 [==============================] - 8s 21ms/step - loss: 4.2269e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9922
Epoch 9/10
375/375 [==============================] - 8s 20ms/step - loss: 3.1525e-05 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9924
Epoch 10/10
375/375 [==============================] - 7s 20ms/step - loss: 1.5961e-05 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9923
</pre>
</div>
</div>
<div id="outline-container-orgfb2c7e2" class="outline-3">
<h3 id="orgfb2c7e2"><span class="section-number-3">4.5.</span> 評估CNN模型</h3>
<div class="outline-text-3" id="text-4-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#35780;&#20272;&#27169;&#22411;</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">loss</span>, <span style="color: #dcaeea;">accuracy</span> = model.evaluate(X_test, Y_test)
<span class="linenr"> 3: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Test loss:'</span>, loss)
<span class="linenr"> 4: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Test accuracy:'</span>, accuracy)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#33719;&#21462;&#35757;&#32451;&#21382;&#21490;&#20013;&#30340;&#25439;&#22833;&#20540;&#21644;&#20934;&#30830;&#29575;&#20540;</span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">train_loss</span> = history.history[<span style="color: #98be65;">'loss'</span>]
<span class="linenr">10: </span><span style="color: #dcaeea;">val_loss</span> = history.history[<span style="color: #98be65;">'val_loss'</span>]
<span class="linenr">11: </span><span style="color: #dcaeea;">train_accuracy</span> = history.history[<span style="color: #98be65;">'accuracy'</span>]
<span class="linenr">12: </span><span style="color: #dcaeea;">val_accuracy</span> = history.history[<span style="color: #98be65;">'val_accuracy'</span>]
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32472;&#21046;&#25439;&#22833;&#20540;&#25240;&#32447;&#22270;</span>
<span class="linenr">15: </span>plt.cla()
<span class="linenr">16: </span>plt.plot(train_loss, label=<span style="color: #98be65;">'Training Loss'</span>)
<span class="linenr">17: </span>plt.plot(val_loss, label=<span style="color: #98be65;">'Validation Loss'</span>)
<span class="linenr">18: </span>plt.title(<span style="color: #98be65;">'Training and Validation Loss'</span>)
<span class="linenr">19: </span>plt.xlabel(<span style="color: #98be65;">'Epoch'</span>)
<span class="linenr">20: </span>plt.ylabel(<span style="color: #98be65;">'Loss'</span>)
<span class="linenr">21: </span>plt.legend()
<span class="linenr">22: </span>plt.savefig(<span style="color: #98be65;">'images/cnn-mnist-Loss.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">23: </span>
<span class="linenr">24: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32472;&#21046;&#20934;&#30830;&#29575;&#25240;&#32447;&#22270;</span>
<span class="linenr">25: </span>plt.cla()
<span class="linenr">26: </span>plt.plot(train_accuracy, label=<span style="color: #98be65;">'Training Accuracy'</span>)
<span class="linenr">27: </span>plt.plot(val_accuracy, label=<span style="color: #98be65;">'Validation Accuracy'</span>)
<span class="linenr">28: </span>plt.title(<span style="color: #98be65;">'Training and Validation Accuracy'</span>)
<span class="linenr">29: </span>plt.xlabel(<span style="color: #98be65;">'Epoch'</span>)
<span class="linenr">30: </span>plt.ylabel(<span style="color: #98be65;">'Accuracy'</span>)
<span class="linenr">31: </span>plt.legend()
<span class="linenr">32: </span>plt.savefig(<span style="color: #98be65;">'images/cnn-mnist-Accuracy.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<pre class="example">
313/313 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9929
Test loss: 0.03584390878677368
Test accuracy: 0.992900013923645
</pre>



<div id="org5ee38e4" class="figure">
<p><img src="images/cnn-mnist-Loss.png" alt="cnn-mnist-Loss.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 22: </span>Training and Validation Loss</p>
</div>


<div id="orge4d33ed" class="figure">
<p><img src="images/cnn-mnist-Accuracy.png" alt="cnn-mnist-Accuracy.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 23: </span>Training and Validation Accuracy</p>
</div>
</div>
</div>
<div id="outline-container-org2a681a6" class="outline-3">
<h3 id="org2a681a6"><span class="section-number-3">4.6.</span> 預測結果</h3>
<div class="outline-text-3" id="text-4-6">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992;&#27169;&#22411;&#36827;&#34892;&#39044;&#27979;</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">predictions</span> = model.predict(x_test)
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36664;&#20986;&#21069;10&#20491;&#27171;&#26412;&#30340;&#39044;&#27979;&#32467;&#26524;</span>
<span class="linenr">5: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">10</span>):
<span class="linenr">6: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Predicted:"</span>, predictions[i].argmax(), <span style="color: #98be65;">"Actual:"</span>, Y_test[i].argmax())
</pre>
</div>

<pre class="example" id="orgb5808c8">
313/313 [==============================] - 1s 4ms/step
Predicted: 7 Actual: 7
Predicted: 2 Actual: 2
Predicted: 1 Actual: 1
Predicted: 0 Actual: 0
Predicted: 4 Actual: 4
Predicted: 1 Actual: 1
Predicted: 4 Actual: 4
Predicted: 9 Actual: 9
Predicted: 6 Actual: 5
Predicted: 9 Actual: 9
</pre>
</div>
</div>
<div id="outline-container-org4efdaac" class="outline-3">
<h3 id="org4efdaac"><span class="section-number-3">4.7.</span> Crosstab</h3>
<div class="outline-text-3" id="text-4-7">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20551;&#35774; predictions &#21644; y_test &#26159;&#27169;&#22411;&#39044;&#27979;&#32467;&#26524;&#21644;&#23454;&#38469;&#26631;&#31614;</span>
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20551;&#35774; predictions &#21644; y_test &#37117;&#26159;&#19968;&#32500;&#25968;&#32452;&#65292;&#27599;&#20491;&#20803;&#32032;&#26159;&#27171;&#26412;&#23545;&#24212;&#30340;&#31867;&#21035;&#26631;&#31614;</span>
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23558;&#39044;&#27979;&#32467;&#26524;&#21644;&#23454;&#38469;&#26631;&#31614;&#36716;&#25442;&#20026; Pandas Series</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">predicted_labels</span> = pd.Series(predictions.argmax(axis=<span style="color: #da8548; font-weight: bold;">1</span>), name=<span style="color: #98be65;">'Predicted'</span>)
<span class="linenr"> 8: </span><span style="color: #dcaeea;">actual_labels</span> = pd.Series(Y_test.argmax(axis=<span style="color: #da8548; font-weight: bold;">1</span>), name=<span style="color: #98be65;">'Actual'</span>)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992; pd.crosstab &#35745;&#31639;&#20132;&#21449;&#34920;</span>
<span class="linenr">11: </span><span style="color: #dcaeea;">crosstab_result</span> = pd.crosstab(actual_labels, predicted_labels)
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36664;&#20986;&#20132;&#21449;&#34920;</span>
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(crosstab_result)
</pre>
</div>

<pre class="example" id="orgb55caad">
Predicted    0     1     2     3    4    5    6     7    8    9
Actual
0          977     0     0     0    1    0    0     1    1    0
1            0  1128     1     1    0    1    1     0    3    0
2            1     1  1026     0    0    0    0     4    0    0
3            0     0     1  1004    0    3    0     0    2    0
4            0     0     0     0  979    0    0     0    1    2
5            2     0     1     9    0  873    3     1    3    0
6            2     2     0     0    3    1  948     0    2    0
7            0     0     3     0    0    0    0  1021    1    3
8            2     0     1     0    0    0    0     2  968    1
9            0     0     0     1    8    2    0     0    3  995
</pre>
</div>
</div>
</div>
<div id="outline-container-orgfbb3a34" class="outline-2">
<h2 id="orgfbb3a34"><span class="section-number-2">5.</span> 實作3: Regression</h2>
<div class="outline-text-2" id="text-5">
<p>
CNN雖然更多場合是用於處理影像相關的處理工作，然而他也可以用來幫我們解決一些數學問題，例如畫迴歸線。開啟colab、新增一個筆記本，逐一將下列程式碼複製、貼到colab執行，觀察結果。<br />
</p>
</div>
<div id="outline-container-orge6da0e5" class="outline-3">
<h3 id="orge6da0e5"><span class="section-number-3">5.1.</span> 產生數據</h3>
<div class="outline-text-3" id="text-5-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #dcaeea;">x</span> = np.random.uniform(<span style="color: #da8548; font-weight: bold;">0.0</span>, <span style="color: #da8548; font-weight: bold;">3</span>, (<span style="color: #da8548; font-weight: bold;">10</span>))
<span class="linenr">5: </span><span style="color: #dcaeea;">y</span> = <span style="color: #da8548; font-weight: bold;">78</span> + <span style="color: #da8548; font-weight: bold;">7.8</span>*x + np.random.normal(<span style="color: #da8548; font-weight: bold;">0.0</span>, <span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #c678dd;">len</span>(x))
<span class="linenr">6: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'x: '</span>, x)
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'y: '</span>, y)
<span class="linenr">8: </span>
<span class="linenr">9: </span>plt.scatter(x, y)
</pre>
</div>
<pre class="example">
x:  [1.04495966 2.63828713 1.05394772 ... 2.7829483  2.5038085  0.7773407 ]
y:  [ 85.07647921  96.21107688  90.60605344 ...  97.41007778 102.38380208 80.86243195]
</pre>


<p>
結果如下圖，一共有10個點，如何畫出一條迴歸線代表這10個點的趨勢？這個題目本身是什麼意思？<br />
</p>

<div id="orgf17d58e" class="figure">
<p><img src="images/cnn-regression-1.png" alt="cnn-regression-1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 24: </span>Caption</p>
</div>

<p>
想像一下，上面是10個學生的資料，X軸是學生對於數學的喜愛程度，Y軸是該生的數學期末考成績，看起來二者間是存在某種關係的。那，如果已知某生對數學的喜愛程為2.0，我們可以預測他的數學期末考成績嗎？&#x2014;可以的，如果我們有一條像底下的迴歸線公式：<br />
\[ MathScore_i = a * MathLove_i + b \]<br />
如此一來，我們就能輸入喜愛程度，得到對數學成績的預測結果。<br />
</p>

<p>
當樣本數不太多，而你的計算能力也不弱時，也許你可以手動將上述公式中的a與b求出，得到一條 \(y=ax+b\) 的迴歸線，但萬一樣本數有2000個點呢(如圖<a href="#orgcfc0986">25</a>)?<br />
</p>

<div id="orgcfc0986" class="figure">
<p><img src="images/cnn-regression-2.png" alt="cnn-regression-2.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 25: </span>2000個資料點</p>
</div>

<p>
接下來我們想建一個CNN模型來幫我們畫一條迴歸線。<br />
</p>
</div>
</div>
<div id="outline-container-orge62a43d" class="outline-3">
<h3 id="orge62a43d"><span class="section-number-3">5.2.</span> scikit learn的線性迴歸模組</h3>
<div class="outline-text-3" id="text-5-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> linear_model
<span class="linenr"> 2: </span><span style="color: #dcaeea;">regr</span>=linear_model.LinearRegression()
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">x</span> = x.reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25913;&#35722;x&#30340;&#26684;&#24335;&#24418;&#29376;&#65292;</span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21407;&#26412;x&#28858; [x1, x2, x3, ...]</span>
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35201;&#25913;&#26684;&#24335;&#31526;&#21512;scikit learn&#36852;&#27512;&#27169;&#32068;&#30340;&#38656;&#27714;&#65292;&#35722;&#25104;: [ [x1], [x2], [x3], ...]</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">y</span> = y.reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 9: </span>regr.fit(x, y)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30701;&#30701;&#20841;&#34892;code&#65292;&#27169;&#22411;&#24050;&#32147;&#24314;&#27083;&#23436;&#25104;&#20102;! &#25509;&#19979;&#20358;&#65292;&#25105;&#20497;&#20358;&#30475;&#30475;&#35347;&#32244;&#38598;&#30340;&#25104;&#26524;&#12290;</span>
<span class="linenr">12: </span>plt.clf()
<span class="linenr">13: </span>plt.scatter(x, y, s=<span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">14: </span>plt.plot(x, regr.predict(x), color=<span style="color: #98be65;">'red'</span>, linewidth=<span style="color: #da8548; font-weight: bold;">4</span>)
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"====&#23526;&#38555;(&#21069;&#19977;&#31558;)===="</span>)
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(y[:<span style="color: #da8548; font-weight: bold;">3</span>])
<span class="linenr">17: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"====&#38928;&#28204;(&#21069;&#19977;&#31558;)===="</span>)
<span class="linenr">18: </span><span style="color: #c678dd;">print</span>(regr.predict(x[:<span style="color: #da8548; font-weight: bold;">3</span>]))
</pre>
</div>

<pre class="example">
====實際(前三筆)====
[[85.07647921]
 [96.21107688]
 [90.60605344]]
====預測(前三筆)====
[[86.09718013]
 [98.58801576]
 [86.16764168]]
</pre>



<div id="org7a78ab4" class="figure">
<p><img src="images/cnn-regression-3.png" alt="cnn-regression-3.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 26: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-org33fb14f" class="outline-3">
<h3 id="org33fb14f"><span class="section-number-3">5.3.</span> 建立model來畫迴歸線</h3>
<div class="outline-text-3" id="text-5-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras.models <span style="color: #51afef;">import</span> Sequential
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras.layers <span style="color: #51afef;">import</span> Dense
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> keras.layers <span style="color: #51afef;">import</span> Dropout
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">A simple regression model</span>
<span class="linenr"> 6: </span><span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr"> 7: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">4</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 8: </span>model.add(Dropout(<span style="color: #da8548; font-weight: bold;">0.5</span>))
<span class="linenr"> 9: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">8</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr">10: </span>model.add(Dropout(<span style="color: #da8548; font-weight: bold;">0.5</span>))
<span class="linenr">11: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">1</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr">12: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'mse'</span>, optimizer=<span style="color: #98be65;">'rmsprop'</span>)
<span class="linenr">13: </span><span style="color: #c678dd;">print</span>(model)
</pre>
</div>

<pre class="example">
&lt;keras.src.engine.sequential.Sequential object at 0x28b748ca0&gt;
</pre>
</div>
</div>
<div id="outline-container-org3302773" class="outline-3">
<h3 id="org3302773"><span class="section-number-3">5.4.</span> 訓練model</h3>
<div class="outline-text-3" id="text-5-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#23526;&#38555;&#36039;&#26009;&#20998;&#28858;&#35347;&#32244;&#38598;&#33287;&#28204;&#35430;&#38598;</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">x_Train</span> = x[:<span style="color: #da8548; font-weight: bold;">1500</span>]
<span class="linenr"> 3: </span><span style="color: #dcaeea;">x_Test</span> = x[<span style="color: #da8548; font-weight: bold;">1500</span>:]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">y_Train</span> = y[:<span style="color: #da8548; font-weight: bold;">1500</span>]
<span class="linenr"> 5: </span><span style="color: #dcaeea;">y_Test</span> = y[<span style="color: #da8548; font-weight: bold;">1500</span>:]
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">The fit() method - trains the model</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">train_history</span> = model.fit(x=x_Train, y=y_Train,
<span class="linenr"> 8: </span>                          validation_split=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 9: </span>                          epochs=<span style="color: #da8548; font-weight: bold;">100</span>, batch_size=<span style="color: #da8548; font-weight: bold;">200</span>,
<span class="linenr">10: </span>                          verbose=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">11: </span><span style="color: #c678dd;">print</span>(train_history)
</pre>
</div>

<pre class="example" id="org199cdbe">
Epoch 1/100
6/6 [==============================] - 0s 6ms/step - loss: 2863.6062 - val_loss: 1743.6255
Epoch 2/100
...略...
Epoch 99/100
6/6 [==============================] - 0s 2ms/step - loss: 2085.9714 - val_loss: 656.8370
Epoch 100/100
6/6 [==============================] - 0s 2ms/step - loss: 2109.9709 - val_loss: 653.3618
&lt;keras.src.callbacks.History object at 0x28c3e2b80&gt;
</pre>
</div>
</div>
<div id="outline-container-orgc948c09" class="outline-3">
<h3 id="orgc948c09"><span class="section-number-3">5.5.</span> 查看訓練過程</h3>
<div class="outline-text-3" id="text-5-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #c678dd;">print</span>(train_history.history)
<span class="linenr"> 2: </span><span style="color: #c678dd;">print</span>(train_history.history.keys())
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 5: </span>plt.cla()
<span class="linenr"> 6: </span>plt.title(<span style="color: #98be65;">'Train History'</span>)
<span class="linenr"> 7: </span>plt.ylabel(<span style="color: #98be65;">'loss'</span>)
<span class="linenr"> 8: </span>plt.xlabel(<span style="color: #98be65;">'Epoch'</span>)
<span class="linenr"> 9: </span>plt.plot(train_history.history[<span style="color: #98be65;">'loss'</span>])
<span class="linenr">10: </span>plt.plot(train_history.history[<span style="color: #98be65;">'val_loss'</span>])
<span class="linenr">11: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">12: </span>plt.savefig(<span style="color: #98be65;">"images/cnn-regression-4.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<pre class="example">
{'loss': [2863.606201171875, 2763.04541015625, 2880.40478515625, 2777.246826171875, 2757.767822265625, 2793.475830078125, 2695.902099609375, 2780.853759765625, 2798.28662109375, 2807.108642578125, 2709.166748046875, 2592.2041015625, 2712.280517578125, 2761.0458984375, 2798.13427734375, 2561.240478515625, 2604.88623046875, 2587.8076171875, 2511.18505859375, 2582.03271484375, 2669.35595703125, 2598.029296875, 2667.6181640625, 2545.345703125, 2409.091552734375, 2577.706787109375, 2511.310791015625, 2462.844482421875, 2486.796875, 2600.557373046875, 2547.994140625, 2679.650634765625, 2535.125732421875, 2373.097412109375, 2493.5498046875, 2496.875732421875, 2429.0732421875, 2539.913818359375, 2375.737060546875, 2531.23193359375, 2364.086181640625, 2500.54638671875, 2466.4326171875, 2267.613525390625, 2501.35546875, 2486.72314453125, 2423.84326171875, 2494.4189453125, 2396.94580078125, 2485.988525390625, 2289.967529296875, 2407.2568359375, 2456.419677734375, 2434.612548828125, 2347.943115234375, 2332.21337890625, 2305.1826171875, 2243.403076171875, 2316.371337890625, 2303.15966796875, 2415.20751953125, 2330.21875, 2453.8359375, 2252.14794921875, 2296.7548828125, 2377.554931640625, 2240.637451171875, 2264.6640625, 2266.652587890625, 2216.469970703125, 2246.009521484375, 2368.211669921875, 2183.10546875, 2212.610107421875, 2208.70947265625, 2360.73583984375, 2349.56884765625, 2230.08740234375, 2123.85302734375, 2198.970947265625, 2208.628173828125, 2170.87646484375, 2142.40380859375, 2231.48828125, 2106.380126953125, 1994.4327392578125, 2083.111572265625, 2316.231201171875, 2183.566162109375, 2096.031005859375, 2137.7255859375, 2119.66162109375, 2163.564208984375, 2055.398681640625, 2071.734619140625, 2098.13671875, 2086.543701171875, 2050.818115234375, 2085.971435546875, 2109.970947265625], 'val_loss': [1743.62548828125, 1676.0625, 1622.7098388671875, 1554.9241943359375, 1505.2408447265625, 1452.3956298828125, 1383.53955078125, 1360.568115234375, 1328.6949462890625, 1292.880859375, 1256.500244140625, 1201.4288330078125, 1179.2587890625, 1171.0894775390625, 1154.2432861328125, 1125.0340576171875, 1108.9866943359375, 1087.2772216796875, 1055.875244140625, 1045.281005859375, 1036.374267578125, 1021.7939453125, 1022.4271850585938, 1018.1765747070312, 967.2241821289062, 982.8093872070312, 985.1171875, 956.1712646484375, 939.5418701171875, 927.49072265625, 924.7468872070312, 935.8602294921875, 952.6116943359375, 920.911865234375, 933.4141845703125, 919.3311157226562, 920.4298095703125, 908.8431396484375, 882.9320068359375, 881.1281127929688, 852.0545043945312, 875.4194946289062, 864.512939453125, 855.1522827148438, 862.8059692382812, 855.7294311523438, 853.6962280273438, 857.2517700195312, 849.6651000976562, 841.4896850585938, 861.3709106445312, 857.759521484375, 868.7303466796875, 859.9783325195312, 839.6546630859375, 845.3351440429688, 820.969970703125, 817.8179931640625, 798.3350219726562, 782.0546875, 787.7767944335938, 790.844970703125, 803.7584228515625, 790.1972045898438, 783.597900390625, 775.7128295898438, 777.0987548828125, 764.4354248046875, 746.651611328125, 732.0689086914062, 755.0868530273438, 757.199462890625, 754.501953125, 754.7967529296875, 722.3506469726562, 744.788818359375, 738.108154296875, 741.9891357421875, 734.1724243164062, 743.3819580078125, 718.5947875976562, 703.7750244140625, 681.1381225585938, 694.630859375, 690.3923950195312, 670.9759521484375, 656.1828002929688, 674.0592651367188, 698.1986083984375, 673.902099609375, 680.8800048828125, 687.5993041992188, 703.650634765625, 696.678955078125, 702.5635986328125, 689.4376831054688, 679.1995239257812, 664.786865234375, 656.8369750976562, 653.36181640625]}
dict_keys(['loss', 'val_loss'])
</pre>



<div id="org31ecd69" class="figure">
<p><img src="images/cnn-regression-4.png" alt="cnn-regression-4.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 27: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-orgbcf783d" class="outline-3">
<h3 id="orgbcf783d"><span class="section-number-3">5.6.</span> 評估model</h3>
<div class="outline-text-3" id="text-5-6">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">The evaluate() method - gets the loss statistics</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">score</span> = model.evaluate(x_Test, y_Test, batch_size=<span style="color: #da8548; font-weight: bold;">200</span>)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(score)
</pre>
</div>

<pre class="example">
3/3 [==============================] - 0s 990us/step - loss: 727.6573
727.6573486328125
</pre>
</div>
</div>
<div id="outline-container-orgc926fa6" class="outline-3">
<h3 id="orgc926fa6"><span class="section-number-3">5.7.</span> 預測結果</h3>
<div class="outline-text-3" id="text-5-7">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">The predict() method - predict the outputs for the given inputs</span>
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(y_Test[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(model.predict(x_Test[:<span style="color: #da8548; font-weight: bold;">5</span>]))
</pre>
</div>

<pre class="example" id="org012af0e">
[[92.71580667]
 [80.35926946]
 [94.14913803]
 [80.94617382]
 [94.81639264]]
1/1 [==============================] - 0s 87ms/step
[[74.310616]
 [49.009674]
 [75.51746 ]
 [54.195095]
 [68.86794 ]]
</pre>
</div>
</div>
<div id="outline-container-org9878384" class="outline-3">
<h3 id="org9878384"><span class="section-number-3">5.8.</span> 調整model/參數</h3>
<div class="outline-text-3" id="text-5-8">
<ul class="org-ul">
<li>model架構<br /></li>
<li>loss function<br /></li>
<li>optimizer<br /></li>
<li>hyper parameters<br /></li>
</ul>
</div>
<div id="outline-container-org19004d7" class="outline-4">
<h4 id="org19004d7"><span class="section-number-4">5.8.1.</span> case #1</h4>
<div class="outline-text-4" id="text-5-8-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">A simple regression model</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr"> 3: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">4</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 4: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">8</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 5: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">4</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 6: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">1</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 7: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'mean_squared_error'</span>, optimizer=<span style="color: #98be65;">'rmsprop'</span>)
<span class="linenr"> 8: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">mean_squared_logarithmic_error</span>
<span class="linenr"> 9: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">mean_absolute_percentage_error</span>
<span class="linenr">10: </span><span style="color: #dcaeea;">train_history</span> = model.fit(x=x_Train, y=y_Train,
<span class="linenr">11: </span>                          validation_split=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">12: </span>                          epochs=<span style="color: #da8548; font-weight: bold;">100</span>, batch_size=<span style="color: #da8548; font-weight: bold;">200</span>,
<span class="linenr">13: </span>                          verbose=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">14: </span><span style="color: #dcaeea;">score</span> = model.evaluate(x_Test, y_Test, batch_size=<span style="color: #da8548; font-weight: bold;">200</span>)
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(score)
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(y_Test[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span class="linenr">17: </span><span style="color: #c678dd;">print</span>(model.predict(x_Test[:<span style="color: #da8548; font-weight: bold;">5</span>]))
</pre>
</div>

<pre class="example" id="org7ff38fd">
3/3 [==============================] - 0s 769us/step - loss: 479.3994
479.3994140625
[[92.71580667]
 [80.35926946]
 [94.14913803]
 [80.94617382]
 [94.81639264]]
1/1 [==============================] - 0s 34ms/step
[[101.1277 ]
 [ 54.4739 ]
 [103.35307]
 [ 64.03558]
 [ 91.09165]]
</pre>
</div>
</div>
<div id="outline-container-org756fa3a" class="outline-4">
<h4 id="org756fa3a"><span class="section-number-4">5.8.2.</span> case #2</h4>
<div class="outline-text-4" id="text-5-8-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr"> 2: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">4</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 3: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">8</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 4: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">16</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 5: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">32</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 6: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">16</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 7: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">4</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 8: </span>model.add(Dense(<span style="color: #da8548; font-weight: bold;">1</span>, input_shape=(<span style="color: #da8548; font-weight: bold;">1</span>,)))
<span class="linenr"> 9: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'mse'</span>, optimizer=<span style="color: #98be65;">'rmsprop'</span>)
<span class="linenr">10: </span><span style="color: #dcaeea;">train_history</span> = model.fit(x=x_Train, y=y_Train,
<span class="linenr">11: </span>                          validation_split=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">12: </span>                          epochs=<span style="color: #da8548; font-weight: bold;">100</span>, batch_size=<span style="color: #da8548; font-weight: bold;">200</span>,
<span class="linenr">13: </span>                          verbose=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">14: </span><span style="color: #dcaeea;">score</span> = model.evaluate(x_Test, y_Test, batch_size=<span style="color: #da8548; font-weight: bold;">200</span>)
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(score)
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(y_Test[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span class="linenr">17: </span><span style="color: #c678dd;">print</span>(model.predict(x_Test[:<span style="color: #da8548; font-weight: bold;">5</span>]))
</pre>
</div>

<pre class="example" id="org6e776eb">
3/3 [==============================] - 0s 864us/step - loss: 14.2688
14.268836975097656
[[92.71580667]
 [80.35926946]
 [94.14913803]
 [80.94617382]
 [94.81639264]]
1/1 [==============================] - 0s 47ms/step
[[97.211815]
 [84.07756 ]
 [97.83831 ]
 [86.76943 ]
 [94.386406]]
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org2adb815" class="outline-2">
<h2 id="org2adb815"><span class="section-number-2">6.</span> 實作4[回家踹]: Cifar-10</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-orgd22d9b0" class="outline-3">
<h3 id="orgd22d9b0"><span class="section-number-3">6.1.</span> 資料集下載/預處理</h3>
<div class="outline-text-3" id="text-6-1">
<p>
回家執行：下載需要 <b>一點</b> 時間&#x2026;.<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">1.  Import Library</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> cifar10
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 4: </span>np.random.seed(<span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">2. &#36039;&#26009;&#28310;&#20633;</span>
<span class="linenr"> 7: </span>(x_img_train,y_label_train),(<span style="color: #dcaeea;">x_img_test</span>,<span style="color: #dcaeea;">y_label_test</span>) = cifar10.load_data()
<span class="linenr"> 8: </span><span style="color: #dcaeea;">x_img_train_normalize</span> = x_img_train.astype(<span style="color: #98be65;">'float32'</span>) / <span style="color: #da8548; font-weight: bold;">255.0</span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">x_img_test_normalize</span> = x_img_test.astype(<span style="color: #98be65;">'float32'</span>) / <span style="color: #da8548; font-weight: bold;">255.0</span>
<span class="linenr">10: </span><span style="color: #83898d;">'''&#27491;&#35215;&#21270;'''</span>
<span class="linenr">11: </span><span style="color: #51afef;">from</span> tensorflow.keras.utils <span style="color: #51afef;">import</span> to_categorical
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #dcaeea;">y_label_train_OneHot</span> = to_categorical(y_label_train)
<span class="linenr">14: </span><span style="color: #dcaeea;">y_label_test_OneHot</span> = to_categorical(y_label_test)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgdfab358" class="outline-3">
<h3 id="orgdfab358"><span class="section-number-3">6.2.</span> 建模</h3>
<div class="outline-text-3" id="text-6-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">3. &#24314;&#31435;&#27169;&#22411;</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 4: </span><span style="color: #98be65;">'''&#21367;&#31309;&#23652;1&#33287;&#27744;&#21270;&#23652;1'''</span>
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38568;&#27231;&#29986;&#29983;32&#20491;3*3&#30340;&#28670;&#37857;&#65292;&#36664;&#20837;&#30340;&#24433;&#20687;&#28858;32*32*3(RGB)</span>
<span class="linenr"> 6: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>model.add(layers.Conv2D(filters=<span style="color: #da8548; font-weight: bold;">32</span>,kernel_size=(<span style="color: #da8548; font-weight: bold;">3</span>,<span style="color: #da8548; font-weight: bold;">3</span>), input_shape=(<span style="color: #da8548; font-weight: bold;">32</span>, <span style="color: #da8548; font-weight: bold;">32</span>, <span style="color: #da8548; font-weight: bold;">3</span>),
<span class="linenr"> 9: </span>                 activation=<span style="color: #98be65;">'relu'</span>, padding=<span style="color: #98be65;">'same'</span>))
<span class="linenr">10: </span>model.add(layers.Dropout(rate=<span style="color: #da8548; font-weight: bold;">0.25</span>)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27599;&#27425;&#35347;&#32244;&#36845;&#20195;&#26178;&#26371;&#38568;&#27231;&#25918;&#26820;25%&#30340;&#31070;&#32147;&#20803;</span>
<span class="linenr">11: </span>model.add(layers.Conv2D(filters=<span style="color: #da8548; font-weight: bold;">32</span>, kernel_size=(<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>),
<span class="linenr">12: </span>                 activation=<span style="color: #98be65;">'relu'</span>, padding=<span style="color: #98be65;">'same'</span>))
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36914;&#34892;&#31532;&#19968;&#27425;&#32302;&#28187;&#21462;&#27171;&#65292;&#23559;&#24433;&#20687;&#32302;&#28858;16*16</span>
<span class="linenr">14: </span>model.add(layers.MaxPooling2D(pool_size=(<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr">15: </span><span style="color: #98be65;">'''&#21367;&#31309;&#23652;2&#33287;&#27744;&#21270;&#23652;2'''</span>
<span class="linenr">16: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#21069;&#19968;&#23652;&#20659;&#36914;&#30340;32&#20491;16*16&#24433;&#20687;&#36681;&#28858;64&#20491;16*16&#24433;&#20687;</span>
<span class="linenr">17: </span>model.add(layers.Conv2D(filters=<span style="color: #da8548; font-weight: bold;">64</span>, kernel_size=(<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), <span style="color: #5B6268;">### </span><span style="color: #5B6268;">&#29986;&#29983;64&#20491;&#24433;&#20687;</span>
<span class="linenr">18: </span>                 activation=<span style="color: #98be65;">'relu'</span>, padding=<span style="color: #98be65;">'same'</span>))
<span class="linenr">19: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.25</span>))
<span class="linenr">20: </span>model.add(layers.Conv2D(filters=<span style="color: #da8548; font-weight: bold;">64</span>, kernel_size=(<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>),
<span class="linenr">21: </span>                 activation=<span style="color: #98be65;">'relu'</span>, padding=<span style="color: #98be65;">'same'</span>))
<span class="linenr">22: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20877;&#23559;64&#20491;16*16&#24433;&#20687;&#32302;&#28187;&#21462;&#27171;&#28858;8*8</span>
<span class="linenr">23: </span>model.add(layers.MaxPooling2D(pool_size=(<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr">24: </span><span style="color: #98be65;">'''&#21367;&#31309;&#23652;3&#33287;&#27744;&#21270;&#23652;3'''</span>
<span class="linenr">25: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;64&#20491;8*8&#20491;&#24433;&#20687;&#36681;&#28858;128&#20491;</span>
<span class="linenr">26: </span>model.add(layers.Conv2D(filters=<span style="color: #da8548; font-weight: bold;">128</span>, kernel_size=(<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>),
<span class="linenr">27: </span>                 activation=<span style="color: #98be65;">'relu'</span>, padding=<span style="color: #98be65;">'same'</span>))
<span class="linenr">28: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.3</span>))
<span class="linenr">29: </span>model.add(layers.Conv2D(filters=<span style="color: #da8548; font-weight: bold;">128</span>, kernel_size=(<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>),
<span class="linenr">30: </span>                 activation=<span style="color: #98be65;">'relu'</span>, padding=<span style="color: #98be65;">'same'</span>))
<span class="linenr">31: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20877;&#23559;128&#20491;8*8&#24433;&#20687;&#32302;&#28187;&#21462;&#27171;&#28858;4*4</span>
<span class="linenr">32: </span>model.add(layers.MaxPooling2D(pool_size=(<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr">33: </span><span style="color: #98be65;">'''&#24314;&#31435;&#31070;&#32147;&#32178;&#36335;(&#24179;&#22374;&#23652;&#12289;&#38577;&#34255;&#23652;&#12289;&#36664;&#20986;&#23652;)'''</span>
<span class="linenr">34: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;128*4*4&#30340;3&#32173;&#30697;&#38499;&#36681;&#28858;1&#32173;(2048&#20491;float&#25976;&#23383;&#65292;&#23565;&#25033;&#21040;2048&#20491;&#31070;&#32147;&#20803;)</span>
<span class="linenr">35: </span>model.add(layers.Flatten())
<span class="linenr">36: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.3</span>))
<span class="linenr">37: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">2500</span>, activation=<span style="color: #98be65;">'relu'</span>)) <span style="color: #5B6268;">### </span><span style="color: #5B6268;">&#38560;&#34255;&#23652;1&#26377;2500&#20491;&#31070;&#32147;&#20803;</span>
<span class="linenr">38: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.3</span>))
<span class="linenr">39: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1500</span>, activation=<span style="color: #98be65;">'relu'</span>)) <span style="color: #5B6268;">### </span><span style="color: #5B6268;">&#38560;&#34255;&#23652;2&#26377;1500&#31070;&#32147;&#20803;</span>
<span class="linenr">40: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.3</span>))
<span class="linenr">41: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">10</span>, activation=<span style="color: #98be65;">'softmax'</span>)) <span style="color: #5B6268;">### </span><span style="color: #5B6268;">10&#20491;label</span>
<span class="linenr">42: </span><span style="color: #c678dd;">print</span>(model.summary())
</pre>
</div>

<pre class="example" id="orgf80b7ea">
Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_19 (Conv2D)          (None, 32, 32, 32)        896

 dropout_18 (Dropout)        (None, 32, 32, 32)        0

 conv2d_20 (Conv2D)          (None, 32, 32, 32)        9248

 max_pooling2d_9 (MaxPoolin  (None, 16, 16, 32)        0
 g2D)

 conv2d_21 (Conv2D)          (None, 16, 16, 64)        18496

 dropout_19 (Dropout)        (None, 16, 16, 64)        0

 conv2d_22 (Conv2D)          (None, 16, 16, 64)        36928

 max_pooling2d_10 (MaxPooli  (None, 8, 8, 64)          0
 ng2D)

 conv2d_23 (Conv2D)          (None, 8, 8, 128)         73856

 dropout_20 (Dropout)        (None, 8, 8, 128)         0

 conv2d_24 (Conv2D)          (None, 8, 8, 128)         147584

 max_pooling2d_11 (MaxPooli  (None, 4, 4, 128)         0
 ng2D)

 flatten_3 (Flatten)         (None, 2048)              0

 dropout_21 (Dropout)        (None, 2048)              0

 dense_9 (Dense)             (None, 2500)              5122500

 dropout_22 (Dropout)        (None, 2500)              0

 dense_10 (Dense)            (None, 1500)              3751500

 dropout_23 (Dropout)        (None, 1500)              0

 dense_11 (Dense)            (None, 10)                15010

=================================================================
Total params: 9176018 (35.00 MB)
Trainable params: 9176018 (35.00 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
None
</pre>
</div>
</div>
<div id="outline-container-org28fe402" class="outline-3">
<h3 id="org28fe402"><span class="section-number-3">6.3.</span> 訓練、評估</h3>
<div class="outline-text-3" id="text-6-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">4. &#36617;&#20837;&#20043;&#21069;&#35347;&#32244;&#30340;&#27169;&#22411;</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">try</span>:
<span class="linenr"> 3: </span>    model.load_weights(<span style="color: #98be65;">"SaveModel/cifarCnnModelnew1.h5"</span>)
<span class="linenr"> 4: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"&#36617;&#20837;&#27169;&#22411;&#25104;&#21151;!&#32380;&#32396;&#35347;&#32244;&#27169;&#22411;"</span>)
<span class="linenr"> 5: </span><span style="color: #51afef;">except</span>:
<span class="linenr"> 6: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"&#36617;&#20837;&#27169;&#22411;&#22833;&#25943;!&#38283;&#22987;&#35347;&#32244;&#19968;&#20491;&#26032;&#27169;&#22411;"</span>)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">5. &#35347;&#32244;&#27169;&#22411;</span>
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;&#21069;&#20808;&#20197;compile&#35373;&#23450;&#27169;&#22411;, &#35373;&#23450;&#20839;&#23481;&#21253;&#21547;</span>
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">1. &#25613;&#22833;&#20989;&#25976;, 2. &#26368;&#20339;&#21270;&#26041;&#27861;, 3. &#35413;&#20272;&#27169;&#22411;&#30340;&#26041;&#27861;</span>
<span class="linenr">11: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'categorical_crossentropy'</span>,
<span class="linenr">12: </span>              optimizer=<span style="color: #98be65;">'adam'</span>, metrics=[<span style="color: #98be65;">'accuracy'</span>])
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38283;&#22987;&#35347;&#32244;, &#22519;&#34892;50&#27425;&#35347;&#32244;&#36913;&#26399;&#12289;&#27599;&#19968;&#25209;&#27425;500&#31558;&#36039;&#26009;</span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">40000&#31558;&#36039;&#26009;&#65292;&#27599;&#19968;&#25209;&#27425;500&#31558;&#36039;&#26009;, &#20998;&#28858;80&#25209;&#27425;&#36914;&#34892;&#35347;&#32244;</span>
<span class="linenr">15: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27599;&#20491;epoch&#35347;&#32244;&#23436;&#24460;&#26371;&#23384;&#19968;&#31558;accuracy&#21644;loss&#35352;&#37636;&#21040;train_history</span>
<span class="linenr">16: </span><span style="color: #dcaeea;">train_history</span>=model.fit(x_img_train_normalize, y_label_train_OneHot,
<span class="linenr">17: </span>                        validation_split=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">18: </span>                        epochs=<span style="color: #da8548; font-weight: bold;">5</span>, batch_size=<span style="color: #da8548; font-weight: bold;">500</span>, verbose=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">19: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">20: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">show_train_history</span>(train_acc,test_acc):
<span class="linenr">21: </span>    plt.plot(train_history.history[train_acc])
<span class="linenr">22: </span>    plt.plot(train_history.history[test_acc])
<span class="linenr">23: </span>    plt.title(<span style="color: #98be65;">'Train History'</span>)
<span class="linenr">24: </span>    plt.ylabel(<span style="color: #98be65;">'Accuracy'</span>)
<span class="linenr">25: </span>    plt.xlabel(<span style="color: #98be65;">'Epoch'</span>)
<span class="linenr">26: </span>    plt.legend([<span style="color: #98be65;">'train'</span>, <span style="color: #98be65;">'test'</span>], loc=<span style="color: #98be65;">'upper left'</span>)
<span class="linenr">27: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">28: </span>show_train_history(<span style="color: #98be65;">'accuracy'</span>,<span style="color: #98be65;">'val_accuracy'</span>)
<span class="linenr">29: </span>
<span class="linenr">30: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">6. &#35413;&#20272;&#27169;&#22411;&#28310;&#30906;&#29575;</span>
<span class="linenr">31: </span><span style="color: #dcaeea;">scores</span> = model.evaluate(x_img_test_normalize,
<span class="linenr">32: </span>                        y_label_test_OneHot, verbose=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">33: </span><span style="color: #c678dd;">print</span>(scores[<span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr">34: </span>
<span class="linenr">35: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">7. &#36914;&#34892;&#38928;&#28204;</span>
<span class="linenr">36: </span><span style="color: #dcaeea;">prediction</span>=model.predict(x_img_test_normalize)
<span class="linenr">37: </span><span style="color: #c678dd;">print</span>(prediction[:<span style="color: #da8548; font-weight: bold;">10</span>])
</pre>
</div>

<pre class="example" id="org2dc8e8e">
載入模型失敗!開始訓練一個新模型
Epoch 1/5
80/80 [==============================] - 71s 879ms/step - loss: 1.9843 - accuracy: 0.2581 - val_loss: 2.0850 - val_accuracy: 0.2409
Epoch 2/5
80/80 [==============================] - 75s 934ms/step - loss: 1.5619 - accuracy: 0.4269 - val_loss: 1.6944 - val_accuracy: 0.3912
Epoch 3/5
80/80 [==============================] - 75s 937ms/step - loss: 1.3769 - accuracy: 0.4967 - val_loss: 1.5183 - val_accuracy: 0.4387
Epoch 4/5
80/80 [==============================] - 75s 938ms/step - loss: 1.2417 - accuracy: 0.5524 - val_loss: 1.2065 - val_accuracy: 0.5647
Epoch 5/5
80/80 [==============================] - 75s 944ms/step - loss: 1.1236 - accuracy: 0.5959 - val_loss: 1.1469 - val_accuracy: 0.5937
0.5929999947547913
313/313 [==============================] - 7s 21ms/step
[[6.46312302e-03 8.62431712e-03 2.74472516e-02 5.00399292e-01
  2.81555019e-02 9.06480253e-02 3.07343274e-01 4.68559610e-03
  2.12734081e-02 4.96020494e-03]
 [7.61443824e-02 3.05925645e-02 8.70503602e-04 7.35422189e-04
  8.07344739e-04 7.03643236e-05 3.87530803e-04 3.73235853e-05
  8.88279617e-01 2.07493710e-03]
 [2.19170123e-01 3.15457061e-02 2.23177653e-02 1.75716318e-02
  3.48090231e-02 5.49549609e-03 1.05224168e-02 3.76811461e-03
  6.39865100e-01 1.49346180e-02]
 [4.80774581e-01 5.90456650e-03 2.44085774e-01 1.69374775e-02
  1.14243045e-01 1.07119661e-02 1.00224596e-02 1.61196198e-02
  9.24141407e-02 8.78633745e-03]
 [5.03382122e-04 9.75311195e-05 6.01756126e-02 4.26706523e-02
  3.55109274e-01 6.51758304e-03 5.32512546e-01 2.19794596e-03
  1.07646527e-04 1.07893706e-04]
 [2.17650877e-03 6.94291375e-04 2.25894004e-02 6.15960397e-02
  2.69289650e-02 1.98316220e-02 8.60564947e-01 3.63973179e-03
  7.52524647e-04 1.22592552e-03]
 [7.00628571e-03 1.10443816e-01 2.33118124e-02 1.84527755e-01
  9.68367886e-03 1.67584091e-01 3.15246195e-01 1.13006774e-02
  1.70870777e-03 1.69187024e-01]
 [5.39396284e-03 2.00870680e-04 2.21061304e-01 5.73799871e-02
  2.93410629e-01 1.22425267e-02 4.05219078e-01 3.07954405e-03
  1.57088123e-03 4.41132550e-04]
 [7.44145736e-03 2.97625345e-04 2.10883513e-01 4.50782835e-01
  5.35527207e-02 2.20824048e-01 3.02264839e-02 2.32125558e-02
  1.64294522e-03 1.13576988e-03]
 [3.26189846e-02 7.81687021e-01 6.97707012e-03 4.02900390e-03
  3.50690144e-03 2.40204763e-03 1.28890313e-02 7.98477267e-04
  3.92462090e-02 1.15845300e-01]]
</pre>
</div>
</div>
<div id="outline-container-orge5feb75" class="outline-3">
<h3 id="orge5feb75"><span class="section-number-3">6.4.</span> 查看結果</h3>
<div class="outline-text-3" id="text-6-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">8. &#26597;&#30475;&#38928;&#28204;&#32080;&#26524;</span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">label_dict</span>={<span style="color: #da8548; font-weight: bold;">0</span>:<span style="color: #98be65;">"airplane"</span>,<span style="color: #da8548; font-weight: bold;">1</span>:<span style="color: #98be65;">"automobile"</span>,<span style="color: #da8548; font-weight: bold;">2</span>:<span style="color: #98be65;">"bird"</span>,<span style="color: #da8548; font-weight: bold;">3</span>:<span style="color: #98be65;">"cat"</span>,<span style="color: #da8548; font-weight: bold;">4</span>:<span style="color: #98be65;">"deer"</span>,
<span class="linenr"> 4: </span>            <span style="color: #da8548; font-weight: bold;">5</span>:<span style="color: #98be65;">"dog"</span>,<span style="color: #da8548; font-weight: bold;">6</span>:<span style="color: #98be65;">"frog"</span>,<span style="color: #da8548; font-weight: bold;">7</span>:<span style="color: #98be65;">"horse"</span>,<span style="color: #da8548; font-weight: bold;">8</span>:<span style="color: #98be65;">"ship"</span>,<span style="color: #da8548; font-weight: bold;">9</span>:<span style="color: #98be65;">"truck"</span>}
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 7: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_images_labels_prediction</span>(images,labels,prediction,idx,num=<span style="color: #da8548; font-weight: bold;">10</span>):
<span class="linenr"> 8: </span>    plt.cla()
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">fig</span> = plt.gcf()
<span class="linenr">10: </span>    fig.set_size_inches(<span style="color: #da8548; font-weight: bold;">12</span>, <span style="color: #da8548; font-weight: bold;">14</span>)
<span class="linenr">11: </span>    <span style="color: #51afef;">if</span> num&gt;<span style="color: #da8548; font-weight: bold;">25</span>: num=<span style="color: #da8548; font-weight: bold;">25</span>
<span class="linenr">12: </span>    <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>, num):
<span class="linenr">13: </span>        <span style="color: #dcaeea;">ax</span>=plt.subplot(<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">5</span>, <span style="color: #da8548; font-weight: bold;">1</span>+i)
<span class="linenr">14: </span>        ax.imshow(images[idx],cmap=<span style="color: #98be65;">'binary'</span>)
<span class="linenr">15: </span>        <span style="color: #dcaeea;">title</span> = <span style="color: #c678dd;">str</span>(i) + <span style="color: #98be65;">','</span> + label_dict[<span style="color: #c678dd;">int</span>(labels[idx][<span style="color: #da8548; font-weight: bold;">0</span>])]
<span class="linenr">16: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;labels[idx]&#36681;&#25563;&#28858;&#25972;&#25976;</span>
<span class="linenr">17: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">title=str(i)+','+label_dict[labels[i][0]]</span>
<span class="linenr">18: </span>        <span style="color: #51afef;">if</span> <span style="color: #c678dd;">len</span>(prediction)&gt;<span style="color: #da8548; font-weight: bold;">0</span>:
<span class="linenr">19: </span>            <span style="color: #dcaeea;">title</span>+=<span style="color: #98be65;">'=&gt;'</span>+label_dict[np.argmax(prediction[i])]
<span class="linenr">20: </span>        ax.set_title(title,fontsize=<span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">21: </span>        ax.set_xticks([]);ax.set_yticks([])
<span class="linenr">22: </span>        <span style="color: #dcaeea;">idx</span>+=<span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">23: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">24: </span>    plt.savefig(<span style="color: #98be65;">'images/cifar10-predict.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">25: </span>plot_images_labels_prediction(x_img_test,y_label_test,
<span class="linenr">26: </span>                              prediction,<span style="color: #da8548; font-weight: bold;">0</span>,<span style="color: #da8548; font-weight: bold;">10</span>)
</pre>
</div>


<div id="orge10d76f" class="figure">
<p><img src="images/cifar10-predict.png" alt="cifar10-predict.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 28: </span>Caption</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">9. &#26597;&#30475;&#38928;&#28204;&#27231;&#29575;</span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">Predicted_Probability</span>=model.predict(x_img_test_normalize)
<span class="linenr"> 4: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">show_Predicted_Probability</span>(y, prediction,
<span class="linenr"> 5: </span>                               x_img, Predicted_Probability, i):
<span class="linenr"> 6: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'label:'</span>,label_dict[y[i][<span style="color: #da8548; font-weight: bold;">0</span>]],
<span class="linenr"> 7: </span>          <span style="color: #98be65;">'predict:'</span>,label_dict[np.argmax(prediction[i])])
<span class="linenr"> 8: </span>    plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">2</span>,<span style="color: #da8548; font-weight: bold;">2</span>))
<span class="linenr"> 9: </span>    plt.imshow(np.reshape(x_img_test[i],(<span style="color: #da8548; font-weight: bold;">32</span>, <span style="color: #da8548; font-weight: bold;">32</span>, <span style="color: #da8548; font-weight: bold;">3</span>)))
<span class="linenr">10: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">11: </span>    plt.savefig(f<span style="color: #98be65;">'images/cifar10-predict-image-</span>{i}<span style="color: #98be65;">.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">12: </span>    <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'images/cifar10-predict-image-</span>{i}<span style="color: #98be65;">.png'</span>)
<span class="linenr">13: </span>    <span style="color: #51afef;">for</span> j <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">10</span>):
<span class="linenr">14: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">print(label_dict[j])</span>
<span class="linenr">15: </span>        <span style="color: #5B6268;">#</span><span style="color: #5B6268;">print(Predicted_Probability[i][j])</span>
<span class="linenr">16: </span>        <span style="color: #c678dd;">print</span>(label_dict[j]+
<span class="linenr">17: </span>              <span style="color: #98be65;">' Probability:%1.9f'</span>%(Predicted_Probability[i][j]))
<span class="linenr">18: </span>
<span class="linenr">19: </span>show_Predicted_Probability(y_label_test, prediction,
<span class="linenr">20: </span>                           x_img_test, Predicted_Probability, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">21: </span>show_Predicted_Probability(y_label_test, prediction,
<span class="linenr">22: </span>                           x_img_test, Predicted_Probability, <span style="color: #da8548; font-weight: bold;">3</span>)
</pre>
</div>

<pre class="example" id="org3e726ad">
313/313 [==============================] - 6s 20ms/step
label: cat predict: cat
images/cifar10-predict-image-0.png
airplane Probability:0.006463123
automobile Probability:0.008624317
bird Probability:0.027447252
cat Probability:0.500399292
deer Probability:0.028155502
dog Probability:0.090648025
frog Probability:0.307343274
horse Probability:0.004685596
ship Probability:0.021273408
truck Probability:0.004960205
label: airplane predict: airplane
images/cifar10-predict-image-3.png
airplane Probability:0.480774581
automobile Probability:0.005904566
bird Probability:0.244085774
cat Probability:0.016937478
deer Probability:0.114243045
dog Probability:0.010711966
frog Probability:0.010022460
horse Probability:0.016119620
ship Probability:0.092414141
truck Probability:0.008786337
</pre>


<div id="orgec339b8" class="figure">
<p><img src="images/cifar10-predict-image-0.png" alt="cifar10-predict-image-0.png" width="50" /><br />
</p>
<p><span class="figure-number">Figure 29: </span>Image 0</p>
</div>

<div id="org3454b80" class="figure">
<p><img src="images/cifar10-predict-image-3.png" alt="cifar10-predict-image-3.png" width="50" /><br />
</p>
<p><span class="figure-number">Figure 30: </span>Image 3</p>
</div>
</div>
</div>
<div id="outline-container-org8c83a69" class="outline-3">
<h3 id="org8c83a69"><span class="section-number-3">6.5.</span> 儲存模型</h3>
<div class="outline-text-3" id="text-6-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">10. confusion matrix</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 3: </span><span style="color: #c678dd;">print</span>(label_dict)
<span class="linenr"> 4: </span>pd.crosstab(y_label_test.reshape(-<span style="color: #da8548; font-weight: bold;">1</span>),np.argmax(prediction, axis=<span style="color: #da8548; font-weight: bold;">1</span>),
<span class="linenr"> 5: </span>            rownames=[<span style="color: #98be65;">'label'</span>],colnames=[<span style="color: #98be65;">'predict'</span>])
<span class="linenr"> 6: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">11. Save model to JSON</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">model_json</span> = model.to_json()
<span class="linenr"> 8: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">"Downloads/cifarCnnModelnew.json"</span>, <span style="color: #98be65;">"w"</span>) <span style="color: #51afef;">as</span> json_file:
<span class="linenr"> 9: </span>    json_file.write(model_json)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;">### </span><span style="color: #5B6268;">12. Save Weight to h5</span>
<span class="linenr">12: </span>model.save_weights(<span style="color: #98be65;">"Downloads/cifarCnnModelnew.h5"</span>)
<span class="linenr">13: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Saved model to disk"</span>)
</pre>
</div>

<pre class="example">
{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}
Saved model to disk
</pre>
</div>
</div>
</div>
<div id="outline-container-org6d6e6e2" class="outline-2">
<h2 id="org6d6e6e2"><span class="section-number-2">7.</span> [課堂練習][作業]&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-orgaec65dc" class="outline-3">
<h3 id="orgaec65dc"><span class="section-number-3">7.1.</span> [課堂練習]Regression&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h3>
<div class="outline-text-3" id="text-7-1">
<p>
現在來看看另一組較複雜的數據資料，請你試著自己建個模型來預測這些詭異的資料&#x2026;<br />
請參考<a href="20221023154410-regression.html#ID-6ae7fb7a-0b38-4448-b19f-073d262513f2">Regression</a><br />
</p>
</div>
<div id="outline-container-org5f03c26" class="outline-4">
<h4 id="org5f03c26"><span class="section-number-4">7.1.1.</span> 資料分佈</h4>
<div class="outline-text-4" id="text-7-1-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Seed the random number generator for reproducibility</span>
<span class="linenr"> 5: </span>np.random.seed(<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">x_data</span> = np.linspace(-<span style="color: #da8548; font-weight: bold;">10</span>, <span style="color: #da8548; font-weight: bold;">10</span>, num=<span style="color: #da8548; font-weight: bold;">2000</span>)
<span class="linenr"> 8: </span><span style="color: #dcaeea;">y_data</span> = <span style="color: #da8548; font-weight: bold;">2.9</span> * np.cos(<span style="color: #da8548; font-weight: bold;">0.6</span> * x_data) + np.random.normal(size=<span style="color: #c678dd;">len</span>(x_data))
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>plt.scatter(x_data, y_data, s=<span style="color: #da8548; font-weight: bold;">6</span>)
<span class="linenr">11: </span>plt.savefig(<span style="color: #98be65;">'images/random_curve.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="org75dd650" class="figure">
<p><img src="images/random_curve.png" alt="random_curve.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 31: </span>CNN迴歸練習</p>
</div>
</div>
</div>
</div>
<div id="outline-container-HomeWork-2" class="outline-3">
<h3 id="HomeWork-2"><span class="section-number-3">7.2.</span> [作業]病例預測&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h3>
<div class="outline-text-3" id="text-HomeWork-2">
</div>
<div id="outline-container-org535f055" class="outline-4">
<h4 id="org535f055"><span class="section-number-4">7.2.1.</span> 背景</h4>
<div class="outline-text-4" id="text-7-2-1">
<p>
某醫學研究中心針對旗下醫院800名疑似患有「無定向喪心病狂間歇性全身機能失調症」的患者做了一份病徵研究，針對以下這些可能病徵進行程度檢驗<br />
</p>
<ol class="org-ol">
<li>抑鬱<br /></li>
<li>癲癇<br /></li>
<li>精神分裂<br /></li>
<li>輕挑驕傲<br /></li>
<li>沒大沒小<br /></li>
<li>有犯罪傾向<br /></li>
<li>月經前緊張(男患者嚴重的話也有)<br /></li>
<li>有自殺傾向<br /></li>
</ol>
<p>
這800份資料可以<a href="https://letranger.github.io/downloads/qq.csv">點選這裡</a>下載，每筆資料有九個欄位，前八欄分別對應到上述八項病徵，最後一欄為0/1，代表病患是否患有該病。<br />
</p>

<p>
請你建立一個預測MODEL，以利該中心未來做檢測使用。將來只要遇到類似病情的個案，該醫院就能先針對這些特徵值進行檢測，並將檢測結果輸入此MODEL來預測個案是否為此病患者，並即時予以適當治療。<br />
</p>
</div>
</div>
<div id="outline-container-orgc6d999c" class="outline-4">
<h4 id="orgc6d999c"><span class="section-number-4">7.2.2.</span> 作業要求</h4>
<div class="outline-text-4" id="text-7-2-2">
<ul class="org-ul">
<li>嗯，基本上就是自由心證，你能交多少就交多少，你想只交一張圖也行，你要從頭交待你在做什麼、每一個步驟有啥意義、一共測了幾種CASE、最後成果如何、你的心得&#x2026;.也行，看你的誠意啦-_-(這向來是最坑人的一句話)<br /></li>
<li>我是這樣覺得啦&#x2026;MODEL積木隨便叠一叠，精確度至少也不應該低於 <b>0.8</b> 吧&#x2026;QQ<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org4846abf" class="outline-3">
<h3 id="org4846abf"><span class="section-number-3">7.3.</span> [作業]照片分類&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h3>
<div class="outline-text-3" id="text-7-3">
</div>
<div id="outline-container-orgdca099a" class="outline-4">
<h4 id="orgdca099a"><span class="section-number-4">7.3.1.</span> 基本要求</h4>
<div class="outline-text-4" id="text-7-3-1">
<ul class="org-ul">
<li>仿照MNist<br /></li>
<li>自行蒐集/生成要分類的圖片，例如：注音符號辨識<br /></li>
<li>需對圖片進行尺寸調整，並進行資料擴增<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgdd98e1e" class="outline-4">
<h4 id="orgdd98e1e"><span class="section-number-4">7.3.2.</span> 繳交項目</h4>
<div class="outline-text-4" id="text-7-3-2">
</div>
<div id="outline-container-orgefeec19" class="outline-5">
<h5 id="orgefeec19"><span class="section-number-5">7.3.2.1.</span> 影像辨識實驗(PDF):</h5>
<div class="outline-text-5" id="text-7-3-2-1">
<ul class="org-ul">
<li>組員名單、每個人所負責的項目(完全沒做事的組員就在項目後寫&ldquo;吉祥物&rdquo;)<br /></li>
<li>實驗目的<br /></li>
<li>實驗內容<br /></li>
<li>資料預處理的過程<br /></li>
<li>模型設計<br /></li>
<li>訓練過程<br /></li>
<li>訓練結果<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org0ea09b3" class="outline-4">
<h4 id="org0ea09b3"><span class="section-number-4">7.3.3.</span> Resources</h4>
<div class="outline-text-4" id="text-7-3-3">
</div>
<div id="outline-container-orgb593806" class="outline-5">
<h5 id="orgb593806"><span class="section-number-5">7.3.3.1.</span> 如何讀取自己的資料:  <a href="https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6">Loading Custom Image Dataset for Deep Learning Models: Part 1</a></h5>
</div>
<div id="outline-container-orgf108322" class="outline-5">
<h5 id="orgf108322"><span class="section-number-5">7.3.3.2.</span> Typical steps for loading custom dataset for Deep Learning Models</h5>
<div class="outline-text-5" id="text-7-3-3-2">
<ol class="org-ol">
<li>Open the image file. The format of the file can be JPEG, PNG, BMP, etc.<br /></li>
<li>Resize the image to match the input size for the Input layer of the Deep Learning model.<br /></li>
<li>Convert the image pixels to float datatype.<br /></li>
<li>Normalize the image to have pixel values scaled down between 0 and 1 from 0 to 255.<br /></li>
<li>Image data for Deep Learning models should be either a numpy array or a tensor object.<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org476960c" class="outline-5">
<h5 id="org476960c"><span class="section-number-5">7.3.3.3.</span> Data augmentation</h5>
<div class="outline-text-5" id="text-7-3-3-3">
<ul class="org-ul">
<li><a href="https://www.gushiciku.cn/pl/pL8p/zh-tw">Kaggle知識點：資料擴增方法</a><br /></li>
<li><a href="https://tw.leaderg.com/article/index?sn=11132">影像資料擴增 (Image Data Augmentation) 的原理與實作</a><br /></li>
<li><a href="https://iter01.com/465481.html">深度學習領域的資料增強</a><br /></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org28d8281" class="outline-2">
<h2 id="org28d8281"><span class="section-number-2">8.</span> 實作4: 真實世界圖片辨識</h2>
<div class="outline-text-2" id="text-8">
<p>
使用少量資料訓練影像分類在實務的電腦視覺應用上十分常見，此處所謂少量樣本從幾百到幾萬張都算在內。此處以 4000 張為例(2000 cats v.s. 2000 dogs)，過程中使用 2000 張來訓練、1000 張用來驗證、1000 張用來測試。接下來導入以下技術來克服 overfitting:<br />
</p>
<ul class="org-ul">
<li>資料擴增法(data augmentation):這是常用於減輕電腦視覺 overfitting 的強大技術，可以改善神經網路的成效，提升到 82%的準確率。<br /></li>
<li>預先訓練神經網路的特徵萃取法(feature extraction with a pretrained network):應用於少量資料集的基本技術，可使神經網路成效達到 90%~96%的準確度。<br /></li>
<li>微調預先訓練神經網路法(fine-tuning a pretrained network):也是常用於深度學習少量資料集的技術，將使神經網路準確率提升到 97%。<br /></li>
</ul>
</div>
<div id="outline-container-org24c815d" class="outline-3">
<h3 id="org24c815d"><span class="section-number-3">8.1.</span> 深度學習與少量資料的相關性</h3>
<div class="outline-text-3" id="text-8-1">
<p>
深度學習的基本特色是在它能自行在訓練資料中找到有趣的特徵，而不需要人為介入，但這只有在具備大量訓練樣本時才成立，特別是對於像圖片這類高維度(high-dimensional)的輸入樣本。所以也有人說深度學習一定要有大量資料才能進行。<br />
</p>

<p>
然而樣本數與神經網路的大小與深度息息相關。只用幾十個樣本不可能訓練出可以解決複雜問題的卷積神經網路；相反的，如果只是要用來解決簡單任務，而且已經做好了 well-regularized 的小 model，那麼幾百個樣本或許就足夠了。因為卷積神經網路可以學習局部 pattern 且具平移不變性，所以在感知問題上具有高度的資料效率性。<br />
</p>

<p>
此外，本質上，深度學習 model 是可高度再利用的。例如，使用大規模資料集訓練的影像 model 或語音轉文字的 model，只要進行小小的更改，便可以重新用於其他不同問題上。以電腦視覺的應用而言，許多預先訓練好的 model(通常是使用 Image-Net 資料集進行訓練)都是可公開下載的，以這些預先訓練好的 model 為基礎，再加以少量資料的訓練，就能產出更強大的 model。<br />
</p>
</div>
</div>
<div id="outline-container-orgdcbe932" class="outline-3">
<h3 id="orgdcbe932"><span class="section-number-3">8.2.</span> 實作</h3>
<div class="outline-text-3" id="text-8-2">
</div>
<div id="outline-container-orga8212d3" class="outline-4">
<h4 id="orga8212d3"><span class="section-number-4">8.2.1.</span> 下載資料</h4>
<div class="outline-text-4" id="text-8-2-1">
<p>
2013 年的 Kaggle 貓狗辨識大賽，最佳 model 即是使用 CNN，當時準確率達 95%，2013 年後的準確率已提高至 98%。本案例之資料來源：<a href="https://www.kaggle.com/c/dogs-vs-cats/data">https://www.kaggle.com/c/dogs-vs-cats/data</a>，由於原始圖片尺寸未做修改，大小各異，故需先額外處理。<br />
</p>

<p>
最終希望生成的資料夾架構如下:<br />
</p>


<div id="orge883468" class="figure">
<p><img src="images/實作4:_真實世界圖片辨識/2024-02-29_12-54-38_2024-02-29_12-52-33.png" alt="2024-02-29_12-54-38_2024-02-29_12-52-33.png" width="200" /><br />
</p>
<p><span class="figure-number">Figure 32: </span>原生資料、訓練用資料架構</p>
</div>

<p>
複製圖片到訓練、驗證和測試目錄的程式碼如下：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> os
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23560;&#26696;&#30340;&#26681;&#30446;&#37636;&#36335;&#24465;</span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">ROOT_DIR</span> = os.getcwd()
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32622;&#25918;coco&#22294;&#20687;&#36039;&#26009;&#33287;&#27161;&#35387;&#36039;&#26009;&#30340;&#30446;&#37636;</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">DATA_PATH</span> = os.path.join(ROOT_DIR, <span style="color: #98be65;">"/Volumes/LaCie/data"</span>)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #51afef;">import</span> os, shutil
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21407;&#22987;&#25976;&#25818;&#38598;&#30340;&#36335;&#24465;</span>
<span class="linenr">12: </span><span style="color: #dcaeea;">original_dataset_dir</span> = os.path.join(DATA_PATH, <span style="color: #98be65;">"raw"</span>)
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23384;&#20786;&#23567;&#25976;&#25818;&#38598;&#30340;&#30446;&#37636;</span>
<span class="linenr">15: </span><span style="color: #dcaeea;">base_dir</span> = os.path.join(DATA_PATH, <span style="color: #98be65;">"cats_and_dogs_small"</span>)
<span class="linenr">16: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(base_dir):
<span class="linenr">17: </span>    os.mkdir(base_dir)
<span class="linenr">18: </span>
<span class="linenr">19: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25105;&#20497;&#30340;&#35347;&#32244;&#36039;&#26009;&#30340;&#30446;&#37636;</span>
<span class="linenr">20: </span><span style="color: #dcaeea;">train_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'train'</span>)
<span class="linenr">21: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(train_dir):
<span class="linenr">22: </span>    os.mkdir(train_dir)
<span class="linenr">23: </span>
<span class="linenr">24: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25105;&#20497;&#30340;&#39511;&#35657;&#36039;&#26009;&#30340;&#30446;&#37636;</span>
<span class="linenr">25: </span><span style="color: #dcaeea;">validation_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'validation'</span>)
<span class="linenr">26: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(validation_dir):
<span class="linenr">27: </span>    os.mkdir(validation_dir)
<span class="linenr">28: </span>
<span class="linenr">29: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25105;&#20497;&#30340;&#28204;&#35430;&#36039;&#26009;&#30340;&#30446;&#37636;</span>
<span class="linenr">30: </span><span style="color: #dcaeea;">test_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'test'</span>)
<span class="linenr">31: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(test_dir):
<span class="linenr">32: </span>    os.mkdir(test_dir)
<span class="linenr">33: </span>
<span class="linenr">34: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35987;&#30340;&#22294;&#29255;&#30340;&#35347;&#32244;&#36039;&#26009;&#30446;&#37636;</span>
<span class="linenr">35: </span><span style="color: #dcaeea;">train_cats_dir</span> = os.path.join(train_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr">36: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(train_cats_dir):
<span class="linenr">37: </span>    os.mkdir(train_cats_dir)
<span class="linenr">38: </span>
<span class="linenr">39: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29399;&#30340;&#22294;&#29255;&#30340;&#35347;&#32244;&#36039;&#26009;&#30446;&#37636;</span>
<span class="linenr">40: </span><span style="color: #dcaeea;">train_dogs_dir</span> = os.path.join(train_dir, <span style="color: #98be65;">'dogs'</span>)
<span class="linenr">41: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(train_dogs_dir):
<span class="linenr">42: </span>    os.mkdir(train_dogs_dir)
<span class="linenr">43: </span>
<span class="linenr">44: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35987;&#30340;&#22294;&#29255;&#30340;&#39511;&#35657;&#36039;&#26009;&#30446;&#37636;</span>
<span class="linenr">45: </span><span style="color: #dcaeea;">validation_cats_dir</span> = os.path.join(validation_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr">46: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(validation_cats_dir):
<span class="linenr">47: </span>    os.mkdir(validation_cats_dir)
<span class="linenr">48: </span>
<span class="linenr">49: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29399;&#30340;&#22294;&#29255;&#30340;&#39511;&#35657;&#36039;&#26009;&#30446;&#37636;</span>
<span class="linenr">50: </span><span style="color: #dcaeea;">validation_dogs_dir</span> = os.path.join(validation_dir, <span style="color: #98be65;">'dogs'</span>)
<span class="linenr">51: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(validation_dogs_dir):
<span class="linenr">52: </span>    os.mkdir(validation_dogs_dir)
<span class="linenr">53: </span>
<span class="linenr">54: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35987;&#30340;&#22294;&#29255;&#30340;&#28204;&#35430;&#36039;&#26009;&#30446;&#37636;</span>
<span class="linenr">55: </span><span style="color: #dcaeea;">test_cats_dir</span> = os.path.join(test_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr">56: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(test_cats_dir):
<span class="linenr">57: </span>    os.mkdir(test_cats_dir)
<span class="linenr">58: </span>
<span class="linenr">59: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29399;&#30340;&#22294;&#29255;&#30340;&#28204;&#35430;&#36039;&#26009;&#30446;&#37636;</span>
<span class="linenr">60: </span><span style="color: #dcaeea;">test_dogs_dir</span> = os.path.join(test_dir, <span style="color: #98be65;">'dogs'</span>)
<span class="linenr">61: </span><span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(test_dogs_dir):
<span class="linenr">62: </span>    os.mkdir(test_dogs_dir)
</pre>
</div>
</div>
</div>
<div id="outline-container-org331f2ef" class="outline-4">
<h4 id="org331f2ef"><span class="section-number-4">8.2.2.</span> 分割資料集</h4>
<div class="outline-text-4" id="text-8-2-2">
<p>
以下程式會產生三組資料集：訓練集狗貓各 1000、驗證集各 500、測試集各 500，可再以下列程式驗證：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35079;&#35069;&#21069;1000&#20491;&#35987;&#30340;&#22294;&#29255;&#21040;train_cats_dir</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">fnames</span> = [<span style="color: #98be65;">'cat.{}.jpg'</span>.<span style="color: #c678dd;">format</span>(i) <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1000</span>)]
<span class="linenr"> 3: </span><span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> fnames:
<span class="linenr"> 4: </span>    <span style="color: #dcaeea;">src</span> = os.path.join(original_dataset_dir, fname)
<span class="linenr"> 5: </span>    <span style="color: #dcaeea;">dst</span> = os.path.join(train_cats_dir, fname)
<span class="linenr"> 6: </span>    <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(dst):
<span class="linenr"> 7: </span>        shutil.copyfile(src, dst)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Copy first 1000 cat images to train_cats_dir complete!'</span>)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35079;&#35069;&#19979;500&#20491;&#35987;&#30340;&#22294;&#29255;&#21040;validation_cats_dir</span>
<span class="linenr">12: </span><span style="color: #dcaeea;">fnames</span> = [<span style="color: #98be65;">'cat.{}.jpg'</span>.<span style="color: #c678dd;">format</span>(i) <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1000</span>, <span style="color: #da8548; font-weight: bold;">1500</span>)]
<span class="linenr">13: </span><span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> fnames:
<span class="linenr">14: </span>    <span style="color: #dcaeea;">src</span> = os.path.join(original_dataset_dir, fname)
<span class="linenr">15: </span>    <span style="color: #dcaeea;">dst</span> = os.path.join(validation_cats_dir, fname)
<span class="linenr">16: </span>    <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(dst):
<span class="linenr">17: </span>        shutil.copyfile(src, dst)
<span class="linenr">18: </span>
<span class="linenr">19: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Copy next 500 cat images to validation_cats_dir complete!'</span>)
<span class="linenr">20: </span>
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35079;&#35069;&#19979;500&#20491;&#35987;&#30340;&#22294;&#29255;&#21040;test_cats_dir</span>
<span class="linenr">22: </span><span style="color: #dcaeea;">fnames</span> = [<span style="color: #98be65;">'cat.{}.jpg'</span>.<span style="color: #c678dd;">format</span>(i) <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1500</span>, <span style="color: #da8548; font-weight: bold;">2000</span>)]
<span class="linenr">23: </span><span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> fnames:
<span class="linenr">24: </span>    <span style="color: #dcaeea;">src</span> = os.path.join(original_dataset_dir, fname)
<span class="linenr">25: </span>    <span style="color: #dcaeea;">dst</span> = os.path.join(test_cats_dir, fname)
<span class="linenr">26: </span>    <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(dst):
<span class="linenr">27: </span>        shutil.copyfile(src, dst)
<span class="linenr">28: </span>
<span class="linenr">29: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Copy next 500 cat images to test_cats_dir complete!'</span>)
<span class="linenr">30: </span>
<span class="linenr">31: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35079;&#35069;&#21069;1000&#20491;&#29399;&#30340;&#22294;&#29255;&#21040;train_dogs_dir</span>
<span class="linenr">32: </span><span style="color: #dcaeea;">fnames</span> = [<span style="color: #98be65;">'dog.{}.jpg'</span>.<span style="color: #c678dd;">format</span>(i) <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1000</span>)]
<span class="linenr">33: </span><span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> fnames:
<span class="linenr">34: </span>    <span style="color: #dcaeea;">src</span> = os.path.join(original_dataset_dir, fname)
<span class="linenr">35: </span>    <span style="color: #dcaeea;">dst</span> = os.path.join(train_dogs_dir, fname)
<span class="linenr">36: </span>    <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(dst):
<span class="linenr">37: </span>        shutil.copyfile(src, dst)
<span class="linenr">38: </span>
<span class="linenr">39: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Copy first 1000 dog images to train_dogs_dir complete!'</span>)
<span class="linenr">40: </span>
<span class="linenr">41: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35079;&#35069;&#19979;500&#20491;&#29399;&#30340;&#22294;&#29255;&#21040;validation_dogs_dir</span>
<span class="linenr">42: </span><span style="color: #dcaeea;">fnames</span> = [<span style="color: #98be65;">'dog.{}.jpg'</span>.<span style="color: #c678dd;">format</span>(i) <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1000</span>, <span style="color: #da8548; font-weight: bold;">1500</span>)]
<span class="linenr">43: </span><span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> fnames:
<span class="linenr">44: </span>    <span style="color: #dcaeea;">src</span> = os.path.join(original_dataset_dir, fname)
<span class="linenr">45: </span>    <span style="color: #dcaeea;">dst</span> = os.path.join(validation_dogs_dir, fname)
<span class="linenr">46: </span>    <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(dst):
<span class="linenr">47: </span>        shutil.copyfile(src, dst)
<span class="linenr">48: </span>
<span class="linenr">49: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Copy next 500 dog images to validation_dogs_dir complete!'</span>)
<span class="linenr">50: </span>
<span class="linenr">51: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">C&#35079;&#35069;&#19979;500&#20491;&#29399;&#30340;&#22294;&#29255;&#21040;test_dogs_dir</span>
<span class="linenr">52: </span><span style="color: #dcaeea;">fnames</span> = [<span style="color: #98be65;">'dog.{}.jpg'</span>.<span style="color: #c678dd;">format</span>(i) <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1500</span>, <span style="color: #da8548; font-weight: bold;">2000</span>)]
<span class="linenr">53: </span><span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> fnames:
<span class="linenr">54: </span>    <span style="color: #dcaeea;">src</span> = os.path.join(original_dataset_dir, fname)
<span class="linenr">55: </span>    <span style="color: #dcaeea;">dst</span> = os.path.join(test_dogs_dir, fname)
<span class="linenr">56: </span>    <span style="color: #51afef;">if</span> <span style="color: #51afef;">not</span> os.path.exists(dst):
<span class="linenr">57: </span>        shutil.copyfile(src, dst)
<span class="linenr">58: </span>
<span class="linenr">59: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Copy next 500 dog images to test_dogs_dir complete!'</span>)
</pre>
</div>

<pre class="example">
Copy first 1000 cat images to train_cats_dir complete!
Copy next 500 cat images to validation_cats_dir complete!
Copy next 500 cat images to test_cats_dir complete!
Copy first 1000 dog images to train_dogs_dir complete!
Copy next 500 dog images to validation_dogs_dir complete!
Copy next 500 dog images to test_dogs_dir complete!
</pre>
</div>
</div>
<div id="outline-container-org027e2d8" class="outline-4">
<h4 id="org027e2d8"><span class="section-number-4">8.2.3.</span> 刪除隱藏檔</h4>
<div class="outline-text-4" id="text-8-2-3">
<p>
只有macos需要<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> os
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23450;&#32681;&#20989;&#24335;&#20358;&#21034;&#38500;&#25351;&#23450;&#30446;&#37636;&#19979;&#25152;&#26377;&#20197; . &#38283;&#38957;&#30340;&#38577;&#34255;&#27284;&#26696;</span>
<span class="linenr"> 4: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">delete_hidden_files</span>(directory):
<span class="linenr"> 5: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36941;&#27511;&#25351;&#23450;&#30446;&#37636;&#19979;&#30340;&#25152;&#26377;&#27284;&#26696;&#21644;&#23376;&#30446;&#37636;</span>
<span class="linenr"> 6: </span>    <span style="color: #51afef;">for</span> root, dirs, files <span style="color: #51afef;">in</span> os.walk(directory):
<span class="linenr"> 7: </span>        <span style="color: #51afef;">for</span> <span style="color: #c678dd;">file</span> <span style="color: #51afef;">in</span> files:
<span class="linenr"> 8: </span>            <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22914;&#26524;&#27284;&#26696;&#21517;&#31281;&#20197; . &#38283;&#38957;&#65292;&#21063;&#21034;&#38500;&#23427;</span>
<span class="linenr"> 9: </span>            <span style="color: #51afef;">if</span> <span style="color: #c678dd;">file</span>.startswith(<span style="color: #98be65;">'.'</span>):
<span class="linenr">10: </span>                <span style="color: #dcaeea;">file_path</span> = os.path.join(root, <span style="color: #c678dd;">file</span>)
<span class="linenr">11: </span>                os.remove(file_path)
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21628;&#21483;&#20989;&#24335;&#20358;&#21034;&#38500;&#38577;&#34255;&#27284;&#26696;</span>
<span class="linenr">14: </span>delete_hidden_files(<span style="color: #98be65;">"/Volumes/LaCie/data/raw"</span>)
<span class="linenr">15: </span>delete_hidden_files(<span style="color: #98be65;">"/Volumes/LaCie/data/cats_and_dogs_small"</span>)
</pre>
</div>
</div>
</div>
<div id="outline-container-orga97bb73" class="outline-4">
<h4 id="orga97bb73"><span class="section-number-4">8.2.4.</span> 複檢檔案個數</h4>
<div class="outline-text-4" id="text-8-2-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'total training cat images:'</span>, <span style="color: #c678dd;">len</span>(os.listdir(train_cats_dir)))
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'total training dog images:'</span>, <span style="color: #c678dd;">len</span>(os.listdir(train_dogs_dir)))
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'total validation cat images:'</span>, <span style="color: #c678dd;">len</span>(os.listdir(validation_cats_dir)))
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'total validation dog images:'</span>, <span style="color: #c678dd;">len</span>(os.listdir(validation_dogs_dir)))
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'total test cat images:'</span>, <span style="color: #c678dd;">len</span>(os.listdir(test_cats_dir)))
<span class="linenr">6: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'total test dog images:'</span>, <span style="color: #c678dd;">len</span>(os.listdir(test_dogs_dir)))
</pre>
</div>

<pre class="example">
total training cat images: 1000
total training dog images: 1000
total validation cat images: 500
total validation dog images: 500
total test cat images: 500
total test dog images: 500
</pre>
</div>
</div>
<div id="outline-container-org82d0404" class="outline-4">
<h4 id="org82d0404"><span class="section-number-4">8.2.5.</span> 資料預處理</h4>
<div class="outline-text-4" id="text-8-2-5">
<p>
資料在送入神經網路前應先將 JPEG 檔案格式化成適當的浮點數張量，其步驟如下：<br />
</p>
<ol class="org-ol">
<li>讀取影像檔<br /></li>
<li>將 JPEG 內容解碼為 RGB 的像素<br /></li>
<li>將 RGB 像素轉為浮點數張量<br /></li>
<li>將像素值(0~255)壓縮到[0,1]區間<br /></li>
</ol>

<p>
上述過程可以用 Keras 的 keras.preprocessing.image 模組來處理，它包含 ImageDataGenerator 類別，過程如下：<br />
</p>
<div class="org-src-container">
<pre class="src src-python" id="orgc821cca"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25152;&#26377;&#30340;&#22294;&#20687;&#23559;&#37325;&#26032;&#34987;&#36914;&#34892;&#27512;&#19968;&#21270;&#34389;&#29702; Rescaled by 1./255</span>
<span id="coderef-ImageDataGenerator" class="coderef-off"><span class="linenr"> 4: </span><span style="color: #dcaeea;">train_datagen</span> = ImageDataGenerator(rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35373;&#23450;&#35347;&#32244;&#12289;&#28204;&#35430;&#36039;&#26009;&#30340; Python &#29986;&#29983;&#22120;&#65292;&#20006;&#23559;&#22294;&#29255;&#20687;&#32032;&#20540;&#20381; 1/255 &#27604;&#20363;&#37325;&#26032;&#22739;&#32302;&#21040; [0, 1]</span></span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">test_datagen</span> = ImageDataGenerator(rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30452;&#25509;&#24478;&#27284;&#26696;&#30446;&#37636;&#35712;&#21462;&#22294;&#20687;&#27284;&#36039;&#26009;</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">train_generator</span> = train_datagen.flow_from_directory(
<span class="linenr"> 9: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36889;&#26159;&#22294;&#20687;&#36039;&#26009;&#30340;&#30446;&#37636;</span>
<span class="linenr">10: </span>        train_dir,
<span class="linenr">11: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25152;&#26377;&#30340;&#22294;&#20687;&#22823;&#23567;&#26371;&#34987;&#36681;&#25563;&#25104;150x150</span>
<span class="linenr">12: </span>        target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>),
<span class="linenr">13: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27599;&#27425;&#29986;&#29983;20&#22294;&#20687;&#30340;&#25209;&#27425;&#36039;&#26009;</span>
<span class="linenr">14: </span>        batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr">15: </span>        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30001;&#26044;&#36889;&#26159;&#19968;&#20491;&#20108;&#20803;&#20998;&#39006;&#21839;&#38988;, y&#30340;lable&#20540;&#20063;&#26371;&#34987;&#36681;&#25563;&#25104;&#20108;&#20803;&#30340;&#27161;&#31844;</span>
<span class="linenr">16: </span>        class_mode=<span style="color: #98be65;">'binary'</span>)
<span class="linenr">17: </span>
<span class="linenr">18: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30452;&#25509;&#24478;&#27284;&#26696;&#30446;&#37636;&#35712;&#21462;&#22294;&#20687;&#27284;&#36039;&#26009;</span>
<span class="linenr">19: </span><span style="color: #dcaeea;">validation_generator</span> = test_datagen.flow_from_directory(
<span class="linenr">20: </span>        validation_dir,
<span class="linenr">21: </span>        target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>),
<span class="linenr">22: </span>        batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr">23: </span>        class_mode=<span style="color: #98be65;">'binary'</span>)
</pre>
</div>

<pre class="example">
Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
</pre>

<p>
查看照片<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">for</span> data_batch, labels_batch <span style="color: #51afef;">in</span> train_generator:
<span class="linenr">2: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'data batch shape:'</span>, data_batch.shape)
<span class="linenr">3: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'labels batch shape:'</span>, labels_batch.shape)
<span class="linenr">4: </span>    <span style="color: #51afef;">break</span>
</pre>
</div>

<pre class="example">
data batch shape: (20, 150, 150, 3)
labels batch shape: (20,)
</pre>


<p>
結果顯示每批次產生出的資料為 20 張 150&times;150 的 RGB 影像以及 20 個 label(即答案)，需留意的是此處的 generator 會無 止盡的生成批次量樣本，也就會不停的持續循環產生影像到目標目錄中，所以要放 break。而上述程式中的 ImageDataGenerator(第<a href="#coderef-ImageDataGenerator" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-ImageDataGenerator');" onmouseout="CodeHighlightOff(this, 'coderef-ImageDataGenerator');">4</a>行)是一種產生器(Generator)，在 Python 中是一個持續迭代運作的物件，是一個可以與 for&#x2026;in 一起使用的物件，產生器是使用 yield 建構的。典型的產生器範例如下：<br />
</p>
<div class="org-src-container">
<pre class="src src-python" id="org78f110e"><span class="linenr"> 1: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">generator</span>():
<span class="linenr"> 2: </span>    <span style="color: #dcaeea;">i</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr"> 3: </span>    <span style="color: #51afef;">while</span> <span style="color: #a9a1e1;">True</span>:
<span class="linenr"> 4: </span>        <span style="color: #dcaeea;">i</span> += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 5: </span>        <span style="color: #51afef;">yield</span> i
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #51afef;">for</span> item <span style="color: #51afef;">in</span> generator():
<span class="linenr"> 8: </span>    <span style="color: #c678dd;">print</span>(item)
<span class="linenr"> 9: </span>    <span style="color: #51afef;">if</span> item &gt; <span style="color: #da8548; font-weight: bold;">3</span>:
<span class="linenr">10: </span>        <span style="color: #51afef;">break</span>
</pre>
</div>

<pre class="example">
1
2
3
4
</pre>
</div>
</div>
<div id="outline-container-org7e42786" class="outline-4">
<h4 id="org7e42786"><span class="section-number-4">8.2.6.</span> 建立神經網路</h4>
<div class="outline-text-4" id="text-8-2-6">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 3: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr"> 4: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">32</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>,
<span class="linenr"> 5: </span>                        input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>)))
<span class="linenr"> 6: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 7: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">64</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 8: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 9: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">128</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">10: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr">11: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">128</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">12: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr">13: </span>model.add(layers.Flatten())
<span class="linenr">14: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">512</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">15: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1</span>, activation=<span style="color: #98be65;">'sigmoid'</span>))
<span class="linenr">16: </span>model.summary()  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26597;&#30475;&#27169;&#22411;&#25688;&#35201;</span>
</pre>
</div>

<pre class="example" id="orgc6e6a13">
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 148, 148, 32)      896

 max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0
 D)

 conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496

 max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0
 g2D)

 conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856

 max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0
 g2D)

 conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584

 max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0
 g2D)

 flatten (Flatten)           (None, 6272)              0

 dense (Dense)               (None, 512)               3211776

 dense_1 (Dense)             (None, 1)                 513

=================================================================
Total params: 3453121 (13.17 MB)
Trainable params: 3453121 (13.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre>
</div>
</div>
<div id="outline-container-org3568d9b" class="outline-4">
<h4 id="org3568d9b"><span class="section-number-4">8.2.7.</span> 訓練模型</h4>
<div class="outline-text-4" id="text-8-2-7">
<p>
建構好 model、整理完資料，接下來就可以調整 model 來搭配產生器所產生的資料，我們可以應用 model 的 fit_generator 方法，這個方法的第 1 個參數即是一個 Python 的產生器，然而由於資料是無止盡地產生，所以在宣告訓練時期之前，Keras model 需要知道從產生器抽取多少樣本，這就是 steps_per_epoch 參數的功能，它指定了從產生器取得的批次量，也就是說，model 在運行了 steps_per_epoch 次的梯度下降步驟後，訓練過程將進入下一個訓練週期(epochs)。在以下的例子中，每個批次量包含 20 個樣本，而目標樣本有 2000 個，所以就需要有 100 個批次量。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#37197;&#32622; model &#20197;&#36914;&#34892;&#35347;&#32244;</span>
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> optimizers
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'binary_crossentropy'</span>,
<span class="linenr"> 5: </span>              optimizer=optimizers.RMSprop(learning_rate=1e-<span style="color: #da8548; font-weight: bold;">4</span>),
<span class="linenr"> 6: </span>              metrics=[<span style="color: #98be65;">'acc'</span>])
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">history</span> = model.fit(
<span class="linenr"> 9: </span>    train_generator,   <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35373;&#23450;&#29986;&#29983;&#22120;</span>
<span class="linenr">10: </span>    steps_per_epoch=<span style="color: #da8548; font-weight: bold;">100</span>,   <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35373;&#23450;&#24478;&#29986;&#29983;&#22120;&#25277;&#21462;100&#20491;&#25209;&#27425;&#37327;</span>
<span class="linenr">11: </span>    epochs=<span style="color: #da8548; font-weight: bold;">30</span>, verbose=<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #5B6268;">#</span><span style="color: #5B6268;">verbose=1, &#19981;&#39023;&#31034;&#35347;&#32244;&#36942;&#31243;</span>
<span class="linenr">12: </span>    validation_data=validation_generator,
<span class="linenr">13: </span>    validation_steps=<span style="color: #da8548; font-weight: bold;">50</span>)
<span class="linenr">14: </span>
<span class="linenr">15: </span>model.save(<span style="color: #98be65;">'cats_and_dogs_small_i.h5'</span>)
</pre>
</div>

<pre class="example" id="orgbef26d3">
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.
Epoch 1/30
100/100 [==============================] - 19s 183ms/step - loss: 0.6925 - acc: 0.5325 - val_loss: 0.6839 - val_acc: 0.5910
Epoch 2/30
100/100 [==============================] - 19s 186ms/step - loss: 0.6794 - acc: 0.5655 - val_loss: 0.6703 - val_acc: 0.5570
Epoch 3/30
100/100 [==============================] - 20s 195ms/step - loss: 0.6570 - acc: 0.6160 - val_loss: 0.6497 - val_acc: 0.6100
Epoch 4/30
100/100 [==============================] - 20s 205ms/step - loss: 0.6314 - acc: 0.6425 - val_loss: 0.6204 - val_acc: 0.6510
Epoch 5/30
100/100 [==============================] - 20s 202ms/step - loss: 0.5973 - acc: 0.6805 - val_loss: 0.6142 - val_acc: 0.6550
Epoch 6/30
100/100 [==============================] - 21s 205ms/step - loss: 0.5708 - acc: 0.7005 - val_loss: 0.6006 - val_acc: 0.6720
Epoch 7/30
100/100 [==============================] - 21s 206ms/step - loss: 0.5496 - acc: 0.7200 - val_loss: 0.5847 - val_acc: 0.6830
Epoch 8/30
100/100 [==============================] - 21s 207ms/step - loss: 0.5374 - acc: 0.7305 - val_loss: 0.5858 - val_acc: 0.6810
Epoch 9/30
100/100 [==============================] - 21s 207ms/step - loss: 0.5207 - acc: 0.7360 - val_loss: 0.5729 - val_acc: 0.6890
Epoch 10/30
100/100 [==============================] - 21s 209ms/step - loss: 0.4929 - acc: 0.7475 - val_loss: 0.6003 - val_acc: 0.6790
Epoch 11/30
100/100 [==============================] - 21s 209ms/step - loss: 0.4752 - acc: 0.7720 - val_loss: 0.5594 - val_acc: 0.7030
Epoch 12/30
100/100 [==============================] - 21s 210ms/step - loss: 0.4528 - acc: 0.7920 - val_loss: 0.6129 - val_acc: 0.6820
Epoch 13/30
100/100 [==============================] - 21s 210ms/step - loss: 0.4314 - acc: 0.7945 - val_loss: 0.6598 - val_acc: 0.6560
Epoch 14/30
100/100 [==============================] - 21s 210ms/step - loss: 0.4089 - acc: 0.8115 - val_loss: 0.5471 - val_acc: 0.7180
Epoch 15/30
100/100 [==============================] - 21s 212ms/step - loss: 0.3870 - acc: 0.8290 - val_loss: 0.5317 - val_acc: 0.7360
Epoch 16/30
100/100 [==============================] - 21s 213ms/step - loss: 0.3602 - acc: 0.8460 - val_loss: 0.5530 - val_acc: 0.7200
Epoch 17/30
100/100 [==============================] - 21s 213ms/step - loss: 0.3459 - acc: 0.8545 - val_loss: 0.6352 - val_acc: 0.7050
Epoch 18/30
100/100 [==============================] - 21s 213ms/step - loss: 0.3171 - acc: 0.8785 - val_loss: 0.5586 - val_acc: 0.7340
Epoch 19/30
100/100 [==============================] - 22s 215ms/step - loss: 0.3034 - acc: 0.8735 - val_loss: 0.5616 - val_acc: 0.7380
Epoch 20/30
100/100 [==============================] - 23s 231ms/step - loss: 0.2810 - acc: 0.8795 - val_loss: 0.6145 - val_acc: 0.7240
Epoch 21/30
100/100 [==============================] - 22s 223ms/step - loss: 0.2573 - acc: 0.9030 - val_loss: 0.5821 - val_acc: 0.7300
Epoch 22/30
100/100 [==============================] - 23s 225ms/step - loss: 0.2400 - acc: 0.9080 - val_loss: 0.6027 - val_acc: 0.7320
Epoch 23/30
100/100 [==============================] - 22s 219ms/step - loss: 0.2166 - acc: 0.9195 - val_loss: 0.6185 - val_acc: 0.7360
Epoch 24/30
100/100 [==============================] - 23s 225ms/step - loss: 0.2017 - acc: 0.9250 - val_loss: 0.6237 - val_acc: 0.7390
Epoch 25/30
100/100 [==============================] - 22s 219ms/step - loss: 0.1797 - acc: 0.9350 - val_loss: 0.7119 - val_acc: 0.7260
Epoch 26/30
100/100 [==============================] - 22s 217ms/step - loss: 0.1644 - acc: 0.9385 - val_loss: 0.7026 - val_acc: 0.7290
Epoch 27/30
100/100 [==============================] - 22s 225ms/step - loss: 0.1365 - acc: 0.9590 - val_loss: 0.6876 - val_acc: 0.7400
Epoch 28/30
100/100 [==============================] - 22s 219ms/step - loss: 0.1319 - acc: 0.9570 - val_loss: 0.6853 - val_acc: 0.7420
Epoch 29/30
100/100 [==============================] - 22s 223ms/step - loss: 0.1172 - acc: 0.9630 - val_loss: 0.7569 - val_acc: 0.7270
Epoch 30/30
100/100 [==============================] - 22s 221ms/step - loss: 0.0980 - acc: 0.9705 - val_loss: 0.7442 - val_acc: 0.7420
/Users/letranger/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
</pre>

<p>
使用上述 fit_generator 時，還可以傳遞 validation_data 參數，此參數可以接收一個資料產生器，也可以接收 Numpy 陣列，如果接收的資料來自產生器，則還要指定 validation_steps 參數，告訴程式要從產生器中抽取多少次批量進行評估。在完成訓練後把 model 存起來，並繪製訓練週期與驗證週期的 model 損失值與準確度。<br />
</p>
</div>
</div>
<div id="outline-container-org01f287d" class="outline-4">
<h4 id="org01f287d"><span class="section-number-4">8.2.8.</span> 評估模型</h4>
<div class="outline-text-4" id="text-8-2-8">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">acc</span> = history.history[<span style="color: #98be65;">'acc'</span>]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">val_acc</span> = history.history[<span style="color: #98be65;">'val_acc'</span>]
<span class="linenr"> 5: </span><span style="color: #dcaeea;">loss</span> = history.history[<span style="color: #98be65;">'loss'</span>]
<span class="linenr"> 6: </span><span style="color: #dcaeea;">val_loss</span> = history.history[<span style="color: #98be65;">'val_loss'</span>]
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">epochs</span> = <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(acc) + <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>plt.clf()
<span class="linenr">11: </span>plt.plot(epochs, acc, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training acc'</span>)
<span class="linenr">12: </span>plt.plot(epochs, val_acc, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation acc'</span>)
<span class="linenr">13: </span>plt.title(<span style="color: #98be65;">'Training and validation accuracy'</span>)
<span class="linenr">14: </span>plt.legend()
<span class="linenr">15: </span>plt.plot()
<span class="linenr">16: </span>plt.savefig(<span style="color: #98be65;">"images/cats-and-dogs-accuracy-v1.png"</span>)
<span class="linenr">17: </span>plt.figure()
<span class="linenr">18: </span>
<span class="linenr">19: </span>plt.clf()
<span class="linenr">20: </span>plt.plot(epochs, loss, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training loss'</span>)
<span class="linenr">21: </span>plt.plot(epochs, val_loss, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation loss'</span>)
<span class="linenr">22: </span>plt.title(<span style="color: #98be65;">'Training and validation loss'</span>)
<span class="linenr">23: </span>plt.legend()
<span class="linenr">24: </span>plt.plot()
<span class="linenr">25: </span>plt.savefig(<span style="color: #98be65;">"images/cats-and-dogs-loss-v1.png"</span>)
</pre>
</div>


<div id="org7256cc6" class="figure">
<p><img src="images/cats-and-dogs-accuracy-v1.png" alt="cats-and-dogs-accuracy-v1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 33: </span>Cats and Dogs Accuracy V1</p>
</div>


<div id="org770d043" class="figure">
<p><img src="images/cats-and-dogs-loss-v1.png" alt="cats-and-dogs-loss-v1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 34: </span>Cats and Dogs Loss V1</p>
</div>

<p>
由圖<a href="#org7256cc6">33</a>看出訓練準確度成線性成長直到逼近 100%，但驗證準確度則在第三個訓練週期後就停留在 70%；訓練損失分數也呈線性下降，但驗證損失分數則約在第 12 週期後達到最低點。這些都是明顯的 overfitting 訊號。<br />
</p>

<p>
由於訓練樣本數(2000)相對較少，overfitting 將成為訓練 model 的首要顧慮因素，幾種緩解 overfitting 的技術有：<br />
</p>
<ul class="org-ul">
<li>dropout<br /></li>
<li>權重調整(L2 regularization)<br /></li>
<li>資料擴增法(data augmentation)<br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9d4e4c4" class="outline-3">
<h3 id="org9d4e4c4"><span class="section-number-3">8.3.</span> 改善#1: 資料擴增</h3>
<div class="outline-text-3" id="text-8-3">
<p>
Overfitting 的部份成因是由於樣本太少導致無法訓練出具備普適性、可套用到新資料的 model，想像一下如果有無限量的資料，則 model 將會因應用手邊資料的各種可能面向，也就不致於 overfitting。資料擴增(Data Augmentation)就是由現有訓練樣本生成更多訓練資料的方法，主要是透過隨機變換原始資料，以產生相似的影像，進而增加訓練樣本數。最終目標是在訓練時，model 不會看到兩次完全相同的影像。<br />
</p>

<p>
在 Keras 中，我們可以藉由設定 ImageDataGenerator，在讀取影像時執行隨機變換(random transformation)來達到資料擴增，至於變換的方向則可以在 ImageDataGenerator 的參數中進一步指定。以下例來看：<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">datagen</span> = ImageDataGenerator(
<span class="linenr">2: </span>    rotation_range=<span style="color: #da8548; font-weight: bold;">40</span>,       <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#26059;&#36681;&#35282;&#24230;&#20540;(0~180)</span>
<span class="linenr">3: </span>    width_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,   <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#27700;&#24179;&#38568;&#27231;&#24179;&#31227;(&#22294;&#29255;&#23532;&#24230;&#20043;&#30334;&#20998;&#27604;)</span>
<span class="linenr">4: </span>    height_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#22402;&#30452;&#38568;&#27231;&#24179;&#31227;(&#22294;&#29255;&#39640;&#24230;&#20043;&#30334;&#20998;&#27604;)</span>
<span class="linenr">5: </span>    shear_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,         <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38568;&#27231;&#20670;&#26012;(&#38918;&#26178;&#37912;&#20670;&#26012;&#35282;&#24230;)</span>
<span class="linenr">6: </span>    zoom_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,          <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38568;&#27231;&#32302;&#25918;(&#32302;&#25918;&#30334;&#20998;&#27604;)</span>
<span class="linenr">7: </span>    horizontal_flip=<span style="color: #a9a1e1;">True</span>,    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38568;&#27231;&#27700;&#24179;&#32763;&#36681;(&#24433;&#20687;&#38750;&#24038;&#21491;&#23565;&#31281;&#25165;&#26377;&#25928;)</span>
<span class="linenr">8: </span>    fill_mode=<span style="color: #98be65;">'nearest'</span>)     <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#26032;&#24314;&#24433;&#20687;&#22635;&#35036;&#20687;&#32032;&#26041;&#27861;</span>
</pre>
</div>

<p>
上述程式之 fill__mode 共提供四種像素填補方法：<br />
</p>
<ul class="org-ul">
<li>constant: 依照輸入的 cval(浮點數或整數)將影像邊界之外都以該值填補，例如 cval=k，則影像填補為 kkkkkkkk|abcd|kkkkkkkk<br /></li>
<li>nearest: 以最接近的像素值填補，如：aaaaaaaa|abcd|dddddddd<br /></li>
<li>reflect: 以影像重複填補(影像以一正一反方向)，如 abcddcba|abcd|dcbaabcd<br /></li>
<li>wrap: 以影像重複填補，如：abcdabcd|abcd|abcdabcd<br /></li>
</ul>

<p>
以下為實際運作的示範：<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> matplotlib
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> platform
<span class="linenr"> 3: </span><span style="color: #51afef;">if</span> platform.system() == <span style="color: #98be65;">'Darwin'</span>:
<span class="linenr"> 4: </span>    matplotlib.use(<span style="color: #98be65;">'MacOSX'</span>)
<span class="linenr"> 5: </span><span style="color: #51afef;">else</span>:
<span class="linenr"> 6: </span>    matplotlib.use(<span style="color: #98be65;">'TkAgg'</span>)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #dcaeea;">datagen</span> = ImageDataGenerator(
<span class="linenr">11: </span>    rotation_range=<span style="color: #da8548; font-weight: bold;">40</span>,       <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#26059;&#36681;&#35282;&#24230;&#20540;(0~180)</span>
<span class="linenr">12: </span>    width_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,   <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#27700;&#24179;&#38568;&#27231;&#24179;&#31227;(&#22294;&#29255;&#23532;&#24230;&#20043;&#30334;&#20998;&#27604;)</span>
<span class="linenr">13: </span>    height_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#22402;&#30452;&#38568;&#27231;&#24179;&#31227;(&#22294;&#29255;&#39640;&#24230;&#20043;&#30334;&#20998;&#27604;)</span>
<span class="linenr">14: </span>    shear_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,         <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38568;&#27231;&#20670;&#26012;(&#38918;&#26178;&#37912;&#20670;&#26012;&#35282;&#24230;)</span>
<span class="linenr">15: </span>    zoom_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,          <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38568;&#27231;&#32302;&#25918;(&#32302;&#25918;&#30334;&#20998;&#27604;)</span>
<span class="linenr">16: </span>    horizontal_flip=<span style="color: #a9a1e1;">True</span>,    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38568;&#27231;&#27700;&#24179;&#32763;&#36681;(&#24433;&#20687;&#38750;&#24038;&#21491;&#23565;&#31281;&#25165;&#26377;&#25928;)</span>
<span class="linenr">17: </span>    fill_mode=<span style="color: #98be65;">'nearest'</span>)     <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#26032;&#24314;&#24433;&#20687;&#22635;&#35036;&#20687;&#32032;&#26041;&#27861;</span>
<span class="linenr">18: </span>
<span class="linenr">19: </span><span style="color: #51afef;">import</span> os, shutil
<span class="linenr">20: </span>
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35299;&#22739;&#32302;&#36039;&#26009;&#22846;&#25152;&#22312;&#30340;&#30446;&#37636;&#36335;&#24465;(&#20197;&#35347;&#32244;&#38598;&#20013;&#30340;&#35987;&#28858;&#20363;)</span>
<span class="linenr">22: </span><span style="color: #dcaeea;">train_cats_dir</span> = os.path.join(train_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr">23: </span>
<span class="linenr">24: </span><span style="color: #51afef;">from</span> keras.preprocessing <span style="color: #51afef;">import</span> image
<span class="linenr">25: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">26: </span>
<span class="linenr">27: </span><span style="color: #dcaeea;">fnames</span> = [os.path.join(train_cats_dir, fname) <span style="color: #51afef;">for</span> fname <span style="color: #51afef;">in</span> os.listdir(train_cats_dir)]
<span class="linenr">28: </span>
<span class="linenr">29: </span><span style="color: #dcaeea;">img_path</span> = fnames[<span style="color: #da8548; font-weight: bold;">3</span>] <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#36984;&#19968;&#24373;&#24433;&#20687;&#20358;&#25844;&#20805;</span>
<span class="linenr">30: </span><span style="color: #c678dd;">print</span>(img_path)
<span class="linenr">31: </span>
<span class="linenr">32: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35712;&#21462;&#24433;&#20687;&#12289;&#35519;&#25972;&#22823;&#23567;</span>
<span class="linenr">33: </span><span style="color: #dcaeea;">img</span> = image.load_img(img_path, target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>))
<span class="linenr">34: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#23559;&#20854;&#35519;&#25972;&#28858;shape=(150, 150, 3)</span>
<span class="linenr">35: </span><span style="color: #dcaeea;">x</span> = image.img_to_array(img)
<span class="linenr">36: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35519;&#25972;shape&#28858;(1, 150, 150, 3)</span>
<span class="linenr">37: </span><span style="color: #dcaeea;">x</span> = x.reshape((<span style="color: #da8548; font-weight: bold;">1</span>, ) + x.shape)
<span class="linenr">38: </span><span style="color: #c678dd;">print</span>(x.shape)
<span class="linenr">39: </span>
<span class="linenr">40: </span><span style="color: #dcaeea;">i</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">41: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32362;&#35069;model&#30340;&#25613;&#22833;&#29575;&#33287;&#31934;&#30906;&#29575;</span>
<span class="linenr">42: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">43: </span>
<span class="linenr">44: </span><span style="color: #51afef;">for</span> batch <span style="color: #51afef;">in</span> datagen.flow(x, batch_size=<span style="color: #da8548; font-weight: bold;">1</span>):
<span class="linenr">45: </span>    plt.figure(i)
<span class="linenr">46: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">imgplot = plt.imshow(image.array_to_img(batch[0]))</span>
<span class="linenr">47: </span>    plt.imshow(image.array_to_img(batch[<span style="color: #da8548; font-weight: bold;">0</span>]))
<span class="linenr">48: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.clf()</span>
<span class="linenr">49: </span>    plt.plot()
<span class="linenr">50: </span>    plt.savefig(<span style="color: #98be65;">"CatsAugmentation"</span>+<span style="color: #c678dd;">str</span>(i)+<span style="color: #98be65;">".png"</span>)
<span class="linenr">51: </span>    <span style="color: #dcaeea;">i</span> += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">52: </span>    <span style="color: #51afef;">if</span> i % <span style="color: #da8548; font-weight: bold;">4</span> == <span style="color: #da8548; font-weight: bold;">0</span>:
<span class="linenr">53: </span>        <span style="color: #51afef;">break</span>
<span class="linenr">54: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">55: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig("CatsAugmentation.png")</span>
</pre>
</div>

<pre class="example">
/Volumes/LaCie/data/cats_and_dogs_small/train/cats/cat.3.jpg
(1, 150, 150, 3)
</pre>



<div id="org2e8489f" class="figure">
<p><img src="images/CatsAugmentation0.png" alt="CatsAugmentation0.png" width="400" /><br />
</p>
<p><span class="figure-number">Figure 35: </span>Cats image augmentation</p>
</div>


<div id="org679bdcb" class="figure">
<p><img src="images/CatsAugmentation1.png" alt="CatsAugmentation1.png" width="400" /><br />
</p>
<p><span class="figure-number">Figure 36: </span>Cats image augmentation</p>
</div>


<div id="org3fd1fd4" class="figure">
<p><img src="images/CatsAugmentation2.png" alt="CatsAugmentation2.png" width="400" /><br />
</p>
<p><span class="figure-number">Figure 37: </span>Cats image augmentation</p>
</div>


<div id="org44d5519" class="figure">
<p><img src="images/CatsAugmentation3.png" alt="CatsAugmentation3.png" width="400" /><br />
</p>
<p><span class="figure-number">Figure 38: </span>Cats image augmentation</p>
</div>

<p>
雖然資料擴增能擴充來自少量的原始圖片，但終究無法自行產生資訊，只能重新混合現有資訊，影像間仍是高度相關，仍不足以完全擺脫 overfitting 問題，所以進一步在密集連接的分類器前，在 model 中增加 Dropout 層(Fatten 層後)。<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">  1: </span><span style="color: #51afef;">import</span> matplotlib
<span class="linenr">  2: </span><span style="color: #51afef;">import</span> platform
<span class="linenr">  3: </span><span style="color: #51afef;">if</span> platform.system() == <span style="color: #98be65;">'Darwin'</span>:
<span class="linenr">  4: </span>    matplotlib.use(<span style="color: #98be65;">'MacOSX'</span>)
<span class="linenr">  5: </span><span style="color: #51afef;">else</span>:
<span class="linenr">  6: </span>    matplotlib.use(<span style="color: #98be65;">'TkAgg'</span>)
<span class="linenr">  7: </span>
<span class="linenr">  8: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr">  9: </span>
<span class="linenr"> 10: </span><span style="color: #51afef;">import</span> os, shutil
<span class="linenr"> 11: </span>
<span class="linenr"> 12: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35299;&#22739;&#32302;&#36039;&#26009;&#22846;&#25152;&#22312;&#30340;&#30446;&#37636;&#36335;&#24465;</span>
<span class="linenr"> 13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21443;&#32771;&#21407;&#31243;&#24335;&#30340;&#36335;&#24465;</span>
<span class="linenr"> 14: </span>
<span class="linenr"> 15: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#25286;&#25104;&#35347;&#32244;&#12289;&#39511;&#35657;&#33287;&#28204;&#35430;&#30446;&#37636;&#20301;&#32622;</span>
<span class="linenr"> 16: </span><span style="color: #dcaeea;">train_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'train'</span>)
<span class="linenr"> 17: </span><span style="color: #dcaeea;">validation_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'validation'</span>)
<span class="linenr"> 18: </span><span style="color: #dcaeea;">test_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'test'</span>)
<span class="linenr"> 19: </span><span style="color: #dcaeea;">train_cats_dir</span> = os.path.join(train_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr"> 20: </span><span style="color: #dcaeea;">train_dogs_dir</span> = os.path.join(train_dir, <span style="color: #98be65;">'dogs'</span>)
<span class="linenr"> 21: </span><span style="color: #dcaeea;">validation_cats_dir</span> = os.path.join(validation_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr"> 22: </span><span style="color: #dcaeea;">validation_dogs_dir</span> = os.path.join(validation_dir, <span style="color: #98be65;">'dogs'</span>)
<span class="linenr"> 23: </span><span style="color: #dcaeea;">test_cats_dir</span> = os.path.join(test_dir, <span style="color: #98be65;">'cats'</span>)
<span class="linenr"> 24: </span><span style="color: #dcaeea;">test_dogs_dir</span> = os.path.join(test_dir, <span style="color: #98be65;">'dogs'</span>)
<span class="linenr"> 25: </span>
<span class="linenr"> 26: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24314;&#31435;&#27169;&#32068;</span>
<span class="linenr"> 27: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 28: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 29: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> regularizers
<span class="linenr"> 30: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr"> 31: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">32</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>,
<span class="linenr"> 32: </span>                        input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>)))
<span class="linenr"> 33: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 34: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">64</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 35: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 36: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">128</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 37: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 38: </span>model.add(layers.Conv2D(<span style="color: #da8548; font-weight: bold;">128</span>, (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">3</span>), activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 39: </span>model.add(layers.MaxPooling2D((<span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">2</span>)))
<span class="linenr"> 40: </span>model.add(layers.Flatten())
<span class="linenr"> 41: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.5</span>))
<span class="linenr"> 42: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">512</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 43: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1</span>, activation=<span style="color: #98be65;">'sigmoid'</span>))
<span class="linenr"> 44: </span>model.summary()  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26597;&#30475;&#27169;&#22411;&#25688;&#35201;</span>
<span class="linenr"> 45: </span>
<span class="linenr"> 46: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#37197;&#32622; model &#20197;&#36914;&#34892;&#35347;&#32244;</span>
<span class="linenr"> 47: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> optimizers
<span class="linenr"> 48: </span>
<span class="linenr"> 49: </span>model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'binary_crossentropy'</span>,
<span class="linenr"> 50: </span>              optimizer=optimizers.RMSprop(learning_rate=1e-<span style="color: #da8548; font-weight: bold;">4</span>),
<span class="linenr"> 51: </span>              metrics=[<span style="color: #98be65;">'acc'</span>])
<span class="linenr"> 52: </span>
<span class="linenr"> 53: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#36039;&#26009;&#25844;&#22686;</span>
<span class="linenr"> 54: </span><span style="color: #dcaeea;">train_datagen</span> = ImageDataGenerator(
<span class="linenr"> 55: </span>    rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>,
<span class="linenr"> 56: </span>    rotation_range=<span style="color: #da8548; font-weight: bold;">40</span>,
<span class="linenr"> 57: </span>    width_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 58: </span>    height_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 59: </span>    shear_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 60: </span>    zoom_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 61: </span>    horizontal_flip=<span style="color: #a9a1e1;">True</span>, )
<span class="linenr"> 62: </span>
<span class="linenr"> 63: </span><span style="color: #dcaeea;">test_datagen</span> = ImageDataGenerator(rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35531;&#27880;&#24847;&#65281;&#39511;&#35657;&#36039;&#26009;&#19981;&#25033;&#35442;&#25844;&#20805;!!!</span>
<span class="linenr"> 64: </span>
<span class="linenr"> 65: </span><span style="color: #dcaeea;">train_generator</span> = train_datagen.flow_from_directory(
<span class="linenr"> 66: </span>  train_dir,    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30446;&#27161;&#30446;&#37636;</span>
<span class="linenr"> 67: </span>  target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>), <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25152;&#26377;&#22294;&#20687;&#22823;&#23567;&#35519;&#25972;&#25104; 150&#215;150</span>
<span class="linenr"> 68: </span>  batch_size=<span style="color: #da8548; font-weight: bold;">32</span>,
<span class="linenr"> 69: </span>  class_mode=<span style="color: #98be65;">'binary'</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22240;&#28858;&#20351;&#29992;&#20108;&#20803;&#20132;&#21449;&#29109; binary_crossentropy &#20316;&#28858;&#25613;&#22833;&#65292;&#25152;&#20197;&#38656;&#35201;&#20108;&#20803;&#27161;&#31844;</span>
<span class="linenr"> 70: </span>
<span class="linenr"> 71: </span><span style="color: #dcaeea;">validation_generator</span> = test_datagen.flow_from_directory(
<span class="linenr"> 72: </span>  validation_dir,
<span class="linenr"> 73: </span>  target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>),
<span class="linenr"> 74: </span>  batch_size=<span style="color: #da8548; font-weight: bold;">32</span>,
<span class="linenr"> 75: </span>  class_mode=<span style="color: #98be65;">'binary'</span>)
<span class="linenr"> 76: </span>
<span class="linenr"> 77: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;</span>
<span class="linenr"> 78: </span><span style="color: #dcaeea;">history</span> = model.fit_generator(
<span class="linenr"> 79: </span>  train_generator,
<span class="linenr"> 80: </span>  epochs=<span style="color: #da8548; font-weight: bold;">50</span>, verbose=<span style="color: #da8548; font-weight: bold;">1</span>,
<span class="linenr"> 81: </span>  validation_data=validation_generator,
<span class="linenr"> 82: </span>  validation_steps=<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 83: </span>
<span class="linenr"> 84: </span>model.save(<span style="color: #98be65;">'cats_and_dogs_small_data_augmentation.h5'</span>)
<span class="linenr"> 85: </span>
<span class="linenr"> 86: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32362;&#35069;model&#30340;&#25613;&#22833;&#29575;&#33287;&#31934;&#30906;&#29575;</span>
<span class="linenr"> 87: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 88: </span>
<span class="linenr"> 89: </span><span style="color: #dcaeea;">acc</span> = history.history[<span style="color: #98be65;">'acc'</span>]
<span class="linenr"> 90: </span><span style="color: #dcaeea;">val_acc</span> = history.history[<span style="color: #98be65;">'val_acc'</span>]
<span class="linenr"> 91: </span><span style="color: #dcaeea;">loss</span> = history.history[<span style="color: #98be65;">'loss'</span>]
<span class="linenr"> 92: </span><span style="color: #dcaeea;">val_loss</span> = history.history[<span style="color: #98be65;">'val_loss'</span>]
<span class="linenr"> 93: </span>
<span class="linenr"> 94: </span><span style="color: #dcaeea;">epochs</span> = <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(acc) + <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 95: </span>plt.clf()
<span class="linenr"> 96: </span>plt.plot(epochs, acc, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training acc'</span>)
<span class="linenr"> 97: </span>plt.plot(epochs, val_acc, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation acc'</span>)
<span class="linenr"> 98: </span>plt.title(<span style="color: #98be65;">'Training and validation accuracy'</span>)
<span class="linenr"> 99: </span>plt.legend()
<span class="linenr">100: </span>plt.plot()
<span class="linenr">101: </span>plt.savefig(<span style="color: #98be65;">"CatsDogsDataAugmentation-acc.png"</span>)
<span class="linenr">102: </span>plt.figure()
<span class="linenr">103: </span>
<span class="linenr">104: </span>plt.clf()
<span class="linenr">105: </span>plt.plot(epochs, loss, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training loss'</span>)
<span class="linenr">106: </span>plt.plot(epochs, val_loss, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation loss'</span>)
<span class="linenr">107: </span>plt.title(<span style="color: #98be65;">'Training and validation loss'</span>)
<span class="linenr">108: </span>plt.legend()
<span class="linenr">109: </span>plt.plot()
<span class="linenr">110: </span>plt.savefig(<span style="color: #98be65;">"CatsDogsDataAugmentation-loss.png"</span>)
</pre>
</div>

<pre class="example" id="org669e766">
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d_12 (Conv2D)          (None, 148, 148, 32)      896

 max_pooling2d_12 (MaxPooli  (None, 74, 74, 32)        0
 ng2D)

 conv2d_13 (Conv2D)          (None, 72, 72, 64)        18496

 max_pooling2d_13 (MaxPooli  (None, 36, 36, 64)        0
 ng2D)

 conv2d_14 (Conv2D)          (None, 34, 34, 128)       73856

 max_pooling2d_14 (MaxPooli  (None, 17, 17, 128)       0
 ng2D)

 conv2d_15 (Conv2D)          (None, 15, 15, 128)       147584

 max_pooling2d_15 (MaxPooli  (None, 7, 7, 128)         0
 ng2D)

 flatten_3 (Flatten)         (None, 6272)              0

 dropout_2 (Dropout)         (None, 6272)              0

 dense_6 (Dense)             (None, 512)               3211776

 dense_7 (Dense)             (None, 1)                 513

=================================================================
Total params: 3453121 (13.17 MB)
Trainable params: 3453121 (13.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.
Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
Epoch 1/50
63/63 [==============================] - 19s 302ms/step - loss: 0.6926 - acc: 0.5030 - val_loss: 0.6853 - val_acc: 0.5312
Epoch 2/50
63/63 [==============================] - 19s 296ms/step - loss: 0.6916 - acc: 0.5195 - val_loss: 0.6850 - val_acc: 0.5625
...略...
Epoch 49/50
63/63 [==============================] - 30s 469ms/step - loss: 0.5058 - acc: 0.7555 - val_loss: 0.4970 - val_acc: 0.7188
Epoch 50/50
63/63 [==============================] - 29s 463ms/step - loss: 0.5037 - acc: 0.7535 - val_loss: 0.5148 - val_acc: 0.7188
</pre>


<div id="orgdd4cba1" class="figure">
<p><img src="images/CatsDogsDataAugmentation-loss.png" alt="CatsDogsDataAugmentation-loss.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 39: </span>Cats and Dogs Data Augmentation - Loss</p>
</div>


<div id="orgf6739af" class="figure">
<p><img src="images/CatsDogsDataAugmentation-acc.png" alt="CatsDogsDataAugmentation-acc.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 40: </span>Cats and Dogs Data Augmentation - Accuracy</p>
</div>

<p>
由圖<a href="#orgf6739af">40</a>和<a href="#orgdd4cba1">39</a>可以發現，在加入了 data augmentation 和 dropout 後，訓練曲線與驗證曲線漸趨一致，不再 overfitting，model 的準確度也達到 84%。但值的一提的是: 同樣的資料集與演算法，在 Google colab 上以 GPU 執行的結果(下圖)與在本機執行(上圖)時並不相同。<br />
</p>


<div id="org10b2032" class="figure">
<p><img src="images/Cat-Dog-Data-Augmentation-Acc-colab.png" alt="Cat-Dog-Data-Augmentation-Acc-colab.png" /><br />
</p>
<p><span class="figure-number">Figure 41: </span>Cats and Dogs Data Augmentation on Google colab - Accuracy</p>
</div>


<div id="orga617aa0" class="figure">
<p><img src="images/Cat-Dog-Data-Augmentation-loss-colab.png" alt="Cat-Dog-Data-Augmentation-loss-colab.png" /><br />
</p>
<p><span class="figure-number">Figure 42: </span>Cats and Dogs Data Augmentation on Google colab - Loss</p>
</div>

<p>
在透過進一步 regularization 技術的使用，以及調整神經網路參數(如每個卷積層的過濾器數量、神經網路中的層數)，我們就能獲得更高的準確度(86%或 87%)，但在資料不及的情況下(如本例)，我們仍很難進一步提升準確度，此時，就要使用預先訓練 model。<br />
</p>
</div>
</div>
<div id="outline-container-orgb8c22b0" class="outline-3">
<h3 id="orgb8c22b0"><span class="section-number-3">8.4.</span> 改善 2: Pretrained network</h3>
<div class="outline-text-3" id="text-8-4">
<p>
Pretrained network，以簡單的話來說，就是「站在巨人的肩膀」<sup><a id="fnr.9" class="footref" href="#fn.9" role="doc-backlink">9</a></sup>，所謂「巨人」，就是別人已經用 ImageNet 訓練好的模型，例如 Google 的 Inception Model、Microsoft 的 Resnet Model 等等，把它當作 Pre-trained Model，幫助我們提取出照片的特徵(feature)。順帶一提，所謂的 Transfer Learning 就是把 Pre-trained Model 最後一層拔掉 (註：最後一層是用來分類的)，加入新的一層，然後用新資料訓練新層的參數。<br />
</p>

<p>
能夠用來被當成 pretrained netwrok 的 model 通常是擁有大量資料集的大規模圖片分類模型，如果這個原始資料集足夠大量且具通用性，那麼 pretrained network 學習的空間層次特徵(spartial hierarchy features)就足以充當視覺世界的通用 model，其特徵對於許多不同的電腦視覺問題都同樣有效，即便是要辨識與原始任務完全不同的類別也能通用。<br />
</p>

<p>
例如，以 ImageNet 先訓練出一個神經網路(其辨識項目為日常生活用品)，然後重新訓練這個已訓練完成的神經網路，去識別和原始樣本天差地別的家具產品等。和許多淺層的神經網路相較，深度學習的關鍵優勢在於學習到的特徵可移植到不同問題上。<br />
</p>

<p>
以下由 Karen Simonyan 和 Andrew Zisserman 於 2014 年開發的 VGG16 架構。使用 pretrain network 有兩種方式：特徵萃取(feature extraction)和徵調(fine-tuning)。<br />
</p>
</div>
<div id="outline-container-org9f0b963" class="outline-4">
<h4 id="org9f0b963"><span class="section-number-4">8.4.1.</span> 特徵萃取</h4>
<div class="outline-text-4" id="text-8-4-1">
<p>
Feature extraction 是使用 pretrained network 學習到的表示法，以這些表示法從新樣本中萃取有趣的特徵，然後將這些特徵輸入到從頭訓練的新分類器中進行處理。用於影像分類的 CNN 分為以下兩部份：以一系列的卷積層和池化層開始，以密集連接的分類器結束。第一部分稱為 model 的 convolutional base (卷積基底)，在 CNN 的情況下，特徵萃取以一個 pretrained network 做為 convolutional base，透過 convolutional base 處理新資料，<br />
</p>

<p>
為何不連分類器也預先訓練？原因是 CNN 的特徵圖是來自影像上通用 pattern 的概念，因此無論面臨何種電腦視覺問題，都能通用；而分類器學習到的表示法可能只適用於 model 所訓練的類別，僅關於整個影像中該類別相關的機率。此外，卷積特徵圖仍會描述物件出現的位置，但全連接層並沒有空間的概念，全連接層學習到的表示法不再包含物件在輸入影像中位罝的任何訊息，所以只要是和物件出現位置相關的問題，全連接層產生的特徵絕大多數是沒有用的。<br />
</p>

<p>
特定卷積層所萃取出來的表示法，其普適程度取於該層的深度，model 中較早出現的層會萃取局部、高度通用的特徵圖（例如可視邊緣、顏色或紋理），而較深入的層則會萃取更抽象的概念（如貓耳朵、狗眼），如果新的資料集與訓練原始 model 的資料集有很大的差別，最好使用 model 的前幾層來進行特徵萃取，而不是使用整個 convolutional base。以下以 ImageNet 訓練的 VGG16 所產生的 convolutional base 來實作，類似 pretrained 的影像分類 model 還有 Xception、Inception V3、ResNet50、VGG19、MobileNet，均已收錄於 keras.applications。<br />
</p>
</div>
<div id="outline-container-org9ce2f8f" class="outline-5">
<h5 id="org9ce2f8f"><span class="section-number-5">8.4.1.1.</span> 初始化 model</h5>
<div class="outline-text-5" id="text-8-4-1-1">
<p>
要使用這個 pretrained model，還需要傳三個參數給 VGG16 建構式：<br />
</p>
<ul class="org-ul">
<li>weights: 用於初始化 model 的權重檢查點<br /></li>
<li>include_top: 指在神經網路頂部有沒有包含密集連接的分類器。預設情況下，密集連接分類器對應於 ImageNet 的 1000 個類別。然而，我們實際想分類的可能沒這麼多層，所以這裡不一定要包含預設分類器。<br /></li>
<li>input_shape: qpaqamo 供給神經網路的影像張量 shape。這個參數為 optional，如果不傳，則神經網路能處理任何 shape 的輸入張量。<br /></li>
</ul>

<p>
這裡會從網路下載VGG16模型以及其參數權重，會花一點時間&#x2026;.<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="org3d5b44d"><span class="linenr">1: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,
<span class="linenr">4: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,
<span class="linenr">5: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr">6: </span>conv_base.summary()
</pre>
</div>

<pre class="example" id="org4ebc33d">
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
58889256/58889256 [==============================] - 98s 2us/step
Model: "vgg16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_1 (InputLayer)        [(None, 150, 150, 3)]     0

 block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792

 block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928

 block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0

 block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856

 block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584

 block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0

 block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168

 block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080

 block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080

 block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0

 block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160

 block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808

 block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808

 block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0

 block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808

 block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808

 block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808

 block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0

=================================================================
Total params: 14714688 (56.13 MB)
Trainable params: 14714688 (56.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre>

<p>
由上述輸出觀察，最終特徵圖的 shape 為(4, 4, 512)，這算是神經網路的 top 層特徵，這個預訓練的 model 共有 13 層 Conv2D 層，最後要再接上密集連接分類器。做法有二：<br />
</p>

<ol class="org-ol">
<li>在資料集上執行 convolutional base，將輸出記錄到硬碟上的 Numpy 陣列，然後再輸入到獨立的密集分類層。這種解決方案只需要為每個輪入影像執行一次 convolutional base，而 convolutional base 是處理過程中成本最高的部份，所以這種做法速度快成本低。但也因如此，這種做法不允許使用資料擴增法。<br /></li>
<li>在頂部(最後端)增加 Dnese 層來擴展 model (conv_base)，並從輸入資料開始，從頭到尾執行整個處理過程。這種方式允許資料擴增技術，因為每次輸入影像在執行 convolutional base 時都會在 model 處理到。但這種方式的成本較高。<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org1d75d37" class="outline-5">
<h5 id="org1d75d37"><span class="section-number-5">8.4.1.2.</span> 快速特徵萃取</h5>
<div class="outline-text-5" id="text-8-4-1-2">
<p>
先執行 ImageDataGenerator，將影像轉換為 Numpy 陣列及其 label 向量，然後呼叫 conv_base model 的 predict 方法從這些影像中萃取特徵。<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,
<span class="linenr"> 4: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,
<span class="linenr"> 5: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #51afef;">import</span> os
<span class="linenr"> 8: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 9: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #dcaeea;">base_dir</span> = r<span style="color: #98be65;">'/Volumes/LaCie/data/cats_and_dogs_small'</span>
<span class="linenr">12: </span><span style="color: #dcaeea;">train_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'train'</span>)
<span class="linenr">13: </span><span style="color: #dcaeea;">validation_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'validation'</span>)
<span class="linenr">14: </span><span style="color: #dcaeea;">test_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'test'</span>)
<span class="linenr">15: </span>
<span class="linenr">16: </span><span style="color: #dcaeea;">datagen</span> = ImageDataGenerator(rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>)
<span class="linenr">17: </span><span style="color: #dcaeea;">batch_size</span> = <span style="color: #da8548; font-weight: bold;">20</span>
<span class="linenr">18: </span>
<span class="linenr">19: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">extract_features</span>(directory, sample_count):
<span class="linenr">20: </span>    <span style="color: #dcaeea;">features</span> = np.zeros(shape=(sample_count, <span style="color: #da8548; font-weight: bold;">4</span>, <span style="color: #da8548; font-weight: bold;">4</span>, <span style="color: #da8548; font-weight: bold;">512</span>))
<span class="linenr">21: </span>    <span style="color: #dcaeea;">labels</span> = np.zeros(shape=(sample_count))
<span class="linenr">22: </span>    <span style="color: #dcaeea;">generator</span> = datagen.flow_from_directory(directory,
<span class="linenr">23: </span>                                            target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>),
<span class="linenr">24: </span>                                            batch_size=batch_size,
<span class="linenr">25: </span>                                            class_mode=<span style="color: #98be65;">'binary'</span>)
<span class="linenr">26: </span>    <span style="color: #dcaeea;">i</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">27: </span>    <span style="color: #51afef;">for</span> inputs_batch, labels_batch <span style="color: #51afef;">in</span> generator:
<span class="linenr">28: </span>        <span style="color: #dcaeea;">features_batch</span> = conv_base.predict(inputs_batch)
<span class="linenr">29: </span>        <span style="color: #dcaeea;">features</span>[i * batch_size : (i + <span style="color: #da8548; font-weight: bold;">1</span>) * batch_size] = features_batch
<span class="linenr">30: </span>        <span style="color: #dcaeea;">labels</span>[i * batch_size : (i + <span style="color: #da8548; font-weight: bold;">1</span>) * batch_size] = labels_batch
<span class="linenr">31: </span>        <span style="color: #dcaeea;">i</span> += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">32: </span>        <span style="color: #c678dd;">print</span>(i, end=<span style="color: #98be65;">' '</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30001;&#26044;&#33795;&#21462;&#38656;&#35201;&#36611;&#38263;&#30340;&#26178;&#38291;&#65292;&#25105;&#20497;&#21360;&#20986; i &#20358;&#27298;&#35222;&#36914;&#24230;</span>
<span class="linenr">33: </span>        <span style="color: #51afef;">if</span> i * batch_size &gt;= sample_count:
<span class="linenr">34: </span>            <span style="color: #51afef;">break</span>
<span class="linenr">35: </span>    <span style="color: #51afef;">return</span> features, labels
<span class="linenr">36: </span>
<span class="linenr">37: </span><span style="color: #dcaeea;">train_features</span>, <span style="color: #dcaeea;">train_labels</span> = extract_features(train_dir, <span style="color: #da8548; font-weight: bold;">2000</span>)
<span class="linenr">38: </span><span style="color: #dcaeea;">validation_features</span>, <span style="color: #dcaeea;">validation_labels</span> = extract_features(validation_dir, <span style="color: #da8548; font-weight: bold;">1000</span>)
<span class="linenr">39: </span><span style="color: #dcaeea;">test_features</span>, <span style="color: #dcaeea;">test_labels</span> = extract_features(test_dir, <span style="color: #da8548; font-weight: bold;">1000</span>)
</pre>
</div>

<pre class="example" id="orga790cda">
Found 2000 images belonging to 2 classes.
1/1 [==============================] - 1s 899ms/step
1/1 [==============================] - 1s 768ms/step
...略...
1/1 [==============================] - 1s 1s/step
100 Found 1000 images belonging to 2 classes.
1/1 [==============================] - 1s 1s/step
...略...
1/1 [==============================] - 1s 1s/step
50 Found 1000 images belonging to 2 classes.
1/1 [==============================] - 1s 1s/step
...略...
1/1 [==============================] - 1s 1s/step
50
</pre>
</div>
</div>
<div id="outline-container-org074e3df" class="outline-5">
<h5 id="org074e3df"><span class="section-number-5">8.4.1.3.</span> 攤平資料</h5>
<div class="outline-text-5" id="text-8-4-1-3">
<p>
由於目前的萃取特徵 shape = (樣本數, 4, 4, 512)，為了要提供給全連接層分類器，必須將資料攤平為(樣本數, 8192)。<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">train_features</span> = np.reshape(train_features, (<span style="color: #da8548; font-weight: bold;">2000</span>, <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">512</span>))
<span class="linenr">2: </span><span style="color: #dcaeea;">validation_features</span> = np.reshape(validation_features, (<span style="color: #da8548; font-weight: bold;">1000</span>, <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">512</span>))
<span class="linenr">3: </span><span style="color: #dcaeea;">test_features</span> = np.reshape(test_features, (<span style="color: #da8548; font-weight: bold;">1000</span>, <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">512</span>))
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd0fb2e1" class="outline-5">
<h5 id="orgd0fb2e1"><span class="section-number-5">8.4.1.4.</span> 訓練</h5>
<div class="outline-text-5" id="text-8-4-1-4">
<p>
接下來就可以建立我們的密集分類層（使用 dropout 和 regularization)在剛剛萃取的資料和標籤上進行訓練。因為只有兩個全連接層，所以訓練的速度會很快。<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> optimizers
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr"> 6: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">256</span>, activation=<span style="color: #98be65;">'relu'</span>, input_dim=<span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">4</span> * <span style="color: #da8548; font-weight: bold;">512</span>))
<span class="linenr"> 7: </span>model.add(layers.Dropout(<span style="color: #da8548; font-weight: bold;">0.5</span>))  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#19999;&#26820;&#27861;</span>
<span class="linenr"> 8: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1</span>, activation=<span style="color: #98be65;">'sigmoid'</span>))
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>model.<span style="color: #c678dd;">compile</span>(optimizer=optimizers.RMSprop(lr=2e-<span style="color: #da8548; font-weight: bold;">5</span>),
<span class="linenr">11: </span>              loss=<span style="color: #98be65;">'binary_crossentropy'</span>,
<span class="linenr">12: </span>              metrics=[<span style="color: #98be65;">'acc'</span>])
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #dcaeea;">history</span> = model.fit(train_features,
<span class="linenr">15: </span>                    train_labels,epochs=<span style="color: #da8548; font-weight: bold;">30</span>,
<span class="linenr">16: </span>                    batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr">17: </span>                    validation_data=(validation_features, validation_labels))
</pre>
</div>

<pre class="example" id="org7e04f43">
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.
WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.
Epoch 1/30
100/100 [==============================] - 1s 9ms/step - loss: 0.7346 - acc: 0.7575 - val_loss: 0.4003 - val_acc: 0.8000
...略...
Epoch 30/30
100/100 [==============================] - 1s 6ms/step - loss: 0.0202 - acc: 0.9920 - val_loss: 0.6260 - val_acc: 0.9030
</pre>
</div>
</div>
<div id="outline-container-orgb06409d" class="outline-5">
<h5 id="orgb06409d"><span class="section-number-5">8.4.1.5.</span> 繪圖</h5>
<div class="outline-text-5" id="text-8-4-1-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">acc</span> = history.history[<span style="color: #98be65;">'acc'</span>]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">val_acc</span> = history.history[<span style="color: #98be65;">'val_acc'</span>]
<span class="linenr"> 5: </span><span style="color: #dcaeea;">loss</span> = history.history[<span style="color: #98be65;">'loss'</span>]
<span class="linenr"> 6: </span><span style="color: #dcaeea;">val_loss</span> = history.history[<span style="color: #98be65;">'val_loss'</span>]
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">epochs</span> = <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(acc) + <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span>plt.cla()
<span class="linenr">11: </span>plt.plot(epochs, acc, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training acc'</span>)
<span class="linenr">12: </span>plt.plot(epochs, val_acc, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation acc'</span>)
<span class="linenr">13: </span>plt.title(<span style="color: #98be65;">'Training and validation accuracy'</span>)
<span class="linenr">14: </span>plt.legend(loc=<span style="color: #98be65;">"lower right"</span>)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">'images/pretrained-catdog-acc.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">16: </span>
<span class="linenr">17: </span>plt.figure()
<span class="linenr">18: </span>plt.cla()
<span class="linenr">19: </span>plt.plot(epochs, loss, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training loss'</span>)
<span class="linenr">20: </span>plt.plot(epochs, val_loss, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation loss'</span>)
<span class="linenr">21: </span>plt.title(<span style="color: #98be65;">'Training and validation loss'</span>)
<span class="linenr">22: </span>plt.legend(loc=<span style="color: #98be65;">"upper left"</span>)
<span class="linenr">23: </span>plt.savefig(<span style="color: #98be65;">'images/pretrained-catdog-loss.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="orgf7f8b7c" class="figure">
<p><img src="images/pretrained-catdog-acc.png" alt="pretrained-catdog-acc.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 43: </span>Caption</p>
</div>


<div id="org0425bd8" class="figure">
<p><img src="images/pretrained-catdog-loss.png" alt="pretrained-catdog-loss.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 44: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-org3e1b6dd" class="outline-5">
<h5 id="org3e1b6dd"><span class="section-number-5">8.4.1.6.</span> 加入資料擴增的特徵萃取</h5>
<div class="outline-text-5" id="text-8-4-1-6">
<p>
將資料擴增加入特徵萃取的作法是擴展 conv_base model 並從輸入資料開始，從頭到尾執行整個處理過程，這種做法的運算成本非常昂貴，只能在 GPU 上執行，在 CPU 上絕對難以處理。由於 model 的行為與 layer 類似，因此可以將 model(如 conv\uunder{}base)視為 layer，增加到 Sequential model 中，就如同增加神經網路的 layer 一樣。其作法如下：<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="org8501dc3"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,   <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21367;&#31309;&#22522;&#24213;</span>
<span class="linenr"> 6: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21482;&#38656;&#35201;&#21367;&#31309;&#22522;&#24213;&#30340;&#27402;&#37325;&#27169;&#22411;&#36039;&#35338;</span>
<span class="linenr"> 7: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr">10: </span>model.add(conv_base)        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#21367;&#31309;&#22522;&#24213;&#35222;&#28858;&#23652;&#21152;&#20837; Sequential &#27169;&#22411;&#20013;</span>
<span class="linenr">11: </span>model.add(layers.Flatten()) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25892;&#24179;</span>
<span class="linenr">12: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">256</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">13: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1</span>, activation=<span style="color: #98be65;">'sigmoid'</span>)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22686;&#21152;&#20840;&#36899;&#25509;&#23652;&#20998;&#39006;&#22120;</span>
<span class="linenr">14: </span>model.summary() <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26597;&#30475;&#27169;&#22411;&#25688;&#35201;</span>
</pre>
</div>

<pre class="example" id="org54b7460">
Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 vgg16 (Functional)          (None, 4, 4, 512)         14714688

 flatten_4 (Flatten)         (None, 8192)              0

 dense_10 (Dense)            (None, 256)               2097408

 dense_11 (Dense)            (None, 1)                 257

=================================================================
Total params: 16812353 (64.13 MB)
Trainable params: 16812353 (64.13 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre>

<p>
如上圖，VGG16 的 convolutional base 有 14714688 個參數，在頂部(後端)增加的分類器有 200 多萬個參數。在加入資料擴增之前，凍結 convolutional base 是非常重要的，凍結(freeze)表示在訓練期間禁止更新權重，如果不這樣做，則 convolutional base 先前學習到的表示法就會在訓練期間被修改掉，因為頂部的 Dense 層是隨機初始化的，所以非常大量的權重更新將透過神經網路傳播，會導致先前學習到的表示法被破壞掉。<br />
</p>

<p>
在 Keras 中，可以透過設定模型的 trainable 屬性為 False 來凍結 convolutional base 神經網路：<br />
</p>
<div class="org-src-container">
<pre class="src src-python" id="org4a191c7"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">freeze convolutional base</span>
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'This is the number of trainable weights '</span>
<span class="linenr">3: </span><span style="color: #98be65;">'before freezing the conv base:'</span>, <span style="color: #c678dd;">len</span>(model.trainable_weights))
<span class="linenr">4: </span>conv_base.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">False</span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20941;&#32080;&#27402;&#37325;</span>
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'This is the number of trainable weights '</span>
<span class="linenr">6: </span><span style="color: #98be65;">'after freezing the conv base:'</span>, <span style="color: #c678dd;">len</span>(model.trainable_weights))
</pre>
</div>

<pre class="example">
This is the number of trainable weights before freezing the conv base: 30
This is the number of trainable weights after freezing the conv base: 4
</pre>


<p>
由於 conv_base 被凍結更新權重，所以 model 只會訓練增力的兩個 Dense 層權重，每層有兩個參數要更新(主要權重矩陣和偏差向量)，所以一共剩 4 個 trainable weights，原本的 pretrained model 有 13 層 Conv2D，共 26 個 trainable weights。<br />
</p>

<p>
接下來就可以使用資料擴增來訓練 model:<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="orgdcb63cb"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,   <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21367;&#31309;&#22522;&#24213;</span>
<span class="linenr"> 6: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,
<span class="linenr"> 7: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #51afef;">import</span> os
<span class="linenr">10: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">11: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #dcaeea;">base_dir</span> = r<span style="color: #98be65;">'/Volumes/LaCie/data/cats_and_dogs_small'</span>
<span class="linenr">14: </span><span style="color: #dcaeea;">train_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'train'</span>)
<span class="linenr">15: </span><span style="color: #dcaeea;">validation_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'validation'</span>)
<span class="linenr">16: </span><span style="color: #dcaeea;">test_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'test'</span>)
<span class="linenr">17: </span>
<span class="linenr">18: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr">19: </span>model.add(conv_base)        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#21367;&#31309;&#22522;&#24213;&#35222;&#28858;&#23652;&#21152;&#20837; Sequential &#27169;&#22411;&#20013;</span>
<span class="linenr">20: </span>model.add(layers.Flatten()) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25892;&#24179;</span>
<span class="linenr">21: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">256</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">22: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1</span>, activation=<span style="color: #98be65;">'sigmoid'</span>)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22686;&#21152;&#20840;&#36899;&#25509;&#23652;&#20998;&#39006;&#22120;</span>
<span class="linenr">23: </span>
<span class="linenr">24: </span>conv_base.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">False</span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20941;&#32080;&#27402;&#37325;</span>
<span class="linenr">25: </span>
<span class="linenr">26: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">data augmentation</span>
<span class="linenr">27: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr">28: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> optimizers
<span class="linenr">29: </span>
<span class="linenr">30: </span><span style="color: #dcaeea;">train_datagen</span> = ImageDataGenerator( <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25844;&#20805;&#35347;&#32244;&#36039;&#26009;</span>
<span class="linenr">31: </span>  rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>,
<span class="linenr">32: </span>  rotation_range=<span style="color: #da8548; font-weight: bold;">40</span>,
<span class="linenr">33: </span>  width_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">34: </span>  height_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">35: </span>  shear_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">36: </span>  zoom_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr">37: </span>  horizontal_flip=<span style="color: #a9a1e1;">True</span>,
<span class="linenr">38: </span>  fill_mode=<span style="color: #98be65;">'nearest'</span>)
<span class="linenr">39: </span>
<span class="linenr">40: </span><span style="color: #dcaeea;">test_datagen</span> = ImageDataGenerator(rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35531;&#27880;&#24847;&#39511;&#35657;&#36039;&#26009;&#19981;&#25033;&#35442;&#25844;&#20805;</span>
<span class="linenr">41: </span>
<span class="linenr">42: </span><span style="color: #dcaeea;">train_generator</span> = train_datagen.flow_from_directory(
<span class="linenr">43: </span>  train_dir, <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30446;&#27161;&#30446;&#37636;&#36335;&#24465;</span>
<span class="linenr">44: </span>  target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>), <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35519;&#25972;&#25152;&#26377;&#22294;&#20687;&#22823;&#23567;&#25104; 150&#215;150</span>
<span class="linenr">45: </span>  batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr">46: </span>  class_mode=<span style="color: #98be65;">'binary'</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22240;&#28858;&#20351;&#29992;&#20108;&#20803;&#20132;&#21449;&#29109; binary_crossentropy &#20316;&#28858;&#25613;&#22833;&#20998;&#25976;&#65292;&#25152;                     &#20197;&#38656;&#35201;&#20108;&#20803;&#27161;&#31844;</span>
<span class="linenr">47: </span>
<span class="linenr">48: </span><span style="color: #dcaeea;">validation_generator</span> = test_datagen.flow_from_directory(
<span class="linenr">49: </span>  validation_dir,
<span class="linenr">50: </span>  target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>),
<span class="linenr">51: </span>  batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr">52: </span>  class_mode=<span style="color: #98be65;">'binary'</span>)
<span class="linenr">53: </span>
<span class="linenr">54: </span>model.<span style="color: #c678dd;">compile</span>( loss=<span style="color: #98be65;">'binary_crossentropy'</span>,
<span class="linenr">55: </span>       optimizer=optimizers.RMSprop(lr=2e-<span style="color: #da8548; font-weight: bold;">5</span>),
<span class="linenr">56: </span>       metrics=[<span style="color: #98be65;">'acc'</span>])
<span class="linenr">57: </span>
<span class="linenr">58: </span><span style="color: #dcaeea;">history</span> = model.fit_generator(
<span class="linenr">59: </span>  train_generator,
<span class="linenr">60: </span>  steps_per_epoch=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr">61: </span>  epochs=<span style="color: #da8548; font-weight: bold;">30</span>,
<span class="linenr">62: </span>  validation_data=validation_generator,
<span class="linenr">63: </span>  validation_steps=<span style="color: #da8548; font-weight: bold;">50</span>)
<span class="linenr">64: </span>
<span class="linenr">65: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32362;&#35069;model&#30340;&#25613;&#22833;&#29575;&#33287;&#31934;&#30906;&#29575;</span>
<span class="linenr">66: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">67: </span>
<span class="linenr">68: </span><span style="color: #dcaeea;">acc</span> = history.history[<span style="color: #98be65;">'acc'</span>]
<span class="linenr">69: </span><span style="color: #dcaeea;">val_acc</span> = history.history[<span style="color: #98be65;">'val_acc'</span>]
<span class="linenr">70: </span><span style="color: #dcaeea;">loss</span> = history.history[<span style="color: #98be65;">'loss'</span>]
<span class="linenr">71: </span><span style="color: #dcaeea;">val_loss</span> = history.history[<span style="color: #98be65;">'val_loss'</span>]
<span class="linenr">72: </span>
<span class="linenr">73: </span><span style="color: #dcaeea;">epochs</span> = <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(acc) + <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">74: </span>plt.clf()
<span class="linenr">75: </span>plt.plot(epochs, acc, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training acc'</span>)
<span class="linenr">76: </span>plt.plot(epochs, val_acc, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation acc'</span>)
<span class="linenr">77: </span>plt.title(<span style="color: #98be65;">'Training and validation accuracy'</span>)
<span class="linenr">78: </span>plt.legend()
<span class="linenr">79: </span>plt.plot()
<span class="linenr">80: </span>plt.savefig(<span style="color: #98be65;">"images/CatsDogsDataAugmentationPretrained-acc.png"</span>)
<span class="linenr">81: </span>plt.figure()
<span class="linenr">82: </span>
<span class="linenr">83: </span>plt.clf()
<span class="linenr">84: </span>plt.plot(epochs, loss, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training loss'</span>)
<span class="linenr">85: </span>plt.plot(epochs, val_loss, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation loss'</span>)
<span class="linenr">86: </span>plt.title(<span style="color: #98be65;">'Training and validation loss'</span>)
<span class="linenr">87: </span>plt.legend()
<span class="linenr">88: </span>plt.plot()
<span class="linenr">89: </span>plt.savefig(<span style="color: #98be65;">"images/CatsDogsDataAugmentationPretrained-loss.png"</span>)
</pre>
</div>

<pre class="example" id="orgb369c0a">
Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.
WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.
/var/folders/6z/55c40g5s2qz2rh1t3s5zwtzw0000gn/T/pycu86w4:60: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
Epoch 1/30
100/100 [==============================] - 146s 1s/step - loss: 0.7296 - acc: 0.6900 - val_loss: 0.3320 - val_acc: 0.8540
Epoch 2/30
100/100 [==============================] - 175s 2s/step - loss: 0.4518 - acc: 0.7910 - val_loss: 0.2749 - val_acc: 0.8850
...略...
Epoch 29/30
100/100 [==============================] - 242s 2s/step - loss: 0.2696 - acc: 0.8820 - val_loss: 0.2479 - val_acc: 0.9060
Epoch 30/30
100/100 [==============================] - 245s 2s/step - loss: 0.2693 - acc: 0.8760 - val_loss: 0.3019 - val_acc: 0.8830
</pre>


<div id="org6ca466f" class="figure">
<p><img src="images/CatsDogsDataAugmentationPretrained-acc.png" alt="CatsDogsDataAugmentationPretrained-acc.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 45: </span>Cats and Dogs Data Augmentation / Pretrained- Accuracy</p>
</div>


<div id="orgbc51b92" class="figure">
<p><img src="images/CatsDogsDataAugmentationPretrained-loss.png" alt="CatsDogsDataAugmentationPretrained-loss.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 46: </span>Cats and Dogs Data Augmentation - Loss</p>
</div>

<p>
實作結果，驗證準確率達 90%，優於從頭訓練小型神經網路（結果與原書中達 96%有所出入）。<br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgd1003a3" class="outline-4">
<h4 id="orgd1003a3"><span class="section-number-4">8.4.2.</span> 微調</h4>
<div class="outline-text-4" id="text-8-4-2">
<p>
微調(fine-tuning)為另一種廣泛使用的 model reuse 技術，本質上是特徵萃取的變化版，其做法是在特徵萃取的過程中不凍結整個 convolutional base，而是解凍 convolutional base 頂部的某些層以用於特徵萃取，並對於新增加於 model 的部份(如全連接層分類器)與被解凍的部份層一起進行聯合訓練。<br />
</p>

<p>
微調神經網路的步驟如下：<br />
</p>
<ol class="org-ol">
<li>在已訓練過的基礎神經網路(即 convolutional base)上增加自定義神經網路<br /></li>
<li>凍結 convolutional base<br /></li>
<li>訓練步驟 1 增加的部份(即最頂端的分類器)<br /></li>
<li>解凍 convolutional base 的某幾層<br /></li>
<li>共同訓練解凍層和分類器<br /></li>
</ol>

<p>
以 VGG16 的模組架構為例，其分層架構如下：<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="org2fc1af1"><span class="linenr">1: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,
<span class="linenr">4: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,
<span class="linenr">5: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr">6: </span>conv_base.summary()
</pre>
</div>

<pre class="example" id="orge2bcac2">
Model: "vgg16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 150, 150, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</pre>

<p>
我們可以調整這個 convolutional base 的最頂層(block5)三層的卷積層，即 block5_conv1、block5_conv2、block5_conv3 三層，然後凍結 block4_pool 以下的所有層。之所以選擇只解凍 convolutional base 的最頂層，幾個考量原因如下：<br />
</p>

<ul class="org-ul">
<li>相對於 convolutional base 中的低層主要是對更通用、可重複使用的特徵進行編碼；更高層則是對更特定的特徵進行編碼，所以這些特徵需要重新調整才能適用於新的問題。如果是對低層進行微調，則會出現反效果。<br /></li>
</ul>
<ul class="org-ul">
<li>訓練的參數越多，就越可能 overfitting。convolutional base 有近 1500 萬個參數，因此在少量資料集上訓練會有風險。<br /></li>
</ul>

<p>
解凍部份 convolutional base 的方式如下：<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="org4f051da"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,
<span class="linenr"> 4: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,
<span class="linenr"> 5: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr"> 6: </span>conv_base.summary()
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span>conv_base.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">True</span> <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#20808;&#35373;&#23450;&#25152;&#26377;layer&#37117;&#21487;&#35347;&#32244;?</span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">set_trainable</span> = <span style="color: #a9a1e1;">False</span> <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38928;&#35373;&#28858;&#20941;&#32080;</span>
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #51afef;">for</span> layer <span style="color: #51afef;">in</span> conv_base.layers: <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30001;&#20302;&#21040;&#39640;</span>
<span class="linenr">12: </span>    <span style="color: #51afef;">if</span> layer.name == <span style="color: #98be65;">'block5_conv1'</span>: <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30452;&#21040;&#20986;&#29694;block5_conv1&#36889;&#23652;&#24460;&#38283;&#22987;&#35299;&#20941;</span>
<span class="linenr">13: </span>        <span style="color: #dcaeea;">set_trainable</span> = <span style="color: #a9a1e1;">True</span>
<span class="linenr">14: </span>    <span style="color: #51afef;">if</span> set_trainable:
<span class="linenr">15: </span>        layer.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">True</span>
<span class="linenr">16: </span>    <span style="color: #51afef;">else</span>:
<span class="linenr">17: </span>        layer.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">False</span>
</pre>
</div>

<p>
解凍完部份 layer 後即可開始徵調神經網路，這裡使用 RMSProp 優化器以非常低的學習率來微調，降低學習率的目的在減小 3 個解凍層的修改幅度，以免因為過大的修改損害到這些表示法。<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="orgc1b2389"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32232;&#35695;&#27169;&#22411;</span>
<span class="linenr"> 2: </span>model.<span style="color: #c678dd;">compile</span>(
<span class="linenr"> 3: </span>    loss=<span style="color: #98be65;">'binary_crossentropy'</span>,
<span class="linenr"> 4: </span>    optimizer=optimizers.RMSprop(lr=1e-<span style="color: #da8548; font-weight: bold;">5</span>),
<span class="linenr"> 5: </span>    metrics=[<span style="color: #98be65;">'acc'</span>])
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;&#27169;&#22411;</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">history</span> = model.fit_generator(
<span class="linenr"> 9: </span>    train_generator,
<span class="linenr">10: </span>    steps_per_epoch=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr">11: </span>    epochs=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr">12: </span>    validation_data=validation_generator,
<span class="linenr">13: </span>    validation_steps=<span style="color: #da8548; font-weight: bold;">50</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python" id="orgf24c945"><span class="linenr">  1: </span><span style="color: #51afef;">import</span> os
<span class="linenr">  2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">  3: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr">  4: </span>
<span class="linenr">  5: </span><span style="color: #dcaeea;">base_dir</span> = r<span style="color: #98be65;">'/Volumes/LaCie/data/cats_and_dogs_small'</span>
<span class="linenr">  6: </span><span style="color: #dcaeea;">train_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'train'</span>)
<span class="linenr">  7: </span><span style="color: #dcaeea;">validation_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'validation'</span>)
<span class="linenr">  8: </span><span style="color: #dcaeea;">test_dir</span> = os.path.join(base_dir, <span style="color: #98be65;">'test'</span>)
<span class="linenr">  9: </span>
<span class="linenr"> 10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#37096;&#20221;&#20941;&#32080;</span>
<span class="linenr"> 11: </span><span style="color: #51afef;">from</span> keras.applications <span style="color: #51afef;">import</span> VGG16
<span class="linenr"> 12: </span>
<span class="linenr"> 13: </span><span style="color: #dcaeea;">conv_base</span> = VGG16(weights=<span style="color: #98be65;">'imagenet'</span>,
<span class="linenr"> 14: </span>                  include_top=<span style="color: #a9a1e1;">False</span>,
<span class="linenr"> 15: </span>                  input_shape=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">3</span>))
<span class="linenr"> 16: </span>conv_base.summary()
<span class="linenr"> 17: </span>
<span class="linenr"> 18: </span>conv_base.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">True</span> <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#20808;&#35373;&#23450;&#25152;&#26377;layer&#37117;&#21487;&#35347;&#32244;?</span>
<span class="linenr"> 19: </span><span style="color: #dcaeea;">set_trainable</span> = <span style="color: #a9a1e1;">False</span> <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38928;&#35373;&#28858;&#20941;&#32080;</span>
<span class="linenr"> 20: </span>
<span class="linenr"> 21: </span><span style="color: #51afef;">for</span> layer <span style="color: #51afef;">in</span> conv_base.layers: <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30001;&#20302;&#21040;&#39640;</span>
<span class="linenr"> 22: </span>    <span style="color: #51afef;">if</span> layer.name == <span style="color: #98be65;">'block5_conv1'</span>: <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30452;&#21040;&#20986;&#29694;block5_conv1&#36889;&#23652;&#24460;&#38283;&#22987;&#35299;&#20941;</span>
<span class="linenr"> 23: </span>        <span style="color: #dcaeea;">set_trainable</span> = <span style="color: #a9a1e1;">True</span>
<span class="linenr"> 24: </span>    <span style="color: #51afef;">if</span> set_trainable:
<span class="linenr"> 25: </span>        layer.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">True</span>
<span class="linenr"> 26: </span>    <span style="color: #51afef;">else</span>:
<span class="linenr"> 27: </span>        layer.<span style="color: #dcaeea;">trainable</span> = <span style="color: #a9a1e1;">False</span>
<span class="linenr"> 28: </span>
<span class="linenr"> 29: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">data augmentation</span>
<span class="linenr"> 30: </span><span style="color: #51afef;">from</span> keras.preprocessing.image <span style="color: #51afef;">import</span> ImageDataGenerator
<span class="linenr"> 31: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> optimizers
<span class="linenr"> 32: </span>
<span class="linenr"> 33: </span><span style="color: #dcaeea;">train_datagen</span> = ImageDataGenerator( <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25844;&#20805;&#35347;&#32244;&#36039;&#26009;</span>
<span class="linenr"> 34: </span>  rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>,
<span class="linenr"> 35: </span>  rotation_range=<span style="color: #da8548; font-weight: bold;">40</span>,
<span class="linenr"> 36: </span>  width_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 37: </span>  height_shift_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 38: </span>  shear_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 39: </span>  zoom_range=<span style="color: #da8548; font-weight: bold;">0.2</span>,
<span class="linenr"> 40: </span>  horizontal_flip=<span style="color: #a9a1e1;">True</span>,
<span class="linenr"> 41: </span>  fill_mode=<span style="color: #98be65;">'nearest'</span>)
<span class="linenr"> 42: </span>
<span class="linenr"> 43: </span><span style="color: #dcaeea;">test_datagen</span> = ImageDataGenerator(rescale=<span style="color: #da8548; font-weight: bold;">1</span>./<span style="color: #da8548; font-weight: bold;">255</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35531;&#27880;&#24847;&#39511;&#35657;&#36039;&#26009;&#19981;&#25033;&#35442;&#25844;&#20805;</span>
<span class="linenr"> 44: </span>
<span class="linenr"> 45: </span><span style="color: #dcaeea;">train_generator</span> = train_datagen.flow_from_directory(
<span class="linenr"> 46: </span>  train_dir, <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30446;&#27161;&#30446;&#37636;&#36335;&#24465;</span>
<span class="linenr"> 47: </span>  target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>), <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35519;&#25972;&#25152;&#26377;&#22294;&#20687;&#22823;&#23567;&#25104; 150&#215;150</span>
<span class="linenr"> 48: </span>  batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr"> 49: </span>  class_mode=<span style="color: #98be65;">'binary'</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22240;&#28858;&#20351;&#29992;&#20108;&#20803;&#20132;&#21449;&#29109; binary_crossentropy &#20316;&#28858;&#25613;&#22833;&#20998;&#25976;&#65292;&#25152;                     &#20197;&#38656;&#35201;&#20108;&#20803;&#27161;&#31844;</span>
<span class="linenr"> 50: </span>
<span class="linenr"> 51: </span><span style="color: #dcaeea;">validation_generator</span> = test_datagen.flow_from_directory(
<span class="linenr"> 52: </span>  validation_dir,
<span class="linenr"> 53: </span>  target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>),
<span class="linenr"> 54: </span>  batch_size=<span style="color: #da8548; font-weight: bold;">20</span>,
<span class="linenr"> 55: </span>  class_mode=<span style="color: #98be65;">'binary'</span>)
<span class="linenr"> 56: </span>
<span class="linenr"> 57: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr"> 58: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> layers
<span class="linenr"> 59: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> optimizers
<span class="linenr"> 60: </span>
<span class="linenr"> 61: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">model&#36996;&#26159;&#35201;&#21152;&#24460;&#38754;&#30340;layer?</span>
<span class="linenr"> 62: </span><span style="color: #dcaeea;">model</span> = models.Sequential()
<span class="linenr"> 63: </span>model.add(conv_base)        <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#21367;&#31309;&#22522;&#24213;&#35222;&#28858;&#23652;&#21152;&#20837; Sequential &#27169;&#22411;&#20013;</span>
<span class="linenr"> 64: </span>model.add(layers.Flatten()) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25892;&#24179;</span>
<span class="linenr"> 65: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">256</span>, activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr"> 66: </span>model.add(layers.Dense(<span style="color: #da8548; font-weight: bold;">1</span>, activation=<span style="color: #98be65;">'sigmoid'</span>)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22686;&#21152;&#20840;&#36899;&#25509;&#23652;&#20998;&#39006;&#22120;</span>
<span class="linenr"> 67: </span>
<span class="linenr"> 68: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24494;&#35519;</span>
<span class="linenr"> 69: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32232;&#35695;&#27169;&#22411;</span>
<span class="linenr"> 70: </span>model.<span style="color: #c678dd;">compile</span>(
<span class="linenr"> 71: </span>    loss=<span style="color: #98be65;">'binary_crossentropy'</span>,
<span class="linenr"> 72: </span>    optimizer=optimizers.RMSprop(lr=1e-<span style="color: #da8548; font-weight: bold;">5</span>),
<span class="linenr"> 73: </span>    metrics=[<span style="color: #98be65;">'acc'</span>])
<span class="linenr"> 74: </span>
<span class="linenr"> 75: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;&#27169;&#22411;</span>
<span class="linenr"> 76: </span><span style="color: #dcaeea;">history</span> = model.fit_generator(
<span class="linenr"> 77: </span>    train_generator,
<span class="linenr"> 78: </span>    steps_per_epoch=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr"> 79: </span>    epochs=<span style="color: #da8548; font-weight: bold;">100</span>,
<span class="linenr"> 80: </span>    validation_data=validation_generator,
<span class="linenr"> 81: </span>    validation_steps=<span style="color: #da8548; font-weight: bold;">50</span>)
<span class="linenr"> 82: </span>
<span class="linenr"> 83: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32362;&#35069;model&#30340;&#25613;&#22833;&#29575;&#33287;&#31934;&#30906;&#29575;</span>
<span class="linenr"> 84: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 85: </span>
<span class="linenr"> 86: </span><span style="color: #dcaeea;">acc</span> = history.history[<span style="color: #98be65;">'acc'</span>]
<span class="linenr"> 87: </span><span style="color: #dcaeea;">val_acc</span> = history.history[<span style="color: #98be65;">'val_acc'</span>]
<span class="linenr"> 88: </span><span style="color: #dcaeea;">loss</span> = history.history[<span style="color: #98be65;">'loss'</span>]
<span class="linenr"> 89: </span><span style="color: #dcaeea;">val_loss</span> = history.history[<span style="color: #98be65;">'val_loss'</span>]
<span class="linenr"> 90: </span>
<span class="linenr"> 91: </span><span style="color: #dcaeea;">epochs</span> = <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(acc) + <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 92: </span>plt.clf()
<span class="linenr"> 93: </span>plt.plot(epochs, acc, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training acc'</span>)
<span class="linenr"> 94: </span>plt.plot(epochs, val_acc, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation acc'</span>)
<span class="linenr"> 95: </span>plt.title(<span style="color: #98be65;">'Training and validation accuracy'</span>)
<span class="linenr"> 96: </span>plt.legend()
<span class="linenr"> 97: </span>plt.plot()
<span class="linenr"> 98: </span>plt.savefig(<span style="color: #98be65;">"images/FineTune-acc-1.png"</span>)
<span class="linenr"> 99: </span>plt.figure()
<span class="linenr">100: </span>
<span class="linenr">101: </span>plt.clf()
<span class="linenr">102: </span>plt.plot(epochs, loss, <span style="color: #98be65;">'bo'</span>, label=<span style="color: #98be65;">'Training loss'</span>)
<span class="linenr">103: </span>plt.plot(epochs, val_loss, <span style="color: #98be65;">'b'</span>, label=<span style="color: #98be65;">'Validation loss'</span>)
<span class="linenr">104: </span>plt.title(<span style="color: #98be65;">'Training and validation loss'</span>)
<span class="linenr">105: </span>plt.legend()
<span class="linenr">106: </span>plt.plot()
<span class="linenr">107: </span>plt.savefig(<span style="color: #98be65;">"images/FineTune-loss-1.png"</span>)
</pre>
</div>

<pre class="example" id="org58a1232">
Model: "vgg16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 150, 150, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
100/100 [==============================] - 602s 6s/step - loss: 0.0200 - acc: 0.9935 - val_loss: 0.0559 - val_acc: 0.9380
</pre>


<div id="orgcf14979" class="figure">
<p><img src="images/FineTune-acc-1.png" alt="FineTune-acc-1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 47: </span>VGG16 Fine Tune Acc</p>
</div>


<div id="org0104003" class="figure">
<p><img src="images/FineTune-loss-1.png" alt="FineTune-loss-1.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 48: </span>VGG16 Fine Tune Loss</p>
</div>

<p>
微調的訓練準確率來到 99%，驗證準確率也有 94%，這是使用 2000 個訓練樣本就達到的結果。<br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd8c4110" class="outline-2">
<h2 id="orgd8c4110"><span class="section-number-2">9.</span> 視覺化呈現 CNN 的學習內容</h2>
<div class="outline-text-2" id="text-9">
<p>
CNN 學習的表示法非常適合以視覺化呈現，因為它們大部份就是視覺概念的表示法(represnetations of visual concepts)，幾種常用的視得化技術如下：<br />
</p>
<ul class="org-ul">
<li>視覺化中間層 convnet 的輸出(中間啟動函數)：有助於理解 convnet 是如何一層一層的轉化資料，以及對過濾器(filter)的含義。<br /></li>
<li>視覺化 CNN 過濾器：用於準確理解 CNN 中每個過濾器所要接受的視覺 patter 或概念中<br /></li>
<li>視覺化類別激活熱圖(heatmaps of class activation): 有助於了解影像的哪些部份被識別為某個類別，藉以定位影像中的物件。<br /></li>
</ul>
</div>
<div id="outline-container-org6064357" class="outline-3">
<h3 id="org6064357"><span class="section-number-3">9.1.</span> 中間層輸出視覺化</h3>
<div class="outline-text-3" id="text-9-1">
<p>
以下的工作主要是在給定輸入影像後，以圖形化的方式顯示卷積神經網路中各個卷積層和池化層輸出的特徵圖。讓我們能看到在CNN的學習過程中，輸入資料是如何經由逐層分解到不同的過濾器。雖然輸入資料為三個維度(width, height, channel)，但其實每個 channel 會針對相對獨立的特徵值(features)進行編碼，所以此處是將每個 channel 的內容獨立繪製成 2D 圖形秀出。<br />
</p>

<p>
先載入之前儲存好的 model，取一張測試集中的照片(未經訓練過)，秀出原始內容，然後萃取出特徵圖，因為在這裡只是想看一張圖，所以要建新一個新的 Keras model。<br />
</p>

<div class="org-src-container">
<pre class="src src-python" id="orgebf3999"><span class="linenr">1: </span><span style="color: #51afef;">from</span> keras.models <span style="color: #51afef;">import</span> load_model
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21152;&#36617;&#20445;&#23384;&#30340;&#27169;&#22411;&#65306;</span>
<span class="linenr">4: </span><span style="color: #dcaeea;">model</span> = load_model(<span style="color: #98be65;">'cats_and_dogs_small_i.h5'</span>)
<span class="linenr">5: </span>model.summary()  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25171;&#21360;&#27169;&#22411;</span>
</pre>
</div>

<pre class="example" id="orgd4a88b4">
WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 148, 148, 32)      896

 max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0
 D)

 conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496

 max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0
 g2D)

 conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856

 max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0
 g2D)

 conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584

 max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0
 g2D)

 flatten (Flatten)           (None, 6272)              0

 dense (Dense)               (None, 512)               3211776

 dense_1 (Dense)             (None, 1)                 513

=================================================================
Total params: 3453121 (13.17 MB)
Trainable params: 3453121 (13.17 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre>
<p>
留意一下上述的summary()結果，第一層卷積層(conv2d)的輸出為32個channel所生成的148×148的特徵圖，等一下我們就從中間挑出一張來瞧瞧成果。<br />
</p>
</div>
</div>
<div id="outline-container-orgc47b435" class="outline-3">
<h3 id="orgc47b435"><span class="section-number-3">9.2.</span> 查看新圖</h3>
<div class="outline-text-3" id="text-9-2">
<p>
使用一個未被模型看過的圖像作為輸入(一個貓的圖片，它不是訓練集的一部分)：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #dcaeea;">img_path</span> = <span style="color: #98be65;">'/Volumes/LaCie/data/cats_and_dogs_small/test/cats/cat.1700.jpg'</span>
<span class="linenr"> 2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25105;&#20497;&#25226;&#22294;&#20687;&#36681;&#25563;&#25104;&#32178;&#32097;&#35201;&#27714;&#30340;&#24373;&#37327;shape (4D &#24373;&#37327;)</span>
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">(&#27171;&#26412;&#25976;, &#22294;&#20687;&#39640;&#24230;, &#22294;&#20687;&#23532;&#24230;, &#22294;&#20687;&#36890;&#36947;)</span>
<span class="linenr"> 4: </span><span style="color: #51afef;">from</span> keras.preprocessing <span style="color: #51afef;">import</span> image
<span class="linenr"> 5: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">img</span> = image.load_img(img_path, target_size=(<span style="color: #da8548; font-weight: bold;">150</span>, <span style="color: #da8548; font-weight: bold;">150</span>)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36617;&#20837;&#22294;&#20687;&#20006;&#36681;&#25563;&#22823;&#23567;&#28858;150x150</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">img_tensor</span> = image.img_to_array(img) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25226;&#24433;&#20687;&#29289;&#20214;&#36681;&#25563;&#25104; numpy ndarray&#29289;&#20214;</span>
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Origin img_tensor shape: "</span>, img_tensor.shape)
<span class="linenr">11: </span>
<span class="linenr">12: </span><span style="color: #dcaeea;">img_tensor</span> = np.expand_dims(img_tensor, axis=<span style="color: #da8548; font-weight: bold;">0</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22810;&#22686;&#21152;&#19968;&#20491;&#32173;&#24230;&#20358;&#31526;&#21512;Keras Conv2D&#30340;&#35201;&#27714;</span>
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"After reshape img_tensor shape: "</span>, img_tensor.shape)
<span class="linenr">15: </span>
<span class="linenr">16: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36889;&#20491;&#27169;&#22411;&#30340;&#36664;&#20837;&#26159;&#26377;&#32147;&#36942;&#27512;&#19968;&#21270;&#30340;&#21069;&#34389;&#29702;</span>
<span class="linenr">17: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25152;&#20197;&#25105;&#20497;&#20063;&#35201;&#36914;&#34892;&#30456;&#21516;&#30340;&#21069;&#34389;&#29702;</span>
<span class="linenr">18: </span><span style="color: #dcaeea;">img_tensor</span> /= <span style="color: #da8548; font-weight: bold;">255</span>. <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36914;&#34892;&#36039;&#26009;&#23610;&#24230;(scale)&#30340;&#36681;&#25563;</span>
</pre>
</div>

<pre class="example">
Origin img_tensor shape:  (150, 150, 3)
After reshape img_tensor shape:  (1, 150, 150, 3)
</pre>


<p>
這張測試集照片的原圖如下:<br />
</p>

<div id="orgcc90505" class="figure">
<p><img src="images/cat.1700.png" alt="cat.1700.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 49: </span>測試集原圖</p>
</div>

<p>
因為原始模型的目的並不是要讓使用者查看每一層的輸出結果，為了讓我們能強力介入每一層去看出各層的輸出，我們要建立一個新的模型，只以一張圖(圖<a href="#orgcc90505">49</a>)做為輸入，並輸出所有經過卷積層和池化層的激勵輸出結果。<br />
</p>

<p>
這個模型需要兩個參數：輸入張量（或輸入張量列表）以及輸出張量（或輸出張量列表）。所得到的類別是一個Keras模型(model)物件，就如同我們之前所建立的Sequential模型，但是這個Model類別允許具有多個輸出的模型，這是與之前我們建立的Sequential最大的不同。<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> keras <span style="color: #51afef;">import</span> models
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21109;&#24314;&#19968;&#20491;list&#20358;&#20786;&#23384;&#21069;8&#23652;&#34389;&#29702;&#24460;&#30340;outputs</span>
<span class="linenr">4: </span><span style="color: #dcaeea;">layer_outputs</span> = [layer.output <span style="color: #51afef;">for</span> layer <span style="color: #51afef;">in</span> model.layers[:<span style="color: #da8548; font-weight: bold;">8</span>]]
<span class="linenr">5: </span>
<span class="linenr">6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29986;&#29983;&#19968;&#20491;model&#29289;&#20214;, &#23427;&#30340;input&#26159;&#21407;&#20808;&#27169;&#22411;&#30340;input, &#32780;&#23427;&#30340;output&#21063;&#26159;&#21069;8&#23652;&#34389;&#29702;&#24460;&#30340;outputs</span>
<span class="linenr">7: </span><span style="color: #dcaeea;">activation_model</span> = models.Model(inputs=model.<span style="color: #c678dd;">input</span>, outputs=layer_outputs)
<span class="linenr">8: </span>
<span class="linenr">9: </span><span style="color: #c678dd;">print</span>(layer_outputs) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30475;&#19968;&#19979;&#29289;&#20214;&#30340;&#32080;&#27083;</span>
</pre>
</div>

<pre class="example">
[&lt;KerasTensor: shape=(None, 148, 148, 32) dtype=float32 (created by layer 'conv2d')&gt;,
&lt;KerasTensor: shape=(None, 74, 74, 32) dtype=float32 (created by layer 'max_pooling2d')&gt;,
&lt;KerasTensor: shape=(None, 72, 72, 64) dtype=float32 (created by layer 'conv2d_1')&gt;,
&lt;KerasTensor: shape=(None, 36, 36, 64) dtype=float32 (created by layer 'max_pooling2d_1')&gt;,
&lt;KerasTensor: shape=(None, 34, 34, 128) dtype=float32 (created by layer 'conv2d_2')&gt;,
&lt;KerasTensor: shape=(None, 17, 17, 128) dtype=float32 (created by layer 'max_pooling2d_2')&gt;,
&lt;KerasTensor: shape=(None, 15, 15, 128) dtype=float32 (created by layer 'conv2d_3')&gt;,
&lt;KerasTensor: shape=(None, 7, 7, 128) dtype=float32 (created by layer 'max_pooling2d_3')&gt;]
</pre>



<p>
當我們將圖像餵進這個模型時，此模型會傳回原始模型中特定層被激勵函數處理過後的值，這個模型只有1個輸入、8個輸出，每一層的激勵函數輸出結果變成一個輸出。<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36879;&#36942;model.predict()&#30340;&#34389;&#29702;, model&#23559;&#26371;&#22238;&#20659;&#19968;&#20491;&#26377;8&#20491;&#31070;&#32147;&#23652;&#34389;&#29702;&#24460;&#30340;output&#30340;&#21015;&#34920;:</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">activations</span> = activation_model.predict(img_tensor)
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">len</span>(activations)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35731;&#25105;&#20497;&#30906;&#35469;&#19968;&#19979;&#29986;&#29983;&#30340;&#25976;&#37327;</span>
</pre>
</div>

<pre class="example">
1/1 [==============================] - 0s 17ms/step
8
</pre>
</div>
</div>
<div id="outline-container-orgfecd2cd" class="outline-3">
<h3 id="orgfecd2cd"><span class="section-number-3">9.3.</span> 第一層卷積層效果</h3>
<div class="outline-text-3" id="text-9-3">
<p>
以下是我們的貓圖(如圖<a href="#orgcc90505">49</a>)經過CNN後的第一個卷積層在經過的激勵函數轉換<br />
後的輸出：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">first_layer_activation</span> = activations[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(first_layer_activation.shape) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30475;&#19968;&#19979;&#31532;&#19968;&#23652;&#29986;&#29983;&#30340;shape</span>
</pre>
</div>

<pre class="example">
(1, 148, 148, 32)
</pre>


<p>
這是一個具有32個channel的148x148特徵圖(feature map)。<br />
</p>
</div>
<div id="outline-container-orgedb8297" class="outline-4">
<h4 id="orgedb8297"><span class="section-number-4">9.3.1.</span> Channel 3</h4>
<div class="outline-text-4" id="text-9-3-1">
<p>
其中第3個channel的圖像為：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31168;&#20986;&#31532;3&#20491;&#38971;&#23566;&#30340;&#29305;&#24501;&#22294;</span>
<span class="linenr">3: </span>plt.matshow(first_layer_activation[<span style="color: #da8548; font-weight: bold;">0</span>, :, :, <span style="color: #da8548; font-weight: bold;">3</span>], cmap=<span style="color: #98be65;">'viridis'</span>)
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">5: </span>plt.savefig(<span style="color: #98be65;">'images/cat.1700.channel3.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="org5dc8dbb" class="figure">
<p><img src="images/cat.1700.channel3.png" alt="cat.1700.channel3.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 50: </span>Caption</p>
</div>

<p>
這張圖看起來似乎可以看成對圖片對角邊緣的編碼檢測器。讓我們嘗試第30個頻道(P.S. 這裡每個人的執行結果可能會有所差異，因為卷積層學習的特定濾鏡不是確定性的, not deterministic)。<br />
</p>
</div>
</div>
<div id="outline-container-orgfac1d3c" class="outline-4">
<h4 id="orgfac1d3c"><span class="section-number-4">9.3.2.</span> Channel 6</h4>
<div class="outline-text-4" id="text-9-3-2">
<p>
其中第6個channel的圖像為：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31168;&#20986;&#31532;3&#20491;&#38971;&#23566;&#30340;&#29305;&#24501;&#22294;</span>
<span class="linenr">3: </span>plt.matshow(first_layer_activation[<span style="color: #da8548; font-weight: bold;">0</span>, :, :, <span style="color: #da8548; font-weight: bold;">6</span>], cmap=<span style="color: #98be65;">'viridis'</span>)
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">5: </span>plt.savefig(<span style="color: #98be65;">'images/cat.1700.channel6.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="orgba7808e" class="figure">
<p><img src="images/cat.1700.channel6.png" alt="cat.1700.channel6.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 51: </span>Channel 6</p>
</div>
</div>
</div>
<div id="outline-container-orgc50ac57" class="outline-4">
<h4 id="orgc50ac57"><span class="section-number-4">9.3.3.</span> Channel 24</h4>
<div class="outline-text-4" id="text-9-3-3">
<p>
其中第24個channel的圖像為：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31168;&#20986;&#31532;3&#20491;&#38971;&#23566;&#30340;&#29305;&#24501;&#22294;</span>
<span class="linenr">3: </span>plt.matshow(first_layer_activation[<span style="color: #da8548; font-weight: bold;">0</span>, :, :, <span style="color: #da8548; font-weight: bold;">24</span>], cmap=<span style="color: #98be65;">'viridis'</span>)
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">5: </span>plt.savefig(<span style="color: #98be65;">'images/cat.1700.channel24.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="org9b3665b" class="figure">
<p><img src="images/cat.1700.channel24.png" alt="cat.1700.channel24.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 52: </span>Channel 24</p>
</div>
</div>
</div>
<div id="outline-container-org4e774f9" class="outline-4">
<h4 id="org4e774f9"><span class="section-number-4">9.3.4.</span> Channel 27</h4>
<div class="outline-text-4" id="text-9-3-4">
<p>
其中第27個channel的圖像為：<br />
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31168;&#20986;&#31532;3&#20491;&#38971;&#23566;&#30340;&#29305;&#24501;&#22294;</span>
<span class="linenr">3: </span>plt.matshow(first_layer_activation[<span style="color: #da8548; font-weight: bold;">0</span>, :, :, <span style="color: #da8548; font-weight: bold;">27</span>], cmap=<span style="color: #98be65;">'viridis'</span>)
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
<span class="linenr">5: </span>plt.savefig(<span style="color: #98be65;">'images/cat.1700.channel27.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="org4b9b9dd" class="figure">
<p><img src="images/cat.1700.channel27.png" alt="cat.1700.channel27.png" width="300" /><br />
</p>
<p><span class="figure-number">Figure 53: </span>Channel 27</p>
</div>
</div>
</div>
<div id="outline-container-orgd247e24" class="outline-4">
<h4 id="orgd247e24"><span class="section-number-4">9.3.5.</span> 依序觀察每一層的結果</h4>
<div class="outline-text-4" id="text-9-3-5">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31168;&#20986;&#31532;30&#20491;&#38971;&#23566;&#30340;&#29305;&#24501;&#22294;</span>
<span class="linenr">2: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">32</span>):
<span class="linenr">3: </span>    plt.matshow(first_layer_activation[<span style="color: #da8548; font-weight: bold;">0</span>, :, :, i], cmap=<span style="color: #98be65;">'viridis'</span>)
<span class="linenr">4: </span>    plt.title(f<span style="color: #98be65;">'channel: </span>{i}<span style="color: #98be65;">'</span>)
<span class="linenr">5: </span>    plt.show()
<span class="linenr">6: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig('images/cat.1700.channel10.png', dpi=300)</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org8af9aee" class="outline-3">
<h3 id="org8af9aee"><span class="section-number-3">9.4.</span> 各層的輸出結果</h3>
<div class="outline-text-3" id="text-9-4">
<p>
現在，我們來輸出這個CNN模型中每一層輪出的完整樣貌，我們從中提取、繪製每8個特徵圖(feature maps)中的通道，並將結果以類似matplotlib的subplot()呈現出來。<br />
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> keras
<span class="linenr"> 2: </span>
<span class="linenr"> 3: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36664;&#20986;&#27599;&#19968;&#23652;&#30340;&#31070;&#32147;&#23652;&#21517;&#31281;</span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">layer_names</span> = []
<span class="linenr"> 5: </span><span style="color: #51afef;">for</span> layer <span style="color: #51afef;">in</span> model.layers[:<span style="color: #da8548; font-weight: bold;">8</span>]:
<span class="linenr"> 6: </span>    layer_names.append(layer.name)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">images_per_row</span> = <span style="color: #da8548; font-weight: bold;">16</span> <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27599;&#19968;&#25490;&#36664;&#20986;16&#20491;&#29305;&#24501;&#22294;</span>
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27599;&#19968;&#23652;&#29305;&#24501;&#22294;&#30340;Shapes</span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#01 -&gt; (148, 148, 32)</span>
<span class="linenr">12: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#02 -&gt; (74, 74, 32)</span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#03 -&gt; (72, 72, 64)</span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#04 -&gt; (36, 36, 64)</span>
<span class="linenr">15: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#05 -&gt; (34, 34, 128)</span>
<span class="linenr">16: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#06 -&gt; (17, 17, 128)</span>
<span class="linenr">17: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#07 -&gt; (15, 15, 128)</span>
<span class="linenr">18: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">layer#08 -&gt; (7, 7, 128)</span>
<span class="linenr">19: </span>
<span class="linenr">20: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36664;&#20986;&#29305;&#24501;&#22294;</span>
<span class="linenr">21: </span><span style="color: #51afef;">for</span> layer_name, layer_activation <span style="color: #51afef;">in</span> <span style="color: #c678dd;">zip</span>(layer_names, activations): <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25105;&#20497;&#26377;8&#23652;&#30340;&#31070;&#32147;&#20803;&#30340;&#36664;&#20986;</span>
<span class="linenr">22: </span>    <span style="color: #dcaeea;">n_features</span> = layer_activation.shape[-<span style="color: #da8548; font-weight: bold;">1</span>] <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#27599;&#19968;&#23652;&#29305;&#24501;&#22294;&#30340;&#25976;&#37327;</span>
<span class="linenr">23: </span>    <span style="color: #dcaeea;">size</span> = layer_activation.shape[<span style="color: #da8548; font-weight: bold;">1</span>] <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#27599;&#19968;&#20491;&#29305;&#24501;&#22294;&#30340;&#23532;&#33287;&#39640; (1, size, size, n_features)</span>
<span class="linenr">24: </span>
<span class="linenr">25: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25105;&#20497;&#26371;&#25226;&#22810;&#20491;&#29305;&#24501;&#22294;&#20018;&#25509;&#22312;&#19968;&#20491;&#27604;&#36611;&#22823;&#30340;&#30697;&#38499;</span>
<span class="linenr">26: </span>    <span style="color: #dcaeea;">n_cols</span> = n_features // images_per_row <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31639;&#19968;&#19979;&#36889;&#20491;&#22823;&#30697;&#38499;&#30340;&#26371;&#26377;&#24190;&#27396;</span>
<span class="linenr">27: </span>    <span style="color: #dcaeea;">display_grid</span> = np.zeros((size * n_cols, images_per_row * size)) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29986;&#29983;&#19968;&#20491;&#22823;&#30697;&#38499;</span>
<span class="linenr">28: </span>
<span class="linenr">29: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27169;&#25836;matpolotlib subplot()&#25928;&#26524;</span>
<span class="linenr">30: </span>    <span style="color: #51afef;">for</span> col <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(n_cols):
<span class="linenr">31: </span>        <span style="color: #51afef;">for</span> row <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(images_per_row):
<span class="linenr">32: </span>            <span style="color: #dcaeea;">channel_image</span> = layer_activation[<span style="color: #da8548; font-weight: bold;">0</span>, :, :, col * images_per_row + row]
<span class="linenr">33: </span>            <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Post-process the feature to make it visually palatable</span>
<span class="linenr">34: </span>            <span style="color: #dcaeea;">channel_image</span> -= channel_image.mean()
<span class="linenr">35: </span>            <span style="color: #dcaeea;">channel_image</span> /= channel_image.std()
<span class="linenr">36: </span>            <span style="color: #dcaeea;">channel_image</span> *= <span style="color: #da8548; font-weight: bold;">64</span>
<span class="linenr">37: </span>            <span style="color: #dcaeea;">channel_image</span> += <span style="color: #da8548; font-weight: bold;">128</span>
<span class="linenr">38: </span>            <span style="color: #dcaeea;">channel_image</span> = np.clip(channel_image, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">255</span>).astype(<span style="color: #98be65;">'uint8'</span>)
<span class="linenr">39: </span>            <span style="color: #dcaeea;">display_grid</span>[col * size : (col + <span style="color: #da8548; font-weight: bold;">1</span>) * size,
<span class="linenr">40: </span>                         row * size : (row + <span style="color: #da8548; font-weight: bold;">1</span>) * size] = channel_image
<span class="linenr">41: </span>
<span class="linenr">42: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23637;&#31034;&#25340;&#36028;&#20986;&#20358;&#30340;&#32080;&#26524;</span>
<span class="linenr">43: </span>    <span style="color: #dcaeea;">scale</span> = <span style="color: #da8548; font-weight: bold;">1</span>. / size
<span class="linenr">44: </span>    plt.figure(figsize=(scale * display_grid.shape[<span style="color: #da8548; font-weight: bold;">1</span>],
<span class="linenr">45: </span>                        scale * display_grid.shape[<span style="color: #da8548; font-weight: bold;">0</span>]))
<span class="linenr">46: </span>    plt.title(layer_name)
<span class="linenr">47: </span>    plt.grid(<span style="color: #a9a1e1;">False</span>)
<span class="linenr">48: </span>    <span style="color: #dcaeea;">fn</span> = layer_name+<span style="color: #98be65;">".png"</span>
<span class="linenr">49: </span>    plt.imshow(display_grid, aspect=<span style="color: #98be65;">'auto'</span>, cmap=<span style="color: #98be65;">'viridis'</span>)
<span class="linenr">50: </span>    plt.savefig(<span style="color: #98be65;">'images/'</span>+fn, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">51: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
</pre>
</div>

<div id="org532de49" class="figure">
<p><img src="images/conv2d.png" alt="conv2d.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 54: </span>經過第一個卷積層</p>
</div>

<div id="org830c5b1" class="figure">
<p><img src="images/max_pooling2d.png" alt="max_pooling2d.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 55: </span>max pooling轉換後</p>
</div>

<div id="orga2ce3bf" class="figure">
<p><img src="images/conv2d_1.png" alt="conv2d_1.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 56: </span>經過第二個卷積層</p>
</div>

<div id="org5602a11" class="figure">
<p><img src="images/max_pooling2d_1.png" alt="max_pooling2d_1.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 57: </span>經過第二次max pooling</p>
</div>

<div id="org94232fe" class="figure">
<p><img src="images/conv2d_2.png" alt="conv2d_2.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 58: </span>經過第三個卷積層</p>
</div>

<div id="org8ad528d" class="figure">
<p><img src="images/max_pooling2d_2.png" alt="max_pooling2d_2.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 59: </span>第三個max pooling</p>
</div>

<div id="org6b28392" class="figure">
<p><img src="images/conv2d_3.png" alt="conv2d_3.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 60: </span>第四個卷積層</p>
</div>

<div id="org7508236" class="figure">
<p><img src="images/max_pooling2d_3.png" alt="max_pooling2d_3.png" width="800" /><br />
</p>
<p><span class="figure-number">Figure 61: </span>第四個max pooling</p>
</div>

<p>
由上圖可知，隨層數越來越高，啟動函數的輸出變得越來越抽象，視覺上也越來越難解釋，model 開始編碼出更高階的概念。此外，啟動函數輸出的稀疏性也隨著層數的深度而增加，在第一層中，所有的過濾器都被輸入影響所驅動(都有值)，但接下來就有越來越多的 filter 的值是空的(全黑)，這表示在這些層的輸入影像中已經找不到過濾器要編碼的圖案 pattern 了。<br />
</p>

<p>
上述示例也證明了深度神經網路所學習到的表示法有一個重要特性：各層萃取的特徵隨著層的𣶶度而變的越來越抽象，越高階的啟動函數越不會帶有關於特定輸入的資訊，卻具備更多關於目標的資訊（此例中指的是貓或狗）。這和人或動物感知世界的方式很像：在觀察一個場景幾秒中後閉眼，我們可以記得場景中有哪些抽象事物，但不會記得每個物體的特殊外觀，因為大腦也會將事物抽象化。<br />
</p>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://ithelp.ithome.com.tw/articles/10191820">Day 06：處理影像的利器 &#x2013; 卷積神經網路(Convolutional Neural Network)</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/@syshen/%E5%85%A5%E9%96%80%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-2-d694cad7d1e5">入門深度學習 — 2</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/chiukevin0321/cnn-%E5%82%B3%E7%B5%B1nn-comparison-9b0a6a9b1e2d">DNN &amp; CNN comparison</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/@chih.sheng.huang821/%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-convolutional-neural-network-cnn-%E5%8D%B7%E7%A9%8D%E8%A8%88%E7%AE%97%E7%9A%84%E5%80%92%E5%82%B3%E9%81%9E%E6%8E%A8%E5%B0%8E%E8%88%87%E7%A8%80%E7%96%8F%E7%9F%A9%E9%99%A3%E8%A7%80%E9%BB%9E%E4%BE%86%E7%9C%8B%E5%8D%B7%E7%A9%8D%E8%A8%88%E7%AE%97-e82ac16e510f">卷積神經網路(Convolutional neural network, CNN):卷積計算的倒傳遞推導與稀疏矩陣觀點來看卷積計算</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/">An Intuitive Explanation of Convolutional Neural Networks</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6" role="doc-backlink">6</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/0010822932">Deep learning 深度學習必讀：Keras 大神帶你用 Python 實作</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.7" class="footnum" href="#fnr.7" role="doc-backlink">7</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://blog.yeshuanova.com/2018/10/dataset-iris/">機器學習資料集 - Iris dataset </a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.8" class="footnum" href="#fnr.8" role="doc-backlink">8</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://aifreeblog.herokuapp.com/posts/54/data_science_203/">資料的正規化(Normalization)及標準化(Standardization)</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.9" class="footnum" href="#fnr.9" role="doc-backlink">9</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/yiyi-network/transfer-learning-1f87d4f1886f">Kaggle Learn | Deep Learning 深度學習 | 學習資源介紹 (Part 2)</a><br />
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2024-05-03 Fri 09:22</p>
</div>
</body>
</html>
