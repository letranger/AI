:PROPERTIES:
:ID:       20221023T101626.420918
:END:
#+title: 監督式學習

# -*- org-export-babel-evaluate: nil -*-
#+TAGS: AI, Machine Learning, SVM, RBM
#+OPTIONS: toc:2 ^:nil num:5
#+PROPERTY: header-args :eval never-export
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../css/muse.css" />
#+begin_export html
<a href="https://letranger.github.io/AI/20221023101626-監督式學習.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023101626-監督式學習.html.svg"/></a>
#+end_export

* Read :noexport:
- [[https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4][熵及資訊獲利]]
- [[http://debussy.im.nuu.edu.tw/sjchen/MachineLearning/final/CLS_DT.pdf][決策樹學習： 聯合大學資管系]]

* 簡介
監督式學習獲得的結果可以是數值、也可以是類別，以結果分類，我們可以將監督式學分大致分為兩類：[[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][迴歸]](結果為數值)與[[id:1592687a-cca7-4473-83a0-682a36394a28][分類]](結果為類別)。
** 監督式學習的主要類型
*** 分類(Cliasification)

分類問題也稱為離散(discrete)預測問題，因為每個分類都是一個離散群組。In supervised learning, the training set you feed to the algorithm includes the desired solutions, called labels[fn:1].

#+CAPTION: 典型的監督式學習：垃圾郵件分類
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/2022-04-30_10-38-58.jpg]]

可再細分為:
- Binary classification
- Multiclass classification

典型的分類案例: MNIST, IRIS
*** 迴歸(Regression)
另一種監督式學習為[[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][迴歸]]（regression），即，根據一組預測特徵（predictor，如里程數、車齡、品牌）來預測目標數值（如二手車車價）[fn:1]，這個目標數值也是label。

有些迴歸演算法也可以用來分類，例如Logistic，它可以輸出一個數值，以這個數值來表示對應到特定類別的機率，例如，某封email為垃圾郵件的機率為20%、某張圖片為狗的機率為70%。

迴歸問題可再細分為兩類：
- Linear regression:
  * 假設輸入變量(x)與單一輸出變量(y)間存在線性關係，並以此建立模型。
  * 優點: 簡單、容易解釋
  * 缺點: 輸入與輸出變量關係為線性時會導致低度擬合
  * 例: 身高與體重間的關係
- Logistic regression
  * 也是線性方法，但使用logist function轉換輸出的預測結果，其輸出結果為類別機率(class probabilities)
  * 優點: 簡單、容易解釋
  * 缺點: 輸入與輸出變量關係為線性時無法處理分類問題

典型迴歸案例: Boston Housing Data
** 範例
*** 信用卡詐欺
以信用卡公司來說，信用卡詐欺可以透過各種資料對照評分，預測出該事件的分數。例如地點：一個平時生活在台灣的用戶忽然在日本刷卡、或一個平時都是白天刷卡消費的用戶忽然在凌晨三點刷卡，這些事件都可以當成評分指標(特徵)，提供模型做為預測是否為信用卡詐欺的預測依據。
*** 影像辨識
** 特例
[[id:20221023T101626.420918][監督式學習]]主要包括[[id:1592687a-cca7-4473-83a0-682a36394a28][分類]]和[[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][迴歸]]，但也包括以下奇特的例子：
- 序列生成(sequence generation)：給定一張圖，產生一個標題來描述該圖片，有時也可以使用一部份連續的資料進行預測。
- 語法樹預測(syntax tree prediction)：給定一個句子，以語意的結構為節點，預測並分解成語法樹。
- 物體偵測(object detection)：給定一張圖片，繪製邊界框來標示圖片內不同的物體。這也可以視為分類問題（給定許多候選邊界框，對每個邊界框的內容進行分類）或并用分類和迴歸技巧，透過向量迴歸預測邊界框。
- 圖像分割(image segmentation)：給定一張圖片，用像素遮罩(pixel-level mask)來區別不同物體。
- Linear Regression: 拿前幾天的空氣 PM 值預估未來的空氣 PM 值
- Classification
  1) Binary Classification: 垃圾郵件分類
  2) Multi-class Classification: 手語翻譯
  3) k-Nearest Neighbors (KNN)
  4) Naive Bayes Classifiers
  5) Decision Tree
  6) Neural Networks (Deep Learning)
  7) Ensembles of Decision Trees
  8) Linear Models: Logistic regression

* 監督式學習基本步驟
1. 準備學習對象的資料
2. 將資料分為輸入資料（特徵）與輸出資料（標籤、即該組特徵的答案）
3. 將特徵輸入類神經網路
4. 將類神經網路的預測結果與標籤進行比較、計算二者間的差異
5. 將4.的差異回饋給模型、依此更新模型中的參數
6. 回到3.

* 監督式學習演算法
** K-nearest neighbors (KNN)
KNN藉由找出與新資料點最相近的 /k/ 個已具有label的資料點，讓這些資料點投票決定新資料點的label。
- 優點: 能處理更複雜的非線性關係，但仍可被解釋
- 缺點: 隨著資料與features的數量增加，KNN的效果也會降低； /k/ 值的選擇也會影響KNN的效果，太小的 /k/ 值會導致過度擬合、太高的 /k/ 值則會低度擬合。
- 應用: 經常用於推薦系統
** Methods based on tree(Decision tree and Random Forest)
- Single decision tree: 遍歷所有訓練資枓來建立規則，但容易過度擬合
- Bagging: 將上述tree加入bootstrap aggregation(如bagging)，即，使用多次隨機實例採樣(multiple random samples of instances)，並為每次採樣建立一棵decision tree，並對每個資料實例進行預測，預測方式為透過平均每棵樹的預測結果，藉由這種方式可以解決decision tree容易過度擬合的問題。
- Random forest: 除了將資料實例進行採樣，也對每棵decision tree的分支條件中 *待預測label* 進行隨機採樣，而非使用所有的待預測label。透過這種方式，random forest可以建立出彼此相關性更低的decision，進而改善過度擬合與泛化誤差。
** Boosting
同樣是建立許多樹，但是它 *依多建立每棵decision tree* , 利用前一棵decision所習得的資訊來改善下一棵decision tree的預測結果。是所有tree-based solution中表現最好的方式，也是許多machine learning比賽的常勝軍。
- 優點：performance佳，能處理資料缺失與特徵分類問題
- 缺點：可解釋性低
** SVM(Support Vector Machines)
使用演算法和已知的label在空間中建構超平面來分類資料
** 神經網路

* 監督式學習實作
- [[id:1592687a-cca7-4473-83a0-682a36394a28][分類]]
- [[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][迴歸]]

* 推薦系統: 受限波爾茲曼機 on MovieLens
MovieLens 是一個推薦系統和虛擬社區網站，於1997年建立。其主要功能為應用協同過濾技術和用戶對電影的喜好，向用戶推薦電影。該網站是GroupLens研究所旗下一個項目，該研究所隸屬於美國明尼蘇達大學雙城分校計算機科學與工程系。MovieLens 20M資料集包含20,000,263筆關於27,278部電影的評價，評價者共138,493人。
** 資料準備
*** Setup
#+begin_src python -r -n :results output :exports both :session ML
'''Main'''
import numpy as np
import pandas as pd
import os, time, re
import pickle, gzip, datetime
from datetime import datetime
from zipfile import ZipFile
from urllib.request import urlretrieve

'''Data Viz'''
import matplotlib.pyplot as plt
import seaborn as sns
color = sns.color_palette()
import matplotlib as mpl

'''Data Prep and Model Evaluation'''
from sklearn import preprocessing as pp
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import log_loss
from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error

'''Algos'''
#import lightgbm as lgb

'''TensorFlow and Keras'''
import tensorflow as tf
from tensorflow import keras
K = keras.backend

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Activation, Dense, Dropout
from tensorflow.keras.layers import BatchNormalization, Input, Lambda
from tensorflow.keras.layers import Embedding, Flatten, dot
from tensorflow.keras import regularizers
from tensorflow.keras.losses import mse, binary_crossentropy
#+end_src

#+RESULTS:
*** Check library version
#+begin_src python -r -n :results output :exports both :session ML
import sys, sklearn
print(f'sklearn    {sklearn.__version__}')
print(f'tensorflow {tf.__version__}')
print(f'keras      {keras.__version__}')
print(f'numpy      {np.__version__}')
#+end_src

#+RESULTS:
: sklearn    1.0.1
: tensorflow 2.7.0
: keras      2.7.0
: numpy      1.19.5
*** Download and unzip the Data
#+begin_src python -r -n :results output :exports both :session ML
# Download and read into Pandas DataFrame
#import os
#from urllib.request import urlretrieve
current_path = os.getcwd()
urlretrieve("http://files.grouplens.org/datasets/movielens/ml-20m.zip", \
            current_path+"/dataset/movielens.zip")
ZipFile(current_path+"/dataset/movielens.zip", "r").extractall(current_path+"/dataset/")

#+end_src

#+RESULTS:
*** Load data
#+begin_src python -r -n :results output :exports both :session ML
ratingDF = pd.read_csv("./dataset/ml-20m/ratings.csv")
print(ratingDF)
#+end_src

#+RESULTS:
#+begin_example
          userId  movieId  rating   timestamp
0              1        2     3.5  1112486027
1              1       29     3.5  1112484676
2              1       32     3.5  1112484819
3              1       47     3.5  1112484727
4              1       50     3.5  1112484580
...          ...      ...     ...         ...
20000258  138493    68954     4.5  1258126920
20000259  138493    69526     4.5  1259865108
20000260  138493    69644     3.0  1260209457
20000261  138493    70286     5.0  1258126944
20000262  138493    71619     2.5  1255811136

[20000263 rows x 4 columns]
#+end_example
*** 轉換資料
#+begin_src python -r -n :results output :exports both :session ML
# Convert fields into appropriate data types
from datetime import datetime
import pandas as pd
ratingDF = pd.read_csv("./dataset/ml-20m/ratings.csv")
ratingDF.userId = ratingDF.userId.astype(str).astype(int)
ratingDF.movieId = ratingDF.movieId.astype(str).astype(int)
ratingDF.rating = ratingDF.rating.astype(str).astype(float)
ratingDF.timestamp = ratingDF.timestamp.apply(lambda x: \
                        datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))
# Store DataFrame as pickle for faster loading in the future
ratingDF.to_pickle("./dataset/ml-20m/ratingPickle")
ratingDF = pd.read_pickle("./dataset/ml-20m/ratingPickle")
# Preview data
print(ratingDF.head())
#+end_src

#+RESULTS:
:    userId  movieId  rating            timestamp
: 0       1        2     3.5  2005-04-02 23:53:47
: 1       1       29     3.5  2005-04-02 23:31:16
: 2       1       32     3.5  2005-04-02 23:33:39
: 3       1       47     3.5  2005-04-02 23:32:07
: 4       1       50     3.5  2005-04-02 23:29:40
*** 確認使用者、評價數量
#+begin_src python -r -n :results output :exports both :session ML
# Calculate summary statistics on full dataset
n_users = ratingDF.userId.unique().shape[0]
n_movies = ratingDF.movieId.unique().shape[0]
n_ratings = len(ratingDF)
avg_ratings_per_user = n_ratings/n_users

print(f'Number of unique users: {n_users}')
print(f'Number of unique movies: {n_movies}')
print(f'Number of total ratings: {n_ratings}')
print(f'Average number of ratings per user: {round(avg_ratings_per_user,1)}')
#+end_src

#+RESULTS:
: Number of unique users: 138493
: Number of unique movies: 26744
: Number of total ratings: 20000263
: Average number of ratings per user: 144.4
*** 只取前1000筆記錄
#+begin_src python -r -n :results output :exports both :session ML
# Reduce size of dataset by taking top 1000 movies
movieIndex = ratingDF.groupby("movieId").count().sort_values(by=
                "rating",ascending=False)[0:1000].index
ratingDFX2 = ratingDF[ratingDF.movieId.isin(movieIndex)]
print(ratingDFX2.count())
#+end_src

#+RESULTS:
: userId       12840344
: movieId      12840344
: rating       12840344
: timestamp    12840344
: dtype: int64


隨機抽1000位使用者，以這1000位使用者來過濾資料集，如此可以將庫筆數由12840344縮至90213
#+begin_src python -r -n :results output :exports both :session ML
# Reduce size of dataset by sampling 1000 users
userIndex = ratingDFX2.groupby("userId").count().sort_values(by=
    "rating",ascending=False).sample(n=1000, random_state=2018).index
ratingDFX3 = ratingDFX2[ratingDFX2.userId.isin(userIndex)]
print(ratingDFX3.count())
#+end_src

#+RESULTS:
: userId       90213
: movieId      90213
: rating       90213
: timestamp    90213
: dtype: int64
*** 針對已縮減的資料集重建index(movieID, userID)
#+begin_src python -r -n :results output :exports both :session ML
# Reindex movie ID
movies = ratingDFX3.movieId.unique()
moviesDF = pd.DataFrame(data=movies,columns=['originalMovieId'])
moviesDF['newMovieId'] = moviesDF.index+1
print(moviesDF.head())
# Reindex user ID
users = ratingDFX3.userId.unique()
usersDF = pd.DataFrame(data=users,columns=['originalUserId'])
usersDF['newUserId'] = usersDF.index+1
print(usersDF.head())
# Generate newly merged DataFrame
ratingDFX3 = ratingDFX3.merge(moviesDF,left_on='movieId',
                              right_on='originalMovieId')
ratingDFX3.drop(labels='originalMovieId', axis=1, inplace=True)
ratingDFX3 = ratingDFX3.merge(usersDF,left_on='userId',
                              right_on='originalUserId')
ratingDFX3.drop(labels='originalUserId', axis=1, inplace=True)
print(ratingDFX3.head(3))
#+end_src

#+RESULTS:
#+begin_example
   originalMovieId  newMovieId
0               50           1
1              163           2
2              216           3
3              296           4
4              333           5
   originalUserId  newUserId
0              49          1
1             260          2
2             311          3
3             319          4
4             499          5
   userId  movieId  rating            timestamp  newMovieId  newUserId
0      49       50     5.0  2013-05-03 02:50:26           1          1
1      49      163     3.5  2013-05-03 02:43:37           2          1
2      49      216     3.0  2013-05-03 02:45:58           3          1
#+end_example
*** 計算縮減資料庫大小
#+begin_src python -r -n :results output :exports both :session ML
# Calculate summary statistics on reduced dataset
n_users = ratingDFX3.userId.unique().shape[0]
n_movies = ratingDFX3.movieId.unique().shape[0]
n_ratings = len(ratingDFX3)
avg_ratings_per_user = n_ratings/n_users

print(f'Number of unique users: {n_users}')
print(f'Number of unique movies: {n_movies}')
print(f'Number of total ratings: {n_ratings}')
print(f'Average number of ratings per user: {round(avg_ratings_per_user,1)}')
#+end_src

#+RESULTS:
: Number of unique users: 1000
: Number of unique movies: 1000
: Number of total ratings: 90213
: Average number of ratings per user: 90.2
*** 產生訓練集、測試集和驗證集
#+begin_src python -r -n :results output :exports both :session ML
# Split into validation and test, such that each is 5% of the dataset
X_train, X_test = train_test_split(ratingDFX3, test_size=0.10, \
                                   shuffle=True, random_state=2018)
X_valid, X_test = train_test_split(X_test,     test_size=0.50, \
                                   shuffle=True, random_state=2018)
# Confirm size of train, validation, and test datasets
for (l,x) in [('train',X_train),('validation',X_valid),('test',X_test)]:
    print(f'Size of {l} set: {len(x)}')
print(X_train.shape)
print(X_test.shape)
print(X_valid.shape)
#+end_src

#+RESULTS:
: Size of train set: 81191
: Size of validation set: 4511
: Size of test set: 4511
: (81191, 6)
: (4511, 6)
: (4511, 6)
** 定義loss function
先建一個 $m\times n$ 的矩陣，$m$ 為使用者、$n$ 為電影。此為稀疏矩陣，因為一位使用者不會對所有電影評價。
#+begin_src python -r -n :results output :exports both :session ML
# Generate ratings matrix for train, validation and test
ratings_train = np.zeros((n_users, n_movies))
ratings_valid = np.zeros((n_users, n_movies))
ratings_test  = np.zeros((n_users, n_movies))
for (X,ratings) in [(X_train,ratings_train),(X_valid,ratings_valid),(X_test,ratings_test)]:
    for row in X.itertuples():
        ratings[row[6]-1, row[5]-1] = row[3]
print(ratings_train.shape, ratings_valid.shape, ratings_test.shape)
#+end_src

#+RESULTS:
: (1000, 1000) (1000, 1000) (1000, 1000)

使用MSE評估預測值與實際值間的均方差，故需要兩個大小為 /[n,1]/ 的矩陣，一個放實際評價、一個放預估評價
*** 先將稀疏矩陣展開
#+begin_src python -r -n :results output :exports both :session ML
# Flatten the sprace matrix with the rations for the validation set. This will be the vector of actual ratings
actual_valid = ratings_valid[ratings_valid.nonzero()].flatten()
#+end_src

#+RESULTS:

*** 以電影平均評價(3.5)做為驗證集的評價預測，計算MSE，得到基準值1.06
#+begin_src python -r -n :results output :exports both :session ML
pred_valid = np.zeros((len(X_valid),1))
pred_valid[pred_valid==0] = 3.5
naive_prediction = mean_squared_error(pred_valid, actual_valid)
print(f'Mean squared error using naive prediction: {round(naive_prediction,2)}')
#+end_src

#+RESULTS:
: Mean squared error using naive prediction: 1.06

*** 以使用者對所有其他影片的平均評價來預測一部未評價的電影評價
#+begin_src python -r -n :results output :exports both :session ML
ratings_valid_pred = np.zeros((n_users, n_movies))
i = 0
for row in ratings_train:
    ratings_valid_pred[i][ratings_valid_pred[i]==0] = np.mean(row[row>0])
    i += 1

pred_valid = ratings_valid_pred[ratings_valid.nonzero()].flatten()
user_average = mean_squared_error(pred_valid, actual_valid)
print(f'Mean squared error using user average: {round(user_average,3)}')
#+end_src

#+RESULTS:
: Mean squared error using user average: 0.909

MSE改善至0.9
*** 以所有其他使用者對於某電影的評價來預估某使用者的評價
#+begin_src python -r -n :results output :exports both :session ML
ratings_valid_pred = np.zeros((n_users, n_movies)).T
i = 0
for row in ratings_train.T:
    ratings_valid_pred[i][ratings_valid_pred[i]==0] = np.mean(row[row>0])
    i += 1

ratings_valid_pred = ratings_valid_pred.T
pred_valid = ratings_valid_pred[ratings_valid.nonzero()].flatten()
movie_average = mean_squared_error(pred_valid, actual_valid)
print(f'Mean squared error using movie average: {round(movie_average,3)}')
#+end_src

#+RESULTS:
: Mean squared error using movie average: 0.914
** 矩陣分解
矩陣分解(Matrix Factorization)為目前最成功且最受歡迎的協同過濾演算法之一，它將使用者-物品矩陣分解成兩個較低維度矩陣的乘積，使用者與物品各自在較低維的潛在空間內被表示。
假設使用者-物品矩陣為R，有m個使用者和n個物品，矩陣分解會建立兩個低維矩陣:H和W，
- H為「m個使用者」X「k個潛在因子」矩陣
- W為「k個潛在因子」X「m個使用者」矩陣
潛在因子（latent factor）k的數量決定了模型的容量，k越高模型容量越大，但當k過高則易出現過擬合現象。
*** 單個潛在因子
從最簡單的形式（只有一個潛在因子）開始，使用Keras進行矩陣分解
#+begin_src python -r -n :results output :exports both  :session ML
plt.clf()
from tensorflow.keras.layers import BatchNormalization, Input, Lambda
from tensorflow.keras.layers import Embedding, Flatten, dot
n_latent_factors = 1

user_input = Input(shape=[1], name='user')
user_embedding = Embedding(input_dim=n_users + 1,
                           output_dim=n_latent_factors,
                           name='user_embedding')(user_input)
user_vec = Flatten(name='flatten_users')(user_embedding)

movie_input = Input(shape=[1], name='movie')
movie_embedding = Embedding(input_dim=n_movies + 1,
                            output_dim=n_latent_factors,
                            name='movie_embedding')(movie_input)
movie_vec = Flatten(name='flatten_movies')(movie_embedding)

product = dot([movie_vec, user_vec], axes=1)
model = Model(inputs=[user_input, movie_input], outputs=product)
model.compile('adam', 'mean_squared_error')

history = model.fit(x=[X_train.newUserId, X_train.newMovieId],
                    y=X_train.rating, epochs=100,
                    validation_data=([X_valid.newUserId, X_valid.newMovieId], X_valid.rating),
                    verbose=1)

pd.Series(history.history['val_loss'][10:]).plot(logy=False)
plt.xlabel("Epoch")
plt.ylabel("Validation Error")
print(f"Minimum MSE: {round(min(history.history['val_loss']),3)}")
plt.savefig('images/ML-1LF.png', dpi=300)
#+end_src

#+RESULTS:

Minimum MSE: 0.796

#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/ML-1LF.png]]
*** 三個潛在因子
#+begin_src python -r -n :results output :exports both  :session ML
plt.clf()
plt.cla()
from tensorflow.keras.layers import BatchNormalization, Input, Lambda
from tensorflow.keras.layers import Embedding, Flatten, dot
n_latent_factors = 3

user_input = Input(shape=[1], name='user')
user_embedding = Embedding(input_dim=n_users + 1,
                           output_dim=n_latent_factors,
                           name='user_embedding')(user_input)
user_vec = Flatten(name='flatten_users')(user_embedding)

movie_input = Input(shape=[1], name='movie')
movie_embedding = Embedding(input_dim=n_movies + 1,
                            output_dim=n_latent_factors,
                            name='movie_embedding')(movie_input)
movie_vec = Flatten(name='flatten_movies')(movie_embedding)

product = dot([movie_vec, user_vec], axes=1)
model = Model(inputs=[user_input, movie_input], outputs=product)
model.compile('adam', 'mean_squared_error')

history = model.fit(x=[X_train.newUserId, X_train.newMovieId],
                    y=X_train.rating, epochs=100,
                    validation_data=([X_valid.newUserId, X_valid.newMovieId], X_valid.rating),
                    verbose=1)

pd.Series(history.history['val_loss'][10:]).plot(logy=False)
plt.xlabel("Epoch")
plt.ylabel("Validation Error")
print(f"\n\nMinimum MSE: {round(min(history.history['val_loss']),3)}")
plt.savefig('images/ML-3LF.png', dpi=300)
#+end_src
#+RESULTS:
Minimum MSE: 0.76
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/ML-3LF.png]]
*** 五個潛在因子
#+begin_src python -r -n :results output :exports both  :session ML
plt.clf()
plt.cla()
from tensorflow.keras.layers import BatchNormalization, Input, Lambda
from tensorflow.keras.layers import Embedding, Flatten, dot
n_latent_factors = 5

user_input = Input(shape=[1], name='user')
user_embedding = Embedding(input_dim=n_users + 1,
                           output_dim=n_latent_factors,
                           name='user_embedding')(user_input)
user_vec = Flatten(name='flatten_users')(user_embedding)

movie_input = Input(shape=[1], name='movie')
movie_embedding = Embedding(input_dim=n_movies + 1,
                            output_dim=n_latent_factors,
                            name='movie_embedding')(movie_input)
movie_vec = Flatten(name='flatten_movies')(movie_embedding)

product = dot([movie_vec, user_vec], axes=1)
model = Model(inputs=[user_input, movie_input], outputs=product)
model.compile('adam', 'mean_squared_error')

history = model.fit(x=[X_train.newUserId, X_train.newMovieId],
                    y=X_train.rating, epochs=100,
                    validation_data=([X_valid.newUserId, X_valid.newMovieId], X_valid.rating),
                    verbose=1)

pd.Series(history.history['val_loss'][10:]).plot(logy=False)
plt.xlabel("Epoch")
plt.ylabel("Validation Error")
print(f"\n\nMinimum MSE: {round(min(history.history['val_loss']),3)}")
plt.savefig('images/ML-5LF.png', dpi=300)
#+end_src
#+RESULTS:
Minimum MSE: 0.749
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/ML-5LF.png]]
在前25回合後，有明顯的過擬合現象。
** 使用RBMs的協同過濾
受限玻爾茲曼機（RBM，Restricted Boltzmann machine）由多倫多大學的 Geoff Hinton 等人提出，它是一種可以用於降維、分類、回歸、協同過濾、特徵學習以及主題建模的算法。

RBMs有兩層：輸入/可視層(input layer/visible layer)和和隱藏層(hidden layer)，每一層的神經元會與其他層的神經元溝通，但不會與同層內的神經元有所連接，這是RBMs的限制。

RBMs的另一重要特徵是：層之間的溝通是雙向而非單向。

RBMs中的可視層神經元會與隱藏層的神經元溝通，然後隱藏層神經元會回傳資訊給可視層，如此來回數次。RBMs進行這種形式的溝通來發展生成模型，使隱藏層的輸出經過重新建構、近似於原先的輸入。

換言之，RMBs試圖建立一個生成模型，這個模型基於以下兩個相似度來協助預測使用者是否喜歡某部電影：
- 某部電影與使用者作過評價的其他電影間的相似度
- 使用者與為某部電影作過評價的其他使用者間的相似度

可視層中會有X個神經元，X為電影數量。每一個神經元有一個介於0~1的評價(經過歸一化)。可視層的神經元會與隱藏層的神經元溝通，隱藏層的神經元會試著學習資料內部的潛在特徵。

RBMs也被稱為對稱二分雙向圖，對稱是因為每個可視的節點都被連接到每個隱藏層的結點，二分是因為有兩層節點，雙向是因為資訊的交流。
** RBM神經網路架構
參考網路教學....這裡寫的太抽象(這本書竟然想用文字來把它說完，太不負責任)
- 有m個使用者和n部電影，有一個$m\times n$的矩陣
- 訓練RBM時批次傳入k個使用者與其對n部電影的評價，進行特定回合的訓練
- 每個被傳入神經網路的x代表一個使用者對n部電影的評價，可視層有n個節點
- 可以指定隱藏層的節點數量(通常會少於可視層，以便有效率的學習特徵)
- 每個輸入$v0$與其相對應的權重$w$相乘，這個權重是透過可視層到隱藏層的資訊交流而學習到的。最後加上一個隱藏層的偏差值向量$hb$，這個偏差值是為了確保至少有些神經元會觸發，然後將函數$W \times v0+hb$的結果傳入一個激活函數裡。
- 接下來對這個流程的輸出結果進行採樣(稝為 /Gibbs/ 採樣)，也就是從隱藏層的激活函數的輸出最終是被隨機挑選，這種隨機方式有助於強化模型的效能與強韌性。
- 在 /Gibbs/ 採樣後的輸出$h0$透過神經網路以相反的方向被回傳，這個過程稱為backward pass。在backward pass中，那些在forward pass中經由 /Gibbs/ 採樣後的激活函數計算結果被傳入隱藏層，並與之前相同的權重W相乘，然後再加上可視層的新偏差向量vb。
** 重建RBM元件
#+begin_src python -r -n :results output :exports both :session ML
# Make code compatible with v1 of TF
tf.compat.v1.disable_eager_execution()
# Define RBM class
class RBM(object):

    def __init__(self, input_size, output_size,
                 learning_rate, epochs, batchsize):
        # 定義超參數
        self._input_size = input_size
        self._output_size = output_size
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batchsize = batchsize

        # 利用零矩陣初始化權重矩陣與偏差矩陣
        self.w = np.zeros([input_size, output_size], dtype=np.float32)
        self.hb = np.zeros([output_size], dtype=np.float32)
        self.vb = np.zeros([input_size], dtype=np.float32)
    #正向傳遞函式，h為隱藏層，v為可視層
    def prob_h_given_v(self, visible, w, hb):
        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)
    #反向傳遞函式
    def prob_v_given_h(self, hidden, w, vb):
        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)
    #採樣函式
    def sample_prob(self, probs):
        return tf.nn.relu(tf.sign(probs - tf.random.uniform(tf.shape(probs))))

    def train(self, X):
        #以tensorflow建立三個placeholder: 權重矩陣、隱藏層的偏差值向量、可視層的偏差值向量
        _w = tf.compat.v1.placeholder(tf.float32, [self._input_size, self._output_size])
        _hb = tf.compat.v1.placeholder(tf.float32, [self._output_size])
        _vb = tf.compat.v1.placeholder(tf.float32, [self._input_size])

        prv_w = np.zeros([self._input_size, self._output_size], dtype=np.float32)
        prv_hb = np.zeros([self._output_size], dtype=np.float32)
        prv_vb = np.zeros([self._input_size], dtype=np.float32)

        cur_w = np.zeros([self._input_size, self._output_size], dtype=np.float32)
        cur_hb = np.zeros([self._output_size], dtype=np.float32)
        cur_vb = np.zeros([self._input_size], dtype=np.float32)
        #給可視層的placehold
        v0 = tf.compat.v1.placeholder(tf.float32, [None, self._input_size])
        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))
        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))
        h1 = self.prob_h_given_v(v1, _w, _hb)
        # 定義誤差 MSE
        positive_grad = tf.matmul(tf.transpose(v0), h0)
        negative_grad = tf.matmul(tf.transpose(v1), h1)

        update_w = _w + self.learning_rate * \
            (positive_grad - negative_grad) / tf.cast(tf.shape(v0)[0], tf.float32)
        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)
        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)

        err = tf.reduce_mean(tf.square(v0 - v1))

        error_list = []
        #初始化TensorFlow工作階段
        with tf.compat.v1.Session() as sess:
            # 批次將資料傳入進行訓練
            sess.run(tf.compat.v1.global_variables_initializer())

            for epoch in range(self.epochs):
                for start, end in zip(range(0, len(X), \
                        self.batchsize),range(self.batchsize,len(X), \
                                              self.batchsize)):
                    batch = X[start:end]
                    cur_w = sess.run(update_w, feed_dict={v0: batch, \
                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, \
                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, \
                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
                    prv_w = cur_w
                    prv_hb = cur_hb
                    prv_vb = cur_vb
                error = sess.run(err, feed_dict={v0: X, \
                                _w: cur_w, _vb: cur_vb, _hb: cur_hb})
                print ('Epoch: %d' % epoch,'reconstruction error: %f' % error)
                error_list.append(error)
            self.w = prv_w
            self.hb = prv_hb
            self.vb = prv_vb
            return error_list

    def rbm_output(self, X):

        input_X = tf.constant(X)
        _w = tf.constant(self.w)
        _hb = tf.constant(self.hb)
        _vb = tf.constant(self.vb)
        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)
        hiddenGen = self.sample_prob(self.prob_h_given_v(input_X, _w, _hb))
        visibleGen = self.sample_prob(self.prob_v_given_h(hiddenGen, _w, _vb))
        with tf.compat.v1.Session() as sess:
            sess.run(tf.compat.v1.global_variables_initializer())
            return sess.run(out), sess.run(visibleGen), sess.run(hiddenGen)
#+end_src
** 訓練
#+begin_src python -r -n :results output :exports both :session ML
# Convert inputX into float32
plt.clf()
inputX = ratings_train
inputX = inputX.astype(np.float32)

# Define the parameters of the RBMs we will train
rbm=RBM(1000,1000,1,1000,200)
# Train RBM model
err = rbm.train(inputX)
outputX, reconstructedX, hiddenX = rbm.rbm_output(inputX)
# Plot reconstruction errors
pd.Series(err).plot(logy=False)
plt.xlabel("Epoch")
plt.ylabel("Reconstruction Error");
plt.savefig('images/ML-RBM.png', dpi=300)
# Predict ratings for validation set
inputValid = ratings_valid
inputValid = inputValid.astype(np.float32)

_, reconstructedOutput_valid, _ = rbm.rbm_output(inputValid)
# Calculate MSE on validation set
predictionsArray = reconstructedOutput_valid
pred_valid = predictionsArray[ratings_valid.nonzero()].flatten()
actual_valid = ratings_valid[ratings_valid.nonzero()].flatten()

rbm_prediction = mean_squared_error(pred_valid, actual_valid)
print(f'Mean squared error using RBM prediction: {round(rbm_prediction,2)}')
#+end_src

#+RESULTS:
Epoch: 0 reconstruction error: 1.106261
Epoch: 1 reconstruction error: 1.079569
Epoch: 2 reconstruction error: 1.086965
...
Epoch: 998 reconstruction error: 1.072312
Epoch: 999 reconstruction error: 1.072114
Mean squared error using RBM prediction: 9.34
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/ML-RBM.png]]

* 深度信念網路(DBNs)
DBNs在2006年由Geoffrey Hinton在多倫多大學提出。RBMs只有兩層，DBNs由多個RBMs組成，一個RBMs的隱藏層是下一個RBMs的可視層。DBNs可以用來辨識、分群圖片、聲音、文字、影片。
在DBN中，一次只有一層被訓練，從最前面緊鄰輸入層的隱藏層開始，建構第一個RBM，當第一個RBM被訓練完後，第一個RBM的隱藏層就會被當做下一個RBM的可視層，用來訓練第二個RBM的隱藏層。
** MNIST分類
*** 載入函式庫
#+begin_src python -r -n :results output :exports both :session DN
'''Main'''
import numpy as np
import pandas as pd
import os, time, re
import pickle, gzip, datetime

'''Data Viz'''
import matplotlib.pyplot as plt
import seaborn as sns
color = sns.color_palette()
import matplotlib as mpl
from mpl_toolkits.axes_grid1 import Grid

'''Data Prep and Model Evaluation'''
from sklearn import preprocessing as pp
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import log_loss, accuracy_score
from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error

'''Algos'''
import lightgbm as lgb

'''TensorFlow and Keras'''
import tensorflow as tf
from tensorflow import keras
K = keras.backend

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Activation, Dense, Dropout
from tensorflow.keras.layers import BatchNormalization, Input, Lambda
from tensorflow.keras.layers import Embedding, Flatten, dot
from tensorflow.keras import regularizers
from tensorflow.keras.losses import mse, binary_crossentropy
import sys, sklearn
print(f'sklearn    {sklearn.__version__}')
print(f'tensorflow {tf.__version__}')
print(f'keras      {keras.__version__}')
print(f'numpy      {np.__version__}')
# To make the output stable across runs
tf.random.set_seed(42)
np.random.seed(42)
#+end_src

#+RESULTS:
: Python 3.7.13 (default, Mar 28 2022, 07:24:34)
: [Clang 12.0.0 ] :: Anaconda, Inc. on darwin
: Type "help", "copyright", "credits" or "license" for more information.
: >>> sklearn    1.0.2
: tensorflow 2.0.0
: keras      2.2.4-tf
: numpy      1.21.5

*** 資料準備
#+begin_src python -r -n :results output :exports both :session DN
# Load the datasets
current_path = os.getcwd()
file = os.path.sep.join(['', 'dataset', 'mnist.pkl.gz'])
f = gzip.open(current_path+file, 'rb')
train_set, validation_set, test_set = pickle.load(f, encoding='latin1')
f.close()

X_train, y_train = train_set[0], train_set[1]
X_validation, y_validation = validation_set[0], validation_set[1]
X_test, y_test = test_set[0], test_set[1]
# Verify shape of datasets
print("Shape of X_train: ", X_train.shape)
print("Shape of y_train: ", y_train.shape)
print("Shape of X_validation: ", X_validation.shape)
print("Shape of y_validation: ", y_validation.shape)
print("Shape of X_test: ", X_test.shape)
print("Shape of y_test: ", y_test.shape)
#+end_src

#+RESULTS:
: Shape of X_train:  (50000, 784)
: Shape of y_train:  (50000,)
: Shape of X_validation:  (10000, 784)
: Shape of y_validation:  (10000,)
: Shape of X_test:  (10000, 784)
: Shape of y_test:  (10000,)

*** 建立資料集
#+begin_src python -r -n :results output :exports both :session DN
# Create Pandas DataFrames from the datasets
train_index = range(0,len(X_train))
validation_index = range(len(X_train),len(X_train)+len(X_validation))
test_index = range(len(X_train)+len(X_validation), \
                   len(X_train)+len(X_validation)+len(X_test))

X_train = pd.DataFrame(data=X_train,index=train_index)
y_train = pd.Series(data=y_train,index=train_index)

X_validation = pd.DataFrame(data=X_validation,index=validation_index)
y_validation = pd.Series(data=y_validation,index=validation_index)

X_test = pd.DataFrame(data=X_test,index=test_index)
y_test = pd.Series(data=y_test,index=test_index)
# Describe the training matrix
print(X_train.describe())
#+end_src

#+RESULTS:
#+begin_example
           0        1        2        3        4        5        6    ...           777           778           779      780      781      782      783
count  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0  50000.0  ...  50000.000000  50000.000000  50000.000000  50000.0  50000.0  50000.0  50000.0
mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000090      0.000071      0.000009      0.0      0.0      0.0      0.0
std        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.007217      0.007181      0.001483      0.0      0.0      0.0      0.0
min        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.000000      0.000000      0.000000      0.0      0.0      0.0      0.0
max        0.0      0.0      0.0      0.0      0.0      0.0      0.0  ...      0.988281      0.992188      0.242188      0.0      0.0      0.0      0.0

[8 rows x 784 columns]
#+end_example


*** View the digit image
#+begin_src python -r -n :results output :exports both :session DN
def view_digit(X, y, example, fn):
    plt.cla()
    label = y.loc[example]
    image = X.loc[example,:].values.reshape([28,28])
    plt.title('Example: %d  Label: %d' % (example, label))
    plt.imshow(image, cmap=plt.get_cmap('gray'))
    #plt.show()
    # 要存檔的話就不要用show()?
    plt.tight_layout()
    plt.savefig(fn, dpi=300, bbox_inches = 'tight')
# View the first digit
view_digit(X_train, y_train, 0, 'images/firsttest.png')
#+end_src

#+RESULTS:
#+CAPTION: Caption
#+LABEL:fig:firstTest
#+name: fig:firstTest
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/firsttest.png]]

*** 將label以one-hot encoding編碼
#+begin_src python -r -n :results output :exports both :session DN
def one_hot(series):
    label_binarizer = pp.LabelBinarizer()
    label_binarizer.fit(range(max(series)+1))
    return label_binarizer.transform(series)
def reverse_one_hot(originalSeries, newSeries):
    label_binarizer = pp.LabelBinarizer()
    label_binarizer.fit(range(max(originalSeries)+1))
    return label_binarizer.inverse_transform(newSeries)
# Create one-hot vectors for the labels
y_train_oneHot = one_hot(y_train)
y_validation_oneHot = one_hot(y_validation)
y_test_oneHot = one_hot(y_test)
# Show one-hot vector for example 0, which is the number 5
print(y_train[0])
print(y_train_oneHot[0])
#+end_src

#+RESULTS:
: 5
: [0 0 0 0 0 1 0 0 0 0]
圖[[fig:firstTest]]的label和相對應的one-hot encoding如下:
#+RESULTS:
: 5
: [0 0 0 0 0 1 0 0 0 0]
** Restricted Boltzmann Machines (RBMs)
#+begin_src python -r -n :results output :exports both :session DN
# Make code compatible with v1 of TF
tf.compat.v1.disable_eager_execution()
# Define RBM class
class RBM(object):

    def __init__(self, input_size, output_size,
                 learning_rate, epochs, batchsize):
        # Define hyperparameters
        self._input_size = input_size
        self._output_size = output_size
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batchsize = batchsize

        # Initialize weights and biases using zero matrices
        self.w = np.zeros([input_size, output_size], dtype=np.float32)
        self.hb = np.zeros([output_size], dtype=np.float32)
        self.vb = np.zeros([input_size], dtype=np.float32)
    # 正向傳遞
    def prob_h_given_v(self, visible, w, hb):
        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)
    # 反向傳遞
    def prob_v_given_h(self, hidden, w, vb):
        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)
    # 探樣
    def sample_prob(self, probs):
        return tf.nn.relu(tf.sign(probs - tf.compat.v1.random_uniform(tf.shape(probs))))

    def train(self, X):
        _w = tf.compat.v1.placeholder(tf.float32, [self._input_size, self._output_size])
        _hb = tf.compat.v1.placeholder(tf.float32, [self._output_size])
        _vb = tf.compat.v1.placeholder(tf.float32, [self._input_size])

        prv_w = np.zeros([self._input_size, self._output_size], dtype=np.float32)
        prv_hb = np.zeros([self._output_size], dtype=np.float32)
        prv_vb = np.zeros([self._input_size], dtype=np.float32)

        cur_w = np.zeros([self._input_size, self._output_size], dtype=np.float32)
        cur_hb = np.zeros([self._output_size], dtype=np.float32)
        cur_vb = np.zeros([self._input_size], dtype=np.float32)

        v0 = tf.compat.v1.placeholder(tf.float32, [None, self._input_size])
        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))
        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))
        h1 = self.prob_h_given_v(v1, _w, _hb)

        positive_grad = tf.matmul(tf.transpose(v0), h0)
        negative_grad = tf.matmul(tf.transpose(v1), h1)

        update_w = _w + self.learning_rate * \
            (positive_grad - negative_grad) / tf.cast(tf.shape(v0)[0], tf.float32)
        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)
        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)

        err = tf.reduce_mean(tf.square(v0 - v1))

        error_list = []
        # 批次傳入資料並開始訓練
        with tf.compat.v1.Session() as sess:
            sess.run(tf.compat.v1.global_variables_initializer())

            for epoch in range(self.epochs):
                for start, end in zip(range(0, len(X), \
                        self.batchsize),range(self.batchsize,len(X), \
                                              self.batchsize)):
                    batch = X[start:end]
                    cur_w = sess.run(update_w, feed_dict={v0: batch, \
                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, \
                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, \
                                    _w: prv_w, _hb: prv_hb, _vb: prv_vb})
                    prv_w = cur_w
                    prv_hb = cur_hb
                    prv_vb = cur_vb
                error = sess.run(err, feed_dict={v0: X, \
                                _w: cur_w, _vb: cur_vb, _hb: cur_hb})
                print ('Epoch: %d' % epoch,'reconstruction error: %f' % error)
                error_list.append(error)
            self.w = prv_w
            self.hb = prv_hb
            self.vb = prv_vb
            return error_list
    # 使用RBM模型產生影像
    def rbm_output(self, X):

        input_X = tf.constant(X)
        _w = tf.constant(self.w)
        _hb = tf.constant(self.hb)
        _vb = tf.constant(self.vb)
        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)
        hiddenGen = self.sample_prob(self.prob_h_given_v(input_X, _w, _hb))
        visibleGen = self.sample_prob(self.prob_v_given_h(hiddenGen, _w, _vb))
        with tf.compat.v1.Session() as sess:
            sess.run(tf.compat.v1.global_variables_initializer())
            return sess.run(out), sess.run(visibleGen), sess.run(hiddenGen)
    # 查看隱藏層的特徵
    def show_features(self, shape, suptitle, count=-1, fn=''):
        maxw = np.amax(self.w.T)
        minw = np.amin(self.w.T)
        count = self._output_size if count == -1 or count > \
                self._output_size else count
        ncols = count if count < 14 else 14
        nrows = count//ncols
        nrows = nrows if nrows > 2 else 3
        fig = plt.figure(figsize=(ncols, nrows), dpi=100)
        grid = Grid(fig, rect=111, nrows_ncols=(nrows, ncols), axes_pad=0.01)

        for i, ax in enumerate(grid):
            x = self.w.T[i] if i<self._input_size else np.zeros(shape)
            x = (x.reshape(1, -1) - minw)/maxw
            ax.imshow(x.reshape(*shape), cmap=mpl.cm.Greys)
            ax.set_axis_off()

        fig.text(0.5,1, suptitle, fontsize=20, horizontalalignment='center')
        fig.tight_layout()
        #plt.show() #如何傳回fig
        plt.savefig(fn, dpi=300)
        return
#+end_src

#+RESULTS:
** 為DBN訓練三個RBMs
1. 先將訓練資料存成Numpy陣列
1. 建立一個陣列(rbm_list)來保存所訓練的RMBs
1. 定義三個RBM的超參數(輸入值數量、輸出值數量、學習率、訓練回合數、批次大小)
此模型中：
- 第一個RBM接收784維的輸入、輸出700維的矩陣
- 下一個RBM使用前一個RBM輸出的700維矩陣為輸入，輸出一個600維的矩陣
- 最後一個RBM使用這600維的矩陣當成輸入、輸出一個500維的矩陣
- 學習率設為1.0
- 訓練100回合
- 批次大小設為200
#+begin_src python -r -n :results output :exports both :session DN
# Since we are training, set input as training data
# 拿訓練集當成輸入
import numpy as np
inputX = np.array(X_train)
inputX = inputX.astype(np.float32)

# Create list to hold our RBMs
rbm_list = []

# Define the parameters of the RBMs we will train
rbm_list.append(RBM(784,700,1.0,100,200))
rbm_list.append(RBM(700,600,1.0,100,200))
rbm_list.append(RBM(600,500,1.0,100,200))
# 將訓練過的RBM存在outputList
outputList = []
error_list = []
#For each RBM in our list
for i in range(0,len(rbm_list)):
    print('RBM', i+1)
    #Train a new one
    rbm = rbm_list[i]
    err = rbm.train(inputX)
    error_list.append(err)
    #Return the output layer
    outputX, reconstructedX, hiddenX = rbm.rbm_output(inputX)
    outputList.append(outputX)
    inputX = hiddenX
#+end_src

#+RESULTS:
#+begin_example
RBM 1
2022-05-14 23:52:49.162587: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-14 23:52:49.164433: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
Epoch: 0 reconstruction error: 0.074801
...
Epoch: 99 reconstruction error: 0.038867
RBM 2
Epoch: 0 reconstruction error: 0.050241
...
Epoch: 99 reconstruction error: 0.018937
RBM 3
Epoch: 0 reconstruction error: 0.038833
...
Epoch: 99 reconstruction error: 0.017987
#+end_example
** 查看RBM誤差
#+begin_src python -r -n :results output :exports both :session DN
# Plot reconstruction errors
i = 1
for err in error_list:
    plt.clf()
    plt.cla()
    print("RBM",i)
    pd.Series(err).plot(logy=False)
    plt.xlabel("Epoch")
    plt.ylabel("Reconstruction Error")
    #plt.ylim(0,1)
    #plt.show()
    plt.savefig(f'images/DBN-DMB-{i}.png', dpi=300)
    i += 1
#+end_src

#+RESULTS:
: RBM 1
: RBM 2
: RBM 3

#+CAPTION: Caption
#+LABEL:fig:DBN-DBM-1
#+name: fig:DBN-DBM-1
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-DMB-1.png]]
#+CAPTION: Caption
#+LABEL:fig:DBN-DBM-2
#+name: fig:DBN-DBM-2
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-DMB-2.png]]
#+CAPTION: Caption
#+LABEL:fig:DBN-DBM-3
#+name: fig:DBN-DBM-3
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-DMB-3.png]]
** 檢視特徵偵測器
#+begin_src python -r -n :results output :exports both :session DN
# Examine Feature Detectors
rbm_shapes = [(28,28),(35,20),(30,20)]
for i in range(0,len(rbm_list)):
    rbm = rbm_list[i]
    print("RBM",i)
    fn = f'images/DBN-Detect-{i}.png'
    print(rbm.show_features(rbm_shapes[i], "RBM learned features from MNIST", 56, fn))
    #fig = rbm.show_features(rbm_shapes[i])
    #plt.savefig(f'images/DBN-Detect-{i}.png', fig,  dpi=300)

#+end_src

#+RESULTS:
: RBM 0
: None
: RBM 1
: None
: RBM 2
: None

#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 500
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-Detect-0.png]]
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 500
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-Detect-1.png]]
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 500
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-Detect-2.png]]
** 查看RBM生成的影像
#+begin_src python -r -n :results output :exports both :session DN
# View generated images from the first RBM
inputX = np.array(X_train)
rbmOne = rbm_list[0]

print('RBM 1')
outputX_rbmOne, reconstructedX_rbmOne, hiddenX_rbmOne = \
                            rbmOne.rbm_output(inputX)
reconstructedX_rbmOne = pd.DataFrame(data=reconstructedX_rbmOne, \
                                     index=X_train.index)
for j in range(0,10):
    plt.cla()
    plt.clf()
    example = j
    print("Image generated by RBM")
    fn = f'images/DBN-RBMGenerated-{j}.png'
    view_digit(reconstructedX_rbmOne, y_train, example, fn)
    print("Original image")
    fn = f'images/DBN-Original-{j}.png'
    view_digit(X_train, y_train, example, fn)
#+end_src

#+RESULTS:
#+begin_example
RBM 1
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
Image generated by RBM
Original image
#+end_example
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 200
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-Original-9.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-9.png]]
[[file:images/DBN-Original-8.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-8.png]]
[[file:images/DBN-Original-7.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-7.png]]
[[file:images/DBN-Original-6.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-6.png]]
[[file:images/DBN-Original-5.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-5.png]]
[[file:images/DBN-Original-4.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-4.png]]
[[file:images/DBN-Original-3.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-3.png]]
[[file:images/DBN-Original-2.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-2.png]]
[[file:images/DBN-Original-1.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-1.png]]
[[file:images/DBN-Original-0.png]]
#+ATTR_HTML: :width 300
[[file:images/DBN-RBMGenerated-0.png]]
** 完整的DBN
#+begin_src python -r -n :results output :exports both :session DN
class DBN(object):
    def __init__(self, original_input_size, input_size, output_size,
                 learning_rate, epochs, batchsize, rbmOne, rbmTwo, rbmThree):
        # Define hyperparameters
        self._original_input_size = original_input_size
        self._input_size = input_size
        self._output_size = output_size
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batchsize = batchsize
        self.rbmOne = rbmOne
        self.rbmTwo = rbmTwo
        self.rbmThree = rbmThree

        self.w = np.zeros([input_size, output_size], "float")
        self.hb = np.zeros([output_size], "float")
        self.vb = np.zeros([input_size], "float")

    def prob_h_given_v(self, visible, w, hb):
        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)

    def prob_v_given_h(self, hidden, w, vb):
        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)

    def sample_prob(self, probs):
        return tf.nn.relu(tf.sign(probs - tf.compat.v1.random_uniform(tf.shape(probs))))

    def train(self, X):
        _w = tf.compat.v1.placeholder("float", [self._input_size, self._output_size])
        _hb = tf.compat.v1.placeholder("float", [self._output_size])
        _vb = tf.compat.v1.placeholder("float", [self._input_size])

        prv_w = np.zeros([self._input_size, self._output_size], "float")
        prv_hb = np.zeros([self._output_size], "float")
        prv_vb = np.zeros([self._input_size], "float")

        cur_w = np.zeros([self._input_size, self._output_size], "float")
        cur_hb = np.zeros([self._output_size], "float")
        cur_vb = np.zeros([self._input_size], "float")

        v0 = tf.compat.v1.placeholder("float", [None, self._original_input_size])

        forwardOne = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(v0, \
                        self.rbmOne.w) + self.rbmOne.hb) - tf.compat.v1.random_uniform( \
                        tf.shape(tf.nn.sigmoid(tf.matmul(v0, self.rbmOne.w) + \
                        self.rbmOne.hb)))))
        forwardTwo = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(forwardOne, \
                        self.rbmTwo.w) + self.rbmTwo.hb) - tf.compat.v1.random_uniform( \
                        tf.shape(tf.nn.sigmoid(tf.matmul(forwardOne, \
                        self.rbmTwo.w) + self.rbmTwo.hb)))))
        forward = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(forwardTwo, \
                        self.rbmThree.w) + self.rbmThree.hb) - \
                        tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid(tf.matmul( \
                        forwardTwo, self.rbmThree.w) + self.rbmThree.hb)))))
        h0 = self.sample_prob(self.prob_h_given_v(forward, _w, _hb))
        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))
        h1 = self.prob_h_given_v(v1, _w, _hb)

        positive_grad = tf.matmul(tf.transpose(forward), h0)
        negative_grad = tf.matmul(tf.transpose(v1), h1)

        update_w = _w + self.learning_rate * (positive_grad - negative_grad) / \
                        tf.cast(tf.shape(forward)[0], tf.float32)
        update_vb = _vb +  self.learning_rate * tf.reduce_mean(forward - v1, 0)
        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)

        backwardOne = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(v1, \
                            self.rbmThree.w.T) + self.rbmThree.vb) - \
                            tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid( \
                            tf.matmul(v1, self.rbmThree.w.T) + \
                            self.rbmThree.vb)))))
        backwardTwo = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(backwardOne, \
                            self.rbmTwo.w.T) + self.rbmTwo.vb) - \
                            tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid( \
                            tf.matmul(backwardOne, self.rbmTwo.w.T) + \
                            self.rbmTwo.vb)))))
        backward = tf.nn.relu(tf.sign(tf.nn.sigmoid(tf.matmul(backwardTwo, \
                            self.rbmOne.w.T) + self.rbmOne.vb) - \
                            tf.compat.v1.random_uniform(tf.shape(tf.nn.sigmoid( \
                            tf.matmul(backwardTwo, self.rbmOne.w.T) + \
                            self.rbmOne.vb)))))

        err = tf.reduce_mean(tf.square(v0 - backward))
        error_list = []

        with tf.compat.v1.Session() as sess:
            sess.run(tf.compat.v1.global_variables_initializer())

            for epoch in range(self.epochs):
                for start, end in zip(range(0, len(X), self.batchsize), \
                        range(self.batchsize,len(X), self.batchsize)):
                    batch = X[start:end]
                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: \
                                        prv_w, _hb: prv_hb, _vb: prv_vb})
                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: \
                                        prv_w, _hb: prv_hb, _vb: prv_vb})
                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: \
                                        prv_w, _hb: prv_hb, _vb: prv_vb})
                    prv_w = cur_w
                    prv_hb = cur_hb
                    prv_vb = cur_vb
                error = sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: \
                                    cur_vb, _hb: cur_hb})
                print ('Epoch: %d' % epoch,'reconstruction error: %f' % error)
                error_list.append(error)
            self.w = prv_w
            self.hb = prv_hb
            self.vb = prv_vb
            return error_list
    #從DBN產出生成影像，顯示特徵
    def dbn_output(self, X):

        input_X = tf.constant(X)
        forwardOne = tf.nn.sigmoid(tf.matmul(input_X, self.rbmOne.w) + \
                                   self.rbmOne.hb)
        forwardTwo = tf.nn.sigmoid(tf.matmul(forwardOne, self.rbmTwo.w) + \
                                   self.rbmTwo.hb)
        forward = tf.nn.sigmoid(tf.matmul(forwardTwo, self.rbmThree.w) + \
                                self.rbmThree.hb)

        _w = tf.constant(self.w)
        _hb = tf.constant(self.hb)
        _vb = tf.constant(self.vb)

        out = tf.nn.sigmoid(tf.matmul(forward, _w) + _hb)
        hiddenGen = self.sample_prob(self.prob_h_given_v(forward, _w, _hb))
        visibleGen = self.sample_prob(self.prob_v_given_h(hiddenGen, _w, _vb))

        backwardTwo = tf.nn.sigmoid(tf.matmul(visibleGen, self.rbmThree.w.T) + \
                                    self.rbmThree.vb)
        backwardOne = tf.nn.sigmoid(tf.matmul(backwardTwo, self.rbmTwo.w.T) + \
                                    self.rbmTwo.vb)
        backward = tf.nn.sigmoid(tf.matmul(backwardOne, self.rbmOne.w.T) + \
                                 self.rbmOne.vb)

        with tf.compat.v1.Session() as sess:
            sess.run(tf.compat.v1.global_variables_initializer())
            return sess.run(out), sess.run(backward)

    def show_features(self, shape, suptitle, count=-1, fn=''):
        plt.cla()
        maxw = np.amax(self.w.T)
        minw = np.amin(self.w.T)
        count = self._output_size if count == -1 or count > \
                self._output_size else count
        ncols = count if count < 14 else 14
        nrows = count//ncols
        nrows = nrows if nrows > 2 else 3
        fig = plt.figure(figsize=(ncols, nrows), dpi=100)
        grid = Grid(fig, rect=111, nrows_ncols=(nrows, ncols), axes_pad=0.01)

        for i, ax in enumerate(grid):
            x = self.w.T[i] if i<self._input_size else np.zeros(shape)
            x = (x.reshape(1, -1) - minw)/maxw
            ax.imshow(x.reshape(*shape), cmap=mpl.cm.Greys)
            ax.set_axis_off()

        fig.text(0.5,1, suptitle, fontsize=20, horizontalalignment='center')
        fig.tight_layout()
        #plt.show()
        plt.savefig(fn, dpi=300)
        return
#+end_src

#+RESULTS:
** 訓練DBN
#+begin_src python -r -n :results output :exports both :session DN
# Instantiate DBN Class
dbn = DBN(784, 500, 500, 1.0, 50, 200, rbm_list[0], rbm_list[1], rbm_list[2])
# Train
inputX = np.array(X_train)
error_list = []
error_list = dbn.train(inputX)
#+end_src

#+RESULTS:
#+begin_example
Epoch: 0 reconstruction error: 0.088701
....
Epoch: 49 reconstruction error: 0.060786
#+end_example
** 看錯誤
#+begin_src python -r -n :results output :exports both :session DN
# Plot reconstruction errors
print("DBN")
pd.Series(error_list).plot(logy=False)
plt.xlabel("Epoch")
plt.ylabel("Reconstruction Error")
#plt.show()
plt.savefig('images/DBN-learned-MINST.png', dpi=300)
print(dbn.show_features((25,20),"DBN learned features from MNIST", 56, 'images/DBN-learned-from-MNIST.png'))
#+end_src

#+RESULTS:
: DBN
: None
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-learned-MINST.png]]
#+CAPTION: Caption
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 500
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/DBN-learned-from-MNIST.png]]
** 生成影像以建構更好的影像分類器
#+begin_src python -r -n :results output :exports both :session DN
# Generate images and store them
inputXReduced = X_train.loc[:4999]
for i in range(0,20):
    print("Run ",i)
    finalOutput_DBN, reconstructedOutput_DBN = dbn.dbn_output(inputXReduced)
    if i==0:
        generatedImages = finalOutput_DBN
    else:
        generatedImages = np.append(generatedImages, finalOutput_DBN, axis=0)
# Generate a vector of labels for the generated images
# 遍歷訓練label y_train的前5000個label 20次，用來產生labels陣列
for i in range(0,20):
    if i==0:
        labels = y_train.loc[:4999]
    else:
        labels = np.append(labels,y_train.loc[:4999])
# Generate images based on the validation set
# 產生基於驗證集的輸出值(影像)
inputValidation = np.array(X_validation)
finalOutput_DBN_validation, reconstructedOutput_DBN_validation = \
    dbn.dbn_output(inputValidation)
# View first few reconstructed images
for i in range(0,10):
    plt.cla()
    plt.clf()
    example = i
    reconstructedX = pd.DataFrame(data=reconstructedOutput_DBN, \
                                  index=X_train[0:5000].index)
    fn = f'images/reconstructedX-{i}.png'
    view_digit(reconstructedX, y_train, example, fn)
    fn = f'images/X0train-{i}.png'
    view_digit(X_train, y_train, example, fn)
#+end_src

#+RESULTS:
#+begin_example
Run  0
Run  1
Run  2
Run  3
Run  4
Run  5
Run  6
Run  7
Run  8
Run  9
Run  10
Run  11
Run  12
Run  13
Run  14
Run  15
Run  16
Run  17
Run  18
Run  19
#+end_example
#+CAPTION: Run 1
#+LABEL:fig:Run 1
#+name: fig:Run 1
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-0.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-0.png]]
#+CAPTION: Run 2
#+LABEL:fig:Run 2
#+name: fig:Run 2
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-1.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-1.png]]
#+CAPTION: Run 3
#+LABEL:fig:Run 3
#+name: fig:Run 3
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-2.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-2.png]]
#+CAPTION: Run 4
#+LABEL:fig:Run 4
#+name: fig:Run 4
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-3.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-3.png]]
#+CAPTION: Run 5
#+LABEL:fig:Run 5
#+name: fig:Run 5
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-4.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-4.png]]
#+CAPTION: Run 6
#+LABEL:fig:Run 6
#+name: fig:Run 6
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-5.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-5.png]]
#+CAPTION: Run 7
#+LABEL:fig:Run 7
#+name: fig:Run 7
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-6.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-6.png]]
#+CAPTION: Run 8
#+LABEL:fig:Run 8
#+name: fig:Run 8
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-7.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-7.png]]
#+CAPTION: Run 9
#+LABEL:fig:Run 9
#+name: fig:Run 9
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-8.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-8.png]]
#+CAPTION: Run 10
#+LABEL:fig:Run 10
#+name: fig:Run 10
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 300
[[file:images/X0train-9.png]]
#+ATTR_HTML: :width 300
[[file:images/reconstructedX-9.png]]
** 使用DBN來產生新的影像10次
#+begin_src python -r -n :results output :exports both :session DN
# Generate the several versions of the first digit
inputXReduced = X_train.loc[:0]
for i in range(0,10):
    example = 0
    print("Run ",i)
    finalOutput_DBN_fives, reconstructedOutput_DBN_fives = \
        dbn.dbn_output(inputXReduced)
    reconstructedX_fives = pd.DataFrame(data=reconstructedOutput_DBN_fives, \
                                        index=[0])
    print("Generated")
    fn = f'images/reconstructedX-fives-{i}.png'
    view_digit(reconstructedX_fives, y_train.loc[:0], example, fn)
#+end_src

#+RESULTS:
#+begin_example
Run  0
Generated
Run  1
Generated
Run  2
Generated
Run  3
Generated
Run  4
Generated
Run  5
Generated
Run  6
Generated
Run  7
Generated
Run  8
Generated
Run  9
Generated
#+end_example
** 使用LightGBM建構影像分類器
*** 僅使用監督式學習
這裡先用前3000張有label的MNIST影像建立分類器當對照組
#+begin_src python -r -n :results output :exports both :session DN
# Set Parameters
predictionColumns = ['0','1','2','3','4','5','6','7','8','9']

params_lightGB = {
    'task': 'train',
    'num_class':10,
    'boosting': 'gbdt',
    'objective': 'multiclass',
    'metric': 'multi_logloss',
    'metric_freq':50,
    'is_training_metric':False,
    'max_depth':4,
    'num_leaves': 31,
    'learning_rate': 0.1,
    'feature_fraction': 1.0,
    'bagging_fraction': 1.0,
    'bagging_freq': 0,
    'bagging_seed': 2018,
    'verbose': -1,
    'num_threads':16
}
# Train
trainingScore = []
validationScore = []
predictionsLightGBM = pd.DataFrame(data=[], \
                        index=y_validation.index, \
                        columns=predictionColumns)

lgb_train = lgb.Dataset(X_train.loc[:4999], y_train.loc[:4999])
lgb_eval = lgb.Dataset(X_validation, y_validation, reference=lgb_train)
gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=2000,
                   valid_sets=lgb_eval, early_stopping_rounds=200)

loglossTraining = log_loss(y_train.loc[:4999], \
    gbm.predict(X_train.loc[:4999], num_iteration=gbm.best_iteration))
trainingScore.append(loglossTraining)

predictionsLightGBM.loc[X_validation.index,predictionColumns] = \
    gbm.predict(X_validation, num_iteration=gbm.best_iteration)
loglossValidation = log_loss(y_validation,
    predictionsLightGBM.loc[X_validation.index,predictionColumns])
validationScore.append(loglossValidation)
# 查看對數損失函數和整體精確率
print('Training Log Loss: ', loglossTraining)
print('Validation Log Loss: ', loglossValidation)

loglossLightGBM = log_loss(y_validation, predictionsLightGBM)
print('LightGBM Gradient Boosting Log Loss: ', loglossLightGBM)
# Supervised-only Accuracy
predictionsLightGBM_firm = np.argmax(np.array(predictionsLightGBM), axis=1)
accuracyValidation_lightGBM = accuracy_score(np.array(y_validation), \
                                            predictionsLightGBM_firm)
print("Supervised-Only Accuracy: ", accuracyValidation_lightGBM)
#+end_src

#+RESULTS:
#+begin_example
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
[1]	valid_0's multi_logloss: 1.8355
Training until validation scores don't improve for 200 rounds
[2]	valid_0's multi_logloss: 1.5523
...
[335]	valid_0's multi_logloss: 0.221976
Early stopping, best iteration is:
[135]	valid_0's multi_logloss: 0.192358
Training Log Loss:  0.0006489700296153399
Validation Log Loss:  0.19235843980200165
LightGBM Gradient Boosting Log Loss:  0.19235843980200165
Supervised-Only Accuracy:  0.9446
#+end_example

*** 監督式與非監督式學習並用
#+begin_src python -r -n :results output :exports both :session DN
# Prepare DBN-based DataFrames for LightGBM use
generatedImagesDF = pd.DataFrame(data=generatedImages,index=range(0,100000))
labelsDF = pd.DataFrame(data=labels,index=range(0,100000))

X_train_lgb = pd.DataFrame(data=generatedImagesDF,
                           index=generatedImagesDF.index)
X_validation_lgb = pd.DataFrame(data=finalOutput_DBN_validation,
                                index=X_validation.index)
# Train LightGBM
trainingScore = []
validationScore = []
predictionsDBN = pd.DataFrame(data=[],index=y_validation.index,
                              columns=predictionColumns)

lgb_train = lgb.Dataset(X_train_lgb, labels)
lgb_eval = lgb.Dataset(X_validation_lgb, y_validation, reference=lgb_train)
gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=2000,
                   valid_sets=lgb_eval, early_stopping_rounds=200)

loglossTraining = log_loss(labelsDF, gbm.predict(X_train_lgb, \
                            num_iteration=gbm.best_iteration))
trainingScore.append(loglossTraining)

predictionsDBN.loc[X_validation.index,predictionColumns] = \
    gbm.predict(X_validation_lgb, num_iteration=gbm.best_iteration)
loglossValidation = log_loss(y_validation,
    predictionsDBN.loc[X_validation.index,predictionColumns])
validationScore.append(loglossValidation)

print('Training Log Loss: ', loglossTraining)
print('Validation Log Loss: ', loglossValidation)

loglossDBN = log_loss(y_validation, predictionsDBN)
print('LightGBM Gradient Boosting Log Loss: ', loglossDBN)
# DBN-Based Solution Accuracy
predictionsDBN_firm = np.argmax(np.array(predictionsDBN), axis=1)
accuracyValidation_DBN = accuracy_score(np.array(y_validation), \
                                        predictionsDBN_firm)
print("DBN-Based Solution Accuracy: ", accuracyValidation_DBN)
#+end_src

#+RESULTS:
#+begin_example
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
  _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
[1]	valid_0's multi_logloss: 1.66314
Training until validation scores don't improve for 200 rounds
[2]	valid_0's multi_logloss: 1.35732
...
[260]	valid_0's multi_logloss: 0.226954
[261]	valid_0's multi_logloss: 0.227106
[262]	valid_0's multi_logloss: 0.227215
[263]	valid_0's multi_logloss: 0.227329
[264]	valid_0's multi_logloss: 0.227494
Early stopping, best iteration is:
[64]	valid_0's multi_logloss: 0.155201
Training Log Loss:  0.003464589940206874
Validation Log Loss:  0.15520095263526515
LightGBM Gradient Boosting Log Loss:  0.15520095263526515
DBN-Based Solution Accuracy:  0.9561
#+end_example

* Footnotes

[fn:1] Hands-On Machine Learning with Scikit-Learn: Aurelien Geron

[fn:2] [[https://towardsai.net/p/programming/decision-trees-explained-with-a-practical-example-fe47872d3b53][Decision Trees Explained With a Practical Example]]

[fn:3] DEFINITION NOT FOUND.
