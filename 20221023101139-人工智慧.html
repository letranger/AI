<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-01-07 Sun 09:58 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>人工智慧</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
</head>
<body>
<div id="content" class="content">
<h1 class="title">人工智慧</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgdc58942">1. 和AI聊聊天</a>
<ul>
<li><a href="#org73a758d">1.1. ELIZA</a></li>
<li><a href="#org89109d6">1.2. ALICE</a></li>
<li><a href="#org415f297">1.3. Mitsuku</a></li>
</ul>
</li>
<li><a href="#orgf64953c">2. AI, Machine Learning與Deep Learning</a>
<ul>
<li><a href="#orgcf7a2ca">2.1. AI與早期專家系統的差異</a></li>
<li><a href="#orgf8f9a46">2.2. AI</a></li>
<li><a href="#orge99c4ec">2.3. 機器學習</a></li>
<li><a href="#orgc0ffeab">2.4. 類神經網路與深度學習</a></li>
<li><a href="#org70487ba">2.5. 深度學習</a></li>
<li><a href="#org44291eb">2.6. Deep Learning 的概念於 2006 年提出，何以至 2012 年才得到有效應用？</a></li>
</ul>
</li>
<li><a href="#orga0ff6ef">3. AI的發展沿革</a>
<ul>
<li><a href="#org2bd4818">3.1. AI的兩種發展方向</a></li>
<li><a href="#org9fdab91">3.2. AI 發展大事紀</a></li>
<li><a href="#orgc9f3c0d">3.3. AI 應用與影響</a></li>
</ul>
</li>
<li><a href="#org8c007e5">4. AI 的三大學派</a>
<ul>
<li><a href="#org6d06d7a">4.1. 符號主義學派(知識圖譜: 模仿人類邏輯與抽像推理),</a></li>
<li><a href="#org7eca28e">4.2. 連接主義學派(深度學習: 模仿大腦皮層神經網路)</a></li>
<li><a href="#org0ce5cd0">4.3. 行為主義學派(強化學習: 模仿生物奬懲學習機制)</a></li>
</ul>
</li>
<li><a href="#orgea09fc6">5. AI 的五大迷思</a>
<ul>
<li><a href="#orgc2c4f9f">5.1. 迷思一：資料等於價值</a></li>
<li><a href="#org49d126c">5.2. 迷思二：牽涉電腦與資料就是 MIS 部門的工作</a></li>
<li><a href="#orgc70f76c">5.3. 迷思三：資料分析就是產出報表</a></li>
<li><a href="#org846b2b2">5.4. 迷思四：電腦決策不可能贏過人的專業經驗</a></li>
<li><a href="#org4e54425">5.5. 迷思五：導入系統或平台就可以解決營運問題</a></li>
</ul>
</li>
<li><a href="#org019996c">6. AI 擅長的解題領域</a>
<ul>
<li><a href="#org1b9be3a">6.1. 與情境無關的領域</a></li>
<li><a href="#org4b5af8a">6.2. 樣本數多的領域</a></li>
</ul>
</li>
<li><a href="#orgefd0e9c">7. AI 各項產業應用</a>
<ul>
<li><a href="#org360e2c5">7.1. 製造業</a></li>
<li><a href="#org50da89c">7.2. 零售與金融業</a></li>
<li><a href="#org8e39a9d">7.3. 遊戲產業</a></li>
<li><a href="#org55a0000">7.4. 政府機構</a></li>
<li><a href="#org3fc29d3">7.5. Jetson</a></li>
</ul>
</li>
<li><a href="#orgfa4f65c">8. 學習資源</a>
<ul>
<li><a href="#orgab76f56">8.1. Machine Learning [台大李宏毅]</a></li>
<li><a href="#orgcc12b83">8.2. Deep Learning for Human Language Processing (DLHLP) 2020</a></li>
<li><a href="#orgfde7e8e">8.3. 其他線上資源</a></li>
</ul>
</li>
</ul>
</div>
</div>
<a href="https://letranger.github.io/AI/20221023101139-人工智慧.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023101139-人工智慧.html.svg"/></a>
<div id="outline-container-orgdc58942" class="outline-2">
<h2 id="orgdc58942"><span class="section-number-2">1.</span> 和AI聊聊天</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org73a758d" class="outline-3">
<h3 id="org73a758d"><span class="section-number-3">1.1.</span> ELIZA</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/ELIZA#cite_note-turing-1">What is it</a><br /></li>
<li><a href="https://web.njit.edu/~ronkowit/eliza.html">web-based version</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org89109d6" class="outline-3">
<h3 id="org89109d6"><span class="section-number-3">1.2.</span> ALICE</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Artificial_Linguistic_Internet_Computer_Entity">About ALICE</a><br /></li>
<li><a href="http://www.mfellmann.net/content/alice.html">web-based version</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-org415f297" class="outline-3">
<h3 id="org415f297"><span class="section-number-3">1.3.</span> Mitsuku</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Mitsuku">About Mitsuku</a><br /></li>
<li><a href="https://chat.kuki.ai/">Try it</a><br /></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf64953c" class="outline-2">
<h2 id="orgf64953c"><span class="section-number-2">2.</span> AI, Machine Learning與Deep Learning</h2>
<div class="outline-text-2" id="text-2">
<p>
人工智慧、<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>與<a href="20221023101228-深度學習.html#ID-20221023T101228.247381">深度學習</a>是三個常被混為一談的概念，如圖<a href="#orgd7d60a1">1</a>，深度學習是機器學習的一種類型，而機器學習又是人工智慧的一個分支，相較於機器學習，早期實作人工智慧的一種策略是專家系統(Expert System)。<br />
</p>

<div id="orgd7d60a1" class="figure">
<p><img src="images/AMD.png" alt="AMD.png" width="500" /><br />
</p>
<p><span class="figure-number">Figure 1: </span>AI, Machine, Deep Learning</p>
</div>
</div>
<div id="outline-container-orgcf7a2ca" class="outline-3">
<h3 id="orgcf7a2ca"><span class="section-number-3">2.1.</span> AI與早期專家系統的差異</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>專家系統:由人訂規則，告訴電腦判別的方法：狗鼻子較長、耳朵較大&#x2026;<br /></li>
<li><a href="MachineLearning.html">機器學習</a>:給電腦大量標註貓狗的照片，由<a href="MachineLearning.html">機器學習</a>演算法自行歸納辨別二者的方法。<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgf8f9a46" class="outline-3">
<h3 id="orgf8f9a46"><span class="section-number-3">2.2.</span> AI</h3>
<div class="outline-text-3" id="text-2-2">
<p>
AI是一個涵蓋面極廣的名詞，從1964年<a href="https://en.wikipedia.org/wiki/MIT_Computer_Science_and_Artificial_Intelligence_Laboratory">MIT AI Lab</a>的<a href="https://web.njit.edu/~ronkowit/eliza.html">ELIZA</a>對話機器人，到最近的自駕車，再到科幻電影中俱備人類情感的機器人都可以是AI的範圍。在實作上，AI 可以是簡單的 decision tree 或 rule-based 的專家系統(知識庫 + 推理機制)，也可以是包含數十億神經元的類神經網路。那麼，這和我們常聽到的機器學習、深度學習、神經網絡又有什麼關係呢？<br />
</p>
</div>
</div>
<div id="outline-container-orge99c4ec" class="outline-3">
<h3 id="orge99c4ec"><span class="section-number-3">2.3.</span> 機器學習</h3>
<div class="outline-text-3" id="text-2-3">
<p>
在AI的發展中，人們想過以各種方式來達成讓機器具備人類智慧的目的，有人希望能將大量的人類智慧教給電腦，這部份包含了人類在各領域的知識以及推理規則；另一派學者則認為人類的智識大過於廣泛而且不斷的有新知識生成，與其把所有的知識教給電腦，不如讓電腦具備學習的能力，如此電腦就可以自己去學習新的知識，這便是所謂的機器學習。<br />
</p>

<p>
在開發機器學習模型時，我們會基於觀測值計算出一些衍生變數(derived variables)，再將其加入決策判斷的條件中，以增加 model 的預測準確度。例如，由男生的身高體重判斷高血壓的機率，而 BMI 即為一更佳的衍生變數。而<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>模型的成效往往取決於特徵工程的品質，但在某些領域下，特徵工程很難靠領域專家取得好的結果，例如非結構化資料以及序列資料：<br />
</p>
<ul class="org-ul">
<li>非結構化資料：聲音、影像、影片<br /></li>
<li>序列資料：sensor 資料、金融市場資料、交易資料<br /></li>
</ul>

<p>
機器學習有各種不同的實作策略（演算法），而類神經網路就是其中之一。<br />
</p>
</div>
</div>
<div id="outline-container-orgc0ffeab" class="outline-3">
<h3 id="orgc0ffeab"><span class="section-number-3">2.4.</span> 類神經網路與深度學習</h3>
<div class="outline-text-3" id="text-2-4">
<p>
如何讓電腦俱備學習能力？在實作上也有多不同策略，類神經網路就是希望藉由模擬人類腦神經結構的方式來達到這個目的的一種方式，Hinton 於 2006 年提出的 Boltzmann Machine 為一種多層神經網路。典型的類神經網路架構(如圖<a href="#org855769d">2</a>)由輸入層、隱藏層、輸出層組成，學術界稱層數大於3的類神經網路為深度學習。<br />
</p>

<div id="org855769d" class="figure">
<p><img src="images/ANN-640x314.jpeg" alt="ANN-640x314.jpeg" width="500" /><br />
</p>
<p><span class="figure-number">Figure 2: </span>類神經網路架構</p>
</div>

<p>
所以，當你聽到<a href="20221023101228-深度學習.html#ID-20221023T101228.247381">深度學習</a>這個名詞時，有兩件事是可以確定的：<br />
</p>
<ol class="org-ol">
<li>這一定是機器學習<br /></li>
<li>這一定是類神經網路<br /></li>
</ol>

<p>
前面提到 <b>在某些領域下，特徵工程很難靠領域專家取得好的結果</b> ，<a href="20221023101228-深度學習.html#ID-20221023T101228.247381">深度學習</a>的強大之處就在於深度學習連特徵工程也可以自行完成，即，由原始資中自行產生衍生變數。<br />
</p>
</div>
</div>
<div id="outline-container-org70487ba" class="outline-3">
<h3 id="org70487ba"><span class="section-number-3">2.5.</span> 深度學習</h3>
<div class="outline-text-3" id="text-2-5">
<p class="verse">
深度學習與其他機器學習方式最主要的差異在於能否自動進行「特徵工程」(feature engineering)<br />
</p>

<p>
考慮採取傳統機器學習或深度學習時，一個重要關鍵是資料量，若資料量太小，深度學習不一定會有更好的表現。Google Translate 在訓練文件量少於一億篇時，傳統機器學習表現較佳；在文件量超過十億後，深度學習效果就超越傳統機器學習。<br />
</p>

<div id="org7c1a6ac" class="figure">
<p><img src="images/BLEU.png" alt="BLEU.png" width="600" /><br />
</p>
<p><span class="figure-number">Figure 3: </span>BLEU scores for English-Spanish systems trained on 0.4M to 385.7M words of parallel data. Source: Koehn and Knowles (2017) and GPU</p>
</div>
</div>
</div>
<div id="outline-container-org44291eb" class="outline-3">
<h3 id="org44291eb"><span class="section-number-3">2.6.</span> Deep Learning 的概念於 2006 年提出，何以至 2012 年才得到有效應用？</h3>
<div class="outline-text-3" id="text-2-6">
</div>
<ol class="org-ol">
<li><a id="orgef74535"></a>計算速度: GPU 的計算能力由 2018 年起才有突破性的成長<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup><br />
<div class="outline-text-4" id="text-2-6-1">

<div id="orga8393b4" class="figure">
<p><img src="images/GPUCPU1.jpg" alt="GPUCPU1.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 4: </span>Floating-point operations per second for the CPU and GPU</p>
</div>

<div id="org84379ed" class="figure">
<p><img src="images/GPUCPU2.jpg" alt="GPUCPU2.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 5: </span>Memory bandwidth for the CPU and GPU</p>
</div>
</div>
</li>
<li><a id="orgf22bf1a"></a>大量數據<br /></li>
<li><a id="orga527883"></a>軟體<br />
<div class="outline-text-4" id="text-2-6-3">
<p>
相關數學模型、軟體工具(Tensorflow)問世較晚<br />
</p>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-orga0ff6ef" class="outline-2">
<h2 id="orga0ff6ef"><span class="section-number-2">3.</span> AI的發展沿革</h2>
<div class="outline-text-2" id="text-3">
<p>
不論是從 1942 年的<a href="https://zh.wikipedia.org/zh-tw/%E9%98%BF%E5%A1%94%E7%BA%B3%E7%B4%A2%E5%A4%AB-%E8%B4%9D%E7%91%9E%E8%AE%A1%E7%AE%97%E6%9C%BA">ABC</a>或是 1944 年的<a href="https://zh.wikipedia.org/wiki/%E9%A6%AC%E5%85%8B%E4%B8%80%E8%99%9F">MarK I</a>，電腦的發明都過去半個世紀了，為何到 2010 年後，人工智慧才成為熱門話題？<br />
</p>
</div>
<div id="outline-container-org2bd4818" class="outline-3">
<h3 id="org2bd4818"><span class="section-number-3">3.1.</span> AI的兩種發展方向</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<ol class="org-ol">
<li><a id="org93557f8"></a>連結主義(connectionism)<br />
<div class="outline-text-4" id="text-3-1-1">
<p>
一套AI系統應以大腦的基本架構為模型，利用大致像是生物神經元的深度連結元件，強調學習是智慧的核心能力，並認為如果可以讓機器有效的從數據中學習，那麼人腦所具備的其他能力最終也可能會在機器上出現。<br />
</p>
</div>
</li>
<li><a id="orga59ae7f"></a>符號主義<br />
<div class="outline-text-4" id="text-3-1-2">
<p>
採用符號的(symbolic)方式並強調邏輯與推理的應用，對於符號主義者來說，學習並不是那麼重要，智慧的關鍵在於推理、決策和行動來發揮知識的力量。符號主義者不設計可以自己學習的演算法，而是將資訊直接手動編碼到他們建構的系統中，這種作法催生了知識工程的領域。<br />
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org9fdab91" class="outline-3">
<h3 id="org9fdab91"><span class="section-number-3">3.2.</span> AI 發展大事紀</h3>
<div class="outline-text-3" id="text-3-2">
</div>
<ol class="org-ol">
<li><a id="org24c6c96"></a>1940: 人工神經網路<br />
<div class="outline-text-4" id="text-3-2-1">
<p>
1940年 ，Warren McCulloch與Walter Pitts提出了人工神經網路的想法，康乃爾大學心理學教授Frank Rosenblatt後來將這些概念實作出來。<br />
</p>
</div>
</li>
<li><a id="org708a8f2"></a>第一波(符號還輯)：把人類的知識與思考放入電腦<br />
<ol class="org-ol">
<li><a id="orge2f49d8"></a>1950: Computing Machinery and Intelligence<br />
<div class="outline-text-5" id="text-3-2-2-1">
<p>
Turing在他從劍橋大學畢業兩年後(1936)提出通用圖靈機(universal Turing machine)的數學原理，成為所有真實世界的電腦藍圖。1950年Turing發表科學論文Computing Machinery and Intelligence，提出「機器能否思考」的問題。<br />
</p>
</div>
</li>
<li><a id="orgb76a861"></a>1956: 達特茅斯暑期研究專案<br />
<div class="outline-text-5" id="text-3-2-2-2">
<p>
1956年，達特茅斯學院數學教授John McCarthy達特茅斯暑期研究專案，於會中提出artificial intelligence的概念，與會者包括Marvin Minsky, Claude Shannon。Turing未參加(於1954年自殺)<br />
</p>
</div>
</li>
<li><a id="orgf7349c8"></a>1957 年<br />
<div class="outline-text-5" id="text-3-2-2-3">
<p>
Herbert A. Somin(諾貝爾經濟學奬得主)預言電腦能在十年內敗人類(西洋棋)，此預言於 1997由<a href="https://zh.wikipedia.org/zh-tw/%E6%B7%B1%E8%97%8D_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)">IBM Deep</a>實現。<br />
</p>
</div>
</li>
<li><a id="org430c428"></a>1957年: Perceptron<br />
<div class="outline-text-5" id="text-3-2-2-4">
<p>
感知器（英語：Perceptron）是弗蘭克·羅森布拉特在1957年就職於康奈爾航空實驗室（Cornell Aeronautical Laboratory）時所發明的一種人工神經網路。它可以被視為一種最簡單形式的前饋神經網路，是一種二元線性分類器。<br />
羅森布拉特給出了相應的感知機學習算法，常用的有感知機學習、最小二乘法和梯度下降法。譬如，感知機利用梯度下降法對損失函數進行極小化，求出可將訓練數據進行線性劃分的分離超平面，從而求得感知機模型<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>。<br />
</p>
</div>
</li>
<li><a id="orga295916"></a>1966: 史丹佛研究所成立Artificial Intellgience center<br />
<div class="outline-text-5" id="text-3-2-2-5">
<p>
該中心在語言翻譯與語音識別等領域有開創性的成果，並創立了第一個能與環境互動的自主機器人。五十年後該中心分拆出一家新創公司，擁有名為Siri的新型個人助理，於2010被Apple收購。<br />
</p>
</div>
</li>
<li><a id="orge80a723"></a>1970: Minsky的預測<br />
<div class="outline-text-5" id="text-3-2-2-6">
<p>
1970年,Minsky接受LIFE雜誌訪問時預測：在3~8年，我們將擁有一台具有和普通人一樣智慧的機器，能閱讀莎士比亞、幫車上潤滑油、玩辦公室政治、講笑話與打架的機器。屆時，機器將開始以驚人的速速進行自我教育、過幾個月後，它就會達到天才的程度，然後再過幾個月，它的力量將無法估量。<br />
</p>
</div>
</li>
<li><a id="orgf1befe5"></a>1974: 幻滅<br />
<div class="outline-text-5" id="text-3-2-2-7">
<p>
數十年的努力後，人們發現連要打造出基本的AI系統都比預期困難，於是這股熱潮開始退燒，投資者的幻想也開始破滅，許多該領域的研究人員職涯前景也蒙上一層陰影，AI發展進入AI winters時期。<br />
</p>
</div>
</li>
<li><a id="org711a988"></a>這階段的失敗原因<br />
<div class="outline-text-5" id="text-3-2-2-8">
<ul class="org-ul">
<li>對於AI預計要解決的問題真正難度缺乏理解<br /></li>
<li>連人類自己都還搞不清楚自己的思考過程<br /></li>
<li>1990年代之前的電腦速度都過於緩慢<br /></li>
</ul>
</div>
</li>
</ol>
</li>
<li><a id="orgba85e8a"></a>第二波(專家系統)：讓電腦按照人類定義的規則做決策<br />
<ol class="org-ol">
<li><a id="org4eb1ac0"></a>1970 年，專家系統<br />
<div class="outline-text-5" id="text-3-2-3-1">
<p>
一連串條件判斷的推導為<br />
</p>
<ul class="org-ul">
<li>第一波失敗原因：野心太大，這次讓電腦依照人類設定好的規則來思考<br /></li>
<li>expert system 在 1980 年代廣受應用，Fortune 500 大公司有三分之二將之應用於營運工作中，如訂單處理、信用卡徵審、稅務處理。<br /></li>
</ul>
</div>
</li>
<li><a id="orgccf392c"></a>1980年代初期: backpropagation<br />
<div class="outline-text-5" id="text-3-2-3-2">
<p>
加大聖地牙哥分校心理學教授David Rumelhart提出backpropagation，為當今多層神網網路的主要學習演算法。1986年<br />
Ronald Williams與卡內基美隆大學的Hinton共同在Nature描述了該演算法如何應用於深度學習中。Hinton於1981年在加大當博士後研究員時曾與Rumelhart一起工作。<br />
</p>
</div>
</li>
<li><a id="orgec25f6a"></a>1980年末期: 手寫數字辨識<br />
<div class="outline-text-5" id="text-3-2-3-3">
<p>
神經網路的實際應用開始出現，AT&amp;T貝爾實驗室研究員楊立昆在CNN的新架構中使用了backpropagation，該套系統可辨識手寫數字。<br />
</p>
</div>
</li>
<li><a id="org6b8d3d8"></a>1990 年後 expoert system 逐漸勢微<br />
<div class="outline-text-5" id="text-3-2-3-4">
<p>
原因是能力有限，距離人類心目中的人工智慧差距尚大。<br />
Polanyi&rsquo;s Paradox(博藍尼悖論): We can know more than we cantell, i.e., many of the tasks we perform rely on tacit, intuitive knowledge that is diffucult to codify and automate.<br />
</p>
</div>
</li>
<li><a id="org21c3b1e"></a>1990年代: LSTM<br />
<div class="outline-text-5" id="text-3-2-3-5">
<p>
瑞士達勒・莫爾AI研究所(IDSIA)的負責人之一Jurgen Schmidhuber與他的學生開發LSTM。<br />
</p>
</div>
</li>
<li><a id="org828640d"></a>1990年代後期<br />
<div class="outline-text-5" id="text-3-2-3-6">
<p>
速度更快的電腦硬體開始出現<br />
</p>
</div>
</li>
<li><a id="org85a6c6b"></a>1997: Deep Blue<br />
<div class="outline-text-5" id="text-3-2-3-7">
<p>
1997年5月,IBM的Deep Blue險朥西洋棋冠軍Garry Kasparov<br />
</p>
</div>
</li>
</ol>
</li>
<li><a id="org742551c"></a>第三波(<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>)：電腦從資枓歸納規則，關鍵要素為資料與演算法<br />
<ol class="org-ol">
<li><a id="org1d1a916"></a>2006 年：Boltzman Machine<br />
<div class="outline-text-5" id="text-3-2-4-1">
<p>
Geofffrey Hinton 提出 Restricted Boltzmann Machine，成功訓練多層神經網路(multi-layer neural networks)，可用來描述更複雜的非線性函數，並稱之為深度學習(Deep Learning)。<br />
</p>
</div>
</li>
<li><a id="org340b351"></a>2009: 大數據ImageNet<br />
<div class="outline-text-5" id="text-3-2-4-2">
<p>
普林斯頓大學李飛飛意識到要教育機器對現實世界進行視覺感知就需要全面性的教學資源，其中包含正確標記的範例，包括人、動物、建築物、車輛、物體的許多變化形態。她在兩年半的時間，透過外包平台(Mechanical Turk)為5000多個類別中超過300萬張圖片下標題。最後她打造的ImageNet發表，很快成為機器視覺研究不可或缺的資源<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>。<br />
</p>
</div>
</li>
<li><a id="org8f22d87"></a>2011: Watson<br />
<div class="outline-text-5" id="text-3-2-4-3">
<p>
IBM Waton於益智問答節目 危險邊緣 取得冠軍，以一堆來自維基百科的文章為主要數據，運用智慧演算法來同時處理這些數據。Watson預告了一個新時代的到來，預示機器最終將開始解析語言並與人類互動<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup>。<br />
</p>
</div>
</li>
<li><a id="org273819f"></a>2012 年 10 月,Hinton 帶兩個學生參力 ILSVRC 比賽，以深度學習配合 GPU 的運算速度拿下冠軍。<br /></li>
<li><a id="orgdf578bf"></a>2013 ILSVRC(ImageNet Large Scale Visual Recongnition Challenge)<br />
<div class="outline-text-5" id="text-3-2-4-5">
<p>
先讓程式看 120 萬張訓練照片，共 1000 種分類，接下來要求程式為 15 萬張測試照片進行分類。<br />
月- 2013 年，Google 收購 Hinton 和他兩位學生創立的公司：DNNresearch<br />
</p>
</div>
</li>
<li><a id="org503d855"></a>2015 年，Microsoft 在 ILSVRC 以 3.5%的錯誤率奪冠，首次超過人類(5%)。<br />
<div class="outline-text-5" id="text-3-2-4-6">
<p>
以上參考: <a href="https://www.books.com.tw/products/0010821934">人工智慧在台灣</a><br />
</p>
</div>
</li>
<li><a id="org3c5d9e7"></a>2016: Scale AI<br />
<div class="outline-text-5" id="text-3-2-4-7">
<p>
2016年成立的Scale AI由MIT輟學生Alexandr Wang於2016年創立，與超過3萬名群眾外包工作者簽約，為Uber、Lyft、Airbnb和Waymo等客戶標記數據，該公司已獲得超過1億美元的風險投資，現被列為矽谷的獨角獸(估值超過10億美元的新創公司)。<br />
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-orgc9f3c0d" class="outline-3">
<h3 id="orgc9f3c0d"><span class="section-number-3">3.3.</span> AI 應用與影響</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<ol class="org-ol">
<li><a id="org5a501ed"></a>Weak AI v.s. Strong AI<br />
<div class="outline-text-4" id="text-3-3-1">
<ul class="org-ul">
<li>Strong AI: 能思考、有主觀意識，又稱 General AI, FUll AI<br /></li>
<li>Tesla CEO Elon Musk: 2017 年 7 月在美國提倡規管 AI 發展的法案<br /></li>
</ul>
</div>
</li>
<li><a id="org128d4c5"></a>AI 研究趨勢<br />
<div class="outline-text-4" id="text-3-3-2">
<p>
大規模<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a><br />
</p>
<ul class="org-ul">
<li>深度學習<br /></li>
<li>強化學習<br /></li>
<li>計算機視覺(偵測)<br /></li>
<li>自然語言處理<br /></li>
<li>協作系統<br /></li>
<li>Iot 物聯網<br /></li>
<li>交通 / 無人機<br /></li>
<li>家庭 / 服務機器人<br /></li>
<li>醫療: 長照、疾病判斷<br /></li>
<li>教育<br /></li>
<li>低資源社區<br /></li>
<li>公共安全: 監視器<br /></li>
<li>就業和勞資<br /></li>
<li>娛樂<br /></li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org8c007e5" class="outline-2">
<h2 id="org8c007e5"><span class="section-number-2">4.</span> AI 的三大學派</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org6d06d7a" class="outline-3">
<h3 id="org6d06d7a"><span class="section-number-3">4.1.</span> 符號主義學派(知識圖譜: 模仿人類邏輯與抽像推理),</h3>
<div class="outline-text-3" id="text-4-1">
<p>
是指基於符號運算的人工智慧學派，他們認為知識可以用符號來表示，認知可以通過符號運算來實現。例如，專家系統等。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="org5dccec3"></a>主要觀點：思維的基本是符號，思維過程即符號運算；智能的核心是知識，利用知識推理進行問題求解；智能活動的基礎是物理符號系統，人腦、電腦都是物理符號系統；知識可用符號表示，可建立基於符號邏輯的智能理論體系。該學派認為人工智慧源於數理邏輯，其主要的理論基礎是物理符號假設。<br /></li>
<li><a id="orga40f6ce"></a>主要科學方法：基於實驗心理學與計算軟體計算相結合的，以思維過程的功能模擬為重點的「黑箱」方法。<br /></li>
<li><a id="org34d273e"></a>代表性成果：1956 年問世的第一個啟發程序 LT 邏輯理論機；1968 年發表的第一個專家系統 DENTRAL 化學分析專家系統。<br /></li>
<li><a id="orgc45250c"></a>發展途徑：啟發程序→專家系統。<br /></li>
</ol>
</div>
<div id="outline-container-org7eca28e" class="outline-3">
<h3 id="org7eca28e"><span class="section-number-3">4.2.</span> 連接主義學派(深度學習: 模仿大腦皮層神經網路)</h3>
<div class="outline-text-3" id="text-4-2">
<p>
是指神經網絡學派，在神經網絡方面，繼魯梅爾哈特研製出 BP 網絡之後，1987 年，首屆國際人工神經網絡學術大會在聖迭戈（San-Diego）舉行，掀起了人工神經網絡的第二次高潮。之後，隨著模糊邏輯和進化計算的逐步成熟，又形成了「計算智能」這個統一的學科範疇。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="orgafdb2a0"></a>主要觀點：智能活動的基元是神經細胞，智能活動過程是神經網絡的狀態演化過程，智能活動的基礎是神經細胞的突觸聯結機制，智能系統的工作模式仿人腦模式。該學派認為人工智慧源於仿生學，特別是對人腦模型的研究，其主要理論基礎為神經網絡及神經網絡間的連接機制與學習算法。<br /></li>
<li><a id="org9bf897b"></a>主要科學方法：基於神經生理學與生理學的、以神經系統的結構模擬為重點的數學模擬與物理模擬方法。<br /></li>
<li><a id="orgbb858b2"></a>代表性成果：1943 年問世的第一個人工神經細胞——MP 模型；1960 年研製的感知機；1982 年提出的全互連型人工神經網絡——Hopfield 網絡；1986 年開發的多層感知機——BP 神經網絡。<br /></li>
<li><a id="org17ad96b"></a>發展途徑：人工神經細胞→人工神經網絡。<br /></li>
</ol>
</div>
<div id="outline-container-org0ce5cd0" class="outline-3">
<h3 id="org0ce5cd0"><span class="section-number-3">4.3.</span> 行為主義學派(強化學習: 模仿生物奬懲學習機制)</h3>
<div class="outline-text-3" id="text-4-3">
<p>
是指進化主義學派，在行為模擬方面，麻省理工學院的布魯克教授 1991 年研製成功了能在未知的動態環境中漫遊的有 6 條腿的機器蟲。<br />
</p>
</div>
<ol class="org-ol">
<li><a id="orgf598f14"></a>主要觀點：智能行為的基礎是「感知——行動」的反應機制，智能系統的智能行為，需要在真實世界的複雜境遇中進行學習和訓練，在與周圍環境的信息交互與適應過程中不斷進化和體現。該學派認為人工智慧應著重研究在複雜環境下對行為的控制，其主要的理論基礎是控制論。<br /></li>
<li><a id="orgf25ae51"></a>主要科學方法：基於智能控制系統的理論、方法和技術，以生物控制系統的智能行為模擬為重點，研究擬人的智能控制行為。<br /></li>
<li><a id="orgb4da68d"></a>代表性成果：1952 年研製成功的第一個「控制論動物」——香農老鼠；1991 年布魯克斯演示的新型智能機器人。<br /></li>
<li><a id="org80d302a"></a>發展途徑：控制論動物→智能機器人。<br />
<div class="outline-text-4" id="text-4-3-4">
<p>
(以上參考網址：原文網址：<a href="https://kknews.cc/tech/pp8kvlz.html%E3%80%81https://kknews.cc/tech/5gn2gll.html">https://kknews.cc/tech/pp8kvlz.html%E3%80%81https://kknews.cc/tech/5gn2gll.html</a>)<br />
</p>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-orgea09fc6" class="outline-2">
<h2 id="orgea09fc6"><span class="section-number-2">5.</span> AI 的五大迷思</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgc2c4f9f" class="outline-3">
<h3 id="orgc2c4f9f"><span class="section-number-3">5.1.</span> 迷思一：資料等於價值</h3>
<div class="outline-text-3" id="text-5-1">
<p>
資料若沒有經過妥善的加工處理和萃取分析，本身並無太大價值，需要將對的資料用在對的場景。例如，電信公司的通聯記錄，行銷公司只會拿來做行銷，治安機關則可以拿來追查詐騙集團；又如 X 光片的判斷品質決定了 AI model 的成效。資料等於價值的另一反例為 AlphaZero。<br />
</p>
</div>
</div>
<div id="outline-container-org49d126c" class="outline-3">
<h3 id="org49d126c"><span class="section-number-3">5.2.</span> 迷思二：牽涉電腦與資料就是 MIS 部門的工作</h3>
<div class="outline-text-3" id="text-5-2">
<p>
AI 的導入需要跨部門支持，其開發團隊需要資料科學家(數學、統計)、領域專家(領域知識)、資訊人員(程式設計、資料庫)，最後在驗證模型成效時更需要跨部門的支持。<br />
</p>
</div>
</div>
<div id="outline-container-orgc70f76c" class="outline-3">
<h3 id="orgc70f76c"><span class="section-number-3">5.3.</span> 迷思三：資料分析就是產出報表</h3>
<div class="outline-text-3" id="text-5-3">
<p>
資料分析不應只限於公司內部資料庫中的結構化資料，而應包含非結構化資料(影像、聲音、影片、文字、互動)<br />
</p>
</div>
</div>
<div id="outline-container-org846b2b2" class="outline-3">
<h3 id="org846b2b2"><span class="section-number-3">5.4.</span> 迷思四：電腦決策不可能贏過人的專業經驗</h3>
<div class="outline-text-3" id="text-5-4">
<p>
主要原因在人類的短期記憶有限、能留意到的弱訊號太少，此外，有些工作需要極快的反應時間(如股市交易)。1995 年 Amazon 曾讓 50 位資深編輯就「推薦書單」與演算法進行 PK，自此後 Amazon 所有商品推薦都由<a href="MachineLearning.html">機器學習</a>進行。<br />
</p>
</div>
</div>
<div id="outline-container-org4e54425" class="outline-3">
<h3 id="org4e54425"><span class="section-number-3">5.5.</span> 迷思五：導入系統或平台就可以解決營運問題</h3>
<div class="outline-text-3" id="text-5-5">
<p>
AI 不是一個資訊系統(如 ERP)，而是一種根據已知預測未知的方法，它沒有標準做法，其應用情境與方式會隨著企業的狀況與及需求有所不同。因此，問題不在「有沒有導入 AI」，而是「AI 應用的深度與廣度」。<br />
</p>
</div>
</div>
</div>
<div id="outline-container-org019996c" class="outline-2">
<h2 id="org019996c"><span class="section-number-2">6.</span> AI 擅長的解題領域</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org1b9be3a" class="outline-3">
<h3 id="org1b9be3a"><span class="section-number-3">6.1.</span> 與情境無關的領域</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>如棋類遊戲等封閉系統就是與情境無關；反之，個人商品推薦則否，因為影響使用者是否購買特定商品的因素有太多是電商觀測不到的，例如，當天的心情。同理，戰爭的爆發其背後的因素也有可能出人意料之外，如特洛伊。<br /></li>
<li>一些工作雖然與情境相關，但卻因為這些情境可人為控制，所以也適合以 AI 解決，如，人臉辨識可能因為拍照時人的角度、戴口罩、太陽眼鏡、帽子、背景光線、天氣等因素而導致辨識困難，但這些情境因素都可以事先控制，如：要求對象拿下口罩正向面對攝影機。<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org4b5af8a" class="outline-3">
<h3 id="org4b5af8a"><span class="section-number-3">6.2.</span> 樣本數多的領域</h3>
<div class="outline-text-3" id="text-6-2">
<ul class="org-ul">
<li>如颱風一年最多 20 個，累積 50 年也不過 1000 個，不足以建立高複雜度且精確的學習模型(尤其牽涉的的變數很多時)<br /></li>
</ul>

<div id="org495a625" class="figure">
<p><img src="images/AITW.jpg" alt="AITW.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 6: </span>AI 擅長的解題領域</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgefd0e9c" class="outline-2">
<h2 id="orgefd0e9c"><span class="section-number-2">7.</span> AI 各項產業應用</h2>
<div class="outline-text-2" id="text-7">

<div id="org17289ea" class="figure">
<p><img src="images/enterprise.jpg" alt="enterprise.jpg" width="600" /><br />
</p>
<p><span class="figure-number">Figure 7: </span>各產業投資 AI 效益</p>
</div>
</div>
<div id="outline-container-org360e2c5" class="outline-3">
<h3 id="org360e2c5"><span class="section-number-3">7.1.</span> 製造業</h3>
<div class="outline-text-3" id="text-7-1">
<ol class="org-ol">
<li>瑕疵檢測：金屬表面、玻璃、印刷電路、電子產品、牛仔褲、農產品，由 AI 取代人眼。在某家製造商的資料中，人眼檢測瑕疵漏網率為 5%、AI 為 0.01%；人眼檢測速度為每天 30 萬張影像、一台 10 萬左右的電腦每天可檢測 1440 萬張。<br /></li>
<li>自動流程控制：製造業共通的挑戰為設人竹廿月參數的調控及最佳化，或稱為自動流程控制。生產流程中，如馬達轉速、電流、電壓、環境溫度&#x2026;等等需要監控、會影響產品良率的因素可能高達上千個，這些高維度的因素彼此又有交互作用(通常維度高過 5 個，且參數間有交互作用，人類就無法精確掌握)，而且製程可能很長，調整參數後可能隔天才能確認。AI 介入化工製程的例子可以將良率由六成調至 98%<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup>。<br /></li>
<li>預測性維護：包括預測機器何時會出錯以提前進廠保養、預測耗才何時更換最為有利。此類工作涉及訊號鄋理，如：監控馬達電壓、轉速、震動、聲音來判斷馬達是否即將固障；監控機器手臂行程順暢度、夾具穩定度來判斷機器手臂是否有固障徵兆。<sup><a id="fnr.5.100" class="footref" href="#fn.5" role="doc-backlink">5</a></sup><br /></li>
<li>原料組合最佳化：製造業的工作在於取得一種或多種原料，經過物理或化學加工過程後製成產品；但每批原枓可能來自不同供應商、品質、等級或特性可能有所差異，如何在各原料、供應商、等級、成本的排列中找出最高 CP 值的組合即為重要工作。以染整業為例，新的布料與顏色平均要花 3~7 天的打色嚐試才能達到客戶允收範圍，以第一次打色為例，軟體模擬加上師傅經驗調整，成功率約七成；而藉由以深度學習建出模型來描述布料、目標顏色及染料濃度間的關係，可以將成功率達到九成<sup><a id="fnr.5.100" class="footref" href="#fn.5" role="doc-backlink">5</a></sup>。<br /></li>
</ol>
</div>
</div>
<div id="outline-container-org50da89c" class="outline-3">
<h3 id="org50da89c"><span class="section-number-3">7.2.</span> 零售與金融業</h3>
<div class="outline-text-3" id="text-7-2">
<p>
零售及金融之所以相對容易切入 AI 是因為這兩個產業的核心業務就是在處理資訊流。<br />
依據 Gartner 的報告，資料分析可以分四個層次：<br />
</p>
<ol class="org-ol">
<li>描述：評估現況及了解問題。解釋發生了什麼？<br /></li>
<li>解釋：提供問題的初步診斷。解釋為什麼發生？<br /></li>
<li>預測：提供改善和解決問題的工具。未來會不會發生？<br /></li>
<li>最佳化：提供改善和解決問題的工具。如何讓他發生？<br /></li>
</ol>
</div>
<ol class="org-ol">
<li><a id="orgdbfab18"></a>圖表式的決策反而可能誤導<br />
<div class="outline-text-4" id="text-7-2-1">
<p>
以零售業的產銷量問題為例，假設影響因素有：店點、擺設位置、售價，折扣活動、集點活動、包裝、季節&#x2026;，若以圖表顯示，每張圖表一次頂多呈現 1~2 個變數的關係，無法同時呈現所有變數<sup><a id="fnr.5.100" class="footref" href="#fn.5" role="doc-backlink">5</a></sup>。<br />
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org8e39a9d" class="outline-3">
<h3 id="org8e39a9d"><span class="section-number-3">7.3.</span> 遊戲產業</h3>
<div class="outline-text-3" id="text-7-3">
<ol class="org-ol">
<li>提升畫質(俠盗獵車手V)遊戲引撉<sup><a id="fnr.6" class="footref" href="#fn.6" role="doc-backlink">6</a></sup><br /></li>
<li>NPC的進化：可以記住與玩家的互動，產生不固定的對話內容、了解玩家的偏好招式、記住以往的恩怨情仇，即，更像玩家<sup><a id="fnr.6.100" class="footref" href="#fn.6" role="doc-backlink">6</a></sup><br /></li>
</ol>
</div>
</div>
<div id="outline-container-org55a0000" class="outline-3">
<h3 id="org55a0000"><span class="section-number-3">7.4.</span> 政府機構</h3>
<div class="outline-text-3" id="text-7-4">
</div>
<ol class="org-ol">
<li><a id="org1f25c28"></a>交通<br />
<div class="outline-text-4" id="text-7-4-1">
<ul class="org-ul">
<li><a href="https://youtu.be/35PYqhSzZxY?si=C-hZu0bQiiaO6wMC">高市交通局設置AI智慧號誌　降低停等延滯時間　紓解交通瓶頸</a><br /></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org3fc29d3" class="outline-3">
<h3 id="org3fc29d3"><span class="section-number-3">7.5.</span> Jetson</h3>
<div class="outline-text-3" id="text-7-5">
<p>
<a href="https://iotmart.advantech.com.tw/Widget.aspx?WidgetID=3076">Iot應用</a><br />
</p>
<p width="500">
<img src="images/AI_各項產業應用/2023-11-15_20-48-03_2023-11-15_20-47-52.png" alt="2023-11-15_20-48-03_2023-11-15_20-47-52.png" width="500" /><br />
<a href="https://www.cw.com.tw/article/5128007">AI顧嬰，讓爸媽安心睡</a><br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgfa4f65c" class="outline-2">
<h2 id="orgfa4f65c"><span class="section-number-2">8.</span> 學習資源</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-orgab76f56" class="outline-3">
<h3 id="orgab76f56"><span class="section-number-3">8.1.</span> Machine Learning [台大李宏毅]</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<ol class="org-ol">
<li><a id="orge6b5b60"></a>Lecture 0<br />
<div class="outline-text-4" id="text-8-1-1">
<ul class="org-ul">
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html">ML19: 台大[[file:MachineLearning.org][機器學習</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=CXgbekl66jc">ML Lecture 0-1: Introduction of Machine Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=On1N8u1z2Ng">ML Lecture 0-2: Why we need to learn machine learning?</a><br /></li>
</ul>
</div>
</li>
<li><a id="orga6eeafe"></a>Lecture 1<br />
<div class="outline-text-4" id="text-8-1-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fegAeph9UaA">ML Lecture 1: Regression - Case Study</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1UqCjFQiiy0">ML Lecture 1: Regression - Demo</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgd480e48"></a>Lecture 2<br />
<div class="outline-text-4" id="text-8-1-3">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=D_S6y0Jm6dQ">ML Lecture 2: Where does the error come from?</a><br /></li>
</ul>
</div>
</li>
<li><a id="org7308aae"></a>Lecture 3<br />
<div class="outline-text-4" id="text-8-1-4">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=yKKNr-QKz2Q">ML Lecture 3-1: Gradient Descent</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1_HBTJyWgNA">ML Lecture 3-2: Gradient Descent (Demo by AOE)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=wzPAInDF_gI">ML Lecture 3-3: Gradient Descent (Demo by Minecraft)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org67c0fe1"></a>Lecture 4<br />
<div class="outline-text-4" id="text-8-1-5">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fZAZUYEeIMg">ML Lecture 4: Classification</a><br /></li>
</ul>
</div>
</li>
<li><a id="org143348e"></a>Lecture 5<br />
<div class="outline-text-4" id="text-8-1-6">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=hSXFuypLukA">ML Lecture 5: Logistic Regression</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgdd2fbfa"></a>Lecture 6<br />
<div class="outline-text-4" id="text-8-1-7">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Dr-WRlEFefw">ML Lecture 6: Brief Introduction of Deep Learning</a><br /></li>
</ul>
</div>
</li>
<li><a id="orgbe062db"></a>Lecture 7<br />
<div class="outline-text-4" id="text-8-1-8">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=ibJpTrp5mcE">ML Lecture 7: Backpropagation</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=gDp2LXGnVLQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=3&amp;t=0s">Anomaly Detection (1/7)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4">Next Step of Machine Learning (Hung-yi Lee, NTU, 2019)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org8188246"></a>Lecture 8<br />
<div class="outline-text-4" id="text-8-1-9">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Lx3l4lOrquw">ML Lecture 8-1: “Hello world” of deep learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=5BJDJd-dzzg">ML Lecture 8-2: Keras 2.0</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=L8unuZNpWw8">ML Lecture 8-3: Keras Demo</a><br /></li>
</ul>
</div>
</li>
<li><a id="org3bb6805"></a>Explainable ML<br />
<div class="outline-text-4" id="text-8-1-10">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=lnjrn3bF9lA">Explainable ML (1/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&amp;list=PL9McrqOpq3mUCXF5E8rVLjw8f878zkBfX&amp;index=16">Explainable ML (2/8)</a><br /></li>
<li>Explainable ML (3/8)<br /></li>
<li><a href="https://www.youtube.com/watch?v=yORbWn7UsBs">Explainable ML (4/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (5/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=K1mWgthGS-A">Explainable ML (6/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (7/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Explainable ML (8/8)</a><br /></li>
</ol>
</div>
</li>
<li><a id="orgf6cc4da"></a><span class="todo TODO">TODO</span> Attack ML Models<br />
<div class="outline-text-4" id="text-8-1-11">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=NI6yb0WgMBM">Attack ML Models (1/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=zOdg05BwE7I">Attack ML Models (2/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=F9N5zF7N0qY">Attack ML Models (3/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ">Attack ML Models (4/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=2mgLPZJOHNk">Attack ML Models (5/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=z2nmPDLEXI0">Attack ML Models (6/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=KH48zq2RfBA&amp;t=1s">Attack ML Models (7/8)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Attack ML Models (8/8)</a><br /></li>
</ol>
</div>
</li>
<li><a id="orgec6b3d8"></a>Lecture 9<br />
<div class="outline-text-4" id="text-8-1-12">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=xki61j7z-30">ML Lecture 9-1: Tips for Training DNN</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Ky1ku1miDow">ML Lecture 9-2: Keras Demo 2</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=F1vek6ULo9w">ML Lecture 9-3: Fizz Buzz in Tensorflow (sequel)</a><br /></li>
</ul>
</div>
</li>
<li><a id="org1d017b5"></a>Lecture 10<br />
<div class="outline-text-4" id="text-8-1-13">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=FrKWiRv254g">ML Lecture 10: Convolutional Neural Network</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=XsC9byQkUH8">ML Lecture 11: Why Deep?</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=fX_guE7JNnY">ML Lecture 12: Semi-supervised</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=iwh5o_M4BNU">ML Lecture 13: Unsupervised Learning - Linear Methods</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=X7PH3NuYW0Q">ML Lecture 14: Unsupervised Learning - Word Embedding</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=GBUEjkpoxXc">ML Lecture 15: Unsupervised Learning - Neighbor Embedding</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=yyKaACh_j3M&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=45&amp;t=0s">Meta Learning – Metric-based (1/3)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Tk5B4seA-AU">ML Lecture 16: Unsupervised Learning - Auto-encoder</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=YNUek8ioAJk">ML Lecture 17: Unsupervised Learning - Deep Generative Model (Part I)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ">ML Lecture 18: Unsupervised Learning - Deep Generative Model (Part II)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=48&amp;t=0s">More about Auto-encoder (1/4)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=qD6iD4TFsdQ">ML Lecture 19: Transfer Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=7qT5P9KJnWo&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=25">Life Long Learning (1/7)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ZjfjPzXw6og&amp;feature=youtu.be">Sequence-to-sequence Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=33&amp;t=0s">Meta Learning – MAML (1/9)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=QSEPStBgwRQ">ML Lecture 20: Support Vector Machine (SVM)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=xCGidAeyS4M">ML Lecture 21-1: Recurrent Neural Network (Part I)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=rTqmWlnwz_0">ML Lecture 21-2: Recurrent Neural Network (Part II)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=YIuBHB9Ejok&amp;feature=youtu.be">Unsupervised Syntactic Parsing (ft. 莊永松同學)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=tH9FH1DH5n0">ML Lecture 22: Ensemble</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=W8XF3ME8G2I">ML Lecture 23-1: Deep Reinforcement Learning</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=y8UPGr36ccI">ML Lecture 23-2: Policy Gradient (Supplementary Explanation)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=2-JNBzCq77c">ML Lecture 23-3: Reinforcement Learning (including Q-learning)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_">Deep Reinforcement Learning, 2018</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=dPp8rCAnU_A&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=52&amp;t=0s">Network Compression (1/6)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ufcKFjdpT98&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58&amp;t=0s">GAN (Quick Review)</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw">Generative Adversarial Network (GAN), 2018</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58">Transformer</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=UYPa347-DdE&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=62&amp;t=0s">ELMO, BERT, GPT</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=uXY18nzdSsM&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=59">Flow-based Generative Model</a><br /></li>
<li><a href="https://brohrer.mcknote.com/zh-Hant/statistics/how_bayesian_inference_works.html">貝葉斯推斷的運作原理</a><br /></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgcc12b83" class="outline-3">
<h3 id="orgcc12b83"><span class="section-number-3">8.2.</span> Deep Learning for Human Language Processing (DLHLP) 2020</h3>
<div class="outline-text-3" id="text-8-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=nER51ZyJaCQ&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG">[DLHLP 2020] Deep Learning for Human Language Processing (Course Overview)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=AIKu43goh-8&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=2">[DLHLP 2020] Speech Recognition (1/7) - Overview</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=BdUeBa6NbXA&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=3">[DLHLP 2020] Speech Recognition (2/7) - Listen, Attend, Spell</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=CGuLuBaLIeI&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=4">[DLHLP 2020] Speech Recognition (3/7) - CTC, RNN-T and more</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=XWTGY_PNABo&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=5">[DLHLP 2020] Speech Recognition (4/7) - HMM (optional)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=5SSVra6IJY4&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=6">[DLHLP 2020] Speech Recognition (5/7) - Alignment of HMM, CTC and RNN-T (optional)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=gRfTfXCe3LA">[DLHLP 2020] Deep Learning for Question Answering (1/2)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ">[DLHLP 2020] Deep Learning for Question Answering (2/2)</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=DOG1L9lvsDY">[DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=Bywo7m6ySlk">[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA">Transformer</a><br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgfde7e8e" class="outline-3">
<h3 id="orgfde7e8e"><span class="section-number-3">8.3.</span> 其他線上資源</h3>
<div class="outline-text-3" id="text-8-3">
<ul class="org-ul">
<li><a href="http://ocw.aca.ntu.edu.tw/ntu-ocw/ocw/cou/104S204/1">Digital Speech Processing</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher/TensorSecurity">MyDearGreatTeacher/TensorSecurity</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher/PyTorch/blob/master/code/LinearRegression.py">MyDearGreatTeacher/PyTorch</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher/AI201909">MyDearGreatTeacher/AI201909</a><br /></li>
<li><a href="https://github.com/MyDearGreatTeacher?tab=repositories">MyDearGreatTeacher</a><br /></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">MIT Convolutional Neural Networks for Visual Recognition (Spring 2017)</a><br /></li>
<li><a href="https://www.packtpub.com/catalogsearch/result/?q=python&amp;released=Available&amp;language=Python">packt電子書</a><br /></li>
<li><a href="https://www.youtube.com/watch?v=J6Ok8p463C4">Getting Started with Keras (AI Adventures) Youtube</a><br /></li>
<li><a href="https://blog.csdn.net/sunqiande88/article/details/80100891">PyTorch實戰2: ResNet-18實現Cifar-10圖像分類</a><br /></li>
<li><a href="https://github.com/activatedgeek/LeNet-5">LeNet-5</a><br /></li>
<li><a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a><br /></li>
<li><a href="https://github.com/nlpinaction/learning-nlp">自然语言处理算法与实战</a><br /></li>
</ul>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.hindawi.com/journals/mpe/2019/2053156/">A Multi-GPU Parallel Algorithm in Hypersonic Flow Computations</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/zh-tw/%E6%84%9F%E7%9F%A5%E5%99%A8">感知器</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/E050141335">AI無所不在的教來, Rule of the Robots</a>, P.115<br />
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/E050141335">AI無所不在的教來, Rule of the Robots</a>, P.111<br />
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/0010821934?sloc=main">人工智慧在台灣：產業轉型的契機與挑戰，AI應用無所不在，你跟上了嗎？</a><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6" role="doc-backlink">6</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/0010921963">寫給中學生看的AI課</a><br />
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2024-01-07 Sun 09:58</p>
</div>
</body>
</html>