<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-11-13 Wed 09:52 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>人工智慧</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
</head>
<body>
<div id="content" class="content">
<h1 class="title">人工智慧</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org3cbe83d">1. 和AI聊聊天</a>
<ul>
<li><a href="#org9e204c5">1.1. ELIZA</a></li>
<li><a href="#org35f8ee2">1.2. ALICE</a></li>
<li><a href="#org0efe18e">1.3. Mitsuku</a></li>
<li><a href="#orgefa09b7">1.4. ChatGPT</a></li>
<li><a href="#org75d8034">1.5. Bard</a></li>
</ul>
</li>
<li><a href="#orgae8b1fe">2. AI的發展沿革</a>
<ul>
<li><a href="#orge05a005">2.1. AI的兩種發展方向</a></li>
<li><a href="#org68a73e4">2.2. AI 發展大事紀</a></li>
</ul>
</li>
<li><a href="#org3b0b9c0">3. AI, Machine Learning與Deep Learning</a>
<ul>
<li><a href="#org0f95373">3.1. AI與早期專家系統的差異</a></li>
<li><a href="#orgb56b02d">3.2. AI</a></li>
<li><a href="#org74996ae">3.3. 機器學習</a></li>
<li><a href="#orgdab3968">3.4. 類神經網路與深度學習</a></li>
<li><a href="#org5b72ad9">3.5. 深度學習</a></li>
<li><a href="#org47e6cc6">3.6. Deep Learning 的概念於 2006 年提出，何以至 2012 年才得到有效應用？</a></li>
</ul>
</li>
<li><a href="#org16d8d80">4. AI 擅長的解題領域</a>
<ul>
<li><a href="#orgd257ae7">4.1. 與情境無關的領域</a></li>
<li><a href="#org4858530">4.2. 樣本數多的領域</a></li>
</ul>
</li>
<li><a href="#orga392344">5. AI 各項產業應用</a>
<ul>
<li><a href="#orge8c1ac7">5.1. 製造業</a></li>
<li><a href="#org77ce845">5.2. 零售與金融業</a></li>
<li><a href="#org839a573">5.3. 遊戲產業</a></li>
<li><a href="#org0a4e2f1">5.4. 政府機構</a></li>
<li><a href="#org018d292">5.5. 百貨零售業</a></li>
<li><a href="#org92ec7a3">5.6. Jetson</a></li>
</ul>
</li>
<li><a href="#orgb0de9dd">6. AI 的五大迷思</a>
<ul>
<li><a href="#org7dd9166">6.1. 迷思一：資料等於價值</a></li>
<li><a href="#org08c3e6b">6.2. 迷思二：牽涉電腦與資料就是 MIS 部門的工作</a></li>
<li><a href="#org8a79157">6.3. 迷思三：資料分析就是產出報表</a></li>
<li><a href="#orgc877ca7">6.4. 迷思四：電腦決策不可能贏過人的專業經驗</a></li>
<li><a href="#org6736959">6.5. 迷思五：導入系統或平台就可以解決營運問題</a></li>
</ul>
</li>
<li><a href="#orgb1ac2b7">7. 學習資源</a>
<ul>
<li><a href="#org4195561">7.1. Machine Learning [台大李宏毅]</a></li>
<li><a href="#org5a547ab">7.2. Deep Learning for Human Language Processing (DLHLP) 2020</a></li>
<li><a href="#orged06fb9">7.3. 其他線上資源</a></li>
</ul>
</li>
</ul>
</div>
</div>
<a href="https://letranger.github.io/AI/20221023101139-人工智慧.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023101139-人工智慧.html.svg"/></a>
<div id="outline-container-org3cbe83d" class="outline-2">
<h2 id="org3cbe83d"><span class="section-number-2">1.</span> 和AI聊聊天</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org9e204c5" class="outline-3">
<h3 id="org9e204c5"><span class="section-number-3">1.1.</span> ELIZA</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/ELIZA">What is ELIZA</a>: <a href="https://github.com/jeffshrager/elizagen.org/tree/master">Source Code</a></li>
<li><a href="https://web.njit.edu/~ronkowit/eliza.html">web-based version</a></li>
<li><a href="https://letranger.github.io/AI/eliza.html">中文版ELIZA體驗</a></li>
</ul>
</div>
</div>
<div id="outline-container-org35f8ee2" class="outline-3">
<h3 id="org35f8ee2"><span class="section-number-3">1.2.</span> ALICE</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Artificial_Linguistic_Internet_Computer_Entity">About ALICE</a></li>
<li><a href="http://www.mfellmann.net/content/alice.html">web-based version</a></li>
</ul>
</div>
</div>
<div id="outline-container-org0efe18e" class="outline-3">
<h3 id="org0efe18e"><span class="section-number-3">1.3.</span> Mitsuku</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Mitsuku">About Mitsuku</a></li>
<li><a href="https://chat.kuki.ai/">Try it(測試階段)</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgefa09b7" class="outline-3">
<h3 id="orgefa09b7"><span class="section-number-3">1.4.</span> ChatGPT</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li><a href="https://www.cw.com.tw/article/5124860">About ChatGPT</a></li>
<li><a href="https://chat.openai.com/">Try It</a></li>
</ul>
</div>
</div>
<div id="outline-container-org75d8034" class="outline-3">
<h3 id="org75d8034"><span class="section-number-3">1.5.</span> Bard</h3>
<div class="outline-text-3" id="text-1-5">
<ul class="org-ul">
<li><a href="https://www.playpcesor.com/2023/05/google-bard-ai-9.html">About Bard</a></li>
<li><a href="https://bard.google.com">Try It(不能用學校的Gmail)</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgae8b1fe" class="outline-2">
<h2 id="orgae8b1fe"><span class="section-number-2">2.</span> AI的發展沿革</h2>
<div class="outline-text-2" id="text-2">
<p>
不論是從 1942 年的<a href="https://zh.wikipedia.org/zh-tw/%E9%98%BF%E5%A1%94%E7%BA%B3%E7%B4%A2%E5%A4%AB-%E8%B4%9D%E7%91%9E%E8%AE%A1%E7%AE%97%E6%9C%BA">ABC</a>或是 1944 年的<a href="https://zh.wikipedia.org/wiki/%E9%A6%AC%E5%85%8B%E4%B8%80%E8%99%9F">MarK I</a>，電腦的發明都過去半個世紀了，為何到 2010 年後，人工智慧才成為熱門話題？
</p>
</div>
<div id="outline-container-orge05a005" class="outline-3">
<h3 id="orge05a005"><span class="section-number-3">2.1.</span> AI的兩種發展方向</h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-org5668a29" class="outline-4">
<h4 id="org5668a29"><span class="section-number-4">2.1.1.</span> 連結主義(connectionism)</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
一套AI系統應以大腦的基本架構為模型，利用大致像是生物神經元的深度連結元件，強調學習是智慧的核心能力，並認為如果可以讓機器有效的從數據中學習，那麼人腦所具備的其他能力最終也可能會在機器上出現。
</p>
</div>
</div>
<div id="outline-container-orgf5f638f" class="outline-4">
<h4 id="orgf5f638f"><span class="section-number-4">2.1.2.</span> 符號主義</h4>
<div class="outline-text-4" id="text-2-1-2">
<p>
採用符號的(symbolic)方式並強調邏輯與推理的應用，對於符號主義者來說，學習並不是那麼重要，智慧的關鍵在於推理、決策和行動來發揮知識的力量。符號主義者不設計可以自己學習的演算法，而是將資訊直接手動編碼到他們建構的系統中，這種作法催生了知識工程的領域。
</p>
</div>
</div>
</div>
<div id="outline-container-org68a73e4" class="outline-3">
<h3 id="org68a73e4"><span class="section-number-3">2.2.</span> AI 發展大事紀</h3>
<div class="outline-text-3" id="text-2-2">
</div>
<div id="outline-container-orga69816b" class="outline-4">
<h4 id="orga69816b"><span class="section-number-4">2.2.1.</span> 1943: 人工神經網路</h4>
<div class="outline-text-4" id="text-2-2-1">

<div id="org3c65a7c" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_13-06-06_2024-01-30_13-05-47.png" alt="2024-01-30_13-06-06_2024-01-30_13-05-47.png" width="500" />
</p>
<p><span class="figure-number">Figure 1: </span>Warren McCulloch and Aalter Pitts</p>
</div>

<p>
1943年 ，為了模擬人類腦神經元<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>的運作原理
</p>

<div id="orge467836" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_13-00-05_2024-01-30_12-59-41.png" alt="2024-01-30_13-00-05_2024-01-30_12-59-41.png" width="400" />
</p>
<p><span class="figure-number">Figure 2: </span>人腦神經元</p>
</div>

<p>
Warren McCulloch與Walter Pitts提出了人工神經網路(McCulloch-Pitts Neuron<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>)的想法，以如下的數學模型來模仿人類腦神經元接受刺激與生成反應的工作原理，這被視為深度學習的起點。。
</p>


<div id="org26f9b2e" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_12-58-21_2024-01-30_12-50-25.png" alt="2024-01-30_12-58-21_2024-01-30_12-50-25.png" width="400" />
</p>
<p><span class="figure-number">Figure 3: </span>McCulloch-Pitts Neuron</p>
</div>

<p>
康乃爾大學心理學教授Frank Rosenblatt在18年後將這些概念以純硬體方式實作出來。
</p>
</div>
</div>
<div id="outline-container-org5f351dc" class="outline-4">
<h4 id="org5f351dc"><span class="section-number-4">2.2.2.</span> 第一波(符號邏輯)：把人類的知識與思考放入電腦</h4>
<div class="outline-text-4" id="text-2-2-2">
</div>
<div id="outline-container-org703e01c" class="outline-5">
<h5 id="org703e01c"><span class="section-number-5">2.2.2.1.</span> 1950: Computing Machinery and Intelligence</h5>
<div class="outline-text-5" id="text-2-2-2-1">

<div id="orgb71ac67" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_12-22-33_2024-01-30_12-22-05.png" alt="2024-01-30_12-22-33_2024-01-30_12-22-05.png" width="500" />
</p>
<p><span class="figure-number">Figure 4: </span>Turing發表於Psychology and Philosophy季刊的Paper: Computing Machinery and Intelligence</p>
</div>

<p>
Turing在他從劍橋大學畢業兩年後(1936)提出通用圖靈機(universal Turing machine)的數學原理，成為所有真實世界的電腦藍圖。1950年Turing發表科學論文<a href="https://phil415.pbworks.com/f/TuringComputing.pdf">Computing Machinery and Intelligence</a>，提出「機器能否思考」的問題。在這篇文章結尾，Turing提及:
</p>
<blockquote>
<p>
We may hope that machines will eventually compete with men in all purely intellectual fields. But which are the best ones to start with? &#x2026; It can also be maintained that it is best to provide the machine with the best sense organs that money can buy, and then teach it to understand and speak English. This process could follow the normal teaching a child.
</p>
</blockquote>


<div id="orge851565" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_12-35-48_2024-01-30_12-34-55.png" alt="2024-01-30_12-35-48_2024-01-30_12-34-55.png" width="500" />
</p>
<p><span class="figure-number">Figure 5: </span>Turing on fifty pounds</p>
</div>

<p>
2021年英國央行格蘭銀行將Turing肖像印製於50英鎊紙幣上(之前為英國女王、James Watt、Matthew Boulton)
</p>


<div id="org4074f8e" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_12-36-31_2024-01-30_12-35-27.png" alt="2024-01-30_12-36-31_2024-01-30_12-35-27.png" width="500" />
</p>
<p><span class="figure-number">Figure 6: </span>2021年之前的50英磅紙幣</p>
</div>
</div>
</div>
<div id="outline-container-orgb49e956" class="outline-5">
<h5 id="orgb49e956"><span class="section-number-5">2.2.2.2.</span> 1956: 達特茅斯暑期會議</h5>
<div class="outline-text-5" id="text-2-2-2-2">
<p>
1956年夏天，新罕布夏州的達特茅斯學院(Dartmouth College)聚集一群學者，他們會面的目的就是希望集合最聰明的腦袋，找出方法，讓電腦很快能與人類一樣聰明。&#x2026;他們寫信向洛克斐勒基金會爭取經費，信中提到：
</p>

<blockquote>
<p>
「我們會努力找出，如何讓電腦懂得人類語言，擁有抽象思考能力、能進行決策，並能自我改良，以解決人類的各種問題。我們認為，只要謹慎挑選一群傑出科學家共同合作，大約一個夏天的時間，至少會有一個以上的問題將會獲得重大進展。」
</p>
</blockquote>


<div id="orgfbbdd71" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_20-15-35_2024-01-28_20-14-33.png" alt="2024-01-28_20-15-35_2024-01-28_20-14-33.png" width="500" />
</p>
<p><span class="figure-number">Figure 7: </span>一場引發AI誕生的聚會</p>
</div>


<div id="org7741313" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_20-21-25_2024-01-28_20-21-07.png" alt="2024-01-28_20-21-25_2024-01-28_20-21-07.png" width="500" />
</p>
</div>

<p>
參加這個會議的人全都大有來頭(Turing未參加，他於1954年自殺)，其中<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>:
</p>
</div>
<ol class="org-ol">
<li><a id="orgbb5bee2"></a>John McCarthy<br />
<div class="outline-text-6" id="text-2-2-2-2-1">

<div id="org7ab5a31" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_21-20-00_2024-01-28_21-19-33.png" alt="2024-01-28_21-20-00_2024-01-28_21-19-33.png" width="300" />
</p>
<p><span class="figure-number">Figure 9: </span>John McCarthy</p>
</div>
<ul class="org-ul">
<li>1958年發明<a href="https://zh.wikipedia.org/zh-tw/LISP">Lisp</a>語言</li>
<li>1959年提出<a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">Garbage collection</a>解決Lisp的記憶體管理問題</li>
<li>1962年建立幫助建立了史丹佛人工智慧實驗室、在麻省理工學院與Minsky共同創立了人工智慧研究室（MIT電腦科學與人工智慧實驗室的前身）</li>
<li>1971年獲圖靈奬。</li>
</ul>
<p>
以Lisp求5!
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp"><span style="color: #51afef;">(</span><span style="color: #51afef;">defun</span> <span style="color: #c678dd;">factorial</span> <span style="color: #c678dd;">(</span>n<span style="color: #c678dd;">)</span>
  <span style="color: #c678dd;">(</span><span style="color: #51afef;">if</span> <span style="color: #98be65;">(</span><span style="color: #a9a1e1;">=</span> n <span style="color: #da8548; font-weight: bold;">0</span><span style="color: #98be65;">)</span>
      <span style="color: #da8548; font-weight: bold;">1</span>
      <span style="color: #98be65;">(</span><span style="color: #a9a1e1;">*</span> n <span style="color: #a9a1e1;">(</span>factorial <span style="color: #51afef;">(</span><span style="color: #a9a1e1;">-</span> n <span style="color: #da8548; font-weight: bold;">1</span><span style="color: #51afef;">)</span><span style="color: #a9a1e1;">)</span><span style="color: #98be65;">)</span> <span style="color: #c678dd;">)</span> <span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span>factorial <span style="color: #da8548; font-weight: bold;">5</span><span style="color: #51afef;">)</span>
</pre>
</div>
</div>
</li>
<li><a id="orgeeb71a8"></a>Marvin Minsky<br />
<div class="outline-text-6" id="text-2-2-2-2-2">

<div id="org3e4e174" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_21-22-18_2024-01-28_21-22-09.png" alt="2024-01-28_21-22-18_2024-01-28_21-22-09.png" width="300" />
</p>
<p><span class="figure-number">Figure 10: </span>Marvin Minsky</p>
</div>
<ul class="org-ul">
<li><p>
1951年，建構了第一部能自我學習的類神經網路機器<a href="https://cyberneticzoo.com/mazesolvers/1951-maze-solver-minsky-edmonds-american/">SNARC</a>(能走迷宮<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup>)
</p>

<div id="org50304c8" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_12-46-11_2024-01-30_12-45-05.png" alt="2024-01-30_12-46-11_2024-01-30_12-45-05.png" width="500" />
</p>
<p><span class="figure-number">Figure 11: </span>SNARC (Stochastic Neural Analog Reinforcement Computer)</p>
</div></li>

<li>1966年與<a href="https://zh.wikipedia.org/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9">Seymour Papert</a>發明兒童用語言<a href="https://zh.wikipedia.org/wiki/Logo_(%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80)">Logo</a></li>
<li>1969年獲圖靈奬</li>
</ul>
</div>
</li>
<li><a id="org1333bb2"></a>Claude Shannon<br />
<div class="outline-text-6" id="text-2-2-2-2-3">

<div id="orgcc456f9" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_21-23-40_2024-01-28_21-23-31.png" alt="2024-01-28_21-23-40_2024-01-28_21-23-31.png" width="300" />
</p>
<p><span class="figure-number">Figure 12: </span>Claude Shannon</p>
</div>
<ul class="org-ul">
<li>1948年發表了劃時代的論文《<a href="https://cdn.l7audiolab.com/wp-content/uploads/2022/06/%E9%80%9A%E4%BF%A1%E7%9A%84%E6%95%B0%E5%AD%A6%E7%90%86%E8%AE%BA.pdf">通訊的數學理論</a>》，奠定了現代資訊理論的基礎</li>
<li>提出以bit做為衡量資訊量的單位</li>
<li>提出以entropy(熵)來量化資訊的不確定性</li>
<li>1972年IEEE設立有「Claude E. Shannon Award」(資訊理論研究的諾貝爾獎」之稱的「向農獎」、本人則是第一位獲獎人<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup>。</li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-org83f0958" class="outline-5">
<h5 id="org83f0958"><span class="section-number-5">2.2.2.3.</span> 1957 年</h5>
<div class="outline-text-5" id="text-2-2-2-3">
<p>
Herbert A. Somin(諾貝爾經濟學奬得主)預言電腦能在十年內敗人類(西洋棋)，此預言於 1997由<a href="https://zh.wikipedia.org/zh-tw/%E6%B7%B1%E8%97%8D_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)">IBM Deep Blue</a>實現。
</p>
</div>
</div>
<div id="outline-container-orge0acbd1" class="outline-5">
<h5 id="orge0acbd1"><span class="section-number-5">2.2.2.4.</span> 1958年: Perceptron</h5>
<div class="outline-text-5" id="text-2-2-2-4">
<p>
感知器（perceptron）是弗蘭克·羅森布拉特在1957年就職於康奈爾航空實驗室（Cornell Aeronautical Laboratory）時所發明的一種硬體式人工神經網路(如圖<a href="#org1fa5b4e">13</a><sup><a id="fnr.6" class="footref" href="#fn.6" role="doc-backlink">6</a></sup>)，這也是日後類神經網路的重要基礎。
</p>


<div id="org1fa5b4e" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_17-19-05_2024-01-28_17-17-29.png" alt="2024-01-28_17-19-05_2024-01-28_17-17-29.png" width="500" />
</p>
<p><span class="figure-number">Figure 13: </span>Mark I Perceptron全貌</p>
</div>


<div id="org85c2185" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_17-21-04_2024-01-28_17-17-08.png" alt="2024-01-28_17-21-04_2024-01-28_17-17-08.png" width="500" />
</p>
<p><span class="figure-number">Figure 14: </span>Mark I Perceptron架構</p>
</div>


<div id="orgfd11cc2" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_17-23-37_2024-01-28_17-14-35.png" alt="2024-01-28_17-23-37_2024-01-28_17-14-35.png" width="500" />
</p>
<p><span class="figure-number">Figure 15: </span>Mark I Perceotron內部結構-1</p>
</div>


<div id="orgaabe64e" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_17-49-17_2024-01-28_17-48-49.png" alt="2024-01-28_17-49-17_2024-01-28_17-48-49.png" width="500" />
</p>
<p><span class="figure-number">Figure 16: </span>Mark I Perceotron內部結構-2</p>
</div>

<p>
羅森布拉特設計的 Mark I Perceptron 旨在模擬大腦的圖像識別能力，以 400 個光感測元件做為輸入來模擬視網膜(如圖<a href="#org85c2185">14</a><sup><a id="fnr.7" class="footref" href="#fn.7" role="doc-backlink">7</a></sup>)，用 512 台電動機模擬神經細胞處理輸入訊號的功能(如圖<a href="#orgfd11cc2">15</a><sup><a id="fnr.8" class="footref" href="#fn.8" role="doc-backlink">8</a></sup>)，最後輸出 8 個訊號表示看到的物品(如圖<a href="#orgaabe64e">16</a><sup><a id="fnr.9" class="footref" href="#fn.9" role="doc-backlink">9</a></sup>)。
</p>

<p>
以現在的眼光來看，這就是個簡單的線性轉換過程，然而，思考一下這些事件：
</p>
<ul class="org-ul">
<li>1956年AI這個名詞才剛被提出</li>
<li>1956年全世界第一套作業系統GM-NAA I/O問世、運作在IBM 704大型電腦上</li>
<li>如今用來開發AI最常用的Python到1991年才問世</li>
<li>支援的相關函式庫如Numpy於2005年開發</li>
<li>Tensorflow、Keras於2015年開發</li>
</ul>
<p>
換句話說，Rosenblatt是在沒有軟體支援的情境下以線路硬把AI的功能在那個年代實作出來，裡面的線路看起來就像圖<a href="#org5e34360">17</a>那樣複雜&#x2026;.
</p>


<div id="org5e34360" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_17-24-17_2024-01-28_17-24-09.png" alt="2024-01-28_17-24-17_2024-01-28_17-24-09.png" width="500" />
</p>
<p><span class="figure-number">Figure 17: </span>Perceptron內部線路</p>
</div>
</div>
</div>
<div id="outline-container-org2fa8c58" class="outline-5">
<h5 id="org2fa8c58"><span class="section-number-5">2.2.2.5.</span> 1966: 史丹佛研究所成立Artificial Intellgience center</h5>
<div class="outline-text-5" id="text-2-2-2-5">
<p>
該中心在語言翻譯與語音識別等領域有開創性的成果，並創立了第一個能與環境互動的自主機器人。五十年後該中心分拆出一家新創公司，擁有名為 <b>Siri</b> 的新型個人助理，於2010被Apple收購。
</p>
</div>
</div>
<div id="outline-container-orgd7f5f2b" class="outline-5">
<h5 id="orgd7f5f2b"><span class="section-number-5">2.2.2.6.</span> 1970: Minsky的預測</h5>
<div class="outline-text-5" id="text-2-2-2-6">
<p>
1970年,Minsky接受LIFE雜誌訪問時預測：在3~8年，我們將擁有一台具有和普通人一樣智慧的機器，能閱讀莎士比亞、幫車上潤滑油、玩辦公室政治、講笑話與打架的機器。屆時，機器將開始以驚人的速速進行自我教育、過幾個月後，它就會達到天才的程度，然後再過幾個月，它的力量將無法估量。
</p>
</div>
</div>
<div id="outline-container-org3b35f46" class="outline-5">
<h5 id="org3b35f46"><span class="section-number-5">2.2.2.7.</span> 1974: 幻滅</h5>
<div class="outline-text-5" id="text-2-2-2-7">
<p>
數十年的努力後，人們發現連要打造出基本的AI系統都比預期困難，於是這股熱潮開始退燒，投資者的幻想也開始破滅，許多該領域的研究人員職涯前景也蒙上一層陰影，AI發展進入AI winters時期。
</p>
</div>
</div>
<div id="outline-container-orgaba518f" class="outline-5">
<h5 id="orgaba518f"><span class="section-number-5">2.2.2.8.</span> 這階段的失敗原因</h5>
<div class="outline-text-5" id="text-2-2-2-8">
<ul class="org-ul">
<li>對於AI預計要解決的問題真正難度缺乏理解</li>
<li>連人類自己都還搞不清楚自己的思考過程</li>
<li>1990年代之前的電腦速度都過於緩慢</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd9d9fd8" class="outline-4">
<h4 id="orgd9d9fd8"><span class="section-number-4">2.2.3.</span> 第二波(專家系統)：讓電腦按照人類定義的規則做決策</h4>
<div class="outline-text-4" id="text-2-2-3">
</div>
<div id="outline-container-org8a60f48" class="outline-5">
<h5 id="org8a60f48"><span class="section-number-5">2.2.3.1.</span> 1970 年，專家系統</h5>
<div class="outline-text-5" id="text-2-2-3-1">
<p>
利用知識管理(一連串條件判斷)的概念，具有人類專家決策能力的電腦系統。專家系統是一種「知識庫系統」：「這是一種以應用人類專業知識的象徵表達而非演算法或數據法去解決問題的系統。換言之，所謂「知識庫系統」試圖轉譯特定領域人類專家的專業知識，而非使用源自電腦科學或數學，相比之下較複雜且鬆散的方法去解決問題。<sup><a id="fnr.10" class="footref" href="#fn.10" role="doc-backlink">10</a></sup>」
</p>

<div id="org9e7b80a" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_15-01-54_2024-01-30_15-00-39.png" alt="2024-01-30_15-01-54_2024-01-30_15-00-39.png" width="500" />
</p>
<p><span class="figure-number">Figure 18: </span>專家系統</p>
</div>

<ul class="org-ul">
<li>第一波失敗原因：野心太大，這次讓電腦依照人類設定好的規則來思考</li>
<li>expert system 在 1980 年代廣受應用，Fortune 500 大公司有三分之二將之應用於營運工作中，如訂單處理、信用卡徵審、稅務處理。</li>
<li>臨床決策支援系統 (Clinical Decision Support System): 主要目的是醫師在進行診斷、治療方式等醫學相關決策時，由「資訊系統」分析病人個人之臨床資訊，給予相關的決策建議，再由醫師或相關人員進行最後的決斷。而這些決策建議的來源，可能是已被認可多年的診斷方式與臨床治療指引；或是經由醫師、醫療團隊多年經驗的累積以及臨床實驗所分析、統計而得之結果；也可能是歷年所累積的大量病患資料庫中，經由資料探勘、分析等技術，所發現的資訊與知識。
舉一最常見的實例，例如各位醫師在電腦開立A藥物後，資訊系統跳出警示畫面，提醒醫師A藥物與B藥物可能發生交互作用，請醫師確認是否開立A藥<sup><a id="fnr.11" class="footref" href="#fn.11" role="doc-backlink">11</a></sup>。</li>
<li><a href="https://ccckmit.github.io/aibook/htm/logicExpertQuery.html">實作：專家系統 - 互動推論程式</a></li>
<li><a href="https://ir.nctu.edu.tw/bitstream/11536/137353/1/yaucenter-20161015-13.pdf">演算法之父訪問專家系統之父</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgcea3e11" class="outline-5">
<h5 id="orgcea3e11"><span class="section-number-5">2.2.3.2.</span> 1986年: backpropagation</h5>
<div class="outline-text-5" id="text-2-2-3-2">

<div id="orgcce3753" class="figure">
<p><img src="images/AI的發展沿革/2024-01-29_14-14-15_2024-01-29_14-13-47.png" alt="2024-01-29_14-14-15_2024-01-29_14-13-47.png" width="300" />
</p>
<p><span class="figure-number">Figure 19: </span>David Rumelhart</p>
</div>

<p>
加大聖地牙哥分校心理學教授<a href="https://en.wikipedia.org/wiki/David_Rumelhart">David Rumelhart</a><sup><a id="fnr.12" class="footref" href="#fn.12" role="doc-backlink">12</a></sup>於1986年發表的文章<a href="https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf">Learning representations by back-propagating errors</a>中提出<a href="https://medium.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7-%E5%80%92%E5%BA%95%E6%9C%89%E5%A4%9A%E6%99%BA%E6%85%A7/%E5%8F%8D%E5%90%91%E5%82%B3%E6%92%AD%E7%AE%97%E6%B3%95-backpropagation-algorithm-71a1845100cf">backpropagation</a>的概念，為當今多層神網網路的主要學習演算法。1986年，Ronald Williams與卡內基美隆大學的Hinton共同在Nature描述了該演算法如何應用於深度學習中。Hinton於1981年在加大當博士後研究員時曾與Rumelhart一起工作。
</p>
</div>
</div>
<div id="outline-container-org111f1c2" class="outline-5">
<h5 id="org111f1c2"><span class="section-number-5">2.2.3.3.</span> 1980年末期: 手寫數字辨識</h5>
<div class="outline-text-5" id="text-2-2-3-3">

<div id="org52b4c4d" class="figure">
<p><img src="images/AI的發展沿革/2024-01-29_14-26-12_2024-01-29_14-21-23.png" alt="2024-01-29_14-26-12_2024-01-29_14-21-23.png" width="300" />
</p>
<p><span class="figure-number">Figure 20: </span>Yann LeCun</p>
</div>

<p>
神經網路的實際應用開始出現，法國計算機科學家、AT&amp;T貝爾實驗室研究員<a href="https://zh.wikipedia.org/zh-tw/%E6%9D%A8%E7%AB%8B%E6%98%86">Yann Le Cun</a><sup><a id="fnr.13" class="footref" href="#fn.13" role="doc-backlink">13</a></sup>在CNN的新架構中使用了backpropagation，該套系統可辨識手寫數字，LeCun為2018年圖靈獎得主。
</p>
</div>
</div>
<div id="outline-container-org1876431" class="outline-5">
<h5 id="org1876431"><span class="section-number-5">2.2.3.4.</span> 1990 年後 expoert system 逐漸勢微</h5>
<div class="outline-text-5" id="text-2-2-3-4">
<ul class="org-ul">
<li>原因是此時的人工智慧能力有限，距離人類心目中的人工智慧差距尚大。</li>
<li>Polanyi&rsquo;s Paradox(博藍尼悖論): We can know more than we can tell, i.e., many of the tasks we perform rely on tacit, intuitive knowledge that is diffucult to codify and automate.</li>
</ul>
</div>
</div>
<div id="outline-container-org0a8ebaa" class="outline-5">
<h5 id="org0a8ebaa"><span class="section-number-5">2.2.3.5.</span> 1997年: LSTM</h5>
<div class="outline-text-5" id="text-2-2-3-5">

<div id="org3ece572" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_15-56-33_2024-01-30_15-55-58.png" alt="2024-01-30_15-56-33_2024-01-30_15-55-58.png" width="300" />
</p>
<p><span class="figure-number">Figure 21: </span>Jürgen Schmidhuber</p>
</div>


<div id="orge5bd595" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_15-52-20_2024-01-30_15-51-47.png" alt="2024-01-30_15-52-20_2024-01-30_15-51-47.png" width="500" />
</p>
<p><span class="figure-number">Figure 22: </span>LSTM Cell</p>
</div>

<p>
瑞士達勒・莫爾AI研究所(IDSIA)的負責人之一Jürgen Schmidhuber與他的學生開發LSTM。
</p>
</div>
</div>
<div id="outline-container-orgfd193a1" class="outline-5">
<h5 id="orgfd193a1"><span class="section-number-5">2.2.3.6.</span> 1990年代後期</h5>
<div class="outline-text-5" id="text-2-2-3-6">
<p>
速度更快的電腦硬體開始出現
</p>
</div>
</div>
<div id="outline-container-orgd7e2d55" class="outline-5">
<h5 id="orgd7e2d55"><span class="section-number-5">2.2.3.7.</span> 1986年: Hinton</h5>
<div class="outline-text-5" id="text-2-2-3-7">

<div id="org20ef292" class="figure">
<p><img src="images/AI的發展沿革/2024-01-29_14-39-36_2024-01-29_14-34-39.png" alt="2024-01-29_14-39-36_2024-01-29_14-34-39.png" width="300" />
</p>
<p><span class="figure-number">Figure 23: </span>Geoffrey Hinton</p>
</div>

<p>
Hinton 與他的兩位夥伴──David Rumelhart 及 Ronald J. Williams──提出利用反向傳播演算法（backpropagation algorithm）來訓練神經網路
</p>
</div>
</div>
<div id="outline-container-org07ec6c1" class="outline-5">
<h5 id="org07ec6c1"><span class="section-number-5">2.2.3.8.</span> 1997: Deep Blue</h5>
<div class="outline-text-5" id="text-2-2-3-8">

<div id="orgeb07629" class="figure">
<p><img src="images/AI的發展沿革/2024-01-29_14-20-21_2024-01-29_14-20-04.png" alt="2024-01-29_14-20-21_2024-01-29_14-20-04.png" width="500" />
</p>
<p><span class="figure-number">Figure 24: </span>IBM Deep Blue v.s. Kasparov</p>
</div>

<p>
1997年5月,IBM的Deep Blue險朥西洋棋冠軍Garry Kasparov
</p>
</div>
</div>
</div>
<div id="outline-container-orgb2e606d" class="outline-4">
<h4 id="orgb2e606d"><span class="section-number-4">2.2.4.</span> 第三波(<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>)：讓電腦從資料中歸納規則，關鍵要素為資料與演算法</h4>
<div class="outline-text-4" id="text-2-2-4">
</div>
<div id="outline-container-orge23c0ce" class="outline-5">
<h5 id="orge23c0ce"><span class="section-number-5">2.2.4.1.</span> 2006 年：Boltzman Machine</h5>
<div class="outline-text-5" id="text-2-2-4-1">

<div id="orgd69b6e8" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_16-05-48_2024-01-30_16-05-13.png" alt="2024-01-30_16-05-48_2024-01-30_16-05-13.png" width="300" />
</p>
<p><span class="figure-number">Figure 25: </span>Diagram of Boltzman Machine</p>
</div>

<p>
Geofffrey Hinton <sup><a id="fnr.14" class="footref" href="#fn.14" role="doc-backlink">14</a></sup>提出 Restricted Boltzmann Machine<sup><a id="fnr.15" class="footref" href="#fn.15" role="doc-backlink">15</a></sup>，成功訓練多層神經網路(multi-layer neural networks)，可用來描述更複雜的非線性函數，並稱之為深度學習(Deep Learning)，Hinton被譽為「深度學習之父」，於2018年獲圖靈獎。
</p>
</div>
</div>
<div id="outline-container-orgb8c1b71" class="outline-5">
<h5 id="orgb8c1b71"><span class="section-number-5">2.2.4.2.</span> 2009: 大數據ImageNet</h5>
<div class="outline-text-5" id="text-2-2-4-2">

<div id="org57fd53a" class="figure">
<p><img src="images/AI的發展沿革/2024-01-30_16-10-21_2024-01-30_16-10-06.png" alt="2024-01-30_16-10-21_2024-01-30_16-10-06.png" width="500" />
</p>
<p><span class="figure-number">Figure 26: </span>ImageNet</p>
</div>

<p>
普林斯頓大學<a href="https://zh.wikipedia.org/wiki/%E6%9D%8E%E9%A3%9B%E9%A3%9B">李飛飛</a>意識到要教育機器對現實世界進行視覺感知就需要全面性的教學資源，其中包含正確標記的範例，包括人、動物、建築物、車輛、物體的許多變化形態。她在兩年半的時間，透過外包平台(Mechanical Turk)為5000多個類別中超過300萬張圖片下標題。最後她打造的<a href="https://paperswithcode.com/dataset/imagenet">ImageNet</a><sup><a id="fnr.16" class="footref" href="#fn.16" role="doc-backlink">16</a></sup>發表，很快成為機器視覺研究不可或缺的資源<sup><a id="fnr.17" class="footref" href="#fn.17" role="doc-backlink">17</a></sup>。
</p>
</div>
</div>
<div id="outline-container-org7602765" class="outline-5">
<h5 id="org7602765"><span class="section-number-5">2.2.4.3.</span> 2011: Watson</h5>
<div class="outline-text-5" id="text-2-2-4-3">

<div id="orgc5b3d68" class="figure">
<p><img src="images/AI的發展沿革/2024-01-28_21-40-59_2024-01-28_21-40-35.png" alt="2024-01-28_21-40-59_2024-01-28_21-40-35.png" width="500" />
</p>
<p><span class="figure-number">Figure 27: </span>IBM Watson</p>
</div>

<p>
IBM <a href="https://zh.wikipedia.org/zh-tw/%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A8%8B%E5%BA%8F)">Waton</a>於益智問答節目<a href="https://zh.wikipedia.org/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98">危險邊緣</a>取得冠軍，以一堆來自維基百科的文章為主要數據，運用智慧演算法來同時處理這些數據。Watson預告了一個新時代的到來，預示機器最終將開始解析語言並與人類互動<sup><a id="fnr.18" class="footref" href="#fn.18" role="doc-backlink">18</a></sup>。
</p>
</div>
</div>
<div id="outline-container-orge7bb7fc" class="outline-5">
<h5 id="orge7bb7fc"><span class="section-number-5">2.2.4.4.</span> 2012 年 10 月</h5>
<div class="outline-text-5" id="text-2-2-4-4">
<ul class="org-ul">
<li>ILSVRC(ImageNet Large Scale Visual Recongnition Challenge): 先讓程式看 120 萬張訓練照片，共 1000 種分類，接下來要求程式為 15 萬張測試照片進行分類。</li>
<li>Hinton 帶兩個學生參加 <a href="https://image-net.org/challenges/LSVRC/">ILSVRC</a> 比賽，以深度學習配合 GPU 的運算速度拿下冠軍。</li>
</ul>
</div>
</div>
<div id="outline-container-org8a44ac5" class="outline-5">
<h5 id="org8a44ac5"><span class="section-number-5">2.2.4.5.</span> 2013 年</h5>
<div class="outline-text-5" id="text-2-2-4-5">
<p>
Google 收購 Hinton 和他兩位學生創立的公司：DNNresearch
</p>
</div>
</div>
<div id="outline-container-org57beee1" class="outline-5">
<h5 id="org57beee1"><span class="section-number-5">2.2.4.6.</span> 2015 年</h5>
<div class="outline-text-5" id="text-2-2-4-6">
<p>
Microsoft 在 ILSVRC 以 3.5%的錯誤率奪冠，首次超過人類(5%)。
</p>
</div>
</div>
<div id="outline-container-orgc770e4d" class="outline-5">
<h5 id="orgc770e4d"><span class="section-number-5">2.2.4.7.</span> 2016: Scale AI</h5>
<div class="outline-text-5" id="text-2-2-4-7">
<p>
2016年成立的<a href="https://www.gvm.com.tw/article/104424">Scale AI</a>由MIT輟學生Alexandr Wang於2016年創立，與超過3萬名群眾外包工作者簽約，為Uber、Lyft、Airbnb和Waymo等客戶標記數據，該公司已獲得超過1億美元的風險投資，現被列為矽谷的獨角獸(估值超過10億美元的新創公司)。
</p>
</div>
</div>
<div id="outline-container-org7a677c7" class="outline-5">
<h5 id="org7a677c7"><span class="section-number-5">2.2.4.8.</span> 2016 AlphaGo</h5>
<div class="outline-text-5" id="text-2-2-4-8">

<div id="orgefd9ec0" class="figure">
<p><img src="images/AI的發展沿革/2024-01-29_15-38-25_2024-01-29_15-38-17.png" alt="2024-01-29_15-38-25_2024-01-29_15-38-17.png" width="500" />
</p>
<p><span class="figure-number">Figure 28: </span>AlphaGo v.s. 李世乭</p>
</div>

<p>
AlphaGo的研究計劃於2014年啟動，2016年3月，透過自我對弈數以萬計盤進行練習強化，AlphaGo在一場五番棋比賽中4:1擊敗頂尖職業棋士李世乭，成為第一個不藉助讓子而擊敗圍棋職業九段棋士的電腦圍棋程式，立下了里程碑<sup><a id="fnr.19" class="footref" href="#fn.19" role="doc-backlink">19</a></sup>。
</p>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org3b0b9c0" class="outline-2">
<h2 id="org3b0b9c0"><span class="section-number-2">3.</span> AI, Machine Learning與Deep Learning</h2>
<div class="outline-text-2" id="text-3">

<div id="org2262ee0" class="figure">
<p><img src="images/AI,_Machine_Learning與Deep_Learning/2024-02-19_16-24-48_2024-02-19_16-23-09.png" alt="2024-02-19_16-24-48_2024-02-19_16-23-09.png" width="500" />
</p>
<p><span class="figure-number">Figure 29: </span>AI, Machine Learning與Deep Learning</p>
</div>

<p>
人工智慧、<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>與<a href="20221023101228-深度學習.html#ID-20221023T101228.247381">深度學習</a>是三個常被混為一談的概念，如圖<a href="#orgd1ac245">30</a>，深度學習是機器學習的一種類型，而機器學習又是人工智慧的一個分支，相較於機器學習，早期實作人工智慧的一種策略是專家系統(Expert System)。
</p>

<div id="orgd1ac245" class="figure">
<p><img src="images/AMD.png" alt="AMD.png" width="500" />
</p>
<p><span class="figure-number">Figure 30: </span>AI, Machine, Deep Learning</p>
</div>
</div>
<div id="outline-container-org0f95373" class="outline-3">
<h3 id="org0f95373"><span class="section-number-3">3.1.</span> AI與早期專家系統的差異</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>專家系統:由人訂規則，告訴電腦判別的方法：狗鼻子較長、耳朵較大&#x2026;</li>
<li><a href="MachineLearning.html">機器學習</a>:給電腦大量標註貓狗的照片，由機器學習演算法自行歸納辨別二者的方法。</li>
</ul>
</div>
</div>
<div id="outline-container-orgb56b02d" class="outline-3">
<h3 id="orgb56b02d"><span class="section-number-3">3.2.</span> AI</h3>
<div class="outline-text-3" id="text-3-2">
<p>
AI是一個涵蓋面極廣的名詞，從1964年<a href="https://en.wikipedia.org/wiki/MIT_Computer_Science_and_Artificial_Intelligence_Laboratory">MIT AI Lab</a>的<a href="https://web.njit.edu/~ronkowit/eliza.html">ELIZA</a>對話機器人，到最近的自駕車，再到科幻電影中俱備人類情感的機器人都可以是AI的範圍。在實作上，AI 可以是簡單的 decision tree 或 rule-based 的專家系統(知識庫 + 推理機制)，也可以是包含數十億神經元的類神經網路。那麼，這和我們常聽到的機器學習、深度學習、神經網絡又有什麼關係呢？
</p>
</div>
</div>
<div id="outline-container-org74996ae" class="outline-3">
<h3 id="org74996ae"><span class="section-number-3">3.3.</span> 機器學習</h3>
<div class="outline-text-3" id="text-3-3">
<p>
在AI的發展中，人們想過以各種方式來達成讓機器具備人類智慧的目的，有人希望能將大量的人類智慧教給電腦，這部份包含了人類在各領域的知識以及推理規則；另一派學者則認為人類的智識大過於廣泛而且不斷的有新知識生成，與其把所有的知識教給電腦，不如讓電腦具備學習的能力，如此電腦就可以自己去學習新的知識，這便是所謂的機器學習。
</p>

<p>
在開發機器學習模型時，我們會基於觀測值計算出一些衍生變數(derived variables)，再將其加入決策判斷的條件中，以增加 model 的預測準確度。例如，由男生的身高體重判斷高血壓的機率，而 BMI 即為一更佳的衍生變數。而<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>模型的成效往往取決於特徵工程的品質，但在某些領域下，特徵工程很難靠領域專家取得好的結果，例如非結構化資料以及序列資料：
</p>
<ul class="org-ul">
<li>非結構化資料：聲音、影像、影片</li>
<li>序列資料：sensor 資料、金融市場資料、交易資料</li>
</ul>
</div>
<div id="outline-container-orgdd0508d" class="outline-4">
<h4 id="orgdd0508d"><span class="section-number-4">3.3.1.</span> 分類</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
人類是透過觀察學習，機器學習是以程式實作出模型(model)後，將許多資料及 相對應的答案(標籤)餵給模型進行訓練。根據訓練資料與學習類型的差異，機器學習 可大致分為以下四類
</p>


<div id="org810f87d" class="figure">
<p><img src="images/AI,_Machine_Learning與Deep_Learning/2024-01-30_16-36-58_2024-01-30_16-35-22.png" alt="2024-01-30_16-36-58_2024-01-30_16-35-22.png" width="500" />
</p>
<p><span class="figure-number">Figure 31: </span>機器學習的幾種類型</p>
</div>
</div>
<div id="outline-container-orgaf09151" class="outline-5">
<h5 id="orgaf09151"><span class="section-number-5">3.3.1.1.</span> 監督式學習 (supervised learning)</h5>
<div class="outline-text-5" id="text-3-3-1-1">
<p>
監督式學習用來訓練模型的資料包含各種資料特徵(feature)以及資料相對應的標 籤(label)。以銀行對申請貸款客戶進行信用評估為例:銀行現有貸款用戶的薪資、刷 卡行為與信用卡繳費記錄就是資料特徵，而銀行放款單位對這些用戶所做的信用評等則 為標籤。
</p>
</div>
</div>
<div id="outline-container-org410aeaf" class="outline-5">
<h5 id="org410aeaf"><span class="section-number-5">3.3.1.2.</span> 非監督式學習 (unsupervised learning)</h5>
<div class="outline-text-5" id="text-3-3-1-2">
<p>
不同於監督式學習，非監督式學習不需要資料的標籤，純粹讓模型透過機器學習演 算法從眾多的訓練資料中找出潛在規則。同上例，銀行無需準備放款單位對舊用戶的信 用評等記錄(標籤)，只需把所有用戶資料特徵(薪資、刷卡行為與信用卡繳費記錄) 當成訓練資料丟給模型分析，由模型根據資料特徵的統計分佈和相似性歸納出規則，將 這些用戶區分成不同的類別。
</p>
</div>
</div>
<div id="outline-container-orgd6c410b" class="outline-5">
<h5 id="orgd6c410b"><span class="section-number-5">3.3.1.3.</span> 半監督式學習 (semi-supervised learning)</h5>
<div class="outline-text-5" id="text-3-3-1-3">
<p>
為資料進行標註標籤是一項耗費人力的工作，例如銀行放款單位要為上萬名貸款客 戶進行信用評等(這也是為何銀行想將此項工作交由電腦執行)。若想要採取監督式學 習但又缺乏人力為資料標註標籤，此時不妨考慮半監督式學習。半監督式學習只提供部 份訓練資料的標籤，讓模型針對有標籤的資料進行訓練、分析出規則，再對其他沒有標 籤的資料進行預測。
</p>

<p>
早期 Gmail 的垃圾信件分類功能是讓使用者先去標記某些信為垃圾郵件，然後藉由 這些被標記的郵件來推論找出其他可能的垃圾郵件。表面上是 Gmail 提供使用者為信件 加註「垃圾」、「廣告」的功能、免去垃圾郵件的困擾;實際上使用者也在不知不覺中 為 Google 進行信件加註標籤的工作，然後 Gmail 就能根據這些信件與其標籤學習到判 斷規則、對新郵件進行預測。當更多人為信件進行標註，Google 用來預測垃圾郵件的模 型也就越精確。
</p>
</div>
</div>
<div id="outline-container-org0685214" class="outline-5">
<h5 id="org0685214"><span class="section-number-5">3.3.1.4.</span> 強化學習 (reinforcement learning)</h5>
<div class="outline-text-5" id="text-3-3-1-4">
<p>
上述三種類型的機器學習均是從資料中歸納出分析方法再建構預測模型，而強化學 習的模型以「代理人(agent)」的形式存在，由代理人與其所處的動態環境不斷互動， 以此來學習正確執行某項任務。代理人每次採取行動，環境都會做出回應(勵或懲罰)， 代理人再依據回應修正行為做出動作(如圖<a href="#org810f87d">31</a>)，如此不斷重複。藉由這種嘗試錯 誤(trial-and-error)的學習法，模型就可以朝著最終目標前進。著名的 AlphaGo 就是 強化學習的代表。
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgdab3968" class="outline-3">
<h3 id="orgdab3968"><span class="section-number-3">3.4.</span> 類神經網路與深度學習</h3>
<div class="outline-text-3" id="text-3-4">
<p>
如何讓電腦俱備學習能力？在實作上也有多不同策略，類神經網路就是希望藉由模擬人類腦神經結構的方式來達到這個目的的一種方式，Hinton 於 2006 年提出的 Boltzmann Machine 為一種多層神經網路。典型的類神經網路架構(如圖<a href="#orge9074f7">32</a>)由輸入層、隱藏層、輸出層組成，學術界稱層數大於3的類神經網路為深度學習。
</p>

<div id="orge9074f7" class="figure">
<p><img src="images/ANN-640x314.jpeg" alt="ANN-640x314.jpeg" width="500" />
</p>
<p><span class="figure-number">Figure 32: </span>類神經網路架構</p>
</div>

<p>
所以，當你聽到<a href="20221023101228-深度學習.html#ID-20221023T101228.247381">深度學習</a>這個名詞時，有兩件事是可以確定的：
</p>
<ol class="org-ol">
<li>這一定是機器學習</li>
<li>這一定是類神經網路</li>
</ol>

<p>
前面提到 <b>在某些領域下，特徵工程很難靠領域專家取得好的結果</b> ，<a href="20221023101228-深度學習.html#ID-20221023T101228.247381">深度學習</a>的強大之處就在於深度學習連特徵工程也可以自行完成，即，由原始資中自行產生衍生變數。
</p>
</div>
</div>
<div id="outline-container-org5b72ad9" class="outline-3">
<h3 id="org5b72ad9"><span class="section-number-3">3.5.</span> 深度學習</h3>
<div class="outline-text-3" id="text-3-5">
<p class="verse">
深度學習與其他機器學習方式最主要的差異在於能否自動進行「特徵工程」(feature engineering)<br />
</p>

<p>
考慮採取傳統機器學習或深度學習時，一個重要關鍵是資料量，若資料量太小，深度學習不一定會有更好的表現。Google Translate 在訓練文件量少於一億篇時，傳統機器學習表現較佳；在文件量超過十億後，深度學習效果就超越傳統機器學習。
</p>

<div id="org0044cc9" class="figure">
<p><img src="images/BLEU.png" alt="BLEU.png" width="500" />
</p>
<p><span class="figure-number">Figure 33: </span>BLEU scores for English-Spanish systems trained on 0.4M to 385.7M words of parallel data. Source: Koehn and Knowles (2017) and GPU</p>
</div>
</div>
</div>
<div id="outline-container-org47e6cc6" class="outline-3">
<h3 id="org47e6cc6"><span class="section-number-3">3.6.</span> Deep Learning 的概念於 2006 年提出，何以至 2012 年才得到有效應用？</h3>
<div class="outline-text-3" id="text-3-6">
</div>
<div id="outline-container-orge8c21dd" class="outline-4">
<h4 id="orge8c21dd"><span class="section-number-4">3.6.1.</span> 計算速度: GPU 的計算能力由 2018 年起才有突破性的成長<sup><a id="fnr.20" class="footref" href="#fn.20" role="doc-backlink">20</a></sup></h4>
<div class="outline-text-4" id="text-3-6-1">

<div id="orgd5a417b" class="figure">
<p><img src="images/GPUCPU1.jpg" alt="GPUCPU1.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 34: </span>Floating-point operations per second (FLOPS) for the CPU and GPU</p>
</div>

<div id="org893d40e" class="figure">
<p><img src="images/GPUCPU2.jpg" alt="GPUCPU2.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 35: </span>Memory bandwidth for the CPU and GPU</p>
</div>
</div>
</div>
<div id="outline-container-org8519eac" class="outline-4">
<h4 id="org8519eac"><span class="section-number-4">3.6.2.</span> 大量數據</h4>
<div class="outline-text-4" id="text-3-6-2">
<p>
早期缺乏可供AI訓練用的龐大資料
</p>
</div>
</div>
<div id="outline-container-org6ad7f1b" class="outline-4">
<h4 id="org6ad7f1b"><span class="section-number-4">3.6.3.</span> 軟體</h4>
<div class="outline-text-4" id="text-3-6-3">
<p>
相關數學模型、軟體工具(Tensorflow)問世較晚
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org16d8d80" class="outline-2">
<h2 id="org16d8d80"><span class="section-number-2">4.</span> AI 擅長的解題領域</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-orgd257ae7" class="outline-3">
<h3 id="orgd257ae7"><span class="section-number-3">4.1.</span> 與情境無關的領域</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>如棋類遊戲等封閉系統就是與情境無關；反之，個人商品推薦則否，因為影響使用者是否購買特定商品的因素有太多是電商觀測不到的，例如，當天的心情。同理，戰爭的爆發其背後的因素也有可能出人意料之外，如特洛伊。</li>
<li>一些工作雖然與情境相關，但卻因為這些情境可人為控制，所以也適合以 AI 解決，如，人臉辨識可能因為拍照時人的角度、戴口罩、太陽眼鏡、帽子、背景光線、天氣等因素而導致辨識困難，但這些情境因素都可以事先控制，如：要求對象拿下口罩正向面對攝影機。</li>
</ul>
</div>
</div>
<div id="outline-container-org4858530" class="outline-3">
<h3 id="org4858530"><span class="section-number-3">4.2.</span> 樣本數多的領域</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>如颱風一年最多 20 個，累積 50 年也不過 1000 個，不足以建立高複雜度且精確的學習模型(尤其牽涉的的變數很多時)</li>
</ul>

<div id="org4ef3eb9" class="figure">
<p><img src="images/AITW.jpg" alt="AITW.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 36: </span>AI 擅長的解題領域</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orga392344" class="outline-2">
<h2 id="orga392344"><span class="section-number-2">5.</span> AI 各項產業應用</h2>
<div class="outline-text-2" id="text-5">

<div id="org59dd477" class="figure">
<p><img src="images/enterprise.jpg" alt="enterprise.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 37: </span>各產業投資 AI 效益</p>
</div>
</div>
<div id="outline-container-orge8c1ac7" class="outline-3">
<h3 id="orge8c1ac7"><span class="section-number-3">5.1.</span> 製造業</h3>
<div class="outline-text-3" id="text-5-1">
<ol class="org-ol">
<li>瑕疵檢測：金屬表面、玻璃、印刷電路、電子產品、牛仔褲、農產品，由 AI 取代人眼。在某家製造商的資料中，人眼檢測瑕疵漏網率為 5%、AI 為 0.01%；人眼檢測速度為每天 30 萬張影像、一台 10 萬左右的電腦每天可檢測 1440 萬張。</li>
<li>自動流程控制：製造業共通的挑戰為設定參數的調控及最佳化，或稱為自動流程控制。生產流程中，如馬達轉速、電流、電壓、環境溫度&#x2026;等等需要監控、會影響產品良率的因素可能高達上千個，這些高維度的因素彼此又有交互作用(通常維度高過 5 個，且參數間有交互作用，人類就無法精確掌握)，而且製程可能很長，調整參數後可能隔天才能確認。AI 介入化工製程的例子可以將良率由六成調至 98%<sup><a id="fnr.21" class="footref" href="#fn.21" role="doc-backlink">21</a></sup>。</li>
<li>預測性維護：包括預測機器何時會出錯以提前進廠保養、預測耗才何時更換最為有利。此類工作涉及訊號鄋理，如：監控馬達電壓、轉速、震動、聲音來判斷馬達是否即將固障；監控機器手臂行程順暢度、夾具穩定度來判斷機器手臂是否有固障徵兆。<sup><a id="fnr.21.21" class="footref" href="#fn.21" role="doc-backlink">21</a></sup></li>
<li>原料組合最佳化：製造業的工作在於取得一種或多種原料，經過物理或化學加工過程後製成產品；但每批原枓可能來自不同供應商、品質、等級或特性可能有所差異，如何在各原料、供應商、等級、成本的排列中找出最高 CP 值的組合即為重要工作。以染整業為例，新的布料與顏色平均要花 3~7 天的打色嚐試才能達到客戶允收範圍，以第一次打色為例，軟體模擬加上師傅經驗調整，成功率約七成；而藉由以深度學習建出模型來描述布料、目標顏色及染料濃度間的關係，可以將成功率達到九成<sup><a id="fnr.21.21" class="footref" href="#fn.21" role="doc-backlink">21</a></sup>。</li>
</ol>
</div>
</div>
<div id="outline-container-org77ce845" class="outline-3">
<h3 id="org77ce845"><span class="section-number-3">5.2.</span> 零售與金融業</h3>
<div class="outline-text-3" id="text-5-2">
<p>
零售及金融之所以相對容易切入 AI 是因為這兩個產業的核心業務就是在處理資訊流。
依據 Gartner 的報告，資料分析可以分四個層次：
</p>
<ol class="org-ol">
<li>描述：評估現況及了解問題。解釋發生了什麼？</li>
<li>解釋：提供問題的初步診斷。解釋為什麼發生？</li>
<li>預測：提供改善和解決問題的工具。未來會不會發生？</li>
<li>最佳化：提供改善和解決問題的工具。如何讓他發生？</li>
</ol>
</div>
<div id="outline-container-org5719502" class="outline-4">
<h4 id="org5719502"><span class="section-number-4">5.2.1.</span> 圖表式的決策反而可能誤導</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
以零售業的產銷量問題為例，假設影響因素有：店點、擺設位置、售價，折扣活動、集點活動、包裝、季節&#x2026;，若以圖表顯示，每張圖表一次頂多呈現 1~2 個變數的關係，無法同時呈現所有變數<sup><a id="fnr.21.21" class="footref" href="#fn.21" role="doc-backlink">21</a></sup>。
</p>
</div>
</div>
</div>
<div id="outline-container-org839a573" class="outline-3">
<h3 id="org839a573"><span class="section-number-3">5.3.</span> 遊戲產業</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>提升畫質(俠盗獵車手V)遊戲引撉<sup><a id="fnr.22" class="footref" href="#fn.22" role="doc-backlink">22</a></sup></li>
<li><p>
NPC的進化：可以記住與玩家的互動，產生不固定的對話內容、了解玩家的偏好招式、<a href="https://www.youtube.com/watch?app=desktop&amp;v=zzGAGwGtDL0">記住以往的恩怨情仇</a>，即，更像玩家<sup><a id="fnr.22.22" class="footref" href="#fn.22" role="doc-backlink">22</a></sup>
</p>

<div id="org4b46027" class="figure">
<p><img src="images/AI_各項產業應用/2024-01-30_17-06-53_2024-01-30_17-06-42.png" alt="2024-01-30_17-06-53_2024-01-30_17-06-42.png" width="500" />
</p>
<p><span class="figure-number">Figure 38: </span>AI化的NPC</p>
</div></li>
<li>2009 年 Netflix 推出一項總奬金 100 萬美元的競賽，用來改進預測使用者喜愛影片的正確性</li>
<li>AlphaGo: 基於深度學習所製作的「<a href="AI-Introduction.html">人工智慧</a>機」，在 2016 年擊敗世界圍棋冠軍 Lee Sedol。AlphaGo 的優勢在於這個程式並不是專門開發來下圍棋的，而是運用「強化學習」與「深度學習」，透過下了數以千計次的圍棋，學習到如何下圍棋。</li>
<li>AlhpaGo Zero: 2017 年 10 月 19 日，AlphaGo 團隊在《自然》上發表文章介紹了 AlphaGo Zero，文中指出此版本不採用人類玩家的棋譜，且比之前的所有版本都要強大。透過自我對弈，AlphaGo Zero 在三天內以 100 比 0 的戰績戰勝了 AlphaGo Lee，花了 21 天達到 AlphaGo Master 的水平，用 40 天超越了所有舊版本。DeepMind 聯合創始人兼 CEO 傑米斯·哈薩比斯說，AlphaGo Zero「不再受限於人類認知」，很強大。由於專家數據「經常很貴、不可靠或是無法取得」，不藉助人類專家的數據集訓練<a href="AI-Introduction.html">人工智慧</a>，對於<a href="AI-Introduction.html">人工智慧</a>開發超人技能具有重大意義[4]，因為這樣的 AI 不是學習人，是透過對自我的反思和獨有的創造力直接超越人類<sup><a id="fnr.19.19" class="footref" href="#fn.19" role="doc-backlink">19</a></sup>。</li>
<li>繼 AlphaGo 後，同一團隊(DeepMind)繼續打造出 AlphaZero，不再依賴人類棋士的知識與棋譜，只給遊戲規則。在 34 小時的訓練後（約自我訓練 2100 萬局[1]:Table S3），AlphaZero 以 60 勝 40 敗的成績打敗 AlphaGo Zero<sup><a id="fnr.23" class="footref" href="#fn.23" role="doc-backlink">23</a></sup>。</li>
</ul>
</div>
</div>
<div id="outline-container-org0a4e2f1" class="outline-3">
<h3 id="org0a4e2f1"><span class="section-number-3">5.4.</span> 政府機構</h3>
<div class="outline-text-3" id="text-5-4">
</div>
<div id="outline-container-orgdc82965" class="outline-4">
<h4 id="orgdc82965"><span class="section-number-4">5.4.1.</span> 交通</h4>
<div class="outline-text-4" id="text-5-4-1">
<ul class="org-ul">
<li><p>
<a href="https://youtu.be/35PYqhSzZxY?si=C-hZu0bQiiaO6wMC">高市交通局設置AI智慧號誌　降低停等延滯時間　紓解交通瓶頸</a>
</p>

<div id="org5a9a4f6" class="figure">
<p><img src="images/AI_各項產業應用/2024-01-30_17-30-45_2024-01-30_17-30-21.png" alt="2024-01-30_17-30-45_2024-01-30_17-30-21.png" width="500" />
</p>
<p><span class="figure-number">Figure 39: </span>高市交通局設置AI智慧號誌</p>
</div></li>
<li>美國的交通路況分析公司 Inrix 依靠分析歷史和即時路況資訊，除了能提供駕駛即 時的路況報告以避開堵車的路段，還能提前規劃行車路線。許多汽車大廠如奧迪、福特、 日產、甚至是微軟都是 Inrix 的客戶。在可預見的未來，自動輔助駕駛系統甚至是自駕 系統即可能成為新車的標準配備，此類即時路況資訊的重要性更是不言可喻。</li>
</ul>
</div>
</div>
<div id="outline-container-org849b0e5" class="outline-4">
<h4 id="org849b0e5"><span class="section-number-4">5.4.2.</span> 房地產</h4>
<div class="outline-text-4" id="text-5-4-2">
<ul class="org-ul">
<li>澳大利亞：2015 年舉辦一場「預測西澳大利亞租屋價錢」的比賽</li>
</ul>
</div>
</div>
<div id="outline-container-org647c26a" class="outline-4">
<h4 id="org647c26a"><span class="section-number-4">5.4.3.</span> 預防犯罪</h4>
<div class="outline-text-4" id="text-5-4-3">
<ul class="org-ul">
<li>我國警政署在 2018 年也開始陸續建置巨量資料分析平台，以此來分析相關的犯罪 手法、協助偵查人員精確鎖定犯罪嫌疑人、擴展案件相關線索，並深入探勘其他罪行。 透過對巨量資料的分析，刑偵單位可判斷出犯罪發展出的系列性、跨區域性、地域性趨勢。近年來許多假新聞，網路詐騙等案件偵破，巨量資料在偵查破案中的功勞也不可小 覷。</li>
<li>以往名列美國三大犯罪之都的紐約市也開始以巨量資料分析偵測犯罪，1990年起上線的CompStat系統整理強姦、搶劫、竊盗等各種犯罪資料，然後依此擬定因應對策及警力調配，使車輛竊盜案及兇殺案下降約四分之一;2016年上線的CompStat 2.0更允許每位市民查看整個紐約市各種犯罪時間、地點的即時分析結果。</li>
<li><p>
美國加洲的PredPol公司進一步利用巨量資料來預測犯罪的發生，PredPol是從地震預測軟體進化而來的，它以紅色方框表示需要提高警惕的犯罪「熱點」地區(如圖<a href="#org71a6bcb">40</a><sup><a id="fnr.24" class="footref" href="#fn.24" role="doc-backlink">24</a></sup>)，根據某一地區過往的犯罪活動統計數據，藉助特殊演算法，計算出某地發生犯罪的概率、犯罪類型，以及最有可能犯罪的時段。
</p>

<div id="org71a6bcb" class="figure">
<p><img src="images/AI_各項產業應用/2024-01-30_17-39-27_2024-01-30_17-38-20.png" alt="2024-01-30_17-39-27_2024-01-30_17-38-20.png" width="500" />
</p>
<p><span class="figure-number">Figure 40: </span>PredPol Crime Map</p>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgdae797c" class="outline-4">
<h4 id="orgdae797c"><span class="section-number-4">5.4.4.</span> 獨裁統治</h4>
<div class="outline-text-4" id="text-5-4-4">

<div id="orgf8dfbd3" class="figure">
<p><img src="images/AI_各項產業應用/2024-01-29_17-37-59_2024-01-29_17-37-46.png" alt="2024-01-29_17-37-59_2024-01-29_17-37-46.png" width="500" />
</p>
<p><span class="figure-number">Figure 41: </span>中國「社會信用評級」系統</p>
</div>
<ul class="org-ul">
<li>中國利用 2 億個監視器監控 14 億公民，並對公民的「社會信用評級」即時評分，公民分數高低將影響生活各個層面，甚至是行動自由。目前「社會信用評級」計畫尚在某些地區試點，但已有約一千萬人受到懲罰，包含異議人士和調查記者。報導稱中國將在 2020 年全面使用「社會信用評級」系統。
ABC 駐華記者 Matthew Carney 報導指出，36 歲市場專員范丹丹，和其共產黨幹部丈夫張小京育有一個 2 歲兒子。在公民分數金字塔頂端的兩夫妻，對「社會信用評級」態度樂觀，他們不但可以在酒店、機場享有 VIP 待遇，還能有低息貸款，更重要的是，只要夫妻倆都保持良好分數，兒子就能贏在起跑點上：享受最好的住房、學校和醫療保險。
另一方面，43 歲的調查記者劉虎，卻因為「社會信用系統」吃盡了苦頭。他揭露了中國共產黨內高層的腐敗，並解析了一系列謀殺案，因為「言論犯罪」丟了公民分數，甚至被軟禁在家鄉重慶。劉虎曾試圖用手機 App 預訂前往西安的火車票，結果竟被拒絕，「我乘坐高鐵的權利受到法律限制」。正如中共官方一份規劃綱要：「在幾年內，該系統將『使守信者處處受益、失信者寸步難行』。<sup><a id="fnr.25" class="footref" href="#fn.25" role="doc-backlink">25</a></sup>」</li>
<li><a href="https://www.youtube.com/watch?v=PQGLrM54Q5Y&amp;t=5s">知名脫口秀吐槽「一個中國」，用台灣編劇狂酸中國玻璃心</a></li>
<li>新疆的天眼辨識系統嚴密監控當地的維吾爾少數民族<sup><a id="fnr.26" class="footref" href="#fn.26" role="doc-backlink">26</a></sup>。</li>
<li>2021年底，河南省傳出架設人臉辨識系統，追踪記者和國際學生等當局眼中的“可疑人士”。同一時間，上海浦東人民檢察院則開始測試AI檢察官，號稱可根據案件口頭描述，以超過97%的準確率起訴八種犯罪行為，包括信用卡詐騙、妨礙公務和尋釁滋事等<sup><a id="fnr.26.26" class="footref" href="#fn.26" role="doc-backlink">26</a></sup>。</li>
<li>另據《澎湃新聞》報導，四川行政學院早於2017年就開發“智慧紅雲”，來評估黨員學習教育的成效，當時也號稱可“算出”黨員的思想狀況<sup><a id="fnr.26.26" class="footref" href="#fn.26" role="doc-backlink">26</a></sup>。</li>
<li>一位異議人士說，他行經人行道的路邊攝像頭時，被AI人臉辨識出，然後就看著公安拿著手機，從警車下來，直接把他帶走<sup><a id="fnr.26.26" class="footref" href="#fn.26" role="doc-backlink">26</a></sup>。</li>
<li>根據一位人權律師的彙整，中共靠大數據對名列黑名單的維穩人口進行精準管控，包括在兩會等特殊時間，限制他們的人身自由。另外，中國地鐵普遍採用人臉識別進站，超過170個城市也開通“刷臉”繳稅等服務，當局靠著這些大量的人臉信息，集中用於維護獨裁體制的穩固性，也精準打壓異議人士、宗教人士以及上訪者<sup><a id="fnr.26.26" class="footref" href="#fn.26" role="doc-backlink">26</a></sup>。</li>
<li>依據中國政府要求，中國對抗新冠病毒戰略，依賴所謂的「健康碼」，該數位資料會記錄個人的聯繫信息、身份和最近的旅行歷史；「健康碼」已成為任何個人進入商店、乘坐公共交通工具甚至回家的強制性要求。代碼分為3種顏色：紅色、黃色和綠色。如果用戶在48或72小時內收到陰性COVID檢測結果，將可獲得綠色健康碼。相反，政府當局將追查帶有黃色或紅色代碼的人，以進行進一步的隔離或其他限制措施。而在6月份，官媒《新華社》透露，健康碼可能進一步「永久化」並將實踐融入日常生活<sup><a id="fnr.27" class="footref" href="#fn.27" role="doc-backlink">27</a></sup>。</li>
<li>雖然中國政府辯解這是為「流行病管理」的政策，對公眾利益而言是有必要的。但河南省日前爆發建案糾紛，部份人士銀行存款被莫名凍結，民眾蘊釀抗議活動時，地方政府竟直接對特定入發出「紅色」健康碼限制行動，事情鬧大之後，當局對包括4名政府官員在內的5人祭出懲處，但仍無法解決和解釋健康碼的隱私可被窺視、變造問題，進而引發限制人身自由等種種疑慮。</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org018d292" class="outline-3">
<h3 id="org018d292"><span class="section-number-3">5.5.</span> 百貨零售業</h3>
<div class="outline-text-3" id="text-5-5">
<ul class="org-ul">
<li>藉由所有零售業都有的 POS(銷售時點情報系統)，全家便利商店不僅能結合天氣 資訊調整店面上架商品，還整合了 POS 系統中的銷售數據，讓各加盟主的訂購數更 趨近消費者需求數，以降低鮮食報廢率。</li>
<li>臺灣的 7-11 能根據發票資訊制定行銷策略，決定每家店的主打商品;美國的 7-11 所 開發的專屬 App 更能結合地點、天氣和時間資訊，給予消費者最即時的商品優惠券， 如早晨提供咖啡優惠券、中午放送生鮮食品折扣。</li>
<li>美國連鎖百貨 Target 於 2002 年開始分析顧客的購買清單，Target發現顧客通常會在懷孕4個月左右購買容量較大且無香味的乳液;在懷孕的前20周，孕婦會購買大量的維他命營養補充品。如果有人突然開始購買大量的無香精肥皂、大包的棉花球加上洗手液及擦手巾，那就表示這位婦女可能非常接近預產期了。Target的資料分析師找出了25種產品可以作為「懷孕預測指數」的指標，還可以預測預產期，讓行銷人員可以精準地在不同的孕期，寄送專屬的折價券給消費者。</li>
</ul>
</div>
</div>
<div id="outline-container-org92ec7a3" class="outline-3">
<h3 id="org92ec7a3"><span class="section-number-3">5.6.</span> Jetson</h3>
<div class="outline-text-3" id="text-5-6">
<ul class="org-ul">
<li><p>
<a href="https://iotmart.advantech.com.tw/Widget.aspx?WidgetID=3076">Iot應用</a>
</p>

<div id="orgfea882d" class="figure">
<p><img src="images/AI_各項產業應用/2023-11-15_20-48-03_2023-11-15_20-47-52.png" alt="2023-11-15_20-48-03_2023-11-15_20-47-52.png" width="500" />
</p>
<p><span class="figure-number">Figure 42: </span>Jetson nano: AI顧嬰</p>
</div></li>
<li><a href="https://www.cw.com.tw/article/5128007">AI顧嬰，讓爸媽安心睡</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgb0de9dd" class="outline-2">
<h2 id="orgb0de9dd"><span class="section-number-2">6.</span> AI 的五大迷思</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org7dd9166" class="outline-3">
<h3 id="org7dd9166"><span class="section-number-3">6.1.</span> 迷思一：資料等於價值</h3>
<div class="outline-text-3" id="text-6-1">
<p>
資料若沒有經過妥善的加工處理和萃取分析，本身並無太大價值，需要將對的資料用在對的場景。例如，電信公司的通聯記錄，行銷公司只會拿來做行銷，治安機關則可以拿來追查詐騙集團；又如 X 光片的判斷品質決定了 AI model 的成效。資料等於價值的另一反例為 AlphaZero。
</p>
</div>
</div>
<div id="outline-container-org08c3e6b" class="outline-3">
<h3 id="org08c3e6b"><span class="section-number-3">6.2.</span> 迷思二：牽涉電腦與資料就是 MIS 部門的工作</h3>
<div class="outline-text-3" id="text-6-2">
<p>
AI 的導入需要跨部門支持，其開發團隊需要資料科學家(數學、統計)、領域專家(領域知識)、資訊人員(程式設計、資料庫)，最後在驗證模型成效時更需要跨部門的支持。
</p>
</div>
</div>
<div id="outline-container-org8a79157" class="outline-3">
<h3 id="org8a79157"><span class="section-number-3">6.3.</span> 迷思三：資料分析就是產出報表</h3>
<div class="outline-text-3" id="text-6-3">
<p>
資料分析不應只限於公司內部資料庫中的結構化資料，而應包含非結構化資料(影像、聲音、影片、文字、互動)
</p>
</div>
</div>
<div id="outline-container-orgc877ca7" class="outline-3">
<h3 id="orgc877ca7"><span class="section-number-3">6.4.</span> 迷思四：電腦決策不可能贏過人的專業經驗</h3>
<div class="outline-text-3" id="text-6-4">
<p>
主要原因在人類的短期記憶有限、能留意到的弱訊號太少，此外，有些工作需要極快的反應時間(如股市交易)。1995 年 Amazon 曾讓 50 位資深編輯就「推薦書單」與演算法進行 PK，自此後 Amazon 所有商品推薦都由<a href="MachineLearning.html">機器學習</a>進行。
</p>
</div>
</div>
<div id="outline-container-org6736959" class="outline-3">
<h3 id="org6736959"><span class="section-number-3">6.5.</span> 迷思五：導入系統或平台就可以解決營運問題</h3>
<div class="outline-text-3" id="text-6-5">
<p>
AI 不是一個資訊系統(如 ERP)，而是一種根據已知預測未知的方法，它沒有標準做法，其應用情境與方式會隨著企業的狀況與及需求有所不同。因此，問題不在「有沒有導入 AI」，而是「AI 應用的深度與廣度」。
</p>
</div>
</div>
</div>
<div id="outline-container-orgb1ac2b7" class="outline-2">
<h2 id="orgb1ac2b7"><span class="section-number-2">7.</span> 學習資源</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org4195561" class="outline-3">
<h3 id="org4195561"><span class="section-number-3">7.1.</span> Machine Learning [台大李宏毅]</h3>
<div class="outline-text-3" id="text-7-1">
</div>
<div id="outline-container-orgd8aaffc" class="outline-4">
<h4 id="orgd8aaffc"><span class="section-number-4">7.1.1.</span> Lecture 0</h4>
<div class="outline-text-4" id="text-7-1-1">
<ul class="org-ul">
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html">ML19: 台大[[file:MachineLearning.org][機器學習</a></li>
<li><a href="https://www.youtube.com/watch?v=CXgbekl66jc">ML Lecture 0-1: Introduction of Machine Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=On1N8u1z2Ng">ML Lecture 0-2: Why we need to learn machine learning?</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgdde6450" class="outline-4">
<h4 id="orgdde6450"><span class="section-number-4">7.1.2.</span> Lecture 1</h4>
<div class="outline-text-4" id="text-7-1-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fegAeph9UaA">ML Lecture 1: Regression - Case Study</a></li>
<li><a href="https://www.youtube.com/watch?v=1UqCjFQiiy0">ML Lecture 1: Regression - Demo</a></li>
</ul>
</div>
</div>
<div id="outline-container-org083d3b3" class="outline-4">
<h4 id="org083d3b3"><span class="section-number-4">7.1.3.</span> Lecture 2</h4>
<div class="outline-text-4" id="text-7-1-3">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=D_S6y0Jm6dQ">ML Lecture 2: Where does the error come from?</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgc3e022e" class="outline-4">
<h4 id="orgc3e022e"><span class="section-number-4">7.1.4.</span> Lecture 3</h4>
<div class="outline-text-4" id="text-7-1-4">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=yKKNr-QKz2Q">ML Lecture 3-1: Gradient Descent</a></li>
<li><a href="https://www.youtube.com/watch?v=1_HBTJyWgNA">ML Lecture 3-2: Gradient Descent (Demo by AOE)</a></li>
<li><a href="https://www.youtube.com/watch?v=wzPAInDF_gI">ML Lecture 3-3: Gradient Descent (Demo by Minecraft)</a></li>
</ul>
</div>
</div>
<div id="outline-container-org1eab357" class="outline-4">
<h4 id="org1eab357"><span class="section-number-4">7.1.5.</span> Lecture 4</h4>
<div class="outline-text-4" id="text-7-1-5">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=fZAZUYEeIMg">ML Lecture 4: Classification</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf591c69" class="outline-4">
<h4 id="orgf591c69"><span class="section-number-4">7.1.6.</span> Lecture 5</h4>
<div class="outline-text-4" id="text-7-1-6">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=hSXFuypLukA">ML Lecture 5: Logistic Regression</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgc045d87" class="outline-4">
<h4 id="orgc045d87"><span class="section-number-4">7.1.7.</span> Lecture 6</h4>
<div class="outline-text-4" id="text-7-1-7">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Dr-WRlEFefw">ML Lecture 6: Brief Introduction of Deep Learning</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgf25a5fa" class="outline-4">
<h4 id="orgf25a5fa"><span class="section-number-4">7.1.8.</span> Lecture 7</h4>
<div class="outline-text-4" id="text-7-1-8">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=ibJpTrp5mcE">ML Lecture 7: Backpropagation</a></li>
<li><a href="https://www.youtube.com/watch?v=gDp2LXGnVLQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=3&amp;t=0s">Anomaly Detection (1/7)</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4">Next Step of Machine Learning (Hung-yi Lee, NTU, 2019)</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgdd0e2c7" class="outline-4">
<h4 id="orgdd0e2c7"><span class="section-number-4">7.1.9.</span> Lecture 8</h4>
<div class="outline-text-4" id="text-7-1-9">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=Lx3l4lOrquw">ML Lecture 8-1: “Hello world” of deep learning</a></li>
<li><a href="https://www.youtube.com/watch?v=5BJDJd-dzzg">ML Lecture 8-2: Keras 2.0</a></li>
<li><a href="https://www.youtube.com/watch?v=L8unuZNpWw8">ML Lecture 8-3: Keras Demo</a></li>
</ul>
</div>
</div>
<div id="outline-container-org566f0db" class="outline-4">
<h4 id="org566f0db"><span class="section-number-4">7.1.10.</span> Explainable ML</h4>
<div class="outline-text-4" id="text-7-1-10">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=lnjrn3bF9lA">Explainable ML (1/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=pNpk6DPYUh8&amp;list=PL9McrqOpq3mUCXF5E8rVLjw8f878zkBfX&amp;index=16">Explainable ML (2/8)</a></li>
<li>Explainable ML (3/8)</li>
<li><a href="https://www.youtube.com/watch?v=yORbWn7UsBs">Explainable ML (4/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (5/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=K1mWgthGS-A">Explainable ML (6/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=1xnhQbAV1m0">Explainable ML (7/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Explainable ML (8/8)</a></li>
</ol>
</div>
</div>
<div id="outline-container-org826992f" class="outline-4">
<h4 id="org826992f"><span class="section-number-4">7.1.11.</span> <span class="todo TODO">TODO</span> Attack ML Models</h4>
<div class="outline-text-4" id="text-7-1-11">
<ol class="org-ol">
<li><a href="https://www.youtube.com/watch?v=NI6yb0WgMBM">Attack ML Models (1/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=zOdg05BwE7I">Attack ML Models (2/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=F9N5zF7N0qY">Attack ML Models (3/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=qjnMoWmn1FQ">Attack ML Models (4/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=2mgLPZJOHNk">Attack ML Models (5/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=z2nmPDLEXI0">Attack ML Models (6/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=KH48zq2RfBA&amp;t=1s">Attack ML Models (7/8)</a></li>
<li><a href="https://www.youtube.com/watch?v=ah_Ttx6cIVU">Attack ML Models (8/8)</a></li>
</ol>
</div>
</div>
<div id="outline-container-org1312312" class="outline-4">
<h4 id="org1312312"><span class="section-number-4">7.1.12.</span> Lecture 9</h4>
<div class="outline-text-4" id="text-7-1-12">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=xki61j7z-30">ML Lecture 9-1: Tips for Training DNN</a></li>
<li><a href="https://www.youtube.com/watch?v=Ky1ku1miDow">ML Lecture 9-2: Keras Demo 2</a></li>
<li><a href="https://www.youtube.com/watch?v=F1vek6ULo9w">ML Lecture 9-3: Fizz Buzz in Tensorflow (sequel)</a></li>
</ul>
</div>
</div>
<div id="outline-container-org62cbb87" class="outline-4">
<h4 id="org62cbb87"><span class="section-number-4">7.1.13.</span> Lecture 10</h4>
<div class="outline-text-4" id="text-7-1-13">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=FrKWiRv254g">ML Lecture 10: Convolutional Neural Network</a></li>
<li><a href="https://www.youtube.com/watch?v=XsC9byQkUH8">ML Lecture 11: Why Deep?</a></li>
<li><a href="https://www.youtube.com/watch?v=fX_guE7JNnY">ML Lecture 12: Semi-supervised</a></li>
<li><a href="https://www.youtube.com/watch?v=iwh5o_M4BNU">ML Lecture 13: Unsupervised Learning - Linear Methods</a></li>
<li><a href="https://www.youtube.com/watch?v=X7PH3NuYW0Q">ML Lecture 14: Unsupervised Learning - Word Embedding</a></li>
<li><a href="https://www.youtube.com/watch?v=GBUEjkpoxXc">ML Lecture 15: Unsupervised Learning - Neighbor Embedding</a></li>
<li><a href="https://www.youtube.com/watch?v=yyKaACh_j3M&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=45&amp;t=0s">Meta Learning – Metric-based (1/3)</a></li>
<li><a href="https://www.youtube.com/watch?v=Tk5B4seA-AU">ML Lecture 16: Unsupervised Learning - Auto-encoder</a></li>
<li><a href="https://www.youtube.com/watch?v=YNUek8ioAJk">ML Lecture 17: Unsupervised Learning - Deep Generative Model (Part I)</a></li>
<li><a href="https://www.youtube.com/watch?v=8zomhgKrsmQ">ML Lecture 18: Unsupervised Learning - Deep Generative Model (Part II)</a></li>
<li><a href="https://www.youtube.com/watch?v=6ZWu4L7XOiQ&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=48&amp;t=0s">More about Auto-encoder (1/4)</a></li>
<li><a href="https://www.youtube.com/watch?v=qD6iD4TFsdQ">ML Lecture 19: Transfer Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=7qT5P9KJnWo&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=25">Life Long Learning (1/7)</a></li>
<li><a href="https://www.youtube.com/watch?v=ZjfjPzXw6og&amp;feature=youtu.be">Sequence-to-sequence Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=EkAqYbpCYAc&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=33&amp;t=0s">Meta Learning – MAML (1/9)</a></li>
<li><a href="https://www.youtube.com/watch?v=QSEPStBgwRQ">ML Lecture 20: Support Vector Machine (SVM)</a></li>
<li><a href="https://www.youtube.com/watch?v=xCGidAeyS4M">ML Lecture 21-1: Recurrent Neural Network (Part I)</a></li>
<li><a href="https://www.youtube.com/watch?v=rTqmWlnwz_0">ML Lecture 21-2: Recurrent Neural Network (Part II)</a></li>
<li><a href="https://www.youtube.com/watch?v=YIuBHB9Ejok&amp;feature=youtu.be">Unsupervised Syntactic Parsing (ft. 莊永松同學)</a></li>
<li><a href="https://www.youtube.com/watch?v=tH9FH1DH5n0">ML Lecture 22: Ensemble</a></li>
<li><a href="https://www.youtube.com/watch?v=W8XF3ME8G2I">ML Lecture 23-1: Deep Reinforcement Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=y8UPGr36ccI">ML Lecture 23-2: Policy Gradient (Supplementary Explanation)</a></li>
<li><a href="https://www.youtube.com/watch?v=2-JNBzCq77c">ML Lecture 23-3: Reinforcement Learning (including Q-learning)</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsODxQFgzMzPLa16h6B8kWM_">Deep Reinforcement Learning, 2018</a></li>
<li><a href="https://www.youtube.com/watch?v=dPp8rCAnU_A&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=52&amp;t=0s">Network Compression (1/6)</a></li>
<li><a href="https://www.youtube.com/watch?v=ufcKFjdpT98&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58&amp;t=0s">GAN (Quick Review)</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw">Generative Adversarial Network (GAN), 2018</a></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=58">Transformer</a></li>
<li><a href="https://www.youtube.com/watch?v=UYPa347-DdE&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=62&amp;t=0s">ELMO, BERT, GPT</a></li>
<li><a href="https://www.youtube.com/watch?v=uXY18nzdSsM&amp;list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&amp;index=59">Flow-based Generative Model</a></li>
<li><a href="https://brohrer.mcknote.com/zh-Hant/statistics/how_bayesian_inference_works.html">貝葉斯推斷的運作原理</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5a547ab" class="outline-3">
<h3 id="org5a547ab"><span class="section-number-3">7.2.</span> Deep Learning for Human Language Processing (DLHLP) 2020</h3>
<div class="outline-text-3" id="text-7-2">
<ul class="org-ul">
<li><a href="https://www.youtube.com/watch?v=nER51ZyJaCQ&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG">[DLHLP 2020] Deep Learning for Human Language Processing (Course Overview)</a></li>
<li><a href="https://www.youtube.com/watch?v=AIKu43goh-8&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=2">[DLHLP 2020] Speech Recognition (1/7) - Overview</a></li>
<li><a href="https://www.youtube.com/watch?v=BdUeBa6NbXA&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=3">[DLHLP 2020] Speech Recognition (2/7) - Listen, Attend, Spell</a></li>
<li><a href="https://www.youtube.com/watch?v=CGuLuBaLIeI&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=4">[DLHLP 2020] Speech Recognition (3/7) - CTC, RNN-T and more</a></li>
<li><a href="https://www.youtube.com/watch?v=XWTGY_PNABo&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=5">[DLHLP 2020] Speech Recognition (4/7) - HMM (optional)</a></li>
<li><a href="https://www.youtube.com/watch?v=5SSVra6IJY4&amp;list=PLJV_el3uVTsO07RpBYFsXg-bN5Lu0nhdG&amp;index=6">[DLHLP 2020] Speech Recognition (5/7) - Alignment of HMM, CTC and RNN-T (optional)</a></li>
<li><a href="https://www.youtube.com/watch?v=gRfTfXCe3LA">[DLHLP 2020] Deep Learning for Question Answering (1/2)</a></li>
<li><a href="https://www.youtube.com/watch?v=h_Lptoq8spQ">[DLHLP 2020] Deep Learning for Question Answering (2/2)</a></li>
<li><a href="https://www.youtube.com/watch?v=DOG1L9lvsDY">[DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3</a></li>
<li><a href="https://www.youtube.com/watch?v=Bywo7m6ySlk">[DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more</a></li>
<li><a href="https://www.youtube.com/watch?v=ugWDIIOHtPA">Transformer</a></li>
</ul>
</div>
</div>
<div id="outline-container-orged06fb9" class="outline-3">
<h3 id="orged06fb9"><span class="section-number-3">7.3.</span> 其他線上資源</h3>
<div class="outline-text-3" id="text-7-3">
<ul class="org-ul">
<li><a href="http://ocw.aca.ntu.edu.tw/ntu-ocw/ocw/cou/104S204/1">Digital Speech Processing</a></li>
<li><a href="https://github.com/MyDearGreatTeacher/TensorSecurity">MyDearGreatTeacher/TensorSecurity</a></li>
<li><a href="https://github.com/MyDearGreatTeacher/PyTorch/blob/master/code/LinearRegression.py">MyDearGreatTeacher/PyTorch</a></li>
<li><a href="https://github.com/MyDearGreatTeacher/AI201909">MyDearGreatTeacher/AI201909</a></li>
<li><a href="https://github.com/MyDearGreatTeacher?tab=repositories">MyDearGreatTeacher</a></li>
<li><a href="https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">MIT Convolutional Neural Networks for Visual Recognition (Spring 2017)</a></li>
<li><a href="https://www.packtpub.com/catalogsearch/result/?q=python&amp;released=Available&amp;language=Python">packt電子書</a></li>
<li><a href="https://www.youtube.com/watch?v=J6Ok8p463C4">Getting Started with Keras (AI Adventures) Youtube</a></li>
<li><a href="https://blog.csdn.net/sunqiande88/article/details/80100891">PyTorch實戰2: ResNet-18實現Cifar-10圖像分類</a></li>
<li><a href="https://github.com/activatedgeek/LeNet-5">LeNet-5</a></li>
<li><a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></li>
<li><a href="https://github.com/nlpinaction/learning-nlp">自然语言处理算法与实战</a></li>
</ul>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/@pratyush057/mcculloch-pitts-neuron-243252cf987c">McCulloch Pitts Neuron</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1">McCulloch-Pitts Neuron — Mankind’s First Mathematical Model Of A Biological Neuron</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.linkedin.com/pulse/dartmouth-conference-1956-its-lasting-influence-back-arthur-wetzel">The Dartmouth Conference (1956) and its Lasting Influence on Artificial </a>
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.bnext.com.tw/article/38586/BN-2016-01-27-121544-178">人工智慧先驅離世，7件事看馬文·閔斯基對科技發展的貢獻</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://case.ntu.edu.tw/blog/?p=36957">克勞德．向農 Claude Shannon 1916-2001)</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6" role="doc-backlink">6</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.researchgate.net/publication/333039347_Analyzing_the_Prospect_of_an_Approaching_AI_Winter">Analyzing the Prospect of an Approaching AI Winter</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.7" class="footnum" href="#fnr.7" role="doc-backlink">7</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.researchgate.net/publication/347319057_Brain-Inspired_Computing_Models_and_Architectures">Brain-Inspired Computing: Models and Architectures</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.8" class="footnum" href="#fnr.8" role="doc-backlink">8</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://anatomiesofintelligence.github.io/posts/2019-06-21-organization-mark-i-perceptron">Organization of the MARK I Perceptron</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.9" class="footnum" href="#fnr.9" role="doc-backlink">9</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon">Professor’s perceptron paved the way for AI – 60 years too soon</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.10" class="footnum" href="#fnr.10" role="doc-backlink">10</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://ai.iias.sinica.edu.tw/glossary/expert-system/">Expert System</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.11" class="footnum" href="#fnr.11" role="doc-backlink">11</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="http://sdact.tand.org.tw/issue/issue_info.asp?issue_id=280">醫學資訊學在泌尿科的應用</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.12" class="footnum" href="#fnr.12" role="doc-backlink">12</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://en.wikipedia.org/wiki/David_Rumelhart">David Everett Rumelhart </a>
</p></div></div>

<div class="footdef"><sup><a id="fn.13" class="footnum" href="#fnr.13" role="doc-backlink">13</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/zh-tw/%E6%9D%A8%E7%AB%8B%E6%98%86">Yann Le Cun</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.14" class="footnum" href="#fnr.14" role="doc-backlink">14</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/zh-tw/%E6%9D%B0%E5%BC%97%E9%87%8C%C2%B7%E8%BE%9B%E9%A1%BF">Geoffrey Everest Hinton</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.15" class="footnum" href="#fnr.15" role="doc-backlink">15</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine">Restricted Boltzmann machine</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.16" class="footnum" href="#fnr.16" role="doc-backlink">16</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://cv.gluon.ai/build/examples_datasets/imagenet.html">Prepare the ImageNet dataset</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.17" class="footnum" href="#fnr.17" role="doc-backlink">17</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/E050141335">AI無所不在的未來, Rule of the Robots</a>, P.115
</p></div></div>

<div class="footdef"><sup><a id="fn.18" class="footnum" href="#fnr.18" role="doc-backlink">18</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/E050141335">AI無所不在的未來, Rule of the Robots</a>, P.111
</p></div></div>

<div class="footdef"><sup><a id="fn.19" class="footnum" href="#fnr.19" role="doc-backlink">19</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/zh-tw/AlphaGo">AlphaGo</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.20" class="footnum" href="#fnr.20" role="doc-backlink">20</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.hindawi.com/journals/mpe/2019/2053156/">A Multi-GPU Parallel Algorithm in Hypersonic Flow Computations</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.21" class="footnum" href="#fnr.21" role="doc-backlink">21</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/0010821934?sloc=main">人工智慧在台灣：產業轉型的契機與挑戰，AI應用無所不在，你跟上了嗎？</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.22" class="footnum" href="#fnr.22" role="doc-backlink">22</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.books.com.tw/products/0010921963">寫給中學生看的AI課</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.23" class="footnum" href="#fnr.23" role="doc-backlink">23</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://zh.wikipedia.org/wiki/AlphaZero">AlphaZero</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.24" class="footnum" href="#fnr.24" role="doc-backlink">24</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.prnewswire.com/news-releases/predpol-hires-new-ceo---continues-scaling-of-predictive-policing-technology-245961621.html">PredPol Hires New CEO - Continues Scaling of Predictive Policing Technology</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.25" class="footnum" href="#fnr.25" role="doc-backlink">25</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://taronews.tw/2018/09/19/125910/">2億監視器瞄準公民「打分數」 澳媒揭露中國獨裁計畫</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.26" class="footnum" href="#fnr.26" role="doc-backlink">26</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.voacantonese.com/a/ai-tocracy-is-taking-shape-in-china-20220707/6651789.html">中共開發人工智能監控黨員忠誠度專家: AI獨裁入眼入腦入心 </a>
</p></div></div>

<div class="footdef"><sup><a id="fn.27" class="footnum" href="#fnr.27" role="doc-backlink">27</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://www.mobile01.com/topicdetail.php?f=780&amp;t=6615615">美國重要媒體證實中國將「健康碼」做為獨裁監控工具&#x2026;..</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2024-11-13 Wed 09:52</p>
</div>
</body>
</html>
