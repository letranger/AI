<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-12-05 Tue 12:41 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>分類</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">分類</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#IRIS-KNN">1. 分類實作: IRIS(KNN、DecisionTree)</a>
<ul>
<li><a href="#org3d2f47a">1.1. 鳶尾花分類問題</a></li>
<li><a href="#org412cc2c">1.2. KNN實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="iris">iris</span>&#xa0;<span class="KNN">KNN</span>&#xa0;<span class="sklearn">sklearn</span></span></a></li>
<li><a href="#org5fd415c">1.3. 決策樹實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="DecisionTree">DecisionTree</span>&#xa0;<span class="sklearn">sklearn</span></span></a></li>
<li><a href="#org65c15d8">1.4. 課堂作業</a></li>
</ul>
</li>
<li><a href="#orgc307049">2. 分類實作: MNIST(二元分類與多元分類)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="sklearn">sklearn</span>&#xa0;<span class="DSG">DSG</span>&#xa0;<span class="SVM">SVM</span></span></a>
<ul>
<li><a href="#org951b0a4">2.1. MNIST 資料集</a></li>
<li><a href="#org094c882">2.2. 準備 MNIST 資料</a></li>
<li><a href="#org1bdecea">2.3. 查看MNIST內容</a></li>
<li><a href="#orge816385">2.4. 訓練二元分類器</a></li>
<li><a href="#org93d2a8e">2.5. 多類別分類器</a></li>
<li><a href="#org813d29f">2.6. 多標籤分類</a></li>
</ul>
</li>
<li><a href="#org3daaf07">3. 分類實作: MNIST(CNN)</a>
<ul>
<li><a href="#org78510d1">3.1. 準備 MNIST 資料</a></li>
<li><a href="#orge66f25a">3.2. MNIST 的推論處理</a></li>
<li><a href="#org9620b53">3.3. Python 與神經網路運算的批次處理</a></li>
<li><a href="#orga70dc1d">3.4. MNIST 資料集:以 DNN Sequential 模型為例&#xa0;&#xa0;&#xa0;<span class="tag"><span class="CNN">CNN</span></span></a></li>
</ul>
</li>
<li><a href="#orgbd1cda1">4. 最短距離分類器</a></li>
<li><a href="#classify-homework">5. 個人作業</a>
<ul>
<li><a href="#orgfd0f0e2">5.1. 背景</a></li>
<li><a href="#org82be327">5.2. 作業要求</a></li>
</ul>
</li>
</ul>
</div>
</div>
<a href="https://letranger.github.io/AI/20231204210821-分類.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20231204210821-分類.html.svg"/></a>


<p>
分類(Cliasification)是<a href="20221023101626-監督式學習.html#ID-20221023T101626.420918">監督式學習</a>的方法之一(另一種為迴歸)，分類問題也稱為離散(discrete)預測問題，因為每個分類都是一個離散群組。In supervised learning, the training set you feed to the algorithm includes the desired solutions, called labels<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>.
</p>


<div id="org1064c61" class="figure">
<p><img src="images/2022-04-30_10-38-58.jpg" alt="2022-04-30_10-38-58.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 1: </span>典型的監督式學習：垃圾郵件分類</p>
</div>

<p>
可再細分為:
</p>
<ul class="org-ul">
<li>Binary classification</li>
<li>Multiclass classification</li>
</ul>

<p>
典型的分類案例: MNIST, IRIS
</p>
<div id="outline-container-IRIS-KNN" class="outline-2">
<h2 id="IRIS-KNN"><span class="section-number-2">1.</span> 分類實作: IRIS(KNN、DecisionTree)</h2>
<div class="outline-text-2" id="text-IRIS-KNN">
<p>
K-NearestNeighbor分類算法是機器學習裡監督類學習中最簡單的方法之一,由Cover和Hart在1968年提出。kNN算法的核心思想是如果一個樣本在特徵空間中的k個最相鄰的樣本中的大多數屬於某一個類別，則該樣本也屬於這個類別，並具有這個類別上樣本的特性。
</p>

<p>
KNN為 lazy learner(惰性學習器)的典型例子，所謂惰性是指它不會從「訓練數據集」中學習出「判別函數」(discriminative function)，它的作法是把「訓練數據集」記憶起來。其步驟如下：
</p>
<ol class="org-ol">
<li>選定 k 的值和一個「距離度量」(distance metric)。</li>
<li>找出 k 個想要分類的、最相近的鄰近樣本。</li>
<li>以多數決的方式指定類別標籤。</li>
</ol>
</div>
<div id="outline-container-org3d2f47a" class="outline-3">
<h3 id="org3d2f47a"><span class="section-number-3">1.1.</span> 鳶尾花分類問題</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org0c12ca3" class="outline-4">
<h4 id="org0c12ca3"><span class="section-number-4">1.1.1.</span> DataSet</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
收集了3種鳶尾花的四個特徵，分別是花萼(sepal)長寬、花瓣(petal)長寬度，以及對應的鳶尾花種類。
</p>

<div id="org7efb18c" class="figure">
<p><img src="images/iris-1.png" alt="iris-1.png" width="400" />
</p>
<p><span class="figure-number">Figure 2: </span>鳶尾花的花萼與花瓣</p>
</div>
</div>
</div>
<div id="outline-container-org35c062e" class="outline-4">
<h4 id="org35c062e"><span class="section-number-4">1.1.2.</span> Mission</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
輸入花萼和花瓣數據後，推測所屬的鳶尾花類型。
</p>

<div id="orgde37236" class="figure">
<p><img src="images/iris-2.png" alt="iris-2.png" width="600" />
</p>
<p><span class="figure-number">Figure 3: </span>三種鳶尾花</p>
</div>
</div>
</div>
<div id="outline-container-org0725ee8" class="outline-4">
<h4 id="org0725ee8"><span class="section-number-4">1.1.3.</span> 實作</h4>
<div class="outline-text-4" id="text-1-1-3">
<ol class="org-ol">
<li><p>
讀取資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> datasets

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#20837;&#36039;&#26009;</span>
<span style="color: #dcaeea;">iris</span> = datasets.load_iris()
<span style="color: #c678dd;">print</span>(iris.DESCR)
</pre>
</div></li>

<li><p>
取出特徵與標籤
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #dcaeea;">x</span> = iris.data
<span style="color: #dcaeea;">y</span> = iris.target
<span style="color: #c678dd;">print</span>(x[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span style="color: #c678dd;">print</span>(y[:<span style="color: #da8548; font-weight: bold;">5</span>])
</pre>
</div></li>
<li><p>
資料觀察
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25226;nupmy ndarray&#36681;&#28858;pandas dataFrame,&#21152;&#19978;columns title</span>
<span style="color: #dcaeea;">npx</span> = pd.DataFrame(x, columns=[<span style="color: #98be65;">'fac1'</span>,<span style="color: #98be65;">'fac2'</span>,<span style="color: #98be65;">'fac3'</span>,<span style="color: #98be65;">'fac4'</span>])
<span style="color: #dcaeea;">npy</span> = pd.DataFrame(y.astype(<span style="color: #c678dd;">int</span>), columns=[<span style="color: #98be65;">'category'</span>])
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21512;&#20341;</span>
<span style="color: #dcaeea;">dataPD</span> = pd.concat([npx, npy], axis=<span style="color: #da8548; font-weight: bold;">1</span>)
<span style="color: #c678dd;">print</span>(dataPD)
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30059;&#22294;</span>
sns.lmplot(<span style="color: #98be65;">'fac1'</span>, <span style="color: #98be65;">'fac2'</span>, data=dataPD, hue=<span style="color: #98be65;">'category'</span>, fit_reg=<span style="color: #a9a1e1;">False</span>)
plt.show()
</pre>
</div></li>

<li><p>
分割資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21123;&#20998;&#36039;&#26009;&#38598;</span>
<span style="color: #dcaeea;">x_train</span>, <span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = train_test_split(iris.data, iris.target, random_state=<span style="color: #da8548; font-weight: bold;">6</span>)
</pre>
</div>
<ul class="org-ul">
<li>train_test_split()
所接受的變數其實非常單純，基本上為 3 項：『原始的資料』、『Seed』、『比例』
<ol class="org-ol">
<li>原始的資料：就如同上方的 data 一般，是我們打算切成 Training data 以及 Test data 的原始資料</li>
<li>Seed： 亂數種子，可以固定我們切割資料的結果</li>
<li>比例：可以設定 train_size 或 test_size，只要設定一邊即可，範圍在 [0-1] 之間</li>
</ol></li>
<li><p>
scikit-learn.org: sklearn.model_selection.train_test_split
</p>

<p>
Split arrays or matrices into random train and test subsets
</p>

<p>
Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.
</p>
<div class="org-src-container">
<pre class="src src-python"> sklearn.model_selection.train_test_split(*arrays, test_size=<span style="color: #a9a1e1;">None</span>, train_size=<span style="color: #a9a1e1;">None</span>, random_state=<span style="color: #a9a1e1;">None</span>, shuffle=<span style="color: #a9a1e1;">True</span>, stratify=<span style="color: #a9a1e1;">None</span>)[source]
</pre>
</div>
<ul class="org-ul">
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">online docs</a></li>
</ul></li>
</ul></li>

<li><p>
資料標準化
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#36039;&#26009;&#27161;&#28310;&#21270;: &#21033;&#29992;preprocessing&#27169;&#32068;&#35041;&#30340;StandardScaler&#39006;&#21029;</span>
<span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21033;&#29992;fit&#26041;&#27861;&#65292;&#23565;X_train&#20013;&#27599;&#20491;&#29305;&#24501;&#20540;&#20272;&#24179;&#22343;&#25976;&#21644;&#27161;&#28310;&#24046;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#28982;&#24460;&#23565;&#27599;&#20491;&#29305;&#24501;&#20540;&#36914;&#34892;&#27161;&#28310;&#21270;(train&#21644;test&#37117;&#35201;&#20570;)</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29305;&#24501;&#24037;&#31243;&#65306;&#27161;&#28310;&#21270;</span>
<span style="color: #dcaeea;">transfer</span> = StandardScaler()
<span style="color: #dcaeea;">x_train</span> = transfer.fit_transform(x_train)
<span style="color: #dcaeea;">x_test</span> = transfer.fit_transform(x_test)
</pre>
</div></li>

<li><p>
分類
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> KNeighborsClassifier
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">KNN &#20998;&#39006;&#22120;</span>
<span style="color: #dcaeea;">estimator</span> = KNeighborsClassifier(n_neighbors=<span style="color: #da8548; font-weight: bold;">1</span>)
estimator.fit(x_train, y_train)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27169;&#22411;&#35413;&#20272;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#19968;&#65306;&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;</span>
<span style="color: #dcaeea;">y_predict</span> = estimator.predict(x_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'y_predict&#65306;</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">'</span>, y_predict)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;:</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">'</span>, y_test == y_predict)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#20108;&#65306;&#35336;&#31639;&#28310;&#30906;&#29575;</span>
<span style="color: #dcaeea;">score</span> = estimator.score(x_test, y_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;:</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">'</span>, score)
</pre>
</div></li>
</ol>
</div>
</div>
<div id="outline-container-org62e3cc2" class="outline-4">
<h4 id="org62e3cc2"><span class="section-number-4">1.1.4.</span> 作業</h4>
<div class="outline-text-4" id="text-1-1-4">
<p>
修改上述程式碼，以折線圖表示K值與KNN預測準確度間的關係。
</p>
</div>
</div>
</div>
<div id="outline-container-org412cc2c" class="outline-3">
<h3 id="org412cc2c"><span class="section-number-3">1.2.</span> KNN實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="iris">iris</span>&#xa0;<span class="KNN">KNN</span>&#xa0;<span class="sklearn">sklearn</span></span></h3>
<div class="outline-text-3" id="text-1-2">
<p>
K-NearestNeighbor分類算法是機器學習裡監督類學習中最簡單的方法之一,由Cover和Hart在1968年提出。kNN算法的核心思想是如果一個樣本在特徵空間中的k個最相鄰的樣本中的大多數屬於某一個類別，則該樣本也屬於這個類別，並具有這個類別上樣本的特性。
</p>

<p>
KNN為 lazy learner(惰性學習器)的典型例子，所謂惰性是指它不會從「訓練數據集」中學習出「判別函數」(discriminative function)，它的作法是把「訓練數據集」記憶起來。其步驟如下：
</p>
<ol class="org-ol">
<li>選定 k 的值和一個「距離度量」(distance metric)。</li>
<li>找出 k 個想要分類的、最相近的鄰近樣本。</li>
<li>以多數決的方式指定類別標籤。</li>
</ol>
</div>
<div id="outline-container-org1aeba7e" class="outline-4">
<h4 id="org1aeba7e"><span class="section-number-4">1.2.1.</span> 實作</h4>
<div class="outline-text-4" id="text-1-2-1">
<ol class="org-ol">
<li><p>
讀取資料集
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> datasets

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#20837;&#36039;&#26009;</span>
<span style="color: #dcaeea;">iris</span> = datasets.load_iris()
<span style="color: #c678dd;">print</span>(iris.DESCR)
</pre>
</div></li>

<li><p>
取出特徵與標籤
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #dcaeea;">x</span> = iris.data
<span style="color: #dcaeea;">y</span> = iris.target
<span style="color: #c678dd;">print</span>(x[:<span style="color: #da8548; font-weight: bold;">5</span>])
<span style="color: #c678dd;">print</span>(y[:<span style="color: #da8548; font-weight: bold;">5</span>])
</pre>
</div></li>
<li><p>
資料觀察
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25226;nupmy ndarray&#36681;&#28858;pandas dataFrame,&#21152;&#19978;columns title</span>
<span style="color: #dcaeea;">npx</span> = pd.DataFrame(x, columns=[<span style="color: #98be65;">'fac1'</span>,<span style="color: #98be65;">'fac2'</span>,<span style="color: #98be65;">'fac3'</span>,<span style="color: #98be65;">'fac4'</span>])
<span style="color: #dcaeea;">npy</span> = pd.DataFrame(y.astype(<span style="color: #c678dd;">int</span>), columns=[<span style="color: #98be65;">'category'</span>])
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#21512;&#20341;</span>
<span style="color: #dcaeea;">dataPD</span> = pd.concat([npx, npy], axis=<span style="color: #da8548; font-weight: bold;">1</span>)
<span style="color: #c678dd;">print</span>(dataPD)
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30059;&#22294;</span>
sns.lmplot(<span style="color: #98be65;">'fac1'</span>, <span style="color: #98be65;">'fac2'</span>, data=dataPD, hue=<span style="color: #98be65;">'category'</span>, fit_reg=<span style="color: #a9a1e1;">False</span>)
plt.show()
</pre>
</div></li>

<li><p>
分割資料集
</p>
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21123;&#20998;&#36039;&#26009;&#38598;</span>
<span style="color: #dcaeea;">x_train</span>, <span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = train_test_split(iris.data, iris.target, random_state=<span style="color: #da8548; font-weight: bold;">6</span>)
</pre>
</div>
<ul class="org-ul">
<li>train_test_split()
所接受的變數其實非常單純，基本上為 3 項：『原始的資料』、『Seed』、『比例』
<ol class="org-ol">
<li>原始的資料：就如同上方的 data 一般，是我們打算切成 Training data 以及 Test data 的原始資料</li>
<li>Seed： 亂數種子，可以固定我們切割資料的結果</li>
<li>比例：可以設定 train_size 或 test_size，只要設定一邊即可，範圍在 [0-1] 之間</li>
</ol></li>
<li><p>
scikit-learn.org: sklearn.model_selection.train_test_split
</p>

<p>
Split arrays or matrices into random train and test subsets
</p>

<p>
Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.
</p>
<div class="org-src-container">
<pre class="src src-python">
 sklearn.model_selection.train_test_split(*arrays, test_size=<span style="color: #a9a1e1;">None</span>, train_size=<span style="color: #a9a1e1;">None</span>, random_state=<span style="color: #a9a1e1;">None</span>, shuffle=<span style="color: #a9a1e1;">True</span>, stratify=<span style="color: #a9a1e1;">None</span>)[source]
</pre>
</div>
<ul class="org-ul">
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">online docs</a></li>
</ul></li>
</ul></li>

<li><p>
資料標準化
</p>
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#36039;&#26009;&#27161;&#28310;&#21270;: &#21033;&#29992;preprocessing&#27169;&#32068;&#35041;&#30340;StandardScaler&#39006;&#21029;</span>
<span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21033;&#29992;fit&#26041;&#27861;&#65292;&#23565;X_train&#20013;&#27599;&#20491;&#29305;&#24501;&#20540;&#20272;&#24179;&#22343;&#25976;&#21644;&#27161;&#28310;&#24046;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#28982;&#24460;&#23565;&#27599;&#20491;&#29305;&#24501;&#20540;&#36914;&#34892;&#27161;&#28310;&#21270;(train&#21644;test&#37117;&#35201;&#20570;)</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29305;&#24501;&#24037;&#31243;&#65306;&#27161;&#28310;&#21270;</span>
<span style="color: #dcaeea;">transfer</span> = StandardScaler()
<span style="color: #dcaeea;">x_train</span> = transfer.fit_transform(x_train)
<span style="color: #dcaeea;">x_test</span> = transfer.fit_transform(x_test)
</pre>
</div></li>

<li><p>
分類
</p>
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> KNeighborsClassifier
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">KNN &#20998;&#39006;&#22120;</span>
<span style="color: #dcaeea;">estimator</span> = KNeighborsClassifier(n_neighbors=<span style="color: #da8548; font-weight: bold;">1</span>)
estimator.fit(x_train, y_train)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27169;&#22411;&#35413;&#20272;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#19968;&#65306;&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;</span>
<span style="color: #dcaeea;">y_predict</span> = estimator.predict(x_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'y_predict&#65306;</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">'</span>, y_predict)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#30452;&#25509;&#23565;&#27604;&#30495;&#23526;&#20540;&#21644;&#38928;&#28204;&#20540;:</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">'</span>, y_test == y_predict)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26041;&#27861;&#20108;&#65306;&#35336;&#31639;&#28310;&#30906;&#29575;</span>
<span style="color: #dcaeea;">score</span> = estimator.score(x_test, y_test)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;:</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">'</span>, score)
</pre>
</div></li>
</ol>
</div>
</div>
<div id="outline-container-org44eeae7" class="outline-4">
<h4 id="org44eeae7"><span class="section-number-4">1.2.2.</span> TNFSH作業&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
修改上述程式碼，以折線圖表示K值與KNN預測準確度間的關係。
</p>
</div>
</div>
</div>
<div id="outline-container-org5fd415c" class="outline-3">
<h3 id="org5fd415c"><span class="section-number-3">1.3.</span> 決策樹實作&#xa0;&#xa0;&#xa0;<span class="tag"><span class="DecisionTree">DecisionTree</span>&#xa0;<span class="sklearn">sklearn</span></span></h3>
<div class="outline-text-3" id="text-1-3">
<p>
一棵複雜的決策樹
</p>

<div id="orgc848a4c" class="figure">
<p><img src="images/SBQNWUA1dDtFsMHv.png" alt="SBQNWUA1dDtFsMHv.png" width="800" />
</p>
<p><span class="figure-number">Figure 4: </span>Caption</p>
</div>
</div>
<div id="outline-container-org8f12bea" class="outline-4">
<h4 id="org8f12bea"><span class="section-number-4">1.3.1.</span> iris</h4>
<div class="outline-text-4" id="text-1-3-1">
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> load_iris
<span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> tree
<span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">Load in our dataset</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;"># &#35712;&#20837;&#40182;&#23614;&#33457;&#36039;&#26009;</span>
<span style="color: #dcaeea;">iris</span> = load_iris()
<span style="color: #dcaeea;">iris_x</span> = iris.data
<span style="color: #dcaeea;">iris_y</span> = iris.target

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20999;&#20998;&#35347;&#32244;&#33287;&#28204;&#35430;&#36039;&#26009;</span>
<span style="color: #dcaeea;">train_x</span>, <span style="color: #dcaeea;">test_x</span>, <span style="color: #dcaeea;">train_y</span>, <span style="color: #dcaeea;">test_y</span> = train_test_split(iris_x, iris_y, test_size = <span style="color: #da8548; font-weight: bold;">0.3</span>)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24314;&#31435;&#20998;&#39006;&#22120;</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">Initialize our decision tree object</span>
<span style="color: #dcaeea;">classification_tree</span> = tree.DecisionTreeClassifier(criterion = <span style="color: #98be65;">"entropy"</span>)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">Train our decision tree (tree induction + pruning)</span>
<span style="color: #dcaeea;">classification_tree</span> = classification_tree.fit(iris_x, iris_y)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38928;&#28204;</span>
<span style="color: #dcaeea;">test_y_predicted</span> = classification_tree.predict(test_x)
<span style="color: #c678dd;">print</span>(test_y_predicted)

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27161;&#28310;&#31572;&#26696;</span>
<span style="color: #c678dd;">print</span>(test_y)


<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#24471;&#20998;:'</span>,classification_tree.score(iris_x, iris_y))
<span style="color: #51afef;">import</span> graphviz

<span style="color: #51afef;">import</span> pydot
<span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
plt.clf()
<span style="color: #dcaeea;">dot_data</span> = tree.export_graphviz(classification_tree, out_file=<span style="color: #a9a1e1;">None</span>,
                     feature_names=iris.feature_names,
                     class_names=iris.target_names,
                     filled=<span style="color: #a9a1e1;">True</span>, rounded=<span style="color: #a9a1e1;">True</span>,
                     special_characters=<span style="color: #a9a1e1;">True</span>)
<span style="color: #dcaeea;">graph</span> = graphviz.Source(dot_data)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">graph.render("images/DecisionTree.png", view=True)</span>
graph.<span style="color: #c678dd;">format</span> = <span style="color: #98be65;">'png'</span>
graph.render(<span style="color: #98be65;">'images/DecisionTree'</span>)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig('images/DecisionTree.png', dpi=300)</span>

</pre>
</div>

<pre class="example">
[0 0 0 0 1 2 0 1 0 2 2 0 2 2 2 2 2 1 1 1 0 2 1 1 2 1 2 2 0 2 0 1 0 2 0 2 2
 0 1 1 1 2 2 0 0]
[0 0 0 0 1 2 0 1 0 2 2 0 2 2 2 2 2 1 1 1 0 2 1 1 2 1 2 2 0 2 0 1 0 2 0 2 2
 0 1 1 1 2 2 0 0]
得分: 1.0
</pre>



<div id="org5e497d0" class="figure">
<p><img src="images/DecisionTree.png" alt="DecisionTree.png" width="800" />
</p>
<p><span class="figure-number">Figure 5: </span>Decision Tree</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org65c15d8" class="outline-3">
<h3 id="org65c15d8"><span class="section-number-3">1.4.</span> 課堂作業</h3>
<div class="outline-text-3" id="text-1-4">
<ol class="org-ol">
<li>以Pandas模組讀取線上csv[<a href="https://letranger.github.io/AI/madfhantr.csv">https://letranger.github.io/AI/madfhantr.csv</a>]</li>
<li>移除有缺失值的記錄</li>
<li>將YES/NO、Male/Femal等分類值改為0/1值</li>
<li>依Gender,Married,Dependents,Education,Self_Employed這五個特徵值來決定是否核淮貸款申請</li>
<li>分別以Gini index, Entropy兩種策略來進行分類，比較效能</li>
<li>觀察其他特徵值，你有其他的想法可以提高效能嗎？</li>
</ol>
</div>
<div id="outline-container-org4763c08" class="outline-4">
<h4 id="org4763c08"><span class="section-number-4">1.4.1.</span> DEMO</h4>
<div class="outline-text-4" id="text-1-4-1">
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">1. Load the data and finish the cleaning process</span>
<span style="color: #5B6268;">##    </span><span style="color: #5B6268;">the dataset is available on kaggle too</span>
<span style="color: #dcaeea;">train</span> = pd.read_csv(<span style="color: #98be65;">'./madfhantr.csv'</span>)

<span style="color: #5B6268;">#</span><span style="color: #5B6268;">check for missing values</span>
train.isnull().<span style="color: #c678dd;">sum</span>()
<span style="color: #5B6268;">#</span>
train.dropna(inplace=<span style="color: #a9a1e1;">True</span>)
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">2. Take a Look at the data-set</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">I selected few of the columns from the dataset for this tutorial</span>
<span style="color: #dcaeea;">train</span> = train[[<span style="color: #98be65;">'Gender'</span>,<span style="color: #98be65;">'Married'</span>,<span style="color: #98be65;">'Education'</span>,<span style="color: #98be65;">'Self_Employed'</span>,<span style="color: #98be65;">'Credit_History'</span>,<span style="color: #98be65;">'Loan_Status'</span>]]

<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Gender'</span>]=train[<span style="color: #98be65;">'Gender'</span>].replace(to_replace=<span style="color: #98be65;">'Male'</span>,value=<span style="color: #98be65;">'1'</span>)
<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Gender'</span>]=train[<span style="color: #98be65;">'Gender'</span>].replace(to_replace=<span style="color: #98be65;">'Female'</span>,value=<span style="color: #98be65;">'0'</span>)


<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Married'</span>]=train[<span style="color: #98be65;">'Married'</span>].replace(to_replace=<span style="color: #98be65;">'Yes'</span>,value=<span style="color: #98be65;">'1'</span>)
<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Married'</span>]=train[<span style="color: #98be65;">'Married'</span>].replace(to_replace=<span style="color: #98be65;">'No'</span>,value=<span style="color: #98be65;">'0'</span>)


<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Self_Employed'</span>]=train[<span style="color: #98be65;">'Self_Employed'</span>].replace(to_replace=<span style="color: #98be65;">'No'</span>,value=<span style="color: #98be65;">'0'</span>)
<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Self_Employed'</span>]=train[<span style="color: #98be65;">'Self_Employed'</span>].replace(to_replace=<span style="color: #98be65;">'Yes'</span>,value=<span style="color: #98be65;">'1'</span>)


<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Education'</span>]=train[<span style="color: #98be65;">'Education'</span>].replace(to_replace=<span style="color: #98be65;">'Graduate'</span>,value=<span style="color: #98be65;">'1'</span>)
<span style="color: #dcaeea;">train</span>[<span style="color: #98be65;">'Education'</span>]=train[<span style="color: #98be65;">'Education'</span>].replace(to_replace=<span style="color: #98be65;">'Not Graduate'</span>,value=<span style="color: #98be65;">'0'</span>)
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">3. Split the data-set into train and test sets</span>
<span style="color: #dcaeea;">X</span> = train.drop(columns=[<span style="color: #98be65;">'Loan_Status'</span>])
<span style="color: #dcaeea;">y</span> = train.Loan_Status


<span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span style="color: #dcaeea;">X_train</span>,<span style="color: #dcaeea;">X_test</span>,<span style="color: #dcaeea;">y_train</span>,<span style="color: #dcaeea;">y_test</span> = train_test_split(X,y,test_size=<span style="color: #da8548; font-weight: bold;">0.3</span>,random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">4. Build the model and fit the train set.</span>
<span style="color: #51afef;">from</span> sklearn.tree <span style="color: #51afef;">import</span> DecisionTreeClassifier
<span style="color: #51afef;">from</span> sklearn <span style="color: #51afef;">import</span> tree

<span style="color: #dcaeea;">clf</span> = tree.DecisionTreeClassifier(max_depth=<span style="color: #da8548; font-weight: bold;">3</span>)
<span style="color: #dcaeea;">clf</span> = clf.fit(X_train,y_train)
<span style="color: #c678dd;">print</span>(clf.score(X_train, y_train))
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">5. Visualize the Decision Tree</span>
<span style="color: #51afef;">import</span> graphviz
<span style="color: #dcaeea;">dot_data</span> = tree.export_graphviz(clf, out_file=<span style="color: #a9a1e1;">None</span>,
                               feature_names=[<span style="color: #98be65;">'Gender'</span>,<span style="color: #98be65;">'Married'</span>,<span style="color: #98be65;">'Education'</span>,<span style="color: #98be65;">'Self_Employed'</span>,<span style="color: #98be65;">'Credit_History'</span>],
                               class_names=[<span style="color: #98be65;">'Yes'</span>,<span style="color: #98be65;">'No'</span>],filled=<span style="color: #a9a1e1;">True</span>,
                                rounded=<span style="color: #a9a1e1;">True</span>,
                              special_characters=<span style="color: #a9a1e1;">True</span>)
<span style="color: #dcaeea;">graph</span> = graphviz.Source(dot_data)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">graph.render("Gini")</span>
graph.<span style="color: #c678dd;">format</span> = <span style="color: #98be65;">'png'</span>
graph.render(<span style="color: #98be65;">'images/DecisionTree2'</span>)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">graph</span>
<span style="color: #5B6268;">## </span><span style="color: #5B6268;">6. Check the score of the model</span>
clf.score(X_test,y_test)
</pre>
</div>

<pre class="example">
0.8125
</pre>


<div id="orgc1ba5a6" class="figure">
<p><img src="images/DecisionTree2.png" alt="DecisionTree2.png" width="800" />
</p>
<p><span class="figure-number">Figure 6: </span>Bank Load 2</p>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orgc307049" class="outline-2">
<h2 id="orgc307049"><span class="section-number-2">2.</span> 分類實作: MNIST(二元分類與多元分類)&#xa0;&#xa0;&#xa0;<span class="tag"><span class="sklearn">sklearn</span>&#xa0;<span class="DSG">DSG</span>&#xa0;<span class="SVM">SVM</span></span></h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org951b0a4" class="outline-3">
<h3 id="org951b0a4"><span class="section-number-3">2.1.</span> MNIST 資料集</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>MNIST 是機器學習領域中相當著名的資料集，因為太多研究者使用，故號稱機器學習領域的「Hello world.」，其重要性不言可喻。</li>
<li>MNIST 資料集由 0~9 的數字影像構成(如圖<a href="#org708dccd">7</a>)，共計 70000 張訓練影像、10000 張測試影像。</li>
<li>由美國高中生和人口普查局員工手寫。</li>
<li>一般的 MMIST 資料集的用法為：使用訓練影像進行學習，再利用學習後的模型預測能否正確分類測試影像。</li>
</ul>

<div id="org708dccd" class="figure">
<p><img src="images/MNIST.jpg" alt="MNIST.jpg" width="400" />
</p>
<p><span class="figure-number">Figure 7: </span>MNIST 資料集內容範例</p>
</div>
</div>
</div>
<div id="outline-container-org094c882" class="outline-3">
<h3 id="org094c882"><span class="section-number-3">2.2.</span> 準備 MNIST 資料</h3>
<div class="outline-text-3" id="text-2-2">
<p>
MNIST 數據集來自美國國家標準與技術研究所, National Institute of Standards and Technology (NIST). 訓練集 (training set) 由來自 250 個不同人手寫的數字構成, 其中 50% 是高中學生, 50% 來自人口普查局 (the Census Bureau) 的工作人員. 測試集(test set) 也是同樣比例的手寫數字數據。MNIST 數據集可在 <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 獲取, 它包含了四個部分:
</p>
<ol class="org-ol">
<li>Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解壓後 47 MB, 包含 60,000 個樣本)</li>
<li>Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解壓後 60 KB, 包含 60,000 個標籤)</li>
<li>Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解壓後 7.8 MB, 包含 10,000 個樣本)</li>
<li>Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解壓後 10 KB, 包含 10,000 個標籤)</li>
</ol>
</div>
<div id="outline-container-org1968923" class="outline-4">
<h4 id="org1968923"><span class="section-number-4">2.2.1.</span> 以Scikit-Learn下載</h4>
<div class="outline-text-4" id="text-2-2-1">
<div class="org-src-container">
<pre class="src src-python"> :session MNIST
<span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span style="color: #dcaeea;">mnist</span> = fetch_openml(<span style="color: #98be65;">'mnist_784'</span>, version=<span style="color: #da8548; font-weight: bold;">1</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session MNIST
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(mnist.keys())
</pre>
</div>

<pre class="example">
dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])
</pre>

<p>
大部份可以下載的資料組都長會有data、target(label)、DESCR等屬性。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session MNIST
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(mnist))
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(mnist[<span style="color: #98be65;">'data'</span>].shape)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(mnist[<span style="color: #98be65;">'target'</span>].shape)
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(mnist[<span style="color: #98be65;">'DESCR'</span>][<span style="color: #da8548; font-weight: bold;">0</span>:<span style="color: #da8548; font-weight: bold;">100</span>])
</pre>
</div>

<pre class="example">
&lt;class 'sklearn.utils.Bunch'&gt;
(70000, 784)
(70000,)
**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges
**Source**: [MNIST Website](http:/
</pre>



<p>
每一個手寫數字以一個長度為784 (28*28)的list儲存
</p>
</div>
</div>
<div id="outline-container-org1e7fad9" class="outline-4">
<h4 id="org1e7fad9"><span class="section-number-4">2.2.2.</span> 以tensorflow下載</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
MNIST 資料集是一個適合拿來當作 TensotFlow 的練習素材，在 Tensorflow 的現有套件中，也已經有內建好的 MNIST 資料集，我們只要在安裝好 TensorFlow 的 Python 環境中執行以下程式碼，即可將 MNIST 資料成功讀取進來。.
</p>
<div class="org-src-container">
<pre class="src src-python"> :<span style="color: #c678dd;">eval</span> no
<span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span id="coderef-get-keras-mnist" class="coderef-off">(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()</span>
</pre>
</div>
<p>
在訓練模型之前，需要將樣本資料劃分為訓練集、測試集，有些情況下還會劃分為訓練集、測試集、驗證集。由上述程式第<a href="#coderef-get-keras-mnist" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-get-keras-mnist');" onmouseout="CodeHighlightOff(this, 'coderef-get-keras-mnist');">4</a>行可知，下載後的 MNIST 資料分成訓練資料(training data)與測試資料(testing data)，其中 x 為圖片、y為所對應數字。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 3: </span><span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 4: </span>(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21028;&#26039;&#36039;&#26009;&#24418;&#29376;</span>
<span class="linenr"> 7: </span><span style="color: #c678dd;">print</span>(x_train.shape)
<span class="linenr"> 8: </span><span style="color: #c678dd;">print</span>(x_test.shape)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31532;&#19968;&#20491;label&#30340;&#20839;&#23481;</span>
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#24433;&#20687;&#20839;&#23481;</span>
<span class="linenr">12: </span><span style="color: #51afef;">import</span> matplotlib.pylab <span style="color: #51afef;">as</span> plt
<span class="linenr">13: </span><span style="color: #dcaeea;">img</span> = x_train[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">14: </span>plt.imshow(img)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">"MNIST-Image.png"</span>)
</pre>
</div>
<pre class="example">
(60000, 28, 28)
(10000, 28, 28)
5
</pre>


<p>
由上述程式輸出結果可以看到載入的 x 為大小為 28*28 的圖片共 60000 張，每一筆 MNIST 資料的照片(x)由 784 個 pixels 組成（28*28），照片內容如圖<a href="#org5f660de">19</a>，訓練集的標籤(y)則為其對應的數字(0～9)，此例為 5。
</p>

<div id="org5fe59aa" class="figure">
<p><img src="images/MNIST-Image.png" alt="MNIST-Image.png" width="300" />
</p>
<p><span class="figure-number">Figure 8: </span>MNIST 影像示例</p>
</div>

<p>
x 的影像資料為灰階影像，每個像素的數值介於 0~255 之間，矩陣裡每一項的資料則是代表每個 pixel 顏色深淺的數值，如下圖<a href="#org18cb7fc">20</a>所示：
</p>

<div id="org25e73b6" class="figure">
<p><img src="images/MNIST-Matrix.png" alt="MNIST-Matrix.png" width="300" />
</p>
<p><span class="figure-number">Figure 9: </span>MNIST 資料矩陣</p>
</div>

<p>
載入的 y 為所對應的數字 0~9，在這我們要運用 keras 中的 np_utils.to_categorical 將 y 轉成 one-hot 的形式，將他轉為一個 10 維的 vector，例如：我們所拿到的資料為 y=3，經過 np_utils.to_categorical，會轉換為 y=[0,0,0,1,0,0,0,0,0,0]。這部份的轉換程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr"> 3: </span>  <span style="color: #51afef;">from</span> keras.utils <span style="color: #51afef;">import</span> np_utils
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span>  <span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 6: </span>  <span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 7: </span>  (x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 8: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 9: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#22294;&#29255;&#36681;&#25563;&#28858;&#19968;&#20491;60000*784&#30340;&#21521;&#37327;&#65292;&#20006;&#19988;&#27161;&#28310;&#21270;</span>
<span class="linenr">10: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.reshape(x_train.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">11: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.reshape(x_test.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">12: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">13: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">14: </span>  <span style="color: #dcaeea;">x_train</span> = x_train/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">15: </span>  <span style="color: #dcaeea;">x_test</span> = x_test/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">16: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">17: </span>  <span style="color: #dcaeea;">y_train</span> = np_utils.to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">18: </span>  <span style="color: #dcaeea;">y_test</span> = np_utils.to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">19: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">20: </span>  <span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">21: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">22: </span>  np.set_printoptions(precision=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">23: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">print(x_train[0])</span>
</pre>
</div>

<pre class="example">
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</pre>
</div>
</div>
</div>
<div id="outline-container-org1bdecea" class="outline-3">
<h3 id="org1bdecea"><span class="section-number-3">2.3.</span> 查看MNIST內容</h3>
<div class="outline-text-3" id="text-2-3">
</div>
<div id="outline-container-orge807970" class="outline-4">
<h4 id="orge807970"><span class="section-number-4">2.3.1.</span> 先把bunch存起來</h4>
<div class="outline-text-4" id="text-2-3-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session MNIST
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr">3: </span><span style="color: #dcaeea;">mnist</span> = fetch_openml(<span style="color: #98be65;">'mnist_784'</span>, version=<span style="color: #da8548; font-weight: bold;">1</span>, as_frame=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#22240;&#28858;fetch_openml&#38928;&#35373;&#26371;&#20659;&#22238;pandas&#30340;dataframe&#65292;&#26371;&#21547;column&#30340;title&#65292;&#21487;&#20197;&#23559;as_frame&#35373;&#28858;false</span>
<span class="linenr">5: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr">6: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'wb'</span>) <span style="color: #51afef;">as</span> bunch:
<span class="linenr">7: </span>    pickle.dump(mnist, bunch, protocol=pickle.HIGHEST_PROTOCOL)
</pre>
</div>

<pre class="example">
&gt;&gt;&gt;
</pre>
</div>
</div>
<div id="outline-container-org5fb81c0" class="outline-4">
<h4 id="org5fb81c0"><span class="section-number-4">2.3.2.</span> 再讀回pkl</h4>
<div class="outline-text-4" id="text-2-3-2">
<p>
此時讀回mnist無header, index，適合分析
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :BinaryMNIST
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr"> 4: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> bunch:
<span class="linenr"> 5: </span>    <span style="color: #dcaeea;">mnist</span> = pickle.load(bunch)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #dcaeea;">one_digit</span> = X[<span style="color: #da8548; font-weight: bold;">9527</span>]
<span class="linenr">12: </span><span style="color: #dcaeea;">one_digit_image</span> = one_digit.reshape(<span style="color: #da8548; font-weight: bold;">28</span>, <span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20197;&#22294;&#29255;&#21576;&#29694;</span>
<span class="linenr">15: </span>plt.imshow(one_digit_image)
<span class="linenr">16: </span>plt.savefig(<span style="color: #98be65;">'images/Mnist9527.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">17: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(y[<span style="color: #da8548; font-weight: bold;">9527</span>]))
<span class="linenr">18: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">19: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr">20: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(y[<span style="color: #da8548; font-weight: bold;">9527</span>]))
</pre>
</div>

<pre class="example">
&lt;class 'str'&gt;
&lt;class 'numpy.uint8'&gt;
</pre>


<div id="orgba92c44" class="figure">
<p><img src="images/MNIST9527.png" alt="MNIST9527.png" width="300" />
</p>
<p><span class="figure-number">Figure 10: </span>Caption</p>
</div>
<ul class="org-ul">
<li>多數的演算法label均期望為數字，故應改為int (np.unit8())</li>
<li><p>
分為測試組與訓練組最好是label 0~9平均分佈，MNIST已事先安排好(前60000張為訓練組)
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BinaryMNIST
<span class="linenr">2: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30001;&#36889;&#20491;&#23531;&#27861;&#21487;&#20197;&#29702;&#35299;&#28858;&#20160;&#40636;index&#30340;&#35486;&#27861;&#35201;&#36889;&#27171;&#35373;&#35336;</span>
<span class="linenr">3: </span>  <span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
</pre>
</div></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge816385" class="outline-3">
<h3 id="orge816385"><span class="section-number-3">2.4.</span> 訓練二元分類器</h3>
<div class="outline-text-3" id="text-2-4">
<p>
先簡化分類工作: 每次辨識是否為某一數字(如2)
</p>
</div>
<div id="outline-container-orgbad0bb4" class="outline-4">
<h4 id="orgbad0bb4"><span class="section-number-4">2.4.1.</span> 先建立目標向量</h4>
<div class="outline-text-4" id="text-2-4-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BinaryMNIST
<span class="linenr">2: </span><span style="color: #dcaeea;">y_train_is2</span> = (y_train == <span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">3: </span><span style="color: #dcaeea;">y_test_is2</span> = (y_test ==<span style="color: #da8548; font-weight: bold;">2</span>)
</pre>
</div>

<p>
Scikit-Learn的SDGClassifier可高效處理大量資料庫，也十分適合線上學習系統。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#20837;data set</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 4: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr"> 5: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> bunch:
<span class="linenr"> 6: </span>    <span style="color: #dcaeea;">mnist</span> = pickle.load(bunch)
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr"> 9: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">10: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr">11: </span>
<span class="linenr">12: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#28858;&#28204;&#35430;&#32068;&#33287;&#35347;&#32244;&#32068;</span>
<span class="linenr">13: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20108;&#20803;&#20998;&#39006;&#30446;&#27161;&#20989;&#24335;</span>
<span class="linenr">15: </span><span style="color: #dcaeea;">y_train_is2</span> = (y_train == <span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">16: </span><span style="color: #dcaeea;">y_test_is2</span> = (y_test ==<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">17: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;model</span>
<span class="linenr">18: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> SGDClassifier
<span class="linenr">19: </span><span style="color: #dcaeea;">sgd_clf</span> = SGDClassifier(max_iter=<span style="color: #da8548; font-weight: bold;">1000</span>, tol=1e-<span style="color: #da8548; font-weight: bold;">3</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">20: </span>sgd_clf.fit(X_train, y_train_is2)
<span class="linenr">21: </span><span style="color: #c678dd;">print</span>(sgd_clf)
<span class="linenr">22: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#29992;&#20358;&#38928;&#28204;&#31532;9527&#34399;&#22294;&#29255;(labe&#28858;2)</span>
<span class="linenr">23: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(X[<span style="color: #da8548; font-weight: bold;">9527</span>])) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">ndarray</span>
<span class="linenr">24: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>([X[<span style="color: #da8548; font-weight: bold;">9527</span>]])) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">list</span>
<span class="linenr">25: </span><span style="color: #dcaeea;">result</span> = sgd_clf.predict([X[<span style="color: #da8548; font-weight: bold;">9527</span>]]) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#28858;&#20160;&#40636;&#21482;&#33021;&#19999;list&#36914;&#21435;?</span>
<span class="linenr">26: </span><span style="color: #c678dd;">print</span>(result, <span style="color: #98be65;">'label: '</span>, y[<span style="color: #da8548; font-weight: bold;">9527</span>])
<span class="linenr">27: </span><span style="color: #dcaeea;">result</span> = sgd_clf.predict([X[<span style="color: #da8548; font-weight: bold;">9528</span>]])
<span class="linenr">28: </span><span style="color: #c678dd;">print</span>(result, <span style="color: #98be65;">'label: '</span>,y[<span style="color: #da8548; font-weight: bold;">9528</span>])
<span class="linenr">29: </span>
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; SGDClassifier(random_state=42)
&lt;class 'numpy.ndarray'&gt;
&lt;class 'list'&gt;
[ True] label:  2
[False] label:  8
</pre>
</div>
</div>
<div id="outline-container-org2e820c1" class="outline-4">
<h4 id="org2e820c1"><span class="section-number-4">2.4.2.</span> 效能評估</h4>
<div class="outline-text-4" id="text-2-4-2">
</div>
<ol class="org-ol">
<li><a id="orgcbf2cd9"></a>K-folder 交叉驗證: 把訓練集拆成K個fold<br />
<div class="outline-text-5" id="text-2-4-2-1">

<div id="org060d643" class="figure">
<p><img src="images/20200312143156767.png" alt="20200312143156767.png" width="500" />
</p>
<p><span class="figure-number">Figure 11: </span>Cross Validation</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_score <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30475;&#24471;&#20998;</span>
<span class="linenr">3: </span><span style="color: #dcaeea;">scores</span> = cross_val_score(sgd_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(scores)
</pre>
</div>

<pre class="example">
[0.96645 0.95895 0.904  ]
</pre>
</div>
</li>
<li><a id="orgb5236f3"></a>測試一下其他數字的效能<br />
<div class="outline-text-5" id="text-2-4-2-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24314;&#31435;&#19968;&#20491;&#21028;&#26039;&#26159;&#21542;&#28858;&#25976;&#23383;7&#30340;&#30446;&#27161;&#20989;&#24335;</span>
<span class="linenr">3: </span><span style="color: #dcaeea;">y_train_is7</span> = (y_train == <span style="color: #da8548; font-weight: bold;">7</span>)
<span class="linenr">4: </span>
<span class="linenr">5: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35347;&#32244;</span>
<span class="linenr">6: </span>sgd_clf.fit(X_train, y_train_is7)
<span class="linenr">7: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#35413;&#20998;</span>
<span class="linenr">8: </span><span style="color: #dcaeea;">scores</span> = cross_val_score(sgd_clf, X_train, y_train_is7, cv=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">9: </span><span style="color: #c678dd;">print</span>(scores)
</pre>
</div>
<pre class="example">
[0.98033333 0.9825     0.97333333 0.97725    0.97633333]
</pre>
</div>
</li>
<li><a id="orge7bc26f"></a>混淆矩陣<br />
<div class="outline-text-5" id="text-2-4-2-3">
<p>
評估分類器的較佳工具為confusion matrx，其原理為查看類別A被判定為類別B的次數
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">3: </span><span style="color: #dcaeea;">y_train_pred</span> = cross_val_predict(sgd_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">4: </span>
<span class="linenr">5: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> confusion_matrix
<span class="linenr">6: </span><span style="color: #dcaeea;">result</span> = confusion_matrix(y_train_is7, y_train_pred)
<span class="linenr">7: </span>
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(y_train_pred)
<span class="linenr">9: </span><span style="color: #c678dd;">print</span>(result)
</pre>
</div>

<pre class="example">
[False False False ... False False False]
[[46293  7442]
 [ 6153   112]]
</pre>


<p>
cross_val_predict傳回對各個測試fold進行的預測，confusion matrix傳回的矩陣值如下
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">實際為7</th>
<th scope="col" class="org-left">實際不是7</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">預測為7</td>
<td class="org-left">TP(True Positive)</td>
<td class="org-left">FP(False Positive)</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Type I Error</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">預測不是7</td>
<td class="org-left">FN(False Negative)</td>
<td class="org-left">TN(True Negative)</td>
</tr>

<tr>
<td class="org-left">Type II Error</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
<p>
結果表示：60000張圖片中有46293被model <b>正確預測</b> 為7、有112張被model <b>正確預測</b> 不是7。
</p>

<div id="org5eaaa0e" class="figure">
<p><img src="images/2022-05-05_15-30-09.jpg" alt="2022-05-05_15-30-09.jpg" width="500" />
</p>
<p><span class="figure-number">Figure 12: </span>Caption</p>
</div>
</div>
</li>
<li><a id="orgb6c407d"></a>幾種不同的precision指標<br />
<ol class="org-ol">
<li><a id="orgbad2b69"></a>Precision<br />
<div class="outline-text-6" id="text-2-4-2-4-1">
<p>
\[precision=\frac{TP}{TP+FP}\]
這種評估方式的問題在於只做陽性預測的準確率，忽略了positive之外的問題。就是只對 <b>預測出為7</b> 的那些case感興趣
</p>
</div>
</li>
<li><a id="orga3b9e1f"></a>Recall<br />
<div class="outline-text-6" id="text-2-4-2-4-2">
<p>
\[ recall=\frac{TP}{TP+FN} \]
也叫sensitivity，這是分類器正確認出positve實例的比例，就是只對 <b>實際為7</b> 的那些例子感興趣，
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y_train_pred</span> = cross_val_predict(sgd_clf, X_train, y_train_is7, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> precision_score, recall_score
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">preScore</span> = precision_score(y_train_is7, y_train_pred)
<span class="linenr"> 8: </span><span style="color: #dcaeea;">recScore</span> = recall_score(y_train_is7, y_train_pred)
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Precision Score: </span>{preScore}<span style="color: #98be65;">'</span>)
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'Rescore Score: </span>{recScore}<span style="color: #98be65;">'</span>)
</pre>
</div>
<pre class="example">
Precision Score: 0.8285544495617293
Rescore Score: 0.8901835594573024
</pre>
</div>
</li>
<li><a id="org2b88c15"></a>Precision與Recall的取捨<br />
<div class="outline-text-6" id="text-2-4-2-4-3">
<ul class="org-ul">
<li>兒童影片分類: 寧可錯殺(low recall)，希望能多找出兒童不宜的影片(高precision)，可以犧牲recall</li>
<li>監控小偷的影片分類：希望recall多一點，只要實際有小偷，就一定要判斷出來，可以犧牲precision</li>
<li>地震：recall要高，情願發出1000次警報，把10次地震都預測正確了；也不要預測100次對了8次漏了兩次。</li>
<li>嫌疑人定罪:基於不錯怪一個好人的原則，對於嫌疑人的定罪我們希望是非常準確的。及時有時候放過了一些罪犯（recall低），但也是值得的。</li>
<li>森林大火呢</li>
</ul>
</div>
</li>
<li><a id="org8c84cf3"></a>\(F_1\)<br />
<div class="outline-text-6" id="text-2-4-2-4-4">
<p>
另一種整合precision與recall的評量標準，其公式為:
\[F_1=\frac{2}{\frac{1}{precision}+\frac{1}{recall}}\]
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> f1_score
<span class="linenr">3: </span><span style="color: #dcaeea;">f1Score</span> = f1_score(y_train_is7, y_train_pred)
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'F1 score: </span>{f1Score}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
F1 score: 0.8582640812557709
</pre>
</div>
</li>
</ol>
</li>
<li><a id="org1250ce3"></a>Precision, Recall, Threhold<br />
<div class="outline-text-5" id="text-2-4-2-5">
<p>
Scikit-Learn以決策函數來為每個instance算分數，若分數大於某個threshold(閥值)，就設為positive，否則就為negative。
</p>

<div id="org63f4454" class="figure">
<p><img src="images/2022-05-05_15-31-03.png" alt="2022-05-05_15-31-03.png" width="500" />
</p>
<p><span class="figure-number">Figure 13: </span>Caption</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #dcaeea;">sgd_clf</span> = SGDClassifier(max_iter=<span style="color: #da8548; font-weight: bold;">1000</span>, tol=1e-<span style="color: #da8548; font-weight: bold;">3</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr"> 3: </span>sgd_clf.fit(X_train, y_train_is2)
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">y_scores</span> = sgd_clf.decision_function([X[<span style="color: #da8548; font-weight: bold;">9527</span>]])
<span class="linenr"> 6: </span><span style="color: #c678dd;">print</span>(y_scores)
<span class="linenr"> 7: </span><span style="color: #dcaeea;">threshold</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">y_scores</span> = cross_val_predict(sgd_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>, method=<span style="color: #98be65;">"decision_function"</span>)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> precision_recall_curve
<span class="linenr">11: </span><span style="color: #dcaeea;">precisions</span>, <span style="color: #dcaeea;">recalls</span>, <span style="color: #dcaeea;">thresholds</span> = precision_recall_curve(y_train_is2, y_scores)
<span class="linenr">12: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'precision: </span>{precisions}<span style="color: #98be65;">'</span>)
<span class="linenr">13: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'recalls: </span>{recalls}<span style="color: #98be65;">'</span>)
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'thresholds: </span>{thresholds}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
[6878.3086925]
precision: [0.10072015 0.10070495 0.10070665 ... 1.         1.         1.        ]
recalls: [1.00000000e+00 9.99832158e-01 9.99832158e-01 ... 3.35683115e-04
 1.67841558e-04 0.00000000e+00]
thresholds: [-69733.7356162  -69719.34570155 -69711.85512195 ...  56894.63040719
  59479.43254173  59763.44817006]
</pre>

<p>
二者間的關係
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 3: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_precision_recall_vs_threshold</span>(precisions, recalls, thresholds):
<span class="linenr"> 4: </span>    plt.plot(thresholds, precisions[:-<span style="color: #da8548; font-weight: bold;">1</span>], <span style="color: #98be65;">"b--"</span>, label=<span style="color: #98be65;">"Precision"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr"> 5: </span>    plt.plot(thresholds, recalls[:-<span style="color: #da8548; font-weight: bold;">1</span>], <span style="color: #98be65;">"g-"</span>, label=<span style="color: #98be65;">"Recall"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr"> 6: </span>    plt.legend(loc=<span style="color: #98be65;">"center right"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 7: </span>    plt.xlabel(<span style="color: #98be65;">"Threshold"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 8: </span>    plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr"> 9: </span>    plt.axis([-<span style="color: #da8548; font-weight: bold;">50000</span>, <span style="color: #da8548; font-weight: bold;">50000</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>])             <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Not shown</span>
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #dcaeea;">recall_90_precision</span> = recalls[np.argmax(precisions &gt;= <span style="color: #da8548; font-weight: bold;">0.90</span>)]
<span class="linenr">12: </span><span style="color: #dcaeea;">threshold_90_precision</span> = thresholds[np.argmax(precisions &gt;= <span style="color: #da8548; font-weight: bold;">0.90</span>)]
<span class="linenr">13: </span>
<span class="linenr">14: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">4</span>))
<span class="linenr">15: </span>plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
<span class="linenr">16: </span>plt.plot([threshold_90_precision, threshold_90_precision], [<span style="color: #da8548; font-weight: bold;">0</span>., <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">17: </span>plt.plot([-<span style="color: #da8548; font-weight: bold;">50000</span>, threshold_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>, <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">18: </span>plt.plot([-<span style="color: #da8548; font-weight: bold;">50000</span>, threshold_90_precision], [recall_90_precision, recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">19: </span>plt.plot([threshold_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">20: </span>plt.plot([threshold_90_precision], [recall_90_precision], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">21: </span>plt.savefig(<span style="color: #98be65;">"images/precision_recall_vs_threshold_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">22: </span>plt.show()
<span class="linenr">23: </span>
</pre>
</div>

<p width="500">
<img src="images/precision_recall_vs_threshold_plot.png" alt="precision_recall_vs_threshold_plot.png" width="500" />
要做出precision與recall的取捨，另一種方式是畫出二者的關係圖
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_precision_vs_recall</span>(precisions, recalls):
<span class="linenr"> 3: </span>    plt.plot(recalls, precisions, <span style="color: #98be65;">"b-"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>)&#65292;
<span class="linenr"> 4: </span>    plt.xlabel(<span style="color: #98be65;">"Recall"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 5: </span>    plt.ylabel(<span style="color: #98be65;">"Precision"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 6: </span>    plt.axis([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 7: </span>    plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">10: </span>plot_precision_vs_recall(precisions, recalls)
<span class="linenr">11: </span>plt.plot([recall_90_precision, recall_90_precision], [<span style="color: #da8548; font-weight: bold;">0</span>., <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">12: </span>plt.plot([<span style="color: #da8548; font-weight: bold;">0.0</span>, recall_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>, <span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">13: </span>plt.plot([recall_90_precision], [<span style="color: #da8548; font-weight: bold;">0.9</span>], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">14: </span>plt.savefig(<span style="color: #98be65;">"images/precision_vs_recall_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">15: </span>plt.show()
</pre>
</div>

<p width="500">
<img src="images/precision_vs_recall_plot.png" alt="precision_vs_recall_plot.png" width="500" />
若目標為90%的precision(如圖<a href="#org988e6cb">14</a>)，其threshold大約在8000，若要求較精確的值，可以透過np.argmax()
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #dcaeea;">threshold_90_precision</span> = thresholds[np.argmax(precisions &gt;= <span style="color: #da8548; font-weight: bold;">0.90</span>)]
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(threshold_90_precision)
<span class="linenr">4: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#20197;&#36889;&#20491;threshold&#20358;&#21462;&#20195;&#20998;&#39006;&#22120;&#20013;&#30340;predict()</span>
<span class="linenr">5: </span><span style="color: #dcaeea;">y_train_pred_90</span> = (y_scores &gt;= threshold_90_precision)
<span class="linenr">6: </span><span style="color: #dcaeea;">nPreSco</span> = precision_score(y_train_is2, y_train_pred_90)
<span class="linenr">7: </span><span style="color: #dcaeea;">nRecSco</span> = recall_score(y_train_is2, y_train_pred_90)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'New precision score: </span>{nPreSco}<span style="color: #98be65;">'</span>)
<span class="linenr">9: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'New recall score: </span>{nRecSco}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
5585.140261597363
New precision score: 0.9000641985876311
New recall score: 0.7059415911379657
</pre>

<p>
現在precision就有90%了&#x2026;.
</p>
</div>
</li>
<li><a id="org285a49f"></a>ROC曲線<br />
<div class="outline-text-5" id="text-2-4-2-6">
<p>
接收者業特徵(receiver operating characteristic, ROC)曲線也常和二元分類一起使用，主要是畫出true positive率(recall) v.s. false positive率。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> roc_curve
<span class="linenr"> 3: </span><span style="color: #dcaeea;">fpr</span>, <span style="color: #dcaeea;">tpr</span>, <span style="color: #dcaeea;">thresholds</span> = roc_curve(y_train_is2, y_scores)
<span class="linenr"> 4: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_roc_curve</span>(fpr, tpr, label=<span style="color: #a9a1e1;">None</span>):
<span class="linenr"> 5: </span>    plt.plot(fpr, tpr, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>, label=label)
<span class="linenr"> 6: </span>    plt.plot([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>], [<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>], <span style="color: #98be65;">'k--'</span>) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">dashed diagonal</span>
<span class="linenr"> 7: </span>    plt.axis([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 8: </span>    plt.xlabel(<span style="color: #98be65;">'False Positive Rate (Fall-Out)'</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr"> 9: </span>    plt.ylabel(<span style="color: #98be65;">'True Positive Rate (Recall)'</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr">10: </span>    plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr">11: </span>
<span class="linenr">12: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">13: </span>plot_roc_curve(fpr, tpr)
<span class="linenr">14: </span><span style="color: #dcaeea;">fpr_90</span> = fpr[np.argmax(tpr &gt;= recall_90_precision)]
<span class="linenr">15: </span>plt.plot([fpr_90, fpr_90], [<span style="color: #da8548; font-weight: bold;">0</span>., recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">16: </span>plt.plot([<span style="color: #da8548; font-weight: bold;">0.0</span>, fpr_90], [recall_90_precision, recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">17: </span>plt.plot([fpr_90], [recall_90_precision], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">18: </span>plt.savefig(<span style="color: #98be65;">"images/roc_curve_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">19: </span>plt.show()
</pre>
</div>

<div id="orgd70df42" class="figure">
<p><img src="images/roc_curve_plot.png" alt="roc_curve_plot.png" width="500" />
</p>
<p><span class="figure-number">Figure 14: </span>所有可能的threshold的false positive率與true positive率</p>
</div>

<p>
這個曲線意味著效能還有改善的空間，即，曲線應該還以再往左上方成長
</p>
</div>
<ol class="org-ol">
<li><a id="orgecf5429"></a>比較不同分類器的效能<br />
<div class="outline-text-6" id="text-2-4-2-6-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session BM
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.ensemble <span style="color: #51afef;">import</span> RandomForestClassifier
<span class="linenr"> 3: </span><span style="color: #dcaeea;">forest_clf</span> = RandomForestClassifier(n_estimators=<span style="color: #da8548; font-weight: bold;">100</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr"> 4: </span><span style="color: #dcaeea;">y_probas_forest</span> = cross_val_predict(forest_clf, X_train, y_train_is2, cv=<span style="color: #da8548; font-weight: bold;">3</span>,
<span class="linenr"> 5: </span>                                    method=<span style="color: #98be65;">"predict_proba"</span>)
<span class="linenr"> 6: </span><span style="color: #dcaeea;">y_scores_forest</span> = y_probas_forest[:, <span style="color: #da8548; font-weight: bold;">1</span>] <span style="color: #5B6268;"># </span><span style="color: #5B6268;">score = positive&#39006;&#21029;&#30340;&#27231;&#29575;</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">fpr_forest</span>, <span style="color: #dcaeea;">tpr_forest</span>, <span style="color: #dcaeea;">thresholds_forest</span> = roc_curve(y_train_is2,y_scores_forest)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">recall_for_forest</span> = tpr_forest[np.argmax(fpr_forest &gt;= fpr_90)]
<span class="linenr">10: </span>
<span class="linenr">11: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">12: </span>plt.plot(fpr, tpr, <span style="color: #98be65;">"b:"</span>, linewidth=<span style="color: #da8548; font-weight: bold;">2</span>, label=<span style="color: #98be65;">"SGD"</span>)
<span class="linenr">13: </span>plot_roc_curve(fpr_forest, tpr_forest, <span style="color: #98be65;">"Random Forest"</span>)
<span class="linenr">14: </span>plt.plot([fpr_90, fpr_90], [<span style="color: #da8548; font-weight: bold;">0</span>., recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">15: </span>plt.plot([<span style="color: #da8548; font-weight: bold;">0.0</span>, fpr_90], [recall_90_precision, recall_90_precision], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">16: </span>plt.plot([fpr_90], [recall_90_precision], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">17: </span>plt.plot([fpr_90, fpr_90], [<span style="color: #da8548; font-weight: bold;">0</span>., recall_for_forest], <span style="color: #98be65;">"r:"</span>)
<span class="linenr">18: </span>plt.plot([fpr_90], [recall_for_forest], <span style="color: #98be65;">"ro"</span>)
<span class="linenr">19: </span>plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr">20: </span>plt.legend(loc=<span style="color: #98be65;">"lower right"</span>, fontsize=<span style="color: #da8548; font-weight: bold;">16</span>)
<span class="linenr">21: </span>plt.savefig(<span style="color: #98be65;">"images/roc_curve_comparison_plot.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">22: </span>plt.show()
</pre>
</div>


<div id="org8c25e9b" class="figure">
<p><img src="images/roc_curve_comparison_plot.png" alt="roc_curve_comparison_plot.png" width="500" />
</p>
<p><span class="figure-number">Figure 15: </span>隨機森林分類器 v.s. SGD分類器</p>
</div>
</div>
</li>
</ol>
</li>
</ol>
</div>
</div>
<div id="outline-container-org93d2a8e" class="outline-3">
<h3 id="org93d2a8e"><span class="section-number-3">2.5.</span> 多類別分類器</h3>
<div class="outline-text-3" id="text-2-5">
<ul class="org-ul">
<li>同時可以處理多類別與二元分類的分類器: SGD classifiers, Random Forest classifiers, and naive Bayes classifiers</li>
<li>只能做二元分類: Logistic Regression or Support Vector Machine classifiers</li>
</ul>
</div>
<div id="outline-container-org1edc011" class="outline-4">
<h4 id="org1edc011"><span class="section-number-4">2.5.1.</span> SVM</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
當然也可以拿二元類器(如SVM)來實作多類別分類，例如：
</p>
<ul class="org-ul">
<li>訓練10個二元分類器，每個分類器負責一個數字，這種做法叫one-versus-the-rest(OvR)策略，也叫one-versus-all</li>
<li>另一種做法是幫每一對數字訓練一個二元分類器(0:1, 0:2, 0:3, &#x2026; 1:2, 1:3,&#x2026;..)，這種做法叫one-versus-one(OvO)，麻煩的地方是要建立太多分類器(此例中要訓練出45組)，優點是訓練時只要比較兩個類別</li>
</ul>
</div>
</div>
<div id="outline-container-orgeee4550" class="outline-4">
<h4 id="orgeee4550"><span class="section-number-4">2.5.2.</span> OvO</h4>
<div class="outline-text-4" id="text-2-5-2">
<p>
這段程式用訓練組(X_train)和目標類別(y_train) 來訓練45個SVM二元分類器，取得對於圖片的研判分數，選擇最後在互相競爭中勝出的類別。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.svm <span style="color: #51afef;">import</span> SVC
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #dcaeea;">svm_clf</span> = SVC(gamma=<span style="color: #98be65;">"auto"</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">5: </span>svm_clf.fit(X_train[:<span style="color: #da8548; font-weight: bold;">10000</span>], y_train[:<span style="color: #da8548; font-weight: bold;">10000</span>]) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">y_train, not y_train_2</span>
<span class="linenr">6: </span><span style="color: #dcaeea;">svmResult</span> = svm_clf.predict([X[<span style="color: #da8548; font-weight: bold;">9527</span>]])
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'OvO prediction: </span>{svmResult}<span style="color: #98be65;">'</span>)
</pre>
</div>

<pre class="example">
SVM prediction: [2]
</pre>

<p>
其實上述程式共做了10次預測:
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session BM
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(svm_clf.decision_function([X[<span style="color: #da8548; font-weight: bold;">9527</span>]]))
</pre>
</div>

<pre class="example">
[[ 3.83583746  8.03753281  9.29908463  5.86497842  2.82087068 -0.22917658
   4.84708487  6.91484871  0.80125693  1.81963445]]
</pre>

<p>
其中第三個(9.299&#x2026; 代表2)得分最高
</p>
</div>
</div>
<div id="outline-container-orga8642d9" class="outline-4">
<h4 id="orga8642d9"><span class="section-number-4">2.5.3.</span> OvR</h4>
<div class="outline-text-4" id="text-2-5-3">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session ERR
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> pickle
<span class="linenr"> 4: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> bunch:
<span class="linenr"> 5: </span>    <span style="color: #dcaeea;">mnist</span> = pickle.load(bunch)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr"> 8: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 9: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#28858;&#28204;&#35430;&#32068;&#33287;&#35347;&#32244;&#32068;</span>
<span class="linenr">12: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #51afef;">from</span> sklearn.svm <span style="color: #51afef;">import</span> SVC
<span class="linenr">15: </span><span style="color: #51afef;">from</span> sklearn.multiclass <span style="color: #51afef;">import</span> OneVsRestClassifier
<span class="linenr">16: </span><span style="color: #dcaeea;">ovr_clf</span> = OneVsRestClassifier(SVC(gamma=<span style="color: #98be65;">"auto"</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>))
<span class="linenr">17: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25343;&#21069;10000&#31558;&#36039;&#35338;&#36914;&#21435;&#35347;&#32244;&#30340;&#35441;&#26371;&#36305;&#24456;&#20037;.....</span>
<span class="linenr">18: </span>ovr_clf.fit(X_train[:<span style="color: #da8548; font-weight: bold;">1000</span>], y_train[:<span style="color: #da8548; font-weight: bold;">1000</span>])
<span class="linenr">19: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38928;&#28204;</span>
<span class="linenr">20: </span><span style="color: #c678dd;">print</span>(y[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">21: </span><span style="color: #dcaeea;">ovrResult</span> = ovr_clf.predict([X[<span style="color: #da8548; font-weight: bold;">0</span>]])
<span class="linenr">22: </span>
<span class="linenr">23: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'OvR prediction: </span>{ovrResult}<span style="color: #98be65;">'</span>)
<span class="linenr">24: </span>
</pre>
</div>

<pre class="example">
&gt;&gt;&gt; 5
OvR prediction: [5]
</pre>
</div>
</div>
<div id="outline-container-org1250f08" class="outline-4">
<h4 id="org1250f08"><span class="section-number-4">2.5.4.</span> 誤差分析</h4>
<div class="outline-text-4" id="text-2-5-4">
<p>
匯入library
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session MCL
<span class="linenr"> 2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Python &#8805;3.5 is required</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> sys
<span class="linenr"> 4: </span><span style="color: #51afef;">assert</span> sys.version_info &gt;= (<span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Is this notebook running on Colab or Kaggle?</span>
<span class="linenr"> 7: </span><span style="color: #dcaeea;">IS_COLAB</span> = <span style="color: #98be65;">"google.colab"</span> <span style="color: #51afef;">in</span> sys.modules
<span class="linenr"> 8: </span><span style="color: #dcaeea;">IS_KAGGLE</span> = <span style="color: #98be65;">"kaggle_secrets"</span> <span style="color: #51afef;">in</span> sys.modules
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Scikit-Learn &#8805;0.20 is required</span>
<span class="linenr">11: </span><span style="color: #51afef;">import</span> sklearn
<span class="linenr">12: </span><span style="color: #51afef;">assert</span> sklearn.__version__ &gt;= <span style="color: #98be65;">"0.20"</span>
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Common imports</span>
<span class="linenr">15: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">16: </span><span style="color: #51afef;">import</span> os
<span class="linenr">17: </span>
<span class="linenr">18: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">to make this notebook's output stable across runs</span>
<span class="linenr">19: </span>np.random.seed(<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">20: </span>
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">To plot pretty figures</span>
<span class="linenr">22: </span>
<span class="linenr">23: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr">24: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">25: </span>mpl.rc(<span style="color: #98be65;">'axes'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">14</span>)
<span class="linenr">26: </span>mpl.rc(<span style="color: #98be65;">'xtick'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">12</span>)
<span class="linenr">27: </span>mpl.rc(<span style="color: #98be65;">'ytick'</span>, labelsize=<span style="color: #da8548; font-weight: bold;">12</span>)
<span class="linenr">28: </span>
<span class="linenr">29: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Where to save the figures</span>
<span class="linenr">30: </span><span style="color: #dcaeea;">PROJECT_ROOT_DIR</span> = <span style="color: #98be65;">"."</span>
<span class="linenr">31: </span><span style="color: #dcaeea;">CHAPTER_ID</span> = <span style="color: #98be65;">"classification"</span>
<span class="linenr">32: </span><span style="color: #dcaeea;">IMAGES_PATH</span> = os.path.join(PROJECT_ROOT_DIR, <span style="color: #98be65;">"images"</span>, CHAPTER_ID)
<span class="linenr">33: </span>os.makedirs(IMAGES_PATH, exist_ok=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">34: </span>
<span class="linenr">35: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">save_fig</span>(fig_id, tight_layout=<span style="color: #a9a1e1;">True</span>, fig_extension=<span style="color: #98be65;">"png"</span>, resolution=<span style="color: #da8548; font-weight: bold;">300</span>):
<span class="linenr">36: </span>    <span style="color: #dcaeea;">path</span> = os.path.join(IMAGES_PATH, fig_id + <span style="color: #98be65;">"."</span> + fig_extension)
<span class="linenr">37: </span>    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"Saving figure"</span>, fig_id)
<span class="linenr">38: </span>    <span style="color: #51afef;">if</span> tight_layout:
<span class="linenr">39: </span>        plt.tight_layout()
<span class="linenr">40: </span>    plt.savefig(path, <span style="color: #c678dd;">format</span>=fig_extension, dpi=resolution)
</pre>
</div>

<pre class="example">
Python 3.7.13 (default, Mar 28 2022, 07:24:34)
[Clang 12.0.0 ] :: Anaconda, Inc. on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt;
</pre>


<p>
輸出confusion matrix
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session MCL
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> matplotlib <span style="color: #51afef;">as</span> mpl
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 4: </span><span style="color: #51afef;">from</span> sklearn.datasets <span style="color: #51afef;">import</span> fetch_openml
<span class="linenr"> 5: </span><span style="color: #51afef;">import</span> pickle5 <span style="color: #51afef;">as</span> pickle
<span class="linenr"> 6: </span><span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'mnist.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> bunch:
<span class="linenr"> 7: </span>    <span style="color: #dcaeea;">mnist</span> = pickle.load(bunch)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">X</span>, <span style="color: #dcaeea;">y</span> = mnist[<span style="color: #98be65;">"data"</span>], mnist[<span style="color: #98be65;">"target"</span>]
<span class="linenr">10: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">11: </span><span style="color: #dcaeea;">y</span> = y.astype(np.uint8)
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#28858;&#28204;&#35430;&#32068;&#33287;&#35347;&#32244;&#32068;</span>
<span class="linenr">14: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_train</span>, <span style="color: #dcaeea;">y_test</span> = X[:<span style="color: #da8548; font-weight: bold;">60000</span>], X[<span style="color: #da8548; font-weight: bold;">60000</span>:], y[:<span style="color: #da8548; font-weight: bold;">60000</span>], y[<span style="color: #da8548; font-weight: bold;">60000</span>:]
<span class="linenr">15: </span>
<span class="linenr">16: </span><span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span class="linenr">17: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> SGDClassifier
<span class="linenr">18: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#25226;&#35347;&#32244;&#36039;&#26009;&#27161;&#21270;</span>
<span class="linenr">19: </span><span style="color: #dcaeea;">scaler</span> = StandardScaler()
<span class="linenr">20: </span><span style="color: #dcaeea;">X_train_scaled</span> = scaler.fit_transform(X_train.astype(np.float64))
<span class="linenr">21: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35347;&#32244;&#20998;&#39006;</span>
<span class="linenr">22: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">max_iter&#35373;&#28858;1000&#26371;&#36305;&#24456;&#20037;&#24456;&#20037;....</span>
<span class="linenr">23: </span><span style="color: #dcaeea;">sgd_clf</span> = SGDClassifier(max_iter=<span style="color: #da8548; font-weight: bold;">10</span>, tol=1e-<span style="color: #da8548; font-weight: bold;">3</span>, random_state=<span style="color: #da8548; font-weight: bold;">42</span>)
<span class="linenr">24: </span>
<span class="linenr">25: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_score <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#30475;&#24471;&#20998;</span>
<span class="linenr">26: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20132;&#21449;&#39511;&#35657;</span>
<span class="linenr">27: </span>cross_val_score(sgd_clf, X_train_scaled, y_train, cv=<span style="color: #da8548; font-weight: bold;">3</span>, scoring=<span style="color: #98be65;">"accuracy"</span>)
<span class="linenr">28: </span>
<span class="linenr">29: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> confusion_matrix
<span class="linenr">30: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">31: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#38928;&#28204;&#32080;&#26524;</span>
<span class="linenr">32: </span><span style="color: #dcaeea;">y_train_pred</span> = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">33: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#27714;&#20986;confusion matrix</span>
<span class="linenr">34: </span><span style="color: #dcaeea;">conf_mx</span> = confusion_matrix(y_train, y_train_pred)
<span class="linenr">35: </span><span style="color: #c678dd;">print</span>(conf_mx)
<span class="linenr">36: </span>plt.xticks(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">10</span>))
<span class="linenr">37: </span>plt.matshow(conf_mx, cmap=plt.cm.gray)
<span class="linenr">38: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#28151;&#28102;&#30697;&#38499;&#30340;&#20540;&#38500;&#20197;&#27599;&#19968;&#39006;&#21029;&#30340;&#22294;&#29255;&#25976;&#37327;&#65292;&#21487;&#20197;&#24471;&#21040;&#37679;&#35492;&#29575;</span>
<span class="linenr">39: </span>plt.savefig(<span style="color: #98be65;">'images/MNIST-confusion-matrix.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">40: </span><span style="color: #dcaeea;">row_sums</span> = conf_mx.<span style="color: #c678dd;">sum</span>(axis=<span style="color: #da8548; font-weight: bold;">1</span>, keepdims=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">41: </span><span style="color: #dcaeea;">norm_conf_mx</span> = conf_mx / row_sums
<span class="linenr">42: </span>np.fill_diagonal(norm_conf_mx, <span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">43: </span>plt.matshow(norm_conf_mx, cmap=plt.cm.gray)
<span class="linenr">44: </span>plt.savefig(<span style="color: #98be65;">"images/confusion_matrix_errors_plot.png"</span>, tight_layout=<span style="color: #a9a1e1;">False</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<pre class="example" id="orgbbd9c4c">
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
/Users/letranger/opt/anaconda3/envs/python37/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
[[5715    2   29    9   12   47   46    8   52    3]
 [   1 6461   37   29    7   41    9   10  133   14]
 [  52   36 5314  107   79   29   92   55  179   15]
 [  44   39  140 5340    3  239   33   51  143   99]
 [  18   21   37   10 5338    9   59   27  110  213]
 [  70   37   40  193   75 4598  101   25  185   97]
 [  32   22   45    2   42   95 5629    3   48    0]
 [  23   23   68   32   56   11    4 5771   22  255]
 [  47  130   66  147   10  155   49   26 5093  128]
 [  37   29   26   88  150   34    2  201  104 5278]]
__main__:43: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument "tight_layout" which is no longer supported as of 3.3 and will become an error in 3.6
</pre>

<div id="org4cca051" class="figure">
<p><img src="images/MNIST-confusion-matrix.png" alt="MNIST-confusion-matrix.png" width="300" />
</p>
<p><span class="figure-number">Figure 16: </span>Caption</p>
</div>

<p>
5的顏色比較深，可能代表圖片5在資料庫中較少，也可能代表分類器處理5的能力較低。
將混淆矩陣的值除以每一類別的圖片數量，可以得到錯誤率,
</p>

<div id="org0432ffe" class="figure">
<p><img src="images/confusion_matrix_errors_plot.png" alt="confusion_matrix_errors_plot.png" width="300" />
</p>
<p><span class="figure-number">Figure 17: </span>Caption</p>
</div>

<p>
圖<a href="#org0432ffe">17</a>中的列代表真正的類型、行代表模型所預測出的類型。圖中的8這一直欄特別亮，代表有很多圖被錯誤的歸類為8；然而真正的8這一橫列並沒有特別亮，表示真正的8會被歸類為8。這個混淆矩陣並未對稱，可以看出很多的3和5常被搞混。
</p>

<p>
從這樣的圖看來，我們應該能搜集更多看起來像(但不是)8的訓練資料，加強分類器的學習。
</p>

<p>
分析個別的錯誤也有助於瞭解分類器在做什麼以及它為什麼失敗：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session MCL
<span class="linenr"> 2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">EXTRA</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">plot_digits</span>(instances, images_per_row=<span style="color: #da8548; font-weight: bold;">10</span>, **options):
<span class="linenr"> 4: </span>    <span style="color: #dcaeea;">size</span> = <span style="color: #da8548; font-weight: bold;">28</span>
<span class="linenr"> 5: </span>    <span style="color: #dcaeea;">images_per_row</span> = <span style="color: #c678dd;">min</span>(<span style="color: #c678dd;">len</span>(instances), images_per_row)
<span class="linenr"> 6: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">This is equivalent to n_rows = ceil(len(instances) / images_per_row):</span>
<span class="linenr"> 7: </span>    <span style="color: #dcaeea;">n_rows</span> = (<span style="color: #c678dd;">len</span>(instances) - <span style="color: #da8548; font-weight: bold;">1</span>) // images_per_row + <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Append empty images to fill the end of the grid, if needed:</span>
<span class="linenr">10: </span>    <span style="color: #dcaeea;">n_empty</span> = n_rows * images_per_row - <span style="color: #c678dd;">len</span>(instances)
<span class="linenr">11: </span>    <span style="color: #dcaeea;">padded_instances</span> = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">12: </span>
<span class="linenr">13: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Reshape the array so it's organized as a grid containing 28&#215;28 images:</span>
<span class="linenr">14: </span>    <span style="color: #dcaeea;">image_grid</span> = padded_instances.reshape((n_rows, images_per_row, size, size))
<span class="linenr">15: </span>
<span class="linenr">16: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Combine axes 0 and 2 (vertical image grid axis, and vertical image axis),</span>
<span class="linenr">17: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">and axes 1 and 3 (horizontal axes). We first need to move the axes that we</span>
<span class="linenr">18: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">want to combine next to each other, using transpose(), and only then we</span>
<span class="linenr">19: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">can reshape:</span>
<span class="linenr">20: </span>    <span style="color: #dcaeea;">big_image</span> = image_grid.transpose(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">2</span>, <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">3</span>).reshape(n_rows * size,
<span class="linenr">21: </span>                                                         images_per_row * size)
<span class="linenr">22: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">Now that we have a big image, we just need to show it:</span>
<span class="linenr">23: </span>    plt.imshow(big_image, cmap = mpl.cm.binary, **options)
<span class="linenr">24: </span>    plt.axis(<span style="color: #98be65;">"off"</span>)
<span class="linenr">25: </span>
<span class="linenr">26: </span><span style="color: #dcaeea;">cl_a</span>, <span style="color: #dcaeea;">cl_b</span> = <span style="color: #da8548; font-weight: bold;">3</span>, <span style="color: #da8548; font-weight: bold;">5</span>
<span class="linenr">27: </span><span style="color: #dcaeea;">X_aa</span> = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_a)]
<span class="linenr">28: </span><span style="color: #dcaeea;">X_ab</span> = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_b)]
<span class="linenr">29: </span><span style="color: #dcaeea;">X_ba</span> = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_a)]
<span class="linenr">30: </span><span style="color: #dcaeea;">X_bb</span> = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_b)]
<span class="linenr">31: </span>plt.cla()
<span class="linenr">32: </span>plt.tight_layout()
<span class="linenr">33: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>,<span style="color: #da8548; font-weight: bold;">8</span>))
<span class="linenr">34: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">221</span>); plot_digits(X_aa[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">35: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">222</span>); plot_digits(X_ab[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">36: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">223</span>); plot_digits(X_ba[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">37: </span>plt.subplot(<span style="color: #da8548; font-weight: bold;">224</span>); plot_digits(X_bb[:<span style="color: #da8548; font-weight: bold;">25</span>], images_per_row=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">38: </span>plt.savefig(<span style="color: #98be65;">"images/error_analysis_digits_plot1.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">39: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.show()</span>
</pre>
</div>

<p>
圖<a href="#org2394bc8">18</a>右上為真實類別為3但被預測為5的圖；左下為真實類別為5但被預測為3的圖。SGDClassifier為線性模型、其做法是幫每個像素設定各個類別的權重，當他看到新圖時，它只是把加權的像素強度總和起來，得到每個類別的分數。所以當3和5這兩個只有部份像素有差異的圖，SDGClassifier就很難分辨。
</p>

<div id="org2394bc8" class="figure">
<p><img src="images/error_analysis_digits_plot.png" alt="error_analysis_digits_plot.png" width="500" />
</p>
<p><span class="figure-number">Figure 18: </span>Caption</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org813d29f" class="outline-3">
<h3 id="org813d29f"><span class="section-number-3">2.6.</span> 多標籤分類</h3>
<div class="outline-text-3" id="text-2-6">
<p>
把MNIST改為多類別：「大於等於7」、「奇數」，以y_multilabel陣列儲存多類別標籤，以KNN進行分類
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :session MCL
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.neighbors <span style="color: #51afef;">import</span> KNeighborsClassifier
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">y_train_large</span> = (y_train &gt;= <span style="color: #da8548; font-weight: bold;">7</span>)
<span class="linenr"> 5: </span><span style="color: #dcaeea;">y_train_odd</span> = (y_train % <span style="color: #da8548; font-weight: bold;">2</span> == <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 6: </span><span style="color: #dcaeea;">y_multilabel</span> = np.c_[y_train_large, y_train_odd]
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">knn_clf</span> = KNeighborsClassifier()
<span class="linenr"> 9: </span>knn_clf.fit(X_train, y_multilabel)
<span class="linenr">10: </span><span style="color: #dcaeea;">some_digit</span> = X[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">11: </span><span style="color: #c678dd;">print</span>(y[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">12: </span><span style="color: #c678dd;">print</span>(knn_clf.predict([some_digit]))
</pre>
</div>

<pre class="example">
5
[[False  True]]
</pre>

<p>
這樣會傳回兩個boolean值，表示這個數字沒有「大於等於7」、是奇數。
評估多類別標籤分類器可以為各個單獨的標籤計算$F_1$分數，再計算平均數。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span> :session MCL
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> cross_val_predict
<span class="linenr">3: </span><span style="color: #51afef;">from</span> sklearn.metrics <span style="color: #51afef;">import</span> f1_score
<span class="linenr">4: </span><span style="color: #dcaeea;">y_train_knn_pred</span> = cross_val_predict(knn_clf, X_train, y_multilabel, cv=<span style="color: #da8548; font-weight: bold;">3</span>)
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(f1_score(y_multilabel, y_train_knn_pred, average=<span style="color: #98be65;">"macro"</span>))
</pre>
</div>

<pre class="example">
0.976410265560605
</pre>
</div>
</div>
</div>
<div id="outline-container-org3daaf07" class="outline-2">
<h2 id="org3daaf07"><span class="section-number-2">3.</span> 分類實作: MNIST(CNN)</h2>
<div class="outline-text-2" id="text-3">
<p>
準備資料是訓練模型的第一步，基礎資料可以是網上公開的資料集，也可以是自己的資料集。視覺、語音、語言等各種型別的資料在網上都能找到相應的資料集。
</p>
</div>
<div id="outline-container-org78510d1" class="outline-3">
<h3 id="org78510d1"><span class="section-number-3">3.1.</span> 準備 MNIST 資料</h3>
<div class="outline-text-3" id="text-3-1">
<p>
MNIST 數據集來自美國國家標準與技術研究所, National Institute of Standards and Technology (NIST). 訓練集 (training set) 由來自 250 個不同人手寫的數字構成, 其中 50% 是高中學生, 50% 來自人口普查局 (the Census Bureau) 的工作人員. 測試集(test set) 也是同樣比例的手寫數字數據。MNIST 數據集可在 <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 獲取, 它包含了四個部分:
</p>
<ol class="org-ol">
<li>Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解壓後 47 MB, 包含 60,000 個樣本)</li>
<li>Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解壓後 60 KB, 包含 60,000 個標籤)</li>
<li>Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解壓後 7.8 MB, 包含 10,000 個樣本)</li>
<li>Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解壓後 10 KB, 包含 10,000 個標籤)</li>
</ol>


<p>
MNIST 資料集是一個適合拿來當作 TensotFlow 的練習素材，在 Tensorflow 的現有套件中，也已經有內建好的 MNIST 資料集，我們只要在安裝好 TensorFlow 的 Python 環境中執行以下程式碼，即可將 MNIST 資料成功讀取進來。.
</p>
<div class="org-src-container">
<pre class="src src-python"> :<span style="color: #c678dd;">eval</span> no
<span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span id="coderef-get-keras-mnist" class="coderef-off">(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()</span>
</pre>
</div>
<p>
在訓練模型之前，需要將樣本資料劃分為訓練集、測試集，有些情況下還會劃分為訓練集、測試集、驗證集。由上述程式第<a href="#coderef-get-keras-mnist" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-get-keras-mnist');" onmouseout="CodeHighlightOff(this, 'coderef-get-keras-mnist');">4</a>行可知，下載後的 MNIST 資料分成訓練資料(training data)與測試資料(testing data)，其中 x 為圖片、y為所對應數字。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 3: </span><span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 4: </span>(x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21028;&#26039;&#36039;&#26009;&#24418;&#29376;</span>
<span class="linenr"> 7: </span><span style="color: #c678dd;">print</span>(x_train.shape)
<span class="linenr"> 8: </span><span style="color: #c678dd;">print</span>(x_test.shape)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#31532;&#19968;&#20491;label&#30340;&#20839;&#23481;</span>
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#24433;&#20687;&#20839;&#23481;</span>
<span class="linenr">12: </span><span style="color: #51afef;">import</span> matplotlib.pylab <span style="color: #51afef;">as</span> plt
<span class="linenr">13: </span><span style="color: #dcaeea;">img</span> = x_train[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">14: </span>plt.imshow(img)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">"MNIST-Image.png"</span>)
</pre>
</div>
<pre class="example">
(60000, 28, 28)
(10000, 28, 28)
5
</pre>


<p>
由上述程式輸出結果可以看到載入的 x 為大小為 28*28 的圖片共 60000 張，每一筆 MNIST 資料的照片(x)由 784 個 pixels 組成（28*28），照片內容如圖<a href="#org5f660de">19</a>，訓練集的標籤(y)則為其對應的數字(0～9)，此例為 5。
</p>

<div id="org5f660de" class="figure">
<p><img src="images/MNIST-Image.png" alt="MNIST-Image.png" width="300" />
</p>
<p><span class="figure-number">Figure 19: </span>MNIST 影像示例</p>
</div>

<p>
x 的影像資料為灰階影像，每個像素的數值介於 0~255 之間，矩陣裡每一項的資料則是代表每個 pixel 顏色深淺的數值，如下圖<a href="#org18cb7fc">20</a>所示：
</p>

<div id="org18cb7fc" class="figure">
<p><img src="images/MNIST-Matrix.png" alt="MNIST-Matrix.png" width="500" />
</p>
<p><span class="figure-number">Figure 20: </span>MNIST 資料矩陣</p>
</div>

<p>
載入的 y 為所對應的數字 0~9，在這我們要運用 keras 中的 np_utils.to_categorical 將 y 轉成 one-hot 的形式，將他轉為一個 10 維的 vector，例如：我們所拿到的資料為 y=3，經過 np_utils.to_categorical，會轉換為 y=[0,0,0,1,0,0,0,0,0,0]。這部份的轉換程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr"> 3: </span>  <span style="color: #51afef;">from</span> keras.utils <span style="color: #51afef;">import</span> np_utils
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span>  <span style="color: #51afef;">import</span> tensorflow <span style="color: #51afef;">as</span> tf
<span class="linenr"> 6: </span>  <span style="color: #dcaeea;">mnist</span> = tf.keras.datasets.mnist
<span class="linenr"> 7: </span>  (x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 8: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">=====================================</span>
<span class="linenr"> 9: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#22294;&#29255;&#36681;&#25563;&#28858;&#19968;&#20491;60000*784&#30340;&#21521;&#37327;&#65292;&#20006;&#19988;&#27161;&#28310;&#21270;</span>
<span class="linenr">10: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.reshape(x_train.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">11: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.reshape(x_test.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">12: </span>  <span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">13: </span>  <span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">14: </span>  <span style="color: #dcaeea;">x_train</span> = x_train/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">15: </span>  <span style="color: #dcaeea;">x_test</span> = x_test/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">16: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">17: </span>  <span style="color: #dcaeea;">y_train</span> = np_utils.to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">18: </span>  <span style="color: #dcaeea;">y_test</span> = np_utils.to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">19: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">20: </span>  <span style="color: #c678dd;">print</span>(y_train[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">21: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">22: </span>  np.set_printoptions(precision=<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">23: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">print(x_train[0])</span>
</pre>
</div>

<pre class="example">
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
</pre>
</div>
</div>
<div id="outline-container-orge66f25a" class="outline-3">
<h3 id="orge66f25a"><span class="section-number-3">3.2.</span> MNIST 的推論處理</h3>
<div class="outline-text-3" id="text-3-2">
<p>
如圖<a href="#orgca9ba27">21</a>所示，MNIST 的推論神經網路最前端的輸入層有 784 (\(28*28=784\))個神經元，最後的輸出端有 10 個神經元(\(0~9\)個數字)，至於中間的隠藏層有兩個，第 1 個隱藏層有 50 個神經元，第 2 層有 100 個。此處的 50、100 可以設定為任意數（如，也可以是 128、64）。
</p>

<div id="orgca9ba27" class="figure">
<p><img src="images/MNIST-CNN.png" alt="MNIST-CNN.png" width="500" />
</p>
<p><span class="figure-number">Figure 21: </span>MNIST-NeuralNet</p>
</div>

<p>
為了完成上述推論，此處定義三個函數：get_data()、init_network()、predict()，其中 init_work()直接讀入作者已經訓練好的網絡權重。在以下這段程式碼中，權重與偏權值的參數會儲存成字典型態的變數。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :<span style="color: #c678dd;">eval</span> no
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.datasets.mnist <span style="color: #51afef;">import</span> load_data
<span class="linenr"> 3: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 4: </span>  <span style="color: #51afef;">import</span> pickle
<span class="linenr"> 5: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sigmoid</span>(x):
<span class="linenr"> 6: </span>    <span style="color: #51afef;">return</span> <span style="color: #da8548; font-weight: bold;">1</span> / (<span style="color: #da8548; font-weight: bold;">1</span> + np.exp(-x))
<span class="linenr"> 7: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38450;&#27490;&#28322;&#20986;&#22411;</span>
<span class="linenr"> 8: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">softmax</span>(x):
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">c</span> = np.<span style="color: #c678dd;">max</span>(x)
<span class="linenr">10: </span>    <span style="color: #dcaeea;">exp_x</span> = np.exp(x - c)
<span class="linenr">11: </span>    <span style="color: #dcaeea;">sum_exp_x</span> = np.<span style="color: #c678dd;">sum</span>(exp_x)
<span class="linenr">12: </span>    <span style="color: #51afef;">return</span> exp_x / sum_exp_x
<span class="linenr">13: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">get_data</span>():
<span class="linenr">14: </span>    (X_train, y_train), (<span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span>) = load_data()
<span class="linenr">15: </span>    <span style="color: #51afef;">return</span> X_test.reshape(<span style="color: #da8548; font-weight: bold;">10000</span>, <span style="color: #da8548; font-weight: bold;">784</span>), y_test
<span class="linenr">16: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">init_network</span>():
<span class="linenr">17: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">https://github.com/Bingyy/deep-learning-from-scratch/blob/master/ch03/sample_weight.pkl</span>
<span class="linenr">18: </span>    <span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'/Volumes/Vanessa/MNIST/data/mnist/sample_weight.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> f:
<span class="linenr">19: </span>      <span style="color: #dcaeea;">network</span> = pickle.load(f)
<span class="linenr">20: </span>      <span style="color: #51afef;">return</span> network
<span class="linenr">21: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23384;&#20786;&#30340;&#26159;&#32178;&#32097;&#21443;&#25976;&#23383;&#20856;</span>
<span class="linenr">22: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">23: </span>
<span class="linenr">24: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32068;&#21512;&#32178;&#32097;&#27969;&#31243;&#65292;&#29992;&#26044;&#38928;&#28204;</span>
<span id="coderef-MNIST-predict" class="coderef-off"><span class="linenr">25: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">predict</span>(network, x):</span>
<span class="linenr">26: </span>    <span style="color: #dcaeea;">W1</span>, <span style="color: #dcaeea;">W2</span>, <span style="color: #dcaeea;">W3</span> = network[<span style="color: #98be65;">'W1'</span>], network[<span style="color: #98be65;">'W2'</span>], network[<span style="color: #98be65;">'W3'</span>]
<span class="linenr">27: </span>    <span style="color: #dcaeea;">b1</span>, <span style="color: #dcaeea;">b2</span>, <span style="color: #dcaeea;">b3</span> = network[<span style="color: #98be65;">'b1'</span>], network[<span style="color: #98be65;">'b2'</span>], network[<span style="color: #98be65;">'b3'</span>]
<span class="linenr">28: </span>    <span style="color: #dcaeea;">a1</span> = np.dot(x,W1) + b1
<span class="linenr">29: </span>    <span style="color: #dcaeea;">z1</span> = sigmoid(a1)
<span class="linenr">30: </span>    <span style="color: #dcaeea;">a2</span> = np.dot(z1, W2) + b2
<span class="linenr">31: </span>    <span style="color: #dcaeea;">z2</span> = sigmoid(a2)
<span class="linenr">32: </span>    <span style="color: #dcaeea;">a3</span> = np.dot(z2, W3) + b3
<span class="linenr">33: </span>    <span style="color: #dcaeea;">y</span> = softmax(a3) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#39006;&#29992;&#30340;&#26368;&#24460;&#36664;&#20986;&#23652;&#30340;&#28608;&#27963;&#20989;&#25976;</span>
<span class="linenr">34: </span>    <span style="color: #51afef;">return</span> y
<span class="linenr">35: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992;&#32178;&#32097;&#38928;&#28204;</span>
<span class="linenr">36: </span>  <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span> = get_data() <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24471;&#21040;&#28204;&#35430;&#25976;&#25818;</span>
<span class="linenr">37: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">38: </span>
<span class="linenr">39: </span>  <span style="color: #dcaeea;">accuracy_cnt</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">40: </span>  <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #c678dd;">len</span>(X_test)):
<span id="coderef-y-predict" class="coderef-off"><span class="linenr">41: </span>    <span style="color: #dcaeea;">y</span> = predict(network, X_test[i])</span>
<span id="coderef-np-argmax" class="coderef-off"><span class="linenr">42: </span>    <span style="color: #dcaeea;">p</span> = np.argmax(y)</span>
<span class="linenr">43: </span>    np.set_printoptions(precision=<span style="color: #da8548; font-weight: bold;">4</span>, suppress=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">44: </span>    <span style="color: #51afef;">if</span> p == y_test[i]:
<span class="linenr">45: </span>      <span style="color: #dcaeea;">accuracy_cnt</span> += <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">46: </span>  <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;&#65306;'</span>, <span style="color: #c678dd;">str</span>(<span style="color: #c678dd;">float</span>(accuracy_cnt) / <span style="color: #c678dd;">len</span>(X_test)))
</pre>
</div>

<pre class="example">
準確率： 0.0002
</pre>


<p>
上述程式中，predict 程序(第<a href="#coderef-MNIST-predict" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-MNIST-predict');" onmouseout="CodeHighlightOff(this, 'coderef-MNIST-predict');">25</a>)透過矩陣相乘運算完成神經網路的參數傳遞，最後必須進行準確率的評估，程式碼第<a href="#coderef-y-predict" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-y-predict');" onmouseout="CodeHighlightOff(this, 'coderef-y-predict');">41</a>行為神經網路針對輸入圖片的預測結果，所傳回的值為各猜測值的機率陣列，如：[0.0004 0.0011 0.9859 0.0065 0.     0.0007 0.0051 0.     0.0003 0.    ]；而程式碼第<a href="#coderef-np-argmax" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-np-argmax');" onmouseout="CodeHighlightOff(this, 'coderef-np-argmax');">42</a>則是該圖片的應對標籤，np.argmax(y)會傳回 y 的最大值所在順序，若 y=[0,0,0,1,0,0,0,0,0,0]，則傳回 3，藉此計算預測正確的百分比。
</p>
</div>
</div>
<div id="outline-container-org9620b53" class="outline-3">
<h3 id="org9620b53"><span class="section-number-3">3.3.</span> Python 與神經網路運算的批次處理</h3>
<div class="outline-text-3" id="text-3-3">
<p>
前節程式碼中最後以 for 迴圈來逐一處理預測結果與比較，輸入(X)為單一圖片，其處理程序如圖<a href="#org3865713">22</a>所示：
</p>

<div id="org3865713" class="figure">
<p><img src="images/MNIST-single.png" alt="MNIST-single.png" width="500" />
</p>
<p><span class="figure-number">Figure 22: </span>MNIST-單一處理架構</p>
</div>

<p>
事實上，在使用批次處理（如一次處理 100 張圖）反而能大幅縮短每張圖片的處理時間，因為多數處理數值運算的函式庫都會針對大型陣列運算進行最佳化，尤其是透過 GPU 來處理時更是如此，這時，傳送單張圖片反而成為效能瓶頸，以批次處理則可減輕匯流排頻寛負擔。若以每次處理 100 張為例，其處理程序則如圖<a href="#orgda906c7">23</a>所示。
</p>

<div id="orgda906c7" class="figure">
<p><img src="images/MNIST-batch.png" alt="MNIST-batch.png" width="500" />
</p>
<p><span class="figure-number">Figure 23: </span>MNIST-批次處理架構</p>
</div>

<p>
至於批次運算的程式碼如下。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span>
<span class="linenr"> 2: </span>  <span style="color: #51afef;">from</span> keras.datasets.mnist <span style="color: #51afef;">import</span> load_data
<span class="linenr"> 3: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 4: </span>  <span style="color: #51afef;">import</span> pickle
<span class="linenr"> 5: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">sigmoid</span>(x):
<span class="linenr"> 6: </span>    <span style="color: #51afef;">return</span> <span style="color: #da8548; font-weight: bold;">1</span> / (<span style="color: #da8548; font-weight: bold;">1</span> + np.exp(-x))
<span class="linenr"> 7: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38450;&#27490;&#28322;&#20986;&#22411;</span>
<span class="linenr"> 8: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">softmax</span>(x):
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">c</span> = np.<span style="color: #c678dd;">max</span>(x)
<span class="linenr">10: </span>    <span style="color: #dcaeea;">exp_x</span> = np.exp(x - c)
<span class="linenr">11: </span>    <span style="color: #dcaeea;">sum_exp_x</span> = np.<span style="color: #c678dd;">sum</span>(exp_x)
<span class="linenr">12: </span>    <span style="color: #51afef;">return</span> exp_x / sum_exp_x
<span class="linenr">13: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">get_data</span>():
<span class="linenr">14: </span>    (X_train, y_train), (<span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span>) = load_data()
<span class="linenr">15: </span>    <span style="color: #51afef;">return</span> X_test.reshape(<span style="color: #da8548; font-weight: bold;">10000</span>, <span style="color: #da8548; font-weight: bold;">784</span>), y_test
<span class="linenr">16: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">init_network</span>():
<span class="linenr">17: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">https://github.com/Bingyy/deep-learning-from-scratch/blob/master/ch03/sample_weight.pkl</span>
<span class="linenr">18: </span>    <span style="color: #51afef;">with</span> <span style="color: #c678dd;">open</span>(<span style="color: #98be65;">'/Volumes/Vanessa/MNIST/sample_weight.pkl'</span>, <span style="color: #98be65;">'rb'</span>) <span style="color: #51afef;">as</span> f:
<span class="linenr">19: </span>      <span style="color: #dcaeea;">network</span> = pickle.load(f)
<span class="linenr">20: </span>      <span style="color: #51afef;">return</span> network
<span class="linenr">21: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23384;&#20786;&#30340;&#26159;&#32178;&#32097;&#21443;&#25976;&#23383;&#20856;</span>
<span class="linenr">22: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">23: </span>
<span class="linenr">24: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32068;&#21512;&#32178;&#32097;&#27969;&#31243;&#65292;&#29992;&#26044;&#38928;&#28204;</span>
<span class="linenr">25: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">predict</span>(network, x):
<span class="linenr">26: </span>    <span style="color: #dcaeea;">W1</span>, <span style="color: #dcaeea;">W2</span>, <span style="color: #dcaeea;">W3</span> = network[<span style="color: #98be65;">'W1'</span>], network[<span style="color: #98be65;">'W2'</span>], network[<span style="color: #98be65;">'W3'</span>]
<span class="linenr">27: </span>    <span style="color: #dcaeea;">b1</span>, <span style="color: #dcaeea;">b2</span>, <span style="color: #dcaeea;">b3</span> = network[<span style="color: #98be65;">'b1'</span>], network[<span style="color: #98be65;">'b2'</span>], network[<span style="color: #98be65;">'b3'</span>]
<span class="linenr">28: </span>    <span style="color: #dcaeea;">a1</span> = np.dot(x,W1) + b1
<span class="linenr">29: </span>    <span style="color: #dcaeea;">z1</span> = sigmoid(a1)
<span class="linenr">30: </span>    <span style="color: #dcaeea;">a2</span> = np.dot(z1, W2) + b2
<span class="linenr">31: </span>    <span style="color: #dcaeea;">z2</span> = sigmoid(a2)
<span class="linenr">32: </span>    <span style="color: #dcaeea;">a3</span> = np.dot(z2, W3) + b3
<span class="linenr">33: </span>    <span style="color: #dcaeea;">y</span> = softmax(a3) <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20998;&#39006;&#29992;&#30340;&#26368;&#24460;&#36664;&#20986;&#23652;&#30340;&#28608;&#27963;&#20989;&#25976;</span>
<span class="linenr">34: </span>    <span style="color: #51afef;">return</span> y
<span class="linenr">35: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992;&#32178;&#32097;&#38928;&#28204;</span>
<span class="linenr">36: </span>  <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">y_test</span> = get_data() <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24471;&#21040;&#28204;&#35430;&#25976;&#25818;</span>
<span class="linenr">37: </span>  <span style="color: #dcaeea;">network</span> = init_network()
<span class="linenr">38: </span>
<span class="linenr">39: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25209;&#27425;&#34389;&#29702;&#26550;&#27083;</span>
<span class="linenr">40: </span>  <span style="color: #dcaeea;">batch_size</span> = <span style="color: #da8548; font-weight: bold;">100</span>
<span class="linenr">41: </span>  <span style="color: #dcaeea;">accuracy_cnt</span> = <span style="color: #da8548; font-weight: bold;">0</span>
<span class="linenr">42: </span>  <span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #c678dd;">len</span>(X_test), batch_size):
<span id="coderef-b-mnist-x" class="coderef-off"><span class="linenr">43: </span>    <span style="color: #dcaeea;">x_batch</span> = X_test[i:i+batch_size]</span>
<span class="linenr">44: </span>    <span style="color: #dcaeea;">y_batch</span> = predict(network, x_batch)
<span id="coderef-b-mnist-p" class="coderef-off"><span class="linenr">45: </span>    <span style="color: #dcaeea;">p</span> = np.argmax(y_batch, axis=<span style="color: #da8548; font-weight: bold;">1</span>)</span>
<span class="linenr">46: </span>    <span style="color: #dcaeea;">accuracy_cnt</span> += np.<span style="color: #c678dd;">sum</span>(p == y_test[i:i+batch_size])
<span class="linenr">47: </span>  <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#28310;&#30906;&#29575;&#65306;'</span>, <span style="color: #c678dd;">str</span>(<span style="color: #c678dd;">float</span>(accuracy_cnt) / <span style="color: #c678dd;">len</span>(X_test)))
</pre>
</div>

<pre class="example">
準確率： 0.9207
</pre>


<p>
上述程式中，第<a href="#coderef-b-mnist-x" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-b-mnist-x');" onmouseout="CodeHighlightOff(this, 'coderef-b-mnist-x');">42</a>行每次取出 100 張圖形檔(X 陣列),第<a href="#coderef-b-mnist-p" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-b-mnist-p');" onmouseout="CodeHighlightOff(this, 'coderef-b-mnist-p');">44</a>行則取得這 100 筆資料中各筆資料最大值索引值，若以每次 4 筆資料為例，所得的估計值 p 可能為[7 2 1 0]，相對應的正確標籤值則儲存於 y_test[0:4]中，以此進行準確率的計算。
</p>
</div>
</div>
<div id="outline-container-orga70dc1d" class="outline-3">
<h3 id="orga70dc1d"><span class="section-number-3">3.4.</span> MNIST 資料集:以 DNN Sequential 模型為例&#xa0;&#xa0;&#xa0;<span class="tag"><span class="CNN">CNN</span></span></h3>
<div class="outline-text-3" id="text-3-4">
<p>
此處以最簡單的 DNN (deep neural network) 作為範例。以 Keras 的核心為模型，應用最常使用 Sequential 模型。藉由.add()我們可以一層一層的將神經網路疊起。在每一層之中我們只需要簡單的設定每層的大小(units)與激活函數(activation function)。需要特別記得的是：第一層要記得寫輸入的向量大小、最後一層的 units 要等於輸出的向量大小。在這邊我們最後一層使用的激活函數(activation function)為 softmax。
相對應程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span> :<span style="color: #c678dd;">eval</span> no
<span class="linenr"> 2: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36617;&#20837;&#36039;&#26009;</span>
<span class="linenr"> 3: </span>  <span style="color: #51afef;">from</span> keras.datasets <span style="color: #51afef;">import</span> mnist
<span class="linenr"> 4: </span>  <span style="color: #51afef;">from</span> keras.utils <span style="color: #51afef;">import</span> np_utils
<span class="linenr"> 5: </span>
<span class="linenr"> 6: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">load_data</span>():
<span class="linenr"> 7: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36617;&#20837;minst&#30340;&#36039;&#26009;</span>
<span class="linenr"> 8: </span>    (x_train, y_train), (<span style="color: #dcaeea;">x_test</span>, <span style="color: #dcaeea;">y_test</span>) = mnist.load_data()
<span class="linenr"> 9: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;&#22294;&#29255;&#36681;&#25563;&#28858;&#19968;&#20491;60000*784&#30340;&#21521;&#37327;&#65292;&#20006;&#19988;&#27161;&#28310;&#21270;</span>
<span class="linenr">10: </span>    <span style="color: #dcaeea;">x_train</span> = x_train.reshape(x_train.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">11: </span>    <span style="color: #dcaeea;">x_test</span> = x_test.reshape(x_test.shape[<span style="color: #da8548; font-weight: bold;">0</span>], <span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>)
<span class="linenr">12: </span>    <span style="color: #dcaeea;">x_train</span> = x_train.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">13: </span>    <span style="color: #dcaeea;">x_test</span> = x_test.astype(<span style="color: #98be65;">'float32'</span>)
<span class="linenr">14: </span>    <span style="color: #dcaeea;">x_train</span> = x_train/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">15: </span>    <span style="color: #dcaeea;">x_test</span> = x_test/<span style="color: #da8548; font-weight: bold;">255</span>
<span class="linenr">16: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559;y&#36681;&#25563;&#25104;one-hot encoding</span>
<span class="linenr">17: </span>    <span style="color: #dcaeea;">y_train</span> = np_utils.to_categorical(y_train, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">18: </span>    <span style="color: #dcaeea;">y_test</span> = np_utils.to_categorical(y_test, <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">19: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22238;&#20659;&#34389;&#29702;&#23436;&#30340;&#36039;&#26009;</span>
<span class="linenr">20: </span>    <span style="color: #51afef;">return</span> (x_train, y_train), (x_test, y_test)
<span class="linenr">21: </span>
<span class="linenr">22: </span>  <span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">23: </span>  <span style="color: #51afef;">from</span> keras.models <span style="color: #51afef;">import</span> Sequential
<span class="linenr">24: </span>  <span style="color: #51afef;">from</span> keras.layers.core <span style="color: #51afef;">import</span> Dense,Activation
<span class="linenr">25: </span>  <span style="color: #51afef;">from</span> keras.optimizers <span style="color: #51afef;">import</span>  Adam
<span class="linenr">26: </span>
<span class="linenr">27: </span>  <span style="color: #51afef;">def</span> <span style="color: #c678dd;">build_model</span>():<span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#24314;&#31435;&#27169;&#22411;</span>
<span class="linenr">28: </span>    <span style="color: #dcaeea;">model</span> = Sequential()
<span class="linenr">29: </span>    <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#23559;&#27169;&#22411;&#30090;&#36215;</span>
<span class="linenr">30: </span>    model.add(Dense(input_dim=<span style="color: #da8548; font-weight: bold;">28</span>*<span style="color: #da8548; font-weight: bold;">28</span>,units=<span style="color: #da8548; font-weight: bold;">500</span>,activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">31: </span>    model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">500</span>,activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">32: </span>    model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">500</span>,activation=<span style="color: #98be65;">'relu'</span>))
<span class="linenr">33: </span>    model.add(Dense(units=<span style="color: #da8548; font-weight: bold;">10</span>,activation=<span style="color: #98be65;">'softmax'</span>))
<span class="linenr">34: </span>    model.summary()
<span class="linenr">35: </span>    <span style="color: #51afef;">return</span> model
<span class="linenr">36: </span>
<span class="linenr">37: </span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38283;&#22987;&#35347;&#32244;&#27169;&#22411;&#65292;&#27492;&#34389;&#20351;&#29992;&#20102;Adam&#20570;&#28858;&#25105;&#20497;&#30340;&#20778;&#21270;&#22120;&#65292;loss function&#36984;&#29992;&#20102;categorical_crossentropy&#12290;</span>
<span class="linenr">38: </span>  (x_train,y_train),(<span style="color: #dcaeea;">x_test</span>,<span style="color: #dcaeea;">y_test</span>)=load_data()
<span class="linenr">39: </span>  <span style="color: #dcaeea;">model</span> = build_model()
<span class="linenr">40: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#38283;&#22987;&#35347;&#32244;&#27169;&#22411;</span>
<span class="linenr">41: </span>  model.<span style="color: #c678dd;">compile</span>(loss=<span style="color: #98be65;">'categorical_crossentropy'</span>,optimizer=<span style="color: #98be65;">"adam"</span>,metrics=[<span style="color: #98be65;">'accuracy'</span>])
<span class="linenr">42: </span>  model.fit(x_train,y_train,batch_size=<span style="color: #da8548; font-weight: bold;">100</span>,epochs=<span style="color: #da8548; font-weight: bold;">20</span>)
<span class="linenr">43: </span>  <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#39023;&#31034;&#35347;&#32244;&#32080;&#26524;</span>
<span class="linenr">44: </span>  <span style="color: #dcaeea;">score</span> = model.evaluate(x_train,y_train)
<span class="linenr">45: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">Train Acc:'</span>, score[<span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr">46: </span>  <span style="color: #dcaeea;">score</span> = model.evaluate(x_test,y_test)
<span class="linenr">47: </span>  <span style="color: #c678dd;">print</span> (<span style="color: #98be65;">'</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">Test Acc:'</span>, score[<span style="color: #da8548; font-weight: bold;">1</span>])
</pre>
</div>

<pre class="example" id="org2062e16">
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
dense_1 (Dense)              (None, 500)               392500
_________________________________________________________________
dense_2 (Dense)              (None, 500)               250500
_________________________________________________________________
dense_3 (Dense)              (None, 500)               250500
_________________________________________________________________
dense_4 (Dense)              (None, 10)                5010
=================================================================
Total params: 898,510
Trainable params: 898,510
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20

  100/60000 [..............................] - ETA: 2:55 - loss: 2.2917 - acc: 0.1300
  800/60000 [..............................] - ETA: 25s - loss: 1.6424 - ACM: 0.5362
.......
16300/60000 [=======&gt;......................] - ETA: 4s - loss: 0.3752 - acc: 0.8898
17000/60000 [=======&gt;......................] - ETA: 4s - loss: 0.3681 - acc: 0.8916
.......
50600/60000 [========================&gt;.....] - ETA: 0s - loss: 0.2232 - acc: 0.9335
51300/60000 [========================&gt;.....] - ETA: 0s - loss: 0.2220 - acc: 0.9338
.......
59700/60000 [============================&gt;.] - ETA: 0s - loss: 0.2078 - acc: 0.9377
60000/60000 [==============================] - 5s 81us/step - loss: 0.2074 - acc: 0.9379
Epoch 2/20

  100/60000 [..............................] - ETA: 5s - loss: 0.0702 - acc: 0.9800
......
60000/60000 [==============================] - 5s 77us/step - loss: 0.0832 - acc: 0.9740
Epoch 3/20
......
Epoch 29/20

   32/60000 [..............................] - ETA: 1:10
 1440/60000 [..............................] - ETA: 3s
......
58496/60000 [============================&gt;.] - ETA: 0s
60000/60000 [==============================] - 2s 34us/step

Train Acc: 0.9981666666666666

   32/10000 [..............................] - ETA: 0s
 1568/10000 [===&gt;..........................] - ETA: 0s
 3104/10000 [========&gt;.....................] - ETA: 0s
 4640/10000 [============&gt;.................] - ETA: 0s
 6176/10000 [=================&gt;............] - ETA: 0s
 7680/10000 [======================&gt;.......] - ETA: 0s
 9184/10000 [==========================&gt;...] - ETA: 0s
10000/10000 [==============================] - 0s 33us/step

Test Acc: 0.9823
</pre>
</div>
</div>
</div>
<div id="outline-container-orgbd1cda1" class="outline-2">
<h2 id="orgbd1cda1"><span class="section-number-2">4.</span> 最短距離分類器</h2>
<div class="outline-text-2" id="text-4">
<div class="org-src-container">
<pre class="src src-python">
<span style="color: #51afef;">import</span> math
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">from statistics import mean</span>
<span style="color: #5B6268;"># </span><span style="color: #5B6268;">importing reduce()</span>
<span style="color: #51afef;">from</span> functools <span style="color: #51afef;">import</span> <span style="color: #c678dd;">reduce</span>

<span style="color: #51afef;">def</span> <span style="color: #c678dd;">Average</span>(lst):
    <span style="color: #dcaeea;">avgx</span> = <span style="color: #da8548; font-weight: bold;">0</span>
    <span style="color: #dcaeea;">avgy</span> = <span style="color: #da8548; font-weight: bold;">0</span>
    <span style="color: #51afef;">for</span> (x, y) <span style="color: #51afef;">in</span> lst:
        <span style="color: #dcaeea;">avgx</span> += x
        <span style="color: #dcaeea;">avgy</span> += y
    <span style="color: #51afef;">return</span> avgx/<span style="color: #c678dd;">len</span>(lst), avgy/<span style="color: #c678dd;">len</span>(lst)

<span style="color: #51afef;">def</span> <span style="color: #c678dd;">ed</span>(lst, x, y):
    <span style="color: #dcaeea;">dist</span> = <span style="color: #da8548; font-weight: bold;">0</span>
    <span style="color: #51afef;">for</span> (lx, ly) <span style="color: #51afef;">in</span> lst:
        <span style="color: #dcaeea;">dist</span> += (x - lx)*(x - lx) + (y - ly)*(y - ly)
    <span style="color: #51afef;">return</span> math.sqrt(dist)

<span style="color: #dcaeea;">groupA</span> = [[<span style="color: #da8548; font-weight: bold;">4</span>, <span style="color: #da8548; font-weight: bold;">6</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">7</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">8</span>] ,[<span style="color: #da8548; font-weight: bold;">5.8</span>,<span style="color: #da8548; font-weight: bold;">6</span>] ,[<span style="color: #da8548; font-weight: bold;">6</span>,<span style="color: #da8548; font-weight: bold;">6</span>] ,[<span style="color: #da8548; font-weight: bold;">6</span>,<span style="color: #da8548; font-weight: bold;">7</span>] ,[<span style="color: #da8548; font-weight: bold;">7</span>,<span style="color: #da8548; font-weight: bold;">5</span>] ,[<span style="color: #da8548; font-weight: bold;">7</span>,<span style="color: #da8548; font-weight: bold;">7</span>] ,[<span style="color: #da8548; font-weight: bold;">8</span>,<span style="color: #da8548; font-weight: bold;">4</span>] ,[<span style="color: #da8548; font-weight: bold;">9</span>,<span style="color: #da8548; font-weight: bold;">5</span>]]
<span style="color: #dcaeea;">groupB</span> = [[<span style="color: #da8548; font-weight: bold;">2</span>,<span style="color: #da8548; font-weight: bold;">2</span>] ,[<span style="color: #da8548; font-weight: bold;">4</span>,<span style="color: #da8548; font-weight: bold;">2</span>] ,[<span style="color: #da8548; font-weight: bold;">4</span>,<span style="color: #da8548; font-weight: bold;">4</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">4</span>] ,[<span style="color: #da8548; font-weight: bold;">5</span>,<span style="color: #da8548; font-weight: bold;">3</span>] ,[<span style="color: #da8548; font-weight: bold;">6</span>,<span style="color: #da8548; font-weight: bold;">2</span>]]

<span style="color: #dcaeea;">tarx</span> = <span style="color: #da8548; font-weight: bold;">5</span>
<span style="color: #dcaeea;">tary</span> = <span style="color: #da8548; font-weight: bold;">5</span>

<span style="color: #dcaeea;">centerX</span>, <span style="color: #dcaeea;">centerY</span> = Average(groupA)
<span style="color: #dcaeea;">sdA</span> = (tarx - centerX)*(tarx - centerX)
<span style="color: #dcaeea;">centerX</span>, <span style="color: #dcaeea;">centerY</span> = Average(groupB)
<span style="color: #dcaeea;">sdB</span> = (tarx - centerX)*(tarx - centerX)

<span style="color: #51afef;">if</span> sdA &lt; sdB:
    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"A"</span>)
<span style="color: #51afef;">else</span>:
    <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"B"</span>)

<span style="color: #c678dd;">print</span>(ed(groupA, tarx, tary))
<span style="color: #c678dd;">print</span>(ed(groupB, tarx, tary))


</pre>
</div>

<pre class="example">
B
7.851114570556208
6.708203932499369
</pre>
</div>
</div>
<div id="outline-container-classify-homework" class="outline-2">
<h2 id="classify-homework"><span class="section-number-2">5.</span> 個人作業</h2>
<div class="outline-text-2" id="text-classify-homework">
</div>
<div id="outline-container-orgfd0f0e2" class="outline-3">
<h3 id="orgfd0f0e2"><span class="section-number-3">5.1.</span> 背景</h3>
<div class="outline-text-3" id="text-5-1">
<p>
某醫學研究中心針對旗下醫院800名疑似患有「無定向喪心病狂間歇性全身機能失調症」的患者做了一份病徵研究，針對以下這些可能病徵進行程度檢驗
</p>
<ol class="org-ol">
<li>抑鬱</li>
<li>癲癇</li>
<li>精神分裂</li>
<li>輕挑驕傲</li>
<li>沒大沒小</li>
<li>有犯罪傾向</li>
<li>月經前緊張(男患者嚴重的話也有)</li>
<li>有自殺傾向</li>
</ol>
<p>
這800份資料可以<a href="https://letranger.github.io/downloads/qq.csv">點選這裡</a>下載，每筆資料有九個欄位，前八欄分別對應到上述八項病徵，最後一欄為0/1，代表病患是否患有該病。
</p>

<p>
請你建立一個預測MODEL，以利該中心將來遇到類似病情的患者時只要先針對這些特徵值進行檢驗，即可了解該病例是否為此病患者，並即時予以適當治療。
</p>
</div>
</div>
<div id="outline-container-org82be327" class="outline-3">
<h3 id="org82be327"><span class="section-number-3">5.2.</span> 作業要求</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>嗯，基本上就是自由心證，你能交多少就交多少，你想只交一張圖也行，你要從頭交待你在做什麼、每一個步驟有啥意義、一共測了幾種CASE、最後成果如何、你的心得&#x2026;.也行，看你的誠意啦-_-(這向來是最坑人的一句話)</li>
<li>我是這樣覺得啦&#x2026;model隨便叠一叠，精確度至少也不應該低於 <b>0.8</b> 吧&#x2026;QQ</li>
</ul>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Hands-On Machine Learning with Scikit-Learn: Aurelien Geron
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2023-12-05 Tue 12:41</p>
</div>
</body>
</html>