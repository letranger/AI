:PROPERTIES:
:ID:       7dcd56b4-ee51-4f67-ac7b-dfd1ac58d5ff
:END:
#+title: #+title: 線性與非線性

* 模型範例
** 線性模型(Linear Models)
** 非線性模型(Nonlinear Models)
*** 常用的 Nonlinear Models
**** [[id:20221023T101626.420918][監督式學習]]
- Decision tree
- Ensemble models: Random forest, XGBoost
- Neural network
**** [[id:20221023T101716.467694][非監督式學習]]
- tSNE(t-Distributed Stochastic Neighbor Embedding)
*** Decision Tree
**** example: https://en.akinator.com
**** 要定義很多 rule 才能把 tree 建起來
*** Ensemble Models
**** 用多棵樹來決定，做法為
1. Get a set of classifiers, f1(x),f2(x),f3(x),...
2. Aggregate the classifiers (properly)
*** 選取 model 的考量
- Bias v.s. Variance
- Error from bias
- Error from variance
- Error observed
- underfitting v.s. overfitting
  overfitting: 完全符合 training data, 但 testing data 效果很差
*** Bagging
**** This approach would be helpful when your model is complex, easy to overfit.
**** 適用系統:
- decision tree: 只要樹夠深，可以 train 到 100%，但是對新進來的資料完全無用，即 overfitting
**** Random Forest
- 將 decision tree 應用到 bagging 的方式
- 做法：每次從 M 個特徵抽出 m 個來建 decision tree
*** XGBoost
**** eXtreme Gradient Boosting
**** Kaggle 機器學習競賽常用 solution
**** 為一種集思廣益的策略
- hello $$E=mc^2$$
- test
**** 一次一次加入一棵新的 tree,每加一棵新 tree 都要讓 loss 降低
*** CNN
**** 目的在減少類神經網路每一個 layer 的 feature 數量，以減化連結複雜度
**** CNN 主要用來處理圖片: A neuron does not have to see the whole image to discover the pattern.
