:PROPERTIES:
:ID:       20221023T101228.247381
:ROAM_ALIASES: Deep-Learning
:END:
#+title: æ·±åº¦å­¸ç¿’
# -*- org-export-babel-evaluate: nil -*-
#+INCLUDE: ../pdf.org
#+PROPERTY: header-args :eval never-export
#+TAGS: AI, Python
#+EXCLUDE_TAGS: noexport
#+OPTIONS: toc:2 ^:nil num:3
#+OPTIONS: H:4
#+LATEX:\newpage
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../css/muse.css" />
#+begin_export html
<a href="https://letranger.github.io/AI/20221023101228-æ·±åº¦å­¸ç¿’.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023101228-æ·±åº¦å­¸ç¿’.html.svg"/></a>
#+end_export

* æ·±åº¦å­¸ç¿’
#+CAPTION: AI, Machine Learningèˆ‡Deep Learning
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/AI,_Machine_Learningèˆ‡Deep_Learning/2024-02-19_16-24-48_2024-02-19_16-23-09.png]]

åœ¨[[id:d6daa102-05bb-475d-b619-db8b61e86030][ç¥ç¶“ç¶²è·¯]]ä¸­æˆ‘å€‘æ›¾ç¶“æåŠï¼š
#+begin_quote
æ·±åº¦ç¥ç¶“ç¶²è·¯(Deep Neural Network, DNN)ï¼Œé¡§åæ€ç¾©å°±æ˜¯æœ‰å¾ˆå¤šå±¤çš„ç¥ç¶“ç¶²è·¯ã€‚ç„¶è€Œï¼Œå¹¾å±¤æ‰ç®—æ˜¯å¤šå‘¢ï¼Ÿä¸€èˆ¬ä¾†èªªæœ‰1-2å€‹éš±è—å±¤çš„ç¥ç¶“ç¶²çµ¡å°±å¯ä»¥å«åšå¤šå±¤ï¼Œæº–ç¢ºçš„èªªæ˜¯(æ·ºå±¤)ç¥ç¶“ç¶²çµ¡(Shallow Neural Networks)ã€‚éš¨è‘—éš±è—å±¤çš„å¢å¤šï¼Œæ›´æ·±çš„ç¥ç¶“ç¶²çµ¡(ä¸€èˆ¬ä¾†èªªè¶…é3å±¤)å°±éƒ½å«åšæ·±åº¦ç¥ç¶“ç¶²è·¯[fn:1]ã€‚è€Œé‚£äº›ä»¥æ·±åº¦ç¥ç¶“ç¶²è·¯ç‚ºæ¨¡å‹çš„æ©Ÿå™¨å­¸ç¿’å°±æ˜¯æˆ‘å€‘è€³ç†Ÿèƒ½è©³çš„[[id:20221023T101228.247381][æ·±åº¦å­¸ç¿’]]ã€‚
#+end_quote

é‚£éº¼å¹¾å±¤æ‰ç®—æ˜¯å¤ æ·±å‘¢ï¼Ÿå¯¦éš›ä¸Šï¼Œã€Œæ·±åº¦ã€åªæ˜¯ä¸€å€‹å•†æ¥­æ¦‚å¿µï¼Œå¾ˆå¤šæ™‚å€™å·¥æ¥­ç•ŒæŠŠ3å±¤éš±è—å±¤ä¹Ÿå«åšã€Œæ·±åº¦å­¸ç¿’ã€ï¼Œåœ¨æ©Ÿå™¨å­¸ç¿’é ˜åŸŸçš„ç´„å®šä¿—æˆæ˜¯ï¼Œåå­—ä¸­æœ‰æ·±åº¦(Deep)çš„ç¶²çµ¡åƒ…ä»£è¡¨å…¶æœ‰è¶…é5-7å±¤çš„éš±è—å±¤[fn:1]ã€‚

å…¸å‹çš„æ·±åº¦å­¸ç¿’å¦‚åœ–[[fig:python-deep-learning-1]]ï¼Œåœ¨æ­¤ä¾‹ä¸­ï¼Œè¼¸å…¥ç‚ºä¸€å¼µæ‰‹å¯«æ•¸å­—çš„å½±åƒï¼Œç¶“ç”± 4 å±¤çš„æ·±åº¦å­¸ç¿’æ¨¡å‹å¾Œå¾—çŸ¥æ­¤æ•¸å­—ç‚º 4ã€‚

#+CAPTION: å…¸å‹çš„æ·±åº¦ç¥ç¶“ç¶²è·¯-1
#+LABEL:fig:python-deep-learning-1
#+name: fig:python-deep-learning-1
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 400
#+ATTR_HTML: :width 500
[[file:images/img-191107113927.jpg]]

åœ–[[fig:python-deep-learning-2]]é€²ä¸€æ­¥èªªæ˜ç¶²è·¯æ¨¡å‹ä¸­æ¯ä¸€å±¤çš„ä½œç”¨ï¼Œå¯ä»¥å°‡æ¯ä¸€å±¤ç¶²è·¯è¦–ç‚ºå°å½±åƒçš„ç‰¹æ®Šé‹ç®—ï¼Œå¦‚æ­¤ä¸€å±¤ä¸€å±¤é€ä¸€ç²¾ç…‰(purified)ï¼Œæœ€å¾Œå¾—åˆ°çµæœã€‚

#+CAPTION: å…¸å‹çš„æ·±åº¦ç¥ç¶“ç¶²è·¯-2
#+LABEL:fig:python-deep-learning-2
#+name: fig:python-deep-learning-2
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 400
#+ATTR_HTML: :width 500
[[file:images/img-1911071139277.jpg]]

é—œæ–¼å¢åŠ å±¤æ•¸çš„é‡è¦æ€§ï¼Œç›®å‰é‚„ç¼ºä¹ç†è«–ä½è­‰ï¼Œä½†å¾éå¾€çš„ç ”ç©¶æˆ–å¯¦é©—ä¸­ï¼Œæœ‰å¹¾é»å¯ä»¥èªªæ˜ã€‚
1. åœ¨ ILSVRC é€™ç¨®å¤§å‹è¦–è¦ºè¾¨è­˜ç«¶è³½çµæœä¸­ï¼ŒåŠ æ·±å±¤æ•¸çš„æ¯”ä¾‹å¤šèˆ‡è¾¨è­˜æ•ˆèƒ½æˆæ­£æ¯”ã€‚
2. åŠ æ·±å±¤æ•¸å¯ä»¥åœ¨æ¸›å°‘ç¶²è·¯åƒæ•¸çš„ç‹€æ³ä¸‹å¾—åˆ°ç›¸åŒæˆæ•ˆï¼Œé€éé‡å å±¤ç´šï¼Œå¯ä»¥è®“ ReLU ç­‰æ´»åŒ–å‡½æ•¸å¤¾åœ¨å·ç©å±¤ä¹‹é–“ï¼Œé€²ä¸€æ­¥æé«˜ç¶²è·¯çš„è¡¨ç¾åŠ›ï¼Œå› ç‚ºé€éæ´»åŒ–å‡½æ•¸ï¼Œå¯ä»¥åœ¨ç¶²è·¯å¢åŠ ã€Œéç·šæ€§ã€çš„èƒ½åŠ›ï¼Œé‡å éç·šæ€§å‡½æ•¸ï¼Œä¹Ÿèƒ½é”åˆ°æ›´è¤‡é›œçš„è¡¨ç¾åŠ›ã€‚
3. å­¸ç¿’çš„æ•ˆç‡ä¹Ÿæ˜¯åŠ æ·±å±¤æ•¸çš„å„ªé»ä¹‹ä¸€ï¼Œå·ç©å±¤çš„ç¥ç¶“å…ƒæœƒåæ‡‰å‡ºé‚Šç•Œç­‰å–®ç´”å½¢ç‹€ï¼Œéš¨è‘—å±¤æ•¸å¢åŠ ï¼Œå¯ä»¥åæ‡‰å‡ºç´‹ç†ã€ç‰©é«”éƒ¨ä½ç­‰ç‰¹è³ªï¼Œä¾ç…§éšå±¤é€æ¼¸è®Šè¤‡é›œã€‚
4. ä»¥è¾¨è­˜ã€Œç‹—ã€ç‚ºä¾‹å­ï¼Œå¦‚æœè¦ä»¥å±¤æ•¸è¼ƒå°‘çš„ç¶²è·¯ä¾†è§£æ±ºé€™å€‹å•é¡Œï¼Œå·ç©å±¤å°±è¦ä¸€æ¬¡ã€Œç†è§£ã€çœ¾å¤šç‰¹å¾µï¼Œé‚„è¦å› æ‡‰ä¸åŒæ‹æ”ç’°å¢ƒå¸¶ä¾†çš„è®ŠåŒ–ï¼Œä¸€æ¬¡è™•ç†é€™äº›é¾å¤§çš„è³‡æ–™æœƒèŠ±è²»è¨±å¤šå­¸ç¿’æ™‚é–“ï¼› å¦‚æœåŠ æ·±å±¤æ•¸ï¼Œå°±èƒ½ç”¨éšå±¤åˆ†è§£å¿…é ˆå­¸ç¿’çš„å•é¡Œï¼Œæ¯ä¸€å±¤å¯ä»¥è™•ç†å–®ç´”çš„å•é¡Œï¼Œä¾‹å¦‚ï¼Œæœ€åˆçš„å±¤ç´šå¯ä»¥åªå­¸ç¿’é‚Šç•Œï¼Œåˆ©ç”¨å°‘é‡çš„å­¸ç¿’è³‡æ–™ä¾†é€²è¡Œæ•ˆç‡åŒ–çš„å­¸ç¿’ã€‚
5. åŠ æ·±å±¤æ•¸å¯ä»¥éšå±¤æ€§çš„å‚³éè³‡æ–™ï¼Œä¾‹å¦‚ï¼Œæ“·å–å‡ºé‚Šç•Œçš„ä¸‹ä¸€å±¤æœƒä½¿ç”¨é‚Šç•Œè³‡æ–™ä¾†å­¸ç¿’æ›´é«˜éšçš„å•é¡Œï¼ˆå¦‚åˆ¤æ–·å½¢ç‹€ï¼‰ã€‚

** æ·±åº¦å­¸ç¿’çš„çŸ¥åæ¨¡å‹
å¹¾å€‹çŸ¥åçš„æ·±åº¦å­¸ç¿’æ¨¡å‹å¦‚ä¸‹ï¼š
*** VGG
VGG ç‚ºç”±å·ç©å±¤èˆ‡æ± åŒ–å±¤æ§‹æˆçš„åŸºæœ¬ CNNã€‚ç‰¹è‰²æ˜¯å«æ¬Šé‡å±¤ï¼ˆå·ç©å±¤åŠå…¨é€£æ¥å±¤ï¼‰å…± 16-19 å±¤ï¼Œæœ‰æ™‚æœƒç¨±ç‚º VGG16[fn:2] æˆ– VGG19[fn:3]ã€‚VGG ç”±æ–¼çµæ§‹éå¸¸ç°¡å–®ï¼Œæ‡‰ç”¨æ€§é«˜ï¼Œæ‰€ä»¥å¤šæ•¸æŠ€è¡“äººå“¡å–œæ­¡ä½¿ç”¨ä»¥ VGG ç‚ºæœ€åŸºç¤çš„ç¶²è·¯ã€‚

#+CAPTION: VGG-16
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/æ·±åº¦å­¸ç¿’/2024-03-21_15-57-59_2024-03-21_15-57-03.png]]

#+CAPTION: VGG-19
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/æ·±åº¦å­¸ç¿’/2024-03-21_16-01-45_2024-03-21_16-01-21.png]]
*** GoogLeNet
GoogLeNet[fn:4]ç‚º2014 å¹´ ILSVRC (ImageNet Large Scale Visual Recognition Competition)åœ–åƒåˆ†é¡ç«¶è³½çš„å† è»å¾—ä¸»ï¼Œèˆ‡ VGGNetï¼ˆè©²å¹´çš„äºè»ï¼‰ç›¸æ¯”å…·æœ‰ç›¸å°è¼ƒä½çš„éŒ¯èª¤ç‡ã€‚GoogLeNetåŸºæœ¬ä¸Šèˆ‡ CNN ç›¸åŒï¼Œå…¶ç‰¹è‰²æ˜¯ä¸åƒ…æœƒå¾€å‚ç›´æ–¹å‘åŠ æ·±ç¶²è·¯ï¼Œä¹Ÿæœƒå¾€æ°´å¹³æ–¹å‘åŠ æ·±ã€‚GoogLeNet å¾€æ°´å¹³æ–¹å‘çš„åšæ³•ç¨±ç‚ºã€ŒInception çµæ§‹ã€ã€‚
#+CAPTION: GoogLeNet
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 700
[[file:images/æ·±åº¦å­¸ç¿’/2024-03-21_16-04-21_2024-03-21_16-04-02.png]]
*** ResNet
ResNet[fn:5]æ˜¯ç”± Microsoft åœ˜éšŠé–‹ç™¼çš„ç¶²è·¯ï¼Œç‰¹è‰²æ˜¯å…·æœ‰èƒ½åŠ æ·±æ¯”éå»æ›´å¤šå±¤çš„ã€Œçµæ§‹ã€ï¼Œç‚ºäº†è§£æ±ºå› åŠ æ·±éå¤šå±¤æ•¸ç„¡æ³•é †åˆ©å­¸ç¿’çš„å•é¡Œï¼ŒResNet å°å…¥äº†ã€Œè·³èºçµæ§‹ã€ï¼ˆä¹Ÿç¨±ç‚ºæ·å¾‘æˆ–åˆ†æµï¼‰ã€‚è·³èºçµæ§‹æ˜¯ã€Œç›´æ¥ã€å‚³éè¼¸å…¥è³‡æ–™ï¼Œæ‰€ä»¥åœ¨åå‘å‚³æ’­æ™‚ï¼Œä¹Ÿæœƒå°‡ä¸Šå±¤çš„æ¢¯åº¦ã€Œç›´æ¥ã€å‚³éçµ¦ä¸‹å±¤ã€‚é€éé€™ç¨®è·³èºçµæ§‹ï¼Œä¸ç”¨æ“”å¿ƒæ¢¯åº¦è®Šå°ï¼ˆæˆ–è®Šå¾—å¤ªå¤§ï¼‰ï¼Œå¯ä»¥æŠŠã€Œå…·æœ‰æ„ç¾©çš„æ¢¯åº¦ã€å‚³éçµ¦ä¸Šå±¤ã€‚å› æ­¤ï¼Œè·³èºçµæ§‹èƒ½æ¸›å°‘ä¹‹å‰å› ç‚ºåŠ æ·±å±¤æ•¸ï¼Œä½¿å¾—æ¢¯åº¦è®Šå°ï¼Œå‡ºç¾æ¢¯åº¦æ¶ˆå¤±çš„å•é¡Œã€‚
#+CAPTION: ResNet
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 700
[[file:images/æ·±åº¦å­¸ç¿’/2024-03-21_16-13-12_2024-03-21_16-13-03.png]]
*** ImageNetå¤§è³½
å¾ä¸‹åœ–å¯è§€å¯Ÿåˆ°ï¼Œç¶²è·¯çš„å±¤æ•¸å¾2014å¹´GoogLeNetçš„22å±¤çˆ†å¢åˆ°2015å¹´ResNetçš„152å±¤ï¼Œè¶³è¶³å¤šäº†130å±¤ã€‚é€™å€‹çµæœè­‰å¯¦äº†è¶Šæ·±çš„ç¶²è·¯ï¼Œåœ¨æ²’æœ‰Overfittingçš„æƒ…æ³ä¸‹ï¼Œæ•ˆæœæ˜¯è¶Šå¥½çš„[fn:6]ã€‚
#+CAPTION: ImageNetæ­·å¹´å† è»
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/æ·±åº¦å­¸ç¿’/2024-03-21_16-28-03_2024-03-21_16-26-55.png]]

é‚£éº¼...å¦‚æœæƒ³è¦æå‡æ¨¡å‹çš„æ•ˆæœï¼Œæ˜¯ä¸æ˜¯åŠ è¶Šå¤šç¶²è·¯å±¤ï¼Œä½¿ç¶²è·¯è¶Šæ·±å°±å¯ä»¥äº†å‘¢ï¼Ÿï¼Œåº•ä¸‹é€™å€‹ç ”ç©¶çµæœå¯ä»¥çµ¦æˆ‘å€‘ä¸€é»å•Ÿç™¼ï¼š

#+CAPTION: DNNå±¤æ•¸èˆ‡èª¤å·®çš„å¯¦é©—
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/æ·±åº¦å­¸ç¿’/2024-03-21_16-38-24_2024-03-21_16-38-14.png]]

é€™æ˜¯ç‚º2016å¹´IEEE Conference on Computer Vision and Pattern Recognitionçš„ä¸€ç¯‡ç ”ç©¶çµæœ[fn:7]ï¼Œå¯¦é©—çµæœé¡¯ç¤ºä¸€èˆ¬æ·±åº¦ç¶²è·¯å±¤æ•¸è¶Šå¤šï¼Œè¨“ç·´èª¤å·®ä¸é™åå¢ã€‚

** æ·±åº¦å­¸ç¿’çš„é«˜é€ŸåŒ–
ç”±æ–¼å¤§æ•¸æ“š(big data)èˆ‡å¤§å‹ç¶²è·¯çš„é—œä¿‚ï¼Œä½¿å¾—æ·±åº¦å­¸ç¿’å¿…é ˆé€²è¡Œå¤§é‡é‹ç®—ï¼Œéå»æˆ‘å€‘ä½¿ç”¨ CPU ä¾†é€²è¡Œé‹ç®—ï¼Œå¦‚ä»Šå¤šæ•¸æ·±åº¦å­¸ç¿’çš„æ¡†æ¶å¤šæ”¯æ´ GPUï¼Œç”šè‡³æ”¯æ´ä»¥å¤šå€‹ GPU èˆ‡å¤šå°è£ç½®é€²è¡Œåˆ†æ•£å¼å­¸ç¿’ã€‚GPU åŸæœ¬æ˜¯åœ–å½¢å°ˆç”¨è™•ç†å™¨ï¼Œå¯ä»¥å¿«é€Ÿè™•ç†å¹³è¡Œé‹ç®—ï¼ŒGPU é‹ç®—çš„ç›®æ¨™æ˜¯æŠŠå…¶å¼·å¤§çš„æ•ˆèƒ½é‹ç”¨åœ¨å„ç¨®ç”¨é€”ã€‚æ¯”è¼ƒ CPU èˆ‡ GPU åœ¨ AlexNet çš„å­¸ç¿’ï¼ŒCPU éœ€èŠ±è²» 40 å¤©ä»¥ä¸Šï¼ŒGPU å‰‡å¯ä»¥åœ¨ 6 å¤©å…§å®Œæˆã€‚

åˆ©ç”¨ GPU é™¤äº†å¯ä»¥å¤§å¹…æå‡æ·±åº¦å­¸ç¿’çš„é‹ç®—é€Ÿåº¦ï¼Œä½†æ˜¯ä¸€æ—¦è®Šæˆå¤šå±¤ç¶²è·¯æ™‚ï¼Œå°±éœ€è¦èŠ±è²»æ•¸å¤©æˆ–æ•¸é€±çš„æ™‚é–“ä¾†å­¸ç¿’ï¼ŒGoogle çš„ TensorFlowã€Microsoft çš„ CNTK ä¾¿æ˜¯é‡å°åˆ†æ•£å¼å­¸ç¿’ä¾†é–‹ç™¼çš„ï¼Œ100 å€‹åˆ†æ•£å¼çš„ GPU å¯ä»¥æå‡æ¯”å–®ä¸€ GPU é«˜åˆ° 56 å€çš„é€Ÿåº¦ï¼Œæ„å‘³è‘—åŸæœ¬è¦æœ‰å¤©æ‰èƒ½å®Œæˆçš„å­¸ç¿’ï¼Œåªè¦ 3 å°æ™‚å°±å¯ä»¥çµæŸã€‚

åœ¨æ·±åº¦å­¸ç¿’çš„é«˜é€ŸåŒ–éç¨‹ä¸­ï¼ŒåŒ…å«é‹ç®—é‡åœ¨å…§ï¼Œè¨˜æ†¶é«”å®¹é‡ã€åŒ¯æµæ’é »å¯¬ç­‰ï¼Œéƒ½æœƒé€ æˆç“¶é ¸ï¼Œå°±è¨˜æ†¶é«”å®¹é‡ä¾†èªªï¼Œå¿…é ˆè€ƒæ…®åˆ°å¤§é‡æ¬Šé‡åƒæ•¸åŠä¸­é–“è³‡æ–™æœƒå„²å­˜åœ¨è¨˜æ†¶é«”çš„æƒ…æ³ã€‚è‡³æ–¼åŒ¯æµæ’é »å¯›ï¼Œä¸€æ—¦é€šé GPU(æˆ– CPU)çš„åŒ¯æµæ’è³‡æ–™è¶…éä¸€å®šçš„é™åˆ¶ï¼Œè©²è™•å°±æœƒå½¢æˆç“¶é ¸ï¼Œæ‰€ä»¥ï¼Œæœ€å¥½èƒ½å„˜é‡æ¸›å°‘é€šéç¶²è·¯çš„è³‡æ–™ä½å…ƒæ•¸ã€‚
*** GPU v.s. CPU
#+CAPTION: CPU èˆ‡ GPU åœ¨æ¶æ§‹ä¸Šçš„è¨­è¨ˆå·®ç•°
#+LABEL:fig:CPUGPU
#+name: fig:CPUGPU
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/æ·±åº¦å­¸ç¿’/2024-02-20_10-26-27_2024-02-20_10-25-03.png]]

å¦‚åœ–[[fig:CPUGPU]]ï¼ŒCPU å’Œ GPU çš„å·®ç•°èµ·æºæ–¼å…¶ç›¸ç•°çš„è¨­è¨ˆç›®æ¨™èˆ‡æ‡‰ç”¨å ´æ™¯ï¼Œ CPUçš„è¨­è¨ˆç›®çš„æ˜¯è™•ç†å„ç¨®ä¸åŒçš„æ•¸æ“šé‹ç®—ã€é‚è¼¯åˆ¤æ–·å’Œä¸­æ–·è¦æ±‚;è€Œ GPU çš„è¨­è¨ˆç›®çš„å‰‡æ˜¯ç‚ºäº†åœ–å½¢é‹ç®—ï¼Œ å…¶å„ªå‹¢åœ¨æ–¼èƒ½å¿«é€Ÿå°åŒé¡å‹çš„æ•¸æ“šé€²è¡Œå¹³è¡Œé‹ç®—[fn:8]ã€‚äºŒè€…ä¸»è¦å·®ç•°å¤§è‡´å¦‚ä¸‹ï¼š
- CPU æ˜¯ç”±å¹¾å€‹æ¯æ¬¡å¯è™•ç†æ•¸å€‹ç¨ç«‹ã€ŒåŸ·è¡Œç·’ã€(threads)çš„æ ¸å¿ƒ(core)æ‰€çµ„æˆï¼›GPU å‰‡æœ‰æ•¸ç™¾å€‹é€™æ¨£çš„æ ¸å¿ƒï¼ŒåŒæ™‚å¯ä»¥è™•ç†ä¸Šåƒå€‹åŸ·è¡Œç·’
- CPU ä¸»è¦æ˜¯ç·šæ€§åŸ·è¡Œï¼› GPU å‰‡æ˜¯å€‹é«˜åº¦å¹³è¡ŒåŒ–çš„å–®å…ƒ
- CPU çš„ç™¼å±•ä¸»è¦è‡´åŠ›æ–¼æœ€ä½³åŒ–ç³»çµ±çš„é²æ»¯æ™‚é–“ï¼Œè®“ç³»çµ±èƒ½æœ‰è¿…é€Ÿæµæš¢çš„åæ‡‰ï¼›GPU çš„ç™¼å±•å‰‡æ˜¯æœé »å¯¬æœ€ä½³åŒ–åŠªåŠ›ã€‚åœ¨æ·±åº¦ç¥ç¶“ç¶²è·¯ä¸­ï¼Œé »å¯¬ç‚ºä¸»è¦çš„ç³»çµ±ç“¶é ¸
- GPU çš„ Level 1 cache æ¯” CPU å¿«ä¸”å¤§ï¼Œåœ¨æ·±åº¦ç¥ç¶“ç¶²è·¯ä¸­ï¼Œå¤§éƒ¨ä»½çš„è³‡æ–™éƒ½æœƒå†æ¬¡è¢«ä½¿ç”¨åˆ°

** æ·±åº¦å­¸ç¿’æ‡‰ç”¨é ˜åŸŸ :noexport:
*** å½±åƒè¾¨è­˜:å·ç©ç¥ç¶“ç¶²è·¯ CNN
MNIST æ­·å¹´çš„ç«¶è³½å‰å¹¾åéƒ½æ˜¯ä»¥ CNN ç‚ºåŸºç¤ï¼Œé€²ä¸€æ­¥æé«˜è¾¨è­˜æº–ç¢ºç‡çš„æ–¹æ³•é‚„åŒ…æ‹¬æ•´é«”å­¸ç¿’ã€å­¸ç¿’ç‡éæ¸›ï¼ˆlearning rate decayï¼‰ã€è³‡æ–™æ“´å¢ï¼ˆData Augmentation, å¦‚åˆ©ç”¨æ—‹è½‰ã€å‚ç›´æˆ–æ°´å¹³ç§»å‹•è¼¸å…¥å½±åƒä¾†å°å¹…æ”¹è®Šè¼¸å…¥è³‡æ–™ä»¥å¢åŠ è¼¸å…¥å½±åƒå¼µæ•¸ï¼‰ã€‚

å‚³çµ±æ©Ÿå™¨å­¸ç¿’é€²è¡Œåœ–ç‰‡è­˜åˆ¥ï¼Œä¸»è¦æ˜¯å¸Œæœ›èƒ½é€éåŸå§‹åƒæ•¸å€¼æ‰¾å‡ºä¸€ç¨®é©åˆçš„åˆ†é¡å™¨(classifier)ï¼Œä½†äº‹å¯¦è­‰æ˜é€™éº¼åšä¸ç®¡ç”¨ï¼Œå› ç‚ºä¿¡å™ªæ¯”å¤ªä½ã€‚å¾Œä¾†çš„æ”¹å–„æ–¹å¼æ˜¯ç”±äººé¡æŒ‘é¸å‡ºé‡è¦ç‰¹å¾µï¼Œç„¶å¾Œç”±æ©Ÿå™¨å­¸ç¿’æ¼”ç®—æ³•ä½¿ç”¨é€™äº›ã€Œç‰¹å¾µå‘é‡(feature vectors)ã€é€²è¡Œåˆ†é¡åˆ¤æ–·ã€‚é€™ç¨®ç‰¹å¾µæå–(feature extraction)çš„åšæ³•ç¢ºå¯¦æ”¹å–„äº†ä¿¡å™ªæ¯”ï¼Œä½†æ˜¯å¦‚æœåœ–ç‰‡çš„é‡è¦ç‰¹é»å› å…‰ç·šæˆ–å…¶ä»–å› ç´ é›£ä»¥è­˜åˆ¥ï¼Œå‰‡ç²¾ç¢ºç‡æœƒé™ä½å¾ˆå¤šï¼Œè€Œä¸”ï¼Œäº‹å‰çš„äººå·¥æŒ‘é¸ç‰¹å¾µèŠ±å»å¤ªå¤šäººåŠ›ï¼Œä»¥æ·±åº¦å­¸ç¿’é€²è¡Œåœ–ç‰‡è¦–è¦ºå°±æ˜¯è¨­æ³•æ¶ˆé™¤é‚£äº›æ—¢ç¹ç‘£åˆæœƒé€ æˆä¾·é™æ€§çš„ç‰¹å¾µé¸å–ç¨‹åºã€‚David Hubel å’Œ Torsten Wiesel ç™¼ç¾å‹•ç‰©è¦–è¦ºçš®å±¤æœ‰ä¸€éƒ¨ä»½å°ˆé–€è² è²¬æª¢æ¸¬é‚Šç·£ï¼Œ1959 å¹´ä»–å€‘æŠŠé›»æ¥µæ’å…¥è²“çš„å¤§è…¦ä¸­ï¼Œåœ¨è¢å¹•ä¸ŠæŠ•å°„å‡ºé»‘ç™½åœ–æ¡ˆï¼Œç™¼ç¾æœ‰äº›ç¥ç¶“å…ƒåªæœ‰åœ¨å‡ºç¾å‚ç›´ç·šæ™‚è¢«æ¿€ç™¼ï¼Œæœ‰äº›å‰‡åªæœ‰åœ¨å‡ºç¾æ°´å¹³ç·šæ™‚è¢«æ¿€ç™¼ï¼Œæœ‰äº›å‰‡æ˜¯åªæœ‰çœ‹åˆ°æŸç‰¹å®šè§’åº¦çš„ç·šæ™‚è¢«æ¿€ç™¼ã€‚é€²ä¸€æ­¥çš„ç ”ç©¶ç¢ºèªï¼Œè¦–è¦ºçš®å±¤æ˜¯ä»¥åˆ†å±¤çš„çµæ§‹çµ„ç¹”èµ·ä¾†çš„ï¼Œæ¯ä¸€å±¤éƒ½æœƒæ ¹æ“šå‰ä¸€å±¤æ‰€åµæ¸¬åˆ°çš„ç‰¹å¾µå¾—å‡ºé€²ä¸€æ­¥çš„è¨Šæ¯ï¼Œå¾ç·šæ¢ã€è¼ªå»“ã€å½¢ç‹€ï¼Œä¸€ç›´åˆ°æ•´å€‹ç‰©é«”ã€‚ç”±ä¸Šè¿°ç ”ç©¶å¾—ä¾†çš„ç¬¬ä¸€å€‹æ¦‚å¿µå°±æ˜¯ã€Œéæ¿¾å™¨(filter)ã€ã€‚

å…¸å‹çš„éæ¿¾å™¨å¦‚ä¸‹ï¼š
- blur = [[1./9, 1./9, 1./9], [1./9, 1./9, 1./9], [1./9, 1./9, 1./9]]
#+CAPTION: æ¨¡ç³Šéæ¿¾å™¨
#+name: fig:blurFilter
#+ATTR_LATEX: :width 300
#+ATTR_HTML: :width 500
#+ATTR_ORG: :width 300
[[file:images/blur-filter.png]]

- edges = [[1, 1, 1], [1, -8, 1], [1, 1, 1]]
#+CAPTION: é‚Šç·£å¼·èª¿éæ¿¾å™¨
#+name: fig:edgesFilter
#+ATTR_LATEX: :width 300
#+ATTR_HTML: :width 500
#+ATTR_ORG: :width 400
[[file:images/edges-filter.png]]

åœ–[[fig:blurFilter]]ç‚ºä¸€ 3*3 çš„æ¨¡æ¥œå¼·éæ¿¾å™¨ç”¢ç”Ÿçš„æ•ˆæœï¼Œåœ–[[fig:edgesFilter]]å‰‡ç‚ºé‚Šç·£å¼·é€±å™¨çš„æ•ˆæœã€‚éæ¿¾å™¨å¯ä»¥æ”¹è®Šåœ–å½¢ï¼Œä¸¦é¡¯ç¤ºå¯ç”¨æ–¼ã€Œåœ–å½¢åµæ¸¬ã€å’Œã€Œåœ–å½¢åˆ†é¡ã€çš„ç‰¹å¾µã€‚ä¾‹å¦‚ï¼Œç‚ºäº†å°æ•¸å­—é€²è¡Œåˆ†é¡ï¼Œå…§éƒ¨çš„é¡è‰²ä¸¦ä¸é‡è¦ï¼Œæ­¤æ™‚ï¼Œé‚Šç·£å¼·èª¿éæ¿¾å™¨å°±æœ‰åŠ©æ–¼è¾¨è­˜æ•¸å­—çš„ä¸€èˆ¬å½¢ç‹€ï¼Œé€²è€Œæå‡æ•¸å­—è­˜åˆ¥æ•ˆèƒ½ã€‚

æˆ‘å€‘å¯ä»¥ç”¨ã€Œé¡ç¥ç¶“ç¶²è·¯ã€çš„æ–¹å¼ä¾†ç†è§£ã€Œéæ¿¾å™¨ã€ï¼Œå°‡æˆ‘å€‘å®šç¾©çš„ã€Œéæ¿¾å™¨ã€è¦–ç‚ºä¸€çµ„åŠ æ¬Šï¼Œæœ€çµ‚çš„å€¼åˆåšç‚ºä¸‹ä¸€å±¤çš„å•Ÿå‹•å€¼ï¼ˆè¼¸å…¥ï¼‰ã€‚å¦‚åœ–[[fig:filterScanner]]ï¼Œéæ¿¾å™¨æœƒé€æ¬¡æƒéæ•´å¼µåœ–ï¼Œç„¶å¾Œå»ºç«‹ä¸€çµ„æ–°çš„åœ–ç‰‡ï¼Œ
#+CAPTION: éæ¿¾å™¨çš„æƒç„è¨ˆç®—
#+name: fig:filterScanner
#+ATTR_LATEX: :width 260
#+ATTR_ORG: :width 260
#+ATTR_HTML: :width 500
[[file:images/filter-scanner.png]]
*** èªè¨€æ¨¡å‹
[[id:263cb433-d0eb-4400-a373-35175c000c01][å¾ªç’°ç¥ç¶“ç¶²è·¯]]
*** æ£‹ç›¤éŠæˆ²
å¤§ç´„åœ¨ 50 å¹´ä»£ï¼Œç ”ç©¶äººå“¡é–‹å§‹å»ºç«‹å…·æœ‰ AI çš„éŠæˆ²ï¼Œé€™äº›éŠæˆ²ä»¥ã€Œè¥¿æ´‹è·³æ£‹ã€(checkers)å’Œã€Œè¥¿æ´‹æ£‹ã€(chess)ç‚ºä¸»ï¼Œé€™å…©ç¨®éŠæˆ²æœ‰ä¸€äº›å…±åŒä¹‹è™•ï¼š
- å®ƒå€‘æ˜¯æ‰€è¬‚çš„ã€Œé›¶å’ŒéŠæˆ²ã€(zero-sum games)ï¼Œå³ä¸€å€‹ç©å®¶æ‰€å¾—åˆ°çš„å¥¬å‹µå°±ä¾†è‡ªå¦ä¸€å€‹ç©å®¶ç›¸å°æ‡‰çš„æå¤±ã€‚å¦ä¸€é¡ç›¸å°çš„éŠæˆ²å‰‡æ˜¯æŒ‡å…©ä½ç©å®¶å¯ä»¥é¸æ“‡åˆä½œï¼Œå¦‚ ã€Œå›šå¾’å›°å¢ƒã€(prisoner's dilemma)ã€‚
- å®ƒå€‘éƒ½å…·æœ‰ã€Œå®Œå…¨è³‡è¨Šã€(perfect information)ï¼Œå…©æ–¹ä¸åŒç©å®¶éƒ½çŸ¥é“éŠæˆ²çš„æ•´å€‹ç‹€æ…‹ï¼›å¦ä¸€ç¨®ç›¸å°çš„éŠæˆ²å‰‡æ˜¯æ’²å…‹ã€‚å› ç‚ºå¾—çŸ¥ç›®å‰ç‹€æ…‹å°±å¯ä»¥å°å‡ºæœ€å¥½çš„è¡Œå‹•ï¼Œæ‰€ä»¥é€™ç¨®éŠæˆ²å¯ä»¥æ¸›å°‘ AI æ‰€éœ€è™•ç†å•é¡Œçš„è¤‡é›œåº¦ã€‚
- å…©ç¨®éŠæˆ²éƒ½æœ‰ã€Œæ˜ç¢ºæ€§ã€(deterministic): å¦‚æœä¸€å€‹ç©å®¶ä¸‹äº†ä¸€æ­¥ï¼Œé€™æ­¥å°±æœƒå°è‡´ä¸€å€‹æ˜ç¢ºçš„ä¸‹ä¸€å€‹ç‹€æ…‹ï¼›å¦ä¸€ç¨®ç›¸å°çš„éŠæˆ²ä¸­ï¼Œç©å®¶ä¸‹çš„ä¸€æ­¥å¯èƒ½æ˜¯ä¸Ÿä¸€æ¬¡éª°å­æˆ–æ˜¯æŠ½ä¸€å¼µç‰Œï¼Œé€™å°±ç„¡æ³•å°è‡´ä¸€å€‹æ˜ç¢ºçš„ä¸‹ä¸€æ­¥ã€‚
*** é›»è…¦éŠæˆ²
*** ç•°å¸¸åµæ¸¬
*** ç‰©é«”åµæ¸¬
å¾å½±åƒä¸­åˆ†æå‡ºç‰©é«”ä½ç½®ï¼Œé€²è¡Œåˆ†é¡ã€‚ç‰©é«”åµæ¸¬æ¯”ç‰©é«”è¾¨è­˜çš„å•é¡Œæ›´å›°é›£ï¼Œæœ€è‘—åçš„æ–¹å¼ç‚º R-CNNï¼ŒR-CNN çš„å¯¦éš›è™•ç†æµç¨‹æœ‰é»è¤‡é›œï¼ŒåŒ…æ‹¬æŠŠå½±åƒè®Šå½¢æˆæ­£æ–¹å½¢ï¼Œä½¿ç”¨ SVM åˆ†é¡ã€‚
*** å½±åƒåˆ†å‰²
æŒ‡é‡å°å½±åƒä»¥åƒç´ æ¨™ç±¤é€²è¡Œé¡åˆ¥åˆ†é¡ï¼Œåˆ©ç”¨ç¥ç¶“ç¶²è·¯é€²è¡Œå½±åƒåˆ†å‰²ï¼Œæœ€ç°¡å–®çš„æ–¹æ³•å°±æ˜¯ä»¥å…¨éƒ¨çš„åƒç´ ç‚ºå°è±¡ï¼Œå†ä¾ç…§å„å€‹åƒç´ é€²è¡Œæ¨è«–è™•ç†ã€‚å…¸å‹åšæ³•ç‚º FCN(Fully Convolutional Network)ï¼Œç›¸å°æ–¼ä¸€èˆ¬ CNN å«æœ‰å…¨é€£æ¥å±¤çš„æƒ…æ³ï¼ŒFCN æŠŠå…¨é€£æ¥å±¤æ›´æ›æˆã€ŒåŸ·è¡Œç›¸åŒå‹•ä½œçš„å·ç©å±¤ã€ï¼Œåœ¨ç‰©é«”è¾¨è­˜çš„ç¶²è·¯å…¨é€£æ¥å±¤ä¸­ï¼Œä¸­é–“è³‡æ–™çš„ç©ºé–“å¤§å°ç•¶ä½œæ’åˆ—æˆ 1 è¡Œç¯€é»ä¾†è™•ç†ã€‚
*** ç”¢ç”Ÿåœ–èªª
é‡å°å½±åƒè‡ªå‹•ç”¢ç”Ÿèªªæ˜è©²å½±åƒçš„å…§å®¹ï¼Œä»£è¡¨æ€§æ–¹æ³•ç‚º NIC (Neural Image Caption)æ¨¡å‹ï¼ŒNIC æ˜¯ç”±è™•ç†å¤šå±¤ CNN èˆ‡è‡ªç„¶èªè¨€çš„ RNN(Recurrent Neural Network, [[id:263cb433-d0eb-4400-a373-35175c000c01][å¾ªç’°ç¥ç¶“ç¶²è·¯]])æ‰€æ§‹æˆï¼ŒRNN æŒ‡æ“æœ‰éè¿´åŠŸèƒ½çš„ç¶²è·¯ï¼Œå¸¸ç”¨åœ¨è‡ªç„¶èªè¨€ã€æ™‚é–“åºåˆ—è³‡æ–™ç­‰æœ‰é€£çºŒæ€§çš„è³‡æ–™ä¸Šã€‚
*** å½±åƒé¢¨æ ¼è½‰æ›
ä»£è¡¨è«–æ–‡ç‚º A Neural Algorithm of Artistic Styleã€‚
*** ç”¢ç”Ÿå½±åƒ
å¾é›¶é–‹å§‹ç”¢ç”Ÿã€Œè‡¥å®¤ã€å½±åƒï¼Œä»£è¡¨æ€§æ–¹æ³•ç‚º DCGAN(Deep Convolutional Generative Adversarial Network)ã€‚DCGAN åˆ©ç”¨å¤§é‡å½±åƒï¼ˆå¦‚å¤§é‡æ‹æ”è‡¥å®¤å½±åƒï¼‰ä¾†å­¸ç¿’ï¼ŒçµæŸå­¸ç¿’å¾Œï¼Œåªè¦åˆ©ç”¨è©²æ¨¡çµ„å°±èƒ½ç”¢ç”Ÿæ–°çš„å½±åƒã€‚DCGAN é‹ç”¨äº† Generator(ç”Ÿæˆå™¨)èˆ‡ Discriminator(åˆ¤åˆ¥å™¨)ç­‰å…©å€‹ç¥ç¶“ç¶²è·¯ï¼ŒGenerator ç”¢ç”Ÿèˆ‡æœ¬å°Šç›¸ä¼¼çš„å½±åƒï¼ŒDiscriminator åˆ¤æ–·æ˜¯å¦ç‚ºæœ¬å°Šï¼Œå³ï¼Œç¢ºå®šæ˜¯ç”± Generator ç”¢ç”Ÿçš„å½±åƒæˆ–æ˜¯å¯¦éš›æ‹æ”çš„å½±åƒã€‚å…©è€…å½¼æ­¤åˆ¶äš˜å­¸ç¿’ï¼ŒGenerator å¯ä»¥å­¸ç¿’åˆ°æ›´ç²¾å·§çš„å½è£å½±åƒæŠ€è¡“ï¼ŒDiscriminator å‰‡å­¸ç¿’æ›´é«˜çš„é‘‘å®šæŠ€èƒ½ï¼ŒäºŒè€…ç›¸äº’åˆ‡ç£‹æˆé•·ï¼Œæœ€çµ‚ï¼ŒGenerator èƒ½å­¸æœƒç•«å‡ºèˆ‡æœ¬å°Šä¸€æ¨¡ä¸€æ¨£çš„å½±åƒã€‚
*** è‡ªå‹•é§•é§›
æœ€è¿‘åœ¨è¾¨è­˜å‘¨åœç’°å¢ƒçš„æŠ€è¡“ä¸­ï¼Œæ·±åº¦å­¸ç¿’çš„èƒ½åŠ›é —å—æœŸå¾…ï¼Œä¾‹å¦‚ä»¥ CNN ç‚ºåŸºç¤çš„ç¶²è·¯ SegNet å³å¯ç²¾ç¢ºè¾¨è­˜èµ°è·¯çš„ç’°å¢ƒã€‚
*** Deep Q-Network (å¼·åŒ–å­¸ç¿’)
äººé¡æ˜¯é€éåšè©¦éŒ¯èª¤ä¾†å­¸ç¿’ï¼Œä¾‹å¦‚é¨è…³è¸è»Šï¼Œåœ¨é›»è…¦é ˜åŸŸä¸­ï¼Œä¹Ÿæœ‰å¾åšè©¦éŒ¯èª¤çš„éç¨‹ä¸­é€²è¡Œè‡ªä¸»å­¸ç¿’çš„ä¾‹å­ï¼Œç¨±ç‚ºå¼·åŒ–å­¸ç¿’(reinforcement learning)ã€‚åœ¨å¼·åŒ–å­¸ç¿’ä¸­ï¼Œä»£ç†äºº(Agent)æ ¹æ“šç’°å¢ƒç‹€æ³ä¾†æ±ºå®šè¦æ¡å–çš„è¡Œå‹•ï¼Œåˆ©ç”¨è©²è¡Œå‹•è®“ã¼ˆå¢ƒè®ŠåŒ–ã€‚éš¨ç’°å¢ƒè®ŠåŒ–ï¼Œä»£ç†äººç²å¾—æŸäº›å ±é…¬ã€‚å¼·åŒ–å­¸ç¿’çš„ç›®çš„æ˜¯æ±ºå®šä»£ç†äººçš„è¡Œå‹•æ–¹é‡ï¼Œä»¥ç²å¾—æ›´å¥½çš„å ±é…¬ã€‚å…¸å‹çš„ DQN å¯ä»¥è®“éŠæˆ²è‡ªå‹•å­¸ç¿’ï¼Œé”åˆ°è¶…è¶Šäººé¡ç­‰ç´šçš„èƒ½åŠ›ï¼Œä½¿ç”¨ DQN çš„ CNN å¯ä»¥è¼¸å…¥éŠæˆ²å½±åƒ(å¦‚é€£çºŒ 4 å€‹ç•«é¢)ï¼Œæœ€å¾Œé‡å°éŠæˆ²çš„æ§åˆ¶å™¨å‹•ä½œ(æ–æ¡¿çš„å‹•ä½œèˆ‡æŒ‰éˆ•)åˆ†åˆ¥è¼¸å‡ºè©²å‹•ä½œçš„ã€Œåƒ¹å€¼ã€ã€‚ç”±æ–¼ DQN çš„è¼¸å…¥åªæ˜¯å½±åƒï¼Œæ‰€ä»¥ä¸ç”¨éš¨è‘—éŠæˆ²çš„ä¸åŒä¾†æ”¹è®Šè¨­å®šï¼ŒåŒä¸€å¥— DQN å¯ä»¥å­¸ç¿’ã€Œå°ç²¾éˆã€èˆ‡ã€ŒAtariã€ã€‚DQN èˆ‡ AlphaGo éƒ½æ˜¯ Google Deep Mind å…¬å¸çš„ç ”ç©¶ã€‚* ex: å…¥ä¾µåµæ¸¬ç³»çµ±

* æ·±åº¦å­¸ç¿’é‹ä½œåŸç†
** Layer, æå¤±å‡½æ•¸èˆ‡å„ªåŒ–å™¨
å‰ç¯€æ·±åº¦å­¸ç¿’ä¸­çš„æ¯ä¸€ã€Œå±¤ã€(layer)å¦‚ä½•é‹ä½œï¼Œå–æ±ºæ–¼å„²å­˜æ–¼è©²å±¤çš„æ¬Šé‡(weight)ï¼Œè€Œæ¬Šé‡æ˜¯ç”±å¤šå€‹æ•¸å­—çµ„æˆã€‚å¾æŠ€è¡“å±¤é¢ä¾†çœ‹ï¼Œlayer æ˜¯ç”±å„å€‹æ¬Šé‡åƒæ•¸(parameters)ä¾†å’Œè¼¸å…¥çš„è³‡æ–™(å¦‚åœ–[[fig:python-deep-learning-3]]ä¸­çš„X)é€²è¡Œé‹ç®—ä»¥åŸ·è¡Œè³‡æ–™è½‰æ›çš„å·¥ä½œ(å¦‚åœ–[[fig:python-deep-learning-3]])ã€‚è€Œæ‰€è¬‚çš„å­¸ç¿’ï¼ŒæŒ‡çš„å°±æ˜¯å¹«åŠ©ç¥ç¶“ç¶²è·¯çš„æ¯ä¸€å±¤æ‰¾å‡ºé©ç•¶çš„æ¬Šé‡å€¼ï¼Œè®“ç¥ç¶“ç¶²è·¯å¯ä»¥å°‡è¼¸å…¥çš„è¨“ç·´è³‡æ–™ç¶“ç”±èˆ‡æ¬Šé‡çš„é‹ä½œæ¨å°å‡ºæ¥è¿‘æ¨™æº–ç­”æ¡ˆçš„é‹ç®—çµæœ(å³åœ–[[fig:python-deep-learning-3]]ä¸­çš„é æ¸¬ Y)ã€‚

ç„¶è€Œï¼Œé€™åœ¨å¯¦éš›é‹ä½œä¸Šæ˜¯ååˆ†å›°é›£çš„ï¼Œå› ç‚ºä¸€å€‹æ·±åº¦ç¥ç¶“ç¶²è·¯å¯ä»¥åŒ…å«æ•¸åƒè¬å€‹æ¬Šé‡ï¼Œæ­¤å¤–ï¼Œå…¶ä¸­ä¸€å€‹æ¬Šé‡è¢«æ”¹è®Šå¾Œï¼Œå¾€å¾€æœƒå½±éŸ¿å…¶ä»–æ¬Šé‡çš„é‹ä½œã€‚

#+CAPTION: nn ä¸­ layer çš„ parameter
#+LABEL:fig:python-deep-learning-3
#+name: fig:python-deep-learning-3
#+ATTR_LATEX: :width 400
#+ATTR_HTML: :width 400
#+ATTR_ORG: :width 400
[[file:images/img-191107115233.jpg]]

ç‚ºäº†æé«˜ç¥ç¶“ç¶²è·¯çš„æ•ˆèƒ½(é æ¸¬çš„æº–ç¢ºç‡)ï¼Œæˆ‘å€‘è¦å³æ™‚çš„æŒæ¡ç›®å‰çš„è¼¸å‡º(Y)èˆ‡çœŸæ­£çš„æ¨™æº–ç­”æ¡ˆYé‚„å·®å¤šå°‘ï¼Œé€™å€‹è©•ä¼°ç”±ç¥ç¶“ç¶²è·¯çš„æå¤±å‡½æ•¸(loss function;æˆ–ç¨±ç›®æ¨™å‡½æ•¸, objective function;æˆ–ç¨±æˆæœ¬å‡½æ•¸, cost function[fn:9])ä¾†è² è²¬ï¼Œå¦‚åœ–[[fig:python-deep-learning-4]]ã€‚æå¤±å‡½æ•¸æœƒå–å¾—ç¥ç¶“ç¶²è·¯çš„é æ¸¬çµæœèˆ‡æ¨™æº–ç­”æ¡ˆäºŒè€…çš„æå¤±åˆ†æ•¸(åˆç¨±å·®è·åˆ†æ•¸)ï¼Œåšç‚ºæ¯ä¸€æ¬¡å­¸ç¿’çš„è¡¨ç¾æ•ˆèƒ½ä¹‹è©•ä¼°æ¨™æº–ã€‚

#+CAPTION: æå¤±å‡½æ•¸
#+LABEL:fig:python-deep-learning-4
#+name: fig:python-deep-learning-4
#+ATTR_LATEX: :width 400
#+ATTR_HTML: :width 400
#+ATTR_ORG: :width 400
[[file:images/img-191107115304.jpg]]

è€Œæ·±åº¦å­¸ç¿’çš„åŸºæœ¬å·¥ä½œå°±æ˜¯ä½¿ç”¨æå¤±å‡½æ•¸åšç‚ºå›é¥‹è¨Šæ¯ä¾†ä¸€æ­¥æ­¥å¾®èª¿æ¬Šé‡ï¼Œé€æ­¥é™ä½æ¯æ¬¡å­¸ç¿’çš„æå¤±åˆ†æ•¸ï¼Œæœ€çµ‚ç›®æ¨™åœ¨æ–¼è®“æå¤±å‡½æ•¸çµæœé”åˆ°æœ€å°ï¼Œè€Œé€™å€‹å¾®èª¿å·¥ä½œå‰‡ç”±å„ªåŒ–å™¨(optimizerï¼Œä¹Ÿç¨±æœ€ä½³åŒ–å‡½æ•¸)ä¾†åŸ·è¡Œã€‚å„ªåŒ–å™¨å¯¦ä½œäº†åå‘å‚³æ’­æ¼”ç®—æ³•(Backpropagation)ï¼Œé€™ä¹Ÿæ˜¯æ·±åº¦å­¸ç¿’ä¸­çš„æ ¸å¿ƒæ¼”ç®—æ³•ï¼Œè—‰æ­¤ä¾†é€±æ•´æ¬Šé‡ã€‚

#+CAPTION: å„ªåŒ–å™¨
#+LABEL:fig:python-deep-learning-5
#+name: fig:python-deep-learning-5
#+ATTR_LATEX: :width 300
#+ATTR_HTML: :width 400
#+ATTR_ORG: :width 300
[[file:images/img-1911071153041.jpg]]

äº‹å¯¦ä¸Šï¼ŒåŒæ¨£çš„æµç¨‹æˆ‘å€‘ä¹Ÿæ›¾åœ¨[[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][è¿´æ­¸]]è£¡çœ‹éï¼Œåœ¨æ‰¾åˆ°ä¸€æ¢ç†æƒ³çš„è¿´æ­¸æ–¹ç¨‹å¼æ™‚ï¼Œæˆ‘å€‘ä¹Ÿæ˜¯å…ˆéš¨ä¾¿æ‰¾ä¸€æ¢ï¼Œç„¶å¾Œç”¨loss functionå»è©•ä¼°é€™æ¢æ–¹ç¨‹å¼çš„å„ªåŠ£ï¼Œå†ã€Œæ±‚åˆ‡ç·šæ–œç‡ã€çš„æ–¹å¼ä¾†ä¿®æ­£æ–¹ç¨‹å¼çš„ä¿‚æ•¸ã€‚å·®åˆ¥åªåœ¨æ–¼ï¼šåœ¨[[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][è¿´æ­¸]]æ™‚æˆ‘å€‘è¦ä¿®æ­£çš„ä¿‚æ•¸åªæœ‰ä¸€ã€å…©å€‹ï¼Œè€Œåœ¨æ·±åº¦å­¸ç¿’ä¸­ï¼Œæˆ‘å€‘è¦åŒæ™‚ä¿®æ­£æˆåƒä¸Šè¬å€‹æ¬Šé‡ã€‚

é‚£éº¼ï¼Œåœ¨æœ€åˆä¸€æ¬¡çš„å­¸ç¿’ï¼Œæ¬Šé‡çš„å€¼æ˜¯å¦‚ä½•è¨­å®šçš„å‘¢ï¼Ÿå¯ä»¥å…ˆå…¨æ•¸è¨­ç‚ºé›¶ï¼Œä½†æ›´å¸¸ç”¨çš„åšæ³•æ˜¯éš¨æ©ŸæŒ‡å®šï¼Œéš¨è‘—å¤šæ¬¡å­¸ç¿’å¾Œï¼Œæ¬Šé‡æœƒé€æ­¥å¾€æ­£ç¢ºçš„æ–¹å‘èª¿æ•´ï¼Œæå¤±åˆ†æ•¸ä¹Ÿæœƒæ…¢æ…¢é™ä½ã€‚

æˆ‘å€‘å†è¤‡ç¿’ä¸€ä¸‹[[id:d6daa102-05bb-475d-b619-db8b61e86030][ç¥ç¶“ç¶²è·¯]]é€™ç« è£¡çš„æ–‡å­—ï¼š

#+begin_quote
æ˜¯çš„ï¼Œå°±å¦‚åŒè€ƒè©¦æ™‚ä½ é¢å°é™Œç”Ÿé¸æ“‡é¡Œçš„åæ‡‰ï¼Œç¥ç¶“ç¶²è·¯ä¹Ÿæ±ºå®šé€™éº¼å¹¹ï¼Œéš¨ä¾¿ä¸Ÿä¸€äº›æ•¸å€¼å¡«åˆ°çŸ©é™£ä¸­ç•¶æˆç¬¬ä¸€æ‰¹åƒæ•¸ã€‚äº‹å¯¦ä¸Šï¼ŒåŒæ¨£çš„ç­–ç•¥æˆ‘å€‘åœ¨[[id:7cd4a142-4cd9-46b6-b9a4-2ad750ae622f][ç·šæ€§è¿´æ­¸:å¹´é½¡èº«é«˜é æ¸¬/éš¨æ©Ÿçš„åŠ›é‡]]è£¡å·²ç¶“ç©éäº†ï¼Œç•¶åˆåœ¨æ‰¾å‡ºæ–¹ç¨‹å¼çš„æœ€ä½³åƒæ•¸çµ„åˆæ™‚ï¼Œæˆ‘å€‘ä¹Ÿæ˜¯é–‰ä¸Šçœ¼ç›éš¨ä¾¿é¸ä¸€çµ„ã€‚ä¸ç®¡æ•´å€‹ç¶²è·¯ä¸­æœ‰å¤šå°‘åƒæ•¸ï¼Œç•¶æˆ‘å€‘éš¨æ©Ÿè¨­å®šå¥½äº†æ‰€æœ‰åƒæ•¸çš„æœ€åˆå€¼å¾Œï¼Œæ•´å€‹ç¥ç¶“ç¶²å°±å°±å¯ä»¥é‹ä½œäº†ï¼Œå—¯...è‡³å°‘å·²ç¶“å¯ä»¥ä¾ç…§å‰å‘å‚³æ’­çš„æµç¨‹è¼¸å‡ºç¬¬ä¸€å€‹é æ¸¬çµæœäº†ï¼Œä½ çœ‹ï¼Œæˆ‘å€‘å·²ç¶“æœå®Œç¾çš„äººå·¥æ™ºæ…§è·¨è¿‘ä¸€å¤§æ­¥äº†-_-
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 400
[[file:images/é¡ç¥ç¶“ç¶²è·¯/2024-02-18_10-23-40_2024-02-18_10-20-52.png]]

æ¥ä¸‹ä¾†çš„æµç¨‹å…¶å¯¦å’Œ[[id:6ae7fb7a-0b38-4448-b19f-073d262513f2][è¿´æ­¸]]æœ‰é»é¡ä¼¼ï¼Œæˆ‘å€‘è©•ä¼°é æ¸¬çµæœçš„å“è³ªï¼Œç„¶å¾Œå›é ­ä¿®æ­£åƒæ•¸ï¼Œåªæ˜¯é€™æ¬¡çš„å·¥ç¨‹æœ‰é»æµ©å¤§ï¼Œæˆ‘å€‘è¦ä¿®æ­£æ‰€æœ‰çš„åƒæ•¸ï¼Œé€™å€‹å›é ­ä¿®æ­£æ‰€æœ‰åƒæ•¸çš„éç¨‹ç¨±ç‚ºåå‘å‚³æ’­(backward propagation)ã€‚

#+end_quote

* å¯¦ä½œç¯„ä¾‹
** äºŒå…ƒåˆ†é¡ï¼šIMDB
è‡ª IMDB è³‡æ–™é›†ä¸­å–å¾— 50000 å€‹æ­£/è² è©•è«–ï¼Œå„ 25000 å€‹ï¼Œè©²è³‡æ–™é›†å·²å…§å»ºæ–¼ Keras ä¸­ï¼Œä¸”è³‡æ–™å·²å…ˆé è™•ç†ï¼Œé›»å½±è©•è«–å…§å®¹ç‚ºç”±å–®å­—æ§‹æˆçš„ list çµæ§‹ï¼Œä¾‹å¦‚ï¼Œè‹¥è©•è«–å…§å®¹ç‚º
#+begin_src python -r :results output :exports both
In a Wonderful morning...
#+end_src
å…¶ list çµæ§‹å¯èƒ½ç‚º
#+begin_src python -r :results output :exports both
(8, 3, 386, 1969...)
#+end_src
å³ï¼Œæ¯å€‹å–®å­—éƒ½æœƒä¾æ“šå…¶å‡ºç¾é »ç‡çµ¦å®šä¸€å€‹ç·¨è™Ÿï¼Œç·¨è™Ÿè¶Šå°è¶Šå¸¸è¦‹ã€‚(èˆ‡ IMDb ç›¸é—œçš„ paper åƒè¦‹[[https://paperswithcode.com/sota/sentiment-analysis-on-imdb][Sentiment Analysis on IMDb / paperswithcode]]

#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
from keras.datasets import imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)
print(train_data[0])
print(train_labels[0])
#+END_SRC

#+RESULTS:
: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
: 1

å¦‚ä¸Šç‚ºç¬¬ä¸€ç­†è©•è«–çš„å–®å­—ä»£è™Ÿèˆ‡è©•è«–çµæœï¼Œè‹¥è¦å°‡åŸå§‹è³‡æ–™çš„å–®å­—ä»£è™Ÿé‚„åŸï¼Œå…¶ç¨‹å¼ç¢¼å¦‚ä¸‹ï¼š
#+BEGIN_SRC python -r -n:async :results output :exports both :session imdb
# word_index is a dictionary mapping words to an integer index
word_index = imdb.get_word_index()     (ref:wordIndex)
print("å­—å…¸ä¸­keyç‚ºthiså°æ‡‰çš„value:",word_index['this'])
# We reverse it, mapping integer indices to words
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])    (ref:reverseWordIndex)
print("åè½‰å­—å…¸ä¸­keyç‚º11æ‰€å°æ‡‰åˆ°çš„value:",reverse_word_index[11])
print("åè½‰å­—å…¸ä¸­keyç‚º1æ‰€å°æ‡‰åˆ°çš„value:",reverse_word_index[1])
print("åè½‰å­—å…¸ä¸­keyç‚º2æ‰€å°æ‡‰åˆ°çš„value:",reverse_word_index[2])
# We decode the review; note that our indices were offset by 3
# because 0, 1 and 2 are reserved indices for "padding", "start of sequence", and "unknown".
decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]]) (ref:decodedReview)
print(decoded_review)
#+END_SRC

#+RESULTS:
: å­—å…¸ä¸­keyç‚ºthiså°æ‡‰çš„value: 11
: åè½‰å­—å…¸ä¸­keyç‚º11æ‰€å°æ‡‰åˆ°çš„value: this
: åè½‰å­—å…¸ä¸­keyç‚º1æ‰€å°æ‡‰åˆ°çš„value: the
: åè½‰å­—å…¸ä¸­keyç‚º2æ‰€å°æ‡‰åˆ°çš„value: and
: ? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all

ä¸Šè¿°ç¨‹å¼ä¸­ç¬¬[[(wordIndex)]]è¡Œä¸»è¦è² è²¬å–å¾—å–®å­—(key)çš„å°æ‡‰æ•¸å­—(value)çš„å­—å…¸ï¼Œå†è—‰ç”±ç¬¬[[(reverseWordIndex)]]è¡Œå°‡(key:value)è½‰æ›ç‚º(value:key)ï¼Œæœ€å¾Œç¬¬[[(decodedReview)]]è¡Œå°‡å­—å…¸ä¸­çš„å–®å­—å›å¾©è‡³åŸå§‹è©•è«–ï¼Œç¨‹å¼ä¸­(i-3)çš„åŸå› æ˜¯imdb.load_dataå·²é ç•™äº†ç¬¬ 0~2 å€‹ä½ç½®åšç‰¹æ®Šç”¨é€”ã€‚
*** æº–å‚™è³‡æ–™
ç”±æ–¼ IMDB åŒ¯å…¥ train_data åŠ test_data å‡ç‚º list å‹æ…‹ï¼Œè¦å…ˆè½‰æ›ç‚º tensor æ‰èƒ½è¼¸å…¥è‡³ç¥ç¶“ç¶²è·¯ï¼Œæ–¹æ³•æœ‰äºŒï¼š
1. å¡«è£œè³‡æ–™ä¸­æ¯å€‹å­ list å…§å®¹ä½¿å…¶å…·æœ‰ç›¸åŒé•·åº¦ï¼Œå†åšreshape
2. å°æ¯å€‹å­ list åš one-hot encodingï¼Œå…¶ç¨‹å¼ç¢¼å¦‚ä¸‹ï¼š
#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
    # Create an all-zero matrix of shape (len(sequences), dimension)
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.  # set specific indices of results[i] to 1s
    return results
print("====train_data[0]======")
print(train_data[0])
# Our vectorized training data

x_train = vectorize_sequences(train_data)
# Our vectorized test data
x_test = vectorize_sequences(test_data)
print("====x_data[0]======")
print(x_train[0])

# æœ€å¾Œå†å°‡æ¨™ç±¤è³‡æ–™ä¹Ÿå‘é‡åŒ–
y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')
print("====y_data[0]======")
print(y_train[0])
#+END_SRC


#+RESULTS:
: ====train_data[0]======
: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
: ====x_data[0]======
: [0. 1. 1. ... 0. 0. 0.]
: ====y_data[0]======
: 1.0
*** å»ºç«‹ç¥ç¶“ç¶²è·¯
è¦å»ºæ§‹ä¸€å€‹ Dense å±¤å †ç–Šæ¶æ§‹çš„ç¥ç¶“ç¶²è·¯ï¼Œè¦è€ƒæ…®å…©å€‹é—œéµï¼š
1. è¦ç”¨å¤šå°‘å±¤ï¼Ÿ
1. æ¯ä¸€å±¤è¦æœ‰å¤šå°‘ç¥ç¶“å…ƒï¼Ÿ

æ­¤è™•ä½¿ç”¨å…©å€‹ä¸­é–“å±¤ã€ä¸€å€‹è¼¸å‡ºå±¤ï¼Œå¦‚åœ–[[fig:nn3-6]]ï¼Œä¸€èˆ¬çš„ç¥ç¶“ç¶²è·¯ä¸­ï¼Œå°é‚£äº›ä»‹æ–¼è¼¸å…¥å±¤å’Œè¼¸å‡ºå±¤é–“çš„layerï¼Œæˆ‘å€‘ç¿’æ…£ä¸Šç¨±ä¹‹ç‚ºéš±è—å±¤(hidden layers)ï¼Œä½†æ­¤è™• Keras çš„è¼¸å…¥å±¤ä¹Ÿæœ‰éš±è—å±¤çš„ç‰¹æ€§ã€‚åœ–[[fig:nn3-6]]çš„ hidden layer ä»¥ relu ç‚ºå•Ÿå‹•å‡½æ•¸ï¼Œè¼¸å‡ºå±¤ä»¥ sigmoid å•Ÿå‹•å‡½æ•¸è¼¸å‡ºæ©Ÿç‡å€¼ã€‚

#+BEGIN_SRC ditaa :file images/nn3-6.png

        è¼¸å…¥(å‘é‡åŒ–æ–‡å­—)
            |
            v
  +-------------------+
  |+-----------------+|
  || Dense(units=16) ||-+
  |+--------+--------+| |
  |         |         | +-éš±è—å±¤
  |         v         | |
  |+-----------------+| |
  || Dense(units=10) ||-+
  |+--------+--------+|
  |         |         |
  |         v         |
  |+-----------------+|-+
  ||  Dense(units=1) || +-è¼¸å‡ºå±¤
  |+-----------------+|-+
  +-------------------+
  #+END_SRC

#+RESULTS:
#+CAPTION: IMDB model æ¶æ§‹
#+name: fig:nn3-6
#+ATTR_LATEX: :width 200
#+ATTR_HTML: :width 300
#+ATTR_ORG: :width 200
[[file:images/nn3-6.png]]

ç”±æ–¼è¼¸å…¥è³‡æ–™ç‚ºå‘é‡ã€æ¨™ç±¤ç‚ºç´”é‡(1, 0)ï¼Œå°é€™æ¨£çš„å•é¡Œï¼Œé©åˆç”¨ relu å•Ÿå‹•å‡½æ•¸çš„å…¨é€£æ¥å±¤(Dense)å †ç–Šæ¶æ§‹ï¼šDense(16, activation='relu')ã€‚å…¶ä¸­ 16 æŒ‡è©²å±¤ç¥ç¶“å…ƒçš„æ•¸é‡(ä¹Ÿå¯çœ‹æˆè©²å±¤çš„å¯¬åº¦)ï¼Œå…¸å‹æ—³å¯«æ³•ç‚ºï¼š
#+BEGIN_SRC python -r :results output :exports both :eval no
# åŠ å…¥Denseéš±è—å±¤ï¼Œè©²å±¤æœ‰16å€‹ç¥ç¶“å…ƒ
model.add(layers.Dense(16, activation='relu'))
#+END_SRC

æ“æœ‰ 16 å€‹ç¥ç¶“å–®å…ƒè¡¨ç¤ºæ¬Šé‡çŸ©é™£ W çš„ shape ç‚º(input_dimension, 16)ï¼Œåœ¨ W å’Œ input åšå…§ç©å¾Œï¼Œinput è³‡æ–™æœƒè¢«æ˜ å°„åˆ° 16 ç¶­çš„ç©ºé–“ä¸Šï¼Œæœ€å¾ŒåŠ ä¸Š bã€å¥—ç”¨ relu é‹ç®—ä¾†ç”¢ç”Ÿè¼¸å‡ºå€¼ã€‚æ¯ä¸€å±¤çš„ç¥ç¶“å…ƒæ•¸è¶Šå¤šï¼Œå¯ä»¥è®“ç¥ç¶“ç¶²è·¯å­¸ç¿’æ›´è¤‡é›œçš„è³‡æ–™è¡¨ç¤ºæ³•ï¼Œä½†ä¹Ÿä½¿è¨ˆç®—æˆæœ¬æ›´é«˜ã€‚

#+CAPTION: ReLU å‡½æ•¸åœ–
#+LABEL:fig:ReLUFunction
#+name: fig:ReLUFunction
#+ATTR_LATEX: :width 200
#+ATTR_ORG: :width 200
#+ATTR_HTML: :width 300
#+RESULTS:
[[file:images/ReLUPlot.png]]

*** ç‚ºä»€éº¼è¦åŠ å…¥[[id:d3bcc30a-3d94-4a3c-8e66-baaac7325c75][Activation Function]]
ç‚ºä½•è¦æœ‰ relu ç­‰å•Ÿå‹•å‡½æ•¸ï¼ŸåŸå› ä¹‹ä¸€æ˜¯é€™é¡å‡½æ•¸ç‚ºéç·šæ€§å‡½æ•¸(å¦‚åœ–[[fig:ReLUFunction]])ï¼Œå›é¡§[[id:d6daa102-05bb-475d-b619-db8b61e86030][ç¥ç¶“ç¶²è·¯]]ä¸­çš„ã€Œå­¸æ¸¬æˆç¸¾é æ¸¬æ¨¡å‹ã€ï¼Œåƒåœ–[[fig:exam-Network2]]çš„æ¨¡å‹ï¼Œæˆ‘å€‘ä¹Ÿåªæ˜¯åœ¨è§£ä¸€å€‹å¦‚\(f(x)=x_1*w_1+x_2*w_2+x_3*w_3+...+x_7*w_7\)é€™æ¨£çš„å‡½å¼å•é¡Œã€‚

#+begin_src plantuml -t latex :file images/exam-network2p.png
@startuml
storage å­¸æ¸¬æˆç¸¾
storage x1
storage x2
storage x3
storage x4
storage x5
storage x6
storage x7
x1 --|> å­¸æ¸¬æˆç¸¾ : w1
x2 --|> å­¸æ¸¬æˆç¸¾ : w2
x3 --|> å­¸æ¸¬æˆç¸¾ : w3
x4 --|> å­¸æ¸¬æˆç¸¾ : w4
x5 --|> å­¸æ¸¬æˆç¸¾ : w5
x6 --|> å­¸æ¸¬æˆç¸¾ : w6
x7 --|> å­¸æ¸¬æˆç¸¾ : w7
@enduml
#+end_src


#+CAPTION: å­¸æ¸¬æˆç¸¾é æ¸¬æ¨¡å‹#2
#+LABEL:fig:exam-Network2
#+NAME:fig:exam-Network2
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 400
#+ATTR_HTML: :width 400
#+RESULTS:
[[file:images/exam-network2p.png]]

å°±ç®—æˆ‘å€‘æŠŠæ¨¡å‹2é€²åŒ–ç‚ºæ¨¡å‹3(å¦‚åœ–[[fig:exam-Network3]])ï¼Œæœ¬è³ªä¸Šä¹Ÿä»åªæ˜¯ä¸€å±¤ï¼Œå†å¤šçš„å±¤æ•¸ä¹Ÿèƒ½åˆä½µç‚ºä¸€å±¤ï¼Œæ­¤é¡æ¨¡å‹ä¸¦ç„¡åŠ©æ–¼è¤‡é›œçš„å­¸ç¿’ã€‚

#+begin_src plantuml :file images/exam-network3p.png
@startuml
storage å­¸æ¸¬æˆç¸¾
storage x1
storage x2
storage x3
storage x4
storage x5
storage x6
storage x7
storage y1
storage y2
storage y3
x1 --|> y1 : w11
x2 --|> y1 : w21
x3 --|> y1 : w31
x3 --|> y2 : w32
x4 --|> y2 : w42
x5 --|> y2 : w52
x5 --|> y3 : w53
x6 --|> y2 : w62
x6 --|> y3 : w63
x7 --|> y3 : w73
y1 -[dashed]-|> å­¸æ¸¬æˆç¸¾ : w8
y2 -[dashed]-|> å­¸æ¸¬æˆç¸¾ : w9
y3 -[dashed]-|> å­¸æ¸¬æˆç¸¾ : w10
@enduml
#+end_src

#+CAPTION: å­¸æ¸¬æˆç¸¾é æ¸¬æ¨¡å‹#3
#+LABEL:fig:exam-Network3
#+NAME:fig:exam-Network3
#+ATTR_LATEX: :width 400
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
#+RESULTS:
[[file:images/exam-network3p.png]]

ä»¥åœ–[[fig:exam-Network3]]ç‚ºä¾‹ï¼Œæœ€å¾Œå°å­¸æ¸¬æˆç¸¾\(\hat{y}\)çš„é æ¸¬ç‚ºï¼š
$$
\hat{y}=y_1w_8+y_2w_9+y_3w_{10}
$$
å…¶ä¸­
\begin{eqnarray}
y_1 &=& x_1w_{11} + x_2w_{21} + x_3w_{31} \\
y_2 &=& x_3w_{32} + x_4w_{42} + x_5w_{52} + x_6w_{62} \\
y_3 &=& x_5w_{53} + x_6w_{63} + x_7w_{73}
\end{eqnarray}
å¦‚æœæˆ‘å€‘ç¨å¾®æ•´ç†ä¸€ä¸‹ä¸Šé¢é€™å€‹çœ‹èµ·ä¾†åƒå…©å±¤çš„æ¨¡å‹ï¼š
\begin{equation*}
\begin{split}
\hat{y} =& y_1w_8+y_2w_9+y_3w_{10} \\
        =& (x_1w_{11} + x_2w_{21} + x_3w_{31})w_8 \\
         &+ (x_3w_{32} + x_4w_{42} + x_5w_{52} + x_6w_{62})w_9 \\
         &+ (x_5w_{53} + x_6w_{63} + x_7w_{73})w_{10} \\
        =& x_1w_{11}w_8 + x_2w_{21}w_8 + x_3w_{31}w_8 \\
         &+ x_3w_{32}w_9 + x_4w_{42}w_9 + x_5w_{52}w_9 + x_6w_{62}w_9 \\
         &+ x_5w_{53}w_{10} + x_6w_{63}w_{10} + x_7w_{73}w_{10} \\
\end{split}
\end{equation*}
æœ€å¾Œå°±æœƒç™¼ç¾ï¼Œä¸ç®¡å®ƒçœ‹èµ·ä¾†åƒæ˜¯å¹¾å±¤ï¼Œæœ€å¾Œéƒ½èƒ½æ•´ç†æˆä¸€å±¤çš„æ¨¡æ¨£:
\begin{equation*}
\begin{split}
\hat{y} =& x_1\times(w_{11}w_8) \\
         &+ x_2\times(w_{21}w_8) \\
         &+ x_3\times(w_{31}w_8+w_{32}w_9) \\
         &+ x_4\times(w_{42}w_9) \\
         &+ x_5\times(w_{52}w_9 + w_{53}w_{10}) \\
         &+ x_6\times(w_{62}w_9 + w_{63}w_{10})\\
         &+ x_7\times(w_{73}w_{10})
\end{split}
\end{equation*}
çµæœå°±æ˜¯è·Ÿåº•ä¸‹çš„æ–¹ç¨‹å¼ä¸€æ¨£
\(f(x)=x_1*w_1+x_2*w_2+x_3*w_3+...+x_7*w_7\)

ç‚ºäº†æœ‰æ•ˆè®“æ¨¡å‹æ›´åŠ è¤‡é›œï¼Œæ­¤è™•å¯ä»¥åœ¨æ¨¡å‹ä¸­åŠ å…¥éç·šæ€§è½‰æ›ï¼Œå¦‚åœ–[[fig:ReLUFunction]]ä¸­çš„ReLU[[id:d3bcc30a-3d94-4a3c-8e66-baaac7325c75][æ¿€å‹µå‡½æ•¸]]ï¼Œå…¶çµæœå¦‚åœ–[[fig:exam-Network4]]æ‰€ç¤ºã€‚

#+CAPTION: ReLU å‡½æ•¸åœ–
#+LABEL:fig:ReLUFunction
#+name: fig:ReLUFunction
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/ReLUPlot.png]]

#+begin_src plantuml :file images/exam-network4p.png
@startuml
storage å­¸æ¸¬æˆç¸¾
storage x1
storage x2
storage x3
storage x4
storage x5
storage x6
storage x7
storage reLU1 as "reLU" #aliceblue;line:blue;line.dotted;text:blue
storage reLU2 as "reLU" #aliceblue;line:blue;line.dotted;text:blue
storage reLU3 as "reLU" #aliceblue;line:blue;line.dotted;text:blue

storage y1
storage y2
storage y3
storage reLU4 as "reLU" #aliceblue;line:blue;line.dotted;text:blue
storage reLU5 as "reLU" #aliceblue;line:blue;line.dotted;text:blue
storage reLU6 as "reLU" #aliceblue;line:blue;line.dotted;text:blue
reLU1 -[dashed]-|> y1
reLU2 -[dashed]-|> y2
reLU3 -[dashed]-|> y3

x1 --|> reLU1 : w11
x2 --|> reLU1 : w21
x3 --|> reLU1 : w31
x3 --|> reLU2 : w32
x4 --|> reLU2 : w42
x5 --|> reLU2 : w52
x5 --|> reLU3 : w53
x6 --|> reLU2 : w62
x6 --|> reLU3 : w63
x7 --|> reLU3 : w73

y1 --|> reLU4 : w8
y2 --|> reLU5 : w9
y3 --|> reLU6 : w10

reLU4 -[dashed]-|> å­¸æ¸¬æˆç¸¾
reLU5 -[dashed]-|> å­¸æ¸¬æˆç¸¾
reLU6 -[dashed]-|> å­¸æ¸¬æˆç¸¾

@enduml
#+end_src
#+CAPTION: å­¸æ¸¬æˆç¸¾é æ¸¬æ¨¡å‹#4
#+LABEL:fig:exam-Network4
#+name: fig:exam-Network4
#+ATTR_LATEX: :width 500
#+ATTR_ORG: :width 100
#+ATTR_HTML: :width 500
#+RESULTS:
[[file:images/exam-network4p.png]]
*** ç¨‹å¼å¯¦ä½œ
åœ–[[fig:nn3-6]]çš„å¯¦ä½œç¨‹å¼å¦‚ä¸‹ï¼Œæ­¤è™•ä»¥æœ€ç°¡å–®çš„ NN (Neural Network) ä½œç‚ºç¯„ä¾‹ã€‚ä»¥ Keras çš„æ ¸å¿ƒç‚ºæ¨¡å‹ï¼Œæ‡‰ç”¨æœ€å¸¸ä½¿ç”¨ Sequential æ¨¡å‹ã€‚è—‰ç”±.add()æˆ‘å€‘å¯ä»¥ä¸€å±¤ä¸€å±¤çš„å°‡ç¥ç¶“ç¶²è·¯ç–Šèµ·ã€‚åœ¨æ¯ä¸€å±¤ä¹‹ä¸­æˆ‘å€‘åªéœ€è¦ç°¡å–®çš„è¨­å®šæ¯å±¤çš„å¤§å°(units)èˆ‡æ¿€å‹µå‡½æ•¸(activation function)ã€‚
#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
#+END_SRC

#+RESULTS:
: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
:   super().__init__(activity_regularizer=activity_regularizer, **kwargs)

å»ºå¥½ model å¾Œï¼Œè¦é¸æ“‡ä¸€å€‹æå¤±å‡½æ•¸å’Œä¸€å€‹å„ªåŒ–å™¨ï¼Œç”±æ–¼è¦è™•ç†çš„æ˜¯äºŒå…ƒåˆ†é¡å•é¡Œï¼Œæ‰€ä»¥æœ€å¥½ç”¨ binary_crossentropy æå¤±å‡½æ•¸ï¼Œå› ç‚º crossentropy ä¸»è¦å°±æ˜¯ç”¨ä¾†æ¸¬é‡æ©Ÿç‡åˆ†ä½ˆä¹‹é–“çš„è·é›¢(å·®ç•°)ã€‚å…¶å¯¦ä½œå¦‚ä¸‹ï¼š

#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
model.compile(optimizer='rmsprop',
             loss='binary_crossentropy',
             metrics=['accuracy'])
#+END_SRC

#+RESULTS:

ä¹‹æ‰€ä»¥èƒ½å°‡ optimizer å’Œ loss function ä»¥å­—ä¸²æ–¹å¼ç¶“ç”±åƒæ•¸å‚³çµ¦ compile()ï¼Œé€™æ˜¯å› ç‚º rmspropã€binary_crossentropy å’Œ accuracy å‡å·²äº‹å…ˆåœ¨ Keras å¥—ä»¶ä¸­å®šç¾©å¥½äº†ï¼Œè‹¥æ˜¯è¦é€²ä¸€æ­¥è‡ªè¨‚åƒæ•¸(å¦‚è‡ªè¨‚å­¸ç¿’ç‡)ï¼Œåšæ³•å¦‚ä¸‹ï¼š

#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
# èª¿æ•´learning rate
from keras import optimizers

model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# ä½¿ç”¨å¦å¤–çš„è©•ä¼°å‡½æ•¸
from keras import losses
from keras import metrics

model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),
              loss=losses.binary_crossentropy,
              metrics=[metrics.binary_accuracy])
#+END_SRC

#+RESULTS:
è‹¥æ‚¨ä½¿ç”¨çš„æ˜¯M1/M2æ ¸å¿ƒçš„Macé›»è…¦ï¼Œå‰‡å¯èƒ½æœƒå‡ºç¾ä¸Šè¿°è¨Šæ¯ï¼Œé›–ç„¶ä¸å½±éŸ¿æ­£åŸ·è¡Œçµæœï¼Œä½†ä½ ä»å¯ä»¥åƒè€ƒ[[https://stackoverflow.com/questions/77222463/is-there-a-way-to-change-adam-to-legacy-when-using-mac-m1-m2-in-tensorflow][stackoverflowä¸Šçš„é€™ç¯‡æ–‡ç« ]]ä¾†è§£æ±ºé€™äº›æƒ±äººçš„è¨Šæ¯ã€‚
*** é©—è­‰ç¥ç¶“ç¶²è·¯çš„ model
ç‚ºäº†åœ¨è¨“ç·´æœŸé–“ç›£æ§ model å°æ–°è³‡æ–™çš„æº–ç¢ºåº¦ï¼Œå¯ä»¥å¾åŸå§‹è¨“ç·´è³‡æ–™ä¸­åˆ†é›¢å‡º 10000 å€‹æ¨£æœ¬ä¾†å»ºç«‹é©—è­‰è³‡æ–™é›†ã€‚
#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
x_val = x_train[:10000] # å‰10000å€‹è³‡æ–™ç‚ºé©—è­‰é›†
partial_x_train = x_train[10000:] # ç¬¬10000å€‹ä»¥å¾Œç‚ºè¨“ç·´é›†

y_val = y_train[:10000]
partial_y_train = y_train[10000:]
#+END_SRC

#+RESULTS:

æ¥ä¸‹ä¾†æ‰æ˜¯ä½¿ç”¨ fit()ä¾†è¨“ç·´æ¨¡å‹ï¼Œé€²è¡Œ 20 å€‹è¨“ç·´é€±æœŸ(epochï¼Œå³ï¼ŒæŠŠ x_train å’Œ y_train å¼µé‡ä¸­çš„æ‰€æœ‰è¨“ç·´æ¨£æœ¬é€²è¡Œ 20 è¼ªçš„è¨“ç·´)ï¼Œä»¥ 512 å€‹å°æ¨£æœ¬çš„å°æ‰¹é‡(batch_size)é€²è¡Œè¨“ç·´ï¼Œ
#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_val, y_val))
#+END_SRC

#+RESULTS:
#+begin_example
Epoch 1/20
30/30 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 34ms/step - binary_accuracy: 0.6895 - loss: 0.5987 - val_binary_accuracy: 0.8637 - val_loss: 0.3995
...ç•¥...
Epoch 20/20
[1m30/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9995 - loss: 0.0107 - val_binary_accuracy: 0.8726 - val_loss: 0.5637
#+end_example

model.fit()æœƒå›å‚³ä¸€å€‹ history ç‰©ä»¶ï¼Œé€™ç‰©ä»¶æœ¬èº«æœ‰ä¸€å€‹ history å±¬æ€§ï¼Œç‚ºä¸€å€‹åŒ…å«æœ‰é—œè¨“ç·´éç¨‹ä¸­ç›¸é—œæ•¸æ“šçš„å­—å…¸ï¼Œé€™å€‹å­—æœŸåŒ…å«æœ‰ 4 å€‹é …ç›®(val_loss, val_acc, loss, acc)ï¼Œç‚ºè¨“ç·´å’Œé©—è­‰æ™‚ç›£æ§çš„æŒ‡æ¨™ã€‚
#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
print(history.history)
print("binary_accuracy:",history.history['binary_accuracy'])
print("loss:",history.history['loss'])
print("val_binary_accuracy:",history.history['val_binary_accuracy'])
print("val_loss:",history.history['val_loss'])
#+end_src

#+RESULTS:
: {'binary_accuracy': [0.7724000215530396, 0.8913999795913696, 0.9195333123207092, 0.9340000152587891, 0.946066677570343, 0.9564666748046875, 0.9628000259399414, 0.966533362865448, 0.974133312702179, 0.9778666496276855, 0.9836000204086304, 0.9865333437919617, 0.9886000156402588, 0.9922000169754028, 0.9932000041007996, 0.9955999851226807, 0.9947333335876465, 0.9983999729156494, 0.997866690158844, 0.9980000257492065], 'loss': [0.523308277130127, 0.32568830251693726, 0.2428768277168274, 0.195417582988739, 0.16299770772457123, 0.13810740411281586, 0.12029378116130829, 0.10577400773763657, 0.08585202693939209, 0.07604678720235825, 0.0627065971493721, 0.05464218556880951, 0.04679805412888527, 0.03932145610451698, 0.033363644033670425, 0.02628222107887268, 0.026078475639224052, 0.018040597438812256, 0.017737768590450287, 0.014618363231420517], 'val_binary_accuracy': [0.8636999726295471, 0.8859000205993652, 0.8891000151634216, 0.876800000667572, 0.8762000203132629, 0.8863999843597412, 0.8859999775886536, 0.8823999762535095, 0.8826000094413757, 0.8780999779701233, 0.8794999718666077, 0.8788999915122986, 0.878000020980835, 0.8666999936103821, 0.8751999735832214, 0.8748999834060669, 0.8738999962806702, 0.8673999905586243, 0.8712999820709229, 0.8726000189781189], 'val_loss': [0.39949268102645874, 0.3119995892047882, 0.28234928846359253, 0.3045506775379181, 0.30820411443710327, 0.2834608554840088, 0.2936294972896576, 0.3101825714111328, 0.3229252099990845, 0.34479930996894836, 0.36042720079421997, 0.3789125978946686, 0.4012978971004486, 0.46704238653182983, 0.44717246294021606, 0.47011518478393555, 0.4929317533969879, 0.5508306622505188, 0.5428465604782104, 0.563687264919281]}
: binary_accuracy: [0.7724000215530396, 0.8913999795913696, 0.9195333123207092, 0.9340000152587891, 0.946066677570343, 0.9564666748046875, 0.9628000259399414, 0.966533362865448, 0.974133312702179, 0.9778666496276855, 0.9836000204086304, 0.9865333437919617, 0.9886000156402588, 0.9922000169754028, 0.9932000041007996, 0.9955999851226807, 0.9947333335876465, 0.9983999729156494, 0.997866690158844, 0.9980000257492065]
: loss: [0.523308277130127, 0.32568830251693726, 0.2428768277168274, 0.195417582988739, 0.16299770772457123, 0.13810740411281586, 0.12029378116130829, 0.10577400773763657, 0.08585202693939209, 0.07604678720235825, 0.0627065971493721, 0.05464218556880951, 0.04679805412888527, 0.03932145610451698, 0.033363644033670425, 0.02628222107887268, 0.026078475639224052, 0.018040597438812256, 0.017737768590450287, 0.014618363231420517]
: val_binary_accuracy: [0.8636999726295471, 0.8859000205993652, 0.8891000151634216, 0.876800000667572, 0.8762000203132629, 0.8863999843597412, 0.8859999775886536, 0.8823999762535095, 0.8826000094413757, 0.8780999779701233, 0.8794999718666077, 0.8788999915122986, 0.878000020980835, 0.8666999936103821, 0.8751999735832214, 0.8748999834060669, 0.8738999962806702, 0.8673999905586243, 0.8712999820709229, 0.8726000189781189]
: val_loss: [0.39949268102645874, 0.3119995892047882, 0.28234928846359253, 0.3045506775379181, 0.30820411443710327, 0.2834608554840088, 0.2936294972896576, 0.3101825714111328, 0.3229252099990845, 0.34479930996894836, 0.36042720079421997, 0.3789125978946686, 0.4012978971004486, 0.46704238653182983, 0.44717246294021606, 0.47011518478393555, 0.4929317533969879, 0.5508306622505188, 0.5428465604782104, 0.563687264919281]

#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
# ç§€å‡ºhistoryæ¶æ§‹
history_dict = history.history
print(history_dict.keys())

# ç•«åœ–
import matplotlib.pyplot as plt
accuracy = history.history['binary_accuracy']
val_accuracy = history.history['val_binary_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(accuracy) + 1)# "bo" is for "blue dot"
plt.cla()
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.plot()
plt.savefig("images/imdb-Keras-1.png")
plt.cla()
#plt.show()plt.clf()   # clear figureplt.clf()
acc_values = history_dict['binary_accuracy']
val_acc_values = history_dict['val_binary_accuracy']
plt.plot(epochs, accuracy, 'bo', label='Training acc')
plt.plot(epochs, val_accuracy, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.plot()
plt.savefig("images/imdb-Keras-2.png")
#plt.show()
#+END_SRC

#+RESULTS:
: dict_keys(['binary_accuracy', 'loss', 'val_binary_accuracy', 'val_loss'])

#+CAPTION: IMDB-Keras-1
#+LABEL:fig: IMDB-Keras-1
#+name: fig:IMDB-Keras-1
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/imdb-Keras-1.png]]

#+CAPTION:IMDB-Keras-2
#+LABEL:fig:IMDB-Keras-2
#+name: fig:IMDB-Keras-2
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/imdb-Keras-2.png]]
*** å„ªåŒ– model
ç”±åœ–[[fig:IMDB-Keras-1]]ã€[[fig:IMDB-Keras-2]]å¯ä»¥çœ‹å‡ºï¼Œä¸Šè¿° model é›–ç„¶åœ¨è¨“ç·´éšæ®µçš„æ•ˆèƒ½ä¸éŒ¯ï¼Œloss function éš¨ epoch ä¸‹é™ã€accuracy ä¹Ÿéš¨ epoch å‡é«˜ï¼Œä½†åœ¨é©—è­‰éšæ®µçš„è¡¨ç¾å»ååˆ†ä¸ç†æƒ³ï¼Œä¸åƒ… accuracy éš¨ epoch çš„å¢åŠ å‘ˆç·©é™è¶¨å‹¢ï¼Œloss function ç”šè‡³é‚„å¾€ä¸Šæ€¥å‡ã€‚

ç¬¬äºŒç‰ˆçš„ model åšäº†ä»¥ä¸‹æ”¹é€²:
- å°‡è³‡æ–™å‘é‡åŒ–(vectorize_sequences())
- åŠ å…¥äº†å…©å±¤ layer ä»¥åŠ dropout å±¤ï¼Œå…¶æ¶æ§‹å¦‚åœ–[[fig:nn3-6-2]]
#+BEGIN_SRC ditaa :file nn3-6-2.png

        è¼¸å…¥(å‘é‡åŒ–æ–‡å­—)
            |
            v
  +-------------------+
  |+-----------------+|
  || Dense(units=16) ||-+
  |+--------+--------+| |
  |         |         | |
  |         v         | |
  |+-----------------+| |
  || Dense(units=64) || |
  |+--------+--------+| |
  |         |         | |
  |         v         | |
  |+-----------------+| |
  ||  Dropout(0.25)  || |
  |+--------+--------+| |
  |         |         | +-éš±è—å±¤
  |         v         | |
  |+-----------------+| |
  || Dense(units=64) || |
  |+--------+--------+| |
  |         |         | |
  |         v         | |
  |+-----------------+| |
  ||  Dropout(0.25)  || |
  |+--------+--------+| |
  |         |         | |
  |         v         | |
  |+-----------------+| |
  || Dense(units=10) ||-+
  |+--------+--------+|
  |         |         |
  |         v         |
  |+-----------------+|-+
  ||  Dense(units=1) || +-è¼¸å‡ºå±¤
  |+-----------------+|-+
  +-------------------+
  #+END_SRC
#+RESULTS:
#+CAPTION: IMDB model æ¶æ§‹#2
#+name: fig:nn3-6-2
#+ATTR_LATEX: :width 200
#+ATTR_HTML: :width 300
#+ATTR_ORG: :width 200
[[file:images/nn3-6-2.png]]

#+BEGIN_SRC python -r -n :async :results output :exports both :session imdb
# å‘é‡åŒ–function
def vectorize_sequences(sequences, dimension=10000):
    # Create an all-zero matrix of shape (len(sequences), dimension)
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.  # set specific indices of results[i] to 1s
    return results
# Our vectorized training data
x_train = vectorize_sequences(train_data)
# Our vectorized test data
x_test = vectorize_sequences(test_data)
# æœ€å¾Œå†å°‡æ¨™ç±¤è³‡æ–™ä¹Ÿå‘é‡åŒ–
y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')
# å»ºç«‹model
model = models.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.25))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.25))
model.add(layers.Dense(1, activation='sigmoid'))

#åˆ¤æ–·ä½œæ¥­ç³»çµ±é¡å‹ï¼Œé¸æ“‡å„ªåŒ–å™¨
import platform
#if platform.system() == "Darwin" and platform.processor() == "arm":
#    opt = optimizers.legacy.RMSprop(learning_rate=0.0001)
#else:
opt = optimizers.RMSprop(learning_rate=0.0001)

model.compile(optimizer=opt, loss='binary_crossentropy',
              metrics=[metrics.binary_accuracy])

# é©—è­‰æ•¸æ“šé›†
x_val = x_train[:10000] # å‰10000å€‹è³‡æ–™ç‚ºé©—è­‰é›†
partial_x_train = x_train[10000:] # ç¬¬10000å€‹ä»¥å¾Œç‚ºè¨“ç·´é›†
y_val = y_train[:10000]
partial_y_train = y_train[10000:]

# è¨“ç·´model
history = model.fit(partial_x_train, partial_y_train,
                    epochs=20, batch_size=512,
                    validation_data=(x_val, y_val), verbose=0)

# ç§€å‡ºhistoryæ¶æ§‹
history_dict = history.history
print(history_dict.keys())

# é€²è¡Œé æ¸¬
x = model.predict(x_test)
print(x)

# ç•«åœ–
import matplotlib.pyplot as plt
plt.cla()
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(binary_accuracy) + 1)# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.plot()
plt.savefig("images/imdb-Keras-3.png")
#plt.show()

plt.cla()
acc_values = history_dict['binary_accuracy']
val_acc_values = history_dict['val_binary_accuracy']
plt.plot(epochs, binary_accuracy, 'bo', label='Training acc')
plt.plot(epochs, val_binary_accuracy, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.plot()
plt.savefig("images/imdb-Keras-4.png")
#plt.show()
#+END_SRC

#+RESULTS:
: dict_keys(['binary_accuracy', 'loss', 'val_binary_accuracy', 'val_loss'])
: 782/782 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 530us/step
: [[0.28722998]
:  [0.99044675]
:  [0.72447336]
:  ...
:  [0.04659463]
:  [0.12886518]
:  [0.4191768 ]]

#+CAPTION: IMDB-Keras-1
#+LABEL:fig: IMDB-Kera-1
#+name: fig:IMDB-Keras-1
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/imdb-Keras-1.png]]

#+CAPTION: IMDB-Keras-2
#+LABEL:fig: IMDB-Kera-2
#+name: fig:IMDB-Keras-2
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/imdb-Keras-2.png]]

#+CAPTION: IMDB-Keras-3
#+LABEL:fig: IMDB-Kera-3
#+name: fig:IMDB-Keras-3
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/imdb-Keras-3.png]]

#+CAPTION: IMDB-Keras-4
#+LABEL:fig: IMDB-Kera-4
#+name: fig:IMDB-Keras-4
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/imdb-Keras-4.png]]

æ¯”è¼ƒä¸Šè¿°å…©çµ„çµæœï¼Œå¯ä»¥ç™¼ç¾å„ªåŒ–ç‰ˆçš„ model åœ¨ loss function ä»¥åŠ accuracy çš„è¡¨ç¾éƒ½æœ‰é€²æ­¥ã€‚

** å¤šé¡åˆ¥åˆ†é¡ï¼šæ•¸ä½æ–°è
ç›®æ¨™ï¼šå°‡è·¯é€ç¤¾(Reuters)çš„æ•¸ä½æ–°èå°ˆæ¬„åˆ†æˆ 46 å€‹ä¸»é¡Œï¼Œé€™å±¬æ–¼å¤šé¡åˆ¥åˆ†é¡(multiclass classification)å•é¡Œï¼Œæ¯å€‹è³‡æ–™é»åªæœƒè¢«æ­¸å…¥ä¸€å€‹é¡åˆ¥ï¼›å¦‚æœæ¯å€‹è³‡æ–™é»å¯èƒ½å±¬æ–¼å¤šå€‹é¡åˆ¥ï¼Œå‰‡å±¬æ–¼å¤šæ¨™ç±¤å¤šé¡åˆ¥(multilabel multiclass classification)å•é¡Œã€‚
*** è³‡æ–™é›†
å’Œ MNISTã€IMDB ä¸€æ¨£ï¼Œé€™çµ„ç”± Reuters åœ¨ 1986 å¹´ç™¼å¸ƒçš„ç°¡çŸ­æ–°èä¸»é¡Œè³‡æ–™é›†ä¹Ÿå…§å»ºåœ¨ Keras ä¸­ï¼Œé€™å€‹è³‡æ–™é›†ç¸½å…±åˆ†ç‚º 46 å€‹ä¸åŒä¸»é¡Œã€‚
#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
print(train_data[0])
print(train_labels[0])
#+END_SRC

#+RESULTS:
: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]
: 3

å°‡è³‡æ–™å‘é‡åŒ–æœ‰å¹¾ç¨®æ–¹å¼ï¼šå°‡ label list è½‰ç‚ºæ•´æ•¸å¼µé‡ï¼Œæˆ–æ˜¯ç”¨ one-hot ç·¨ç¢¼ã€‚ä»¥ä¸‹ç‚ºä½¿ç”¨ python è‡ªè¨‚çš„ç·¨ç¢¼ç¨‹å¼ï¼š

#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
import numpy as np

def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.
    return results

# Our vectorized training data
x_train = vectorize_sequences(train_data)
# Our vectorized test data
x_test = vectorize_sequences(test_data)
print('åŸå§‹è³‡æ–™é›†ç¶­åº¦:',train_data.shape)
print('å‘é‡åŒ–è³‡æ–™é›†ç¶­åº¦:',x_train.shape)
print(x_train[0])
#+END_SRC

#+RESULTS:
: åŸå§‹è³‡æ–™é›†ç¶­åº¦: (8982,)
: å‘é‡åŒ–è³‡æ–™é›†ç¶­åº¦: (8982, 10000)
: [0. 1. 1. ... 0. 0. 0.]

å¦å¤–ï¼ŒKeras ä¹Ÿæœ‰ä¸€å€‹å…§å»ºçš„å‡½å¼å¯ç”¨ï¼š

#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
from tensorflow.keras.utils import to_categorical

one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
print(one_hot_train_labels.shape)
print(one_hot_train_labels[0])
#+END_SRC

#+RESULTS:
: (8982, 46)
: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
:  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
*** å»ºç«‹ç¥ç¶“ç¶²è·¯æ¨¡å‹

æ­¤æ¬¡é¢è‡¨çš„å•é¡Œä¸ä¼¼ IMDB åªåˆ†æˆå…©é¡ï¼Œè€Œæ˜¯å…±æœ‰ 46 é¡ï¼Œè‹¥æ¯å€‹ Dense layer ä»åªä½¿ç”¨16å€‹ç¶­åº¦ï¼Œå¯èƒ½ç„¡æ³•å­¸æœƒå€åˆ† 46 å€‹ä¸åŒé¡åˆ¥ï¼Œæ•…æœ‰éœ€è¦å°‡ç¶­åº¦å¢åŠ ï¼š

#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(46, activation='softmax'))
#+END_SRC

#+RESULTS:

å¦å¤–ï¼Œè¼¸å‡ºå±¤å°‡å•Ÿå‹•å‡½æ•¸ç”± sigmoid æ”¹ç‚º softmaxï¼Œä»¥æ©Ÿç‡å€¼ä¾†é¡¯ç¤ºé æ¸¬çš„é¡åˆ¥çµæœï¼Œé…åˆé€™ç¨®æƒ…å¢ƒï¼Œæœ€é©åˆçš„æå¤±å‡½æ•¸ç‚º categorical_crossentropyï¼Œå®ƒå¯ä»¥æ¸¬é‡å…©å€‹æ©Ÿç‡åˆ†ä½ˆé–“çš„å·®è·ï¼ˆå³ç¥ç¶“ç¶²è·¯è¼¸å‡ºçš„é æ¸¬æ©Ÿç‡åˆ†ä½ˆèˆ‡çœŸå¯¦åˆ†ä½ˆé–“çš„è·é›¢ï¼‰ï¼Œé€éæœ€å°åŒ–é€™å…©å€‹åˆ†ä½ˆé–“çš„è·é›¢ä¾†è¨“ç·´ç¥ç¶“ç¶²è·¯ï¼Œè®“çµæœæ¥è¿‘ç­”æ¡ˆã€‚

#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
model.compile(optimizer='rmsprop', loss='categorical_crossentropy',
                metrics=['accuracy'])
#+END_SRC

#+RESULTS:

æ­¤è™•çš„metricsç”¨ä¾†å„²å­˜å¾ŒçºŒè©•ä¼°(model.evaluate)æ¨¡å‹çš„è¨˜éŒ„
#+RESULTS:
*** é©—è­‰æ•¸æ“šé›†
ç”±è¨“ç·´é›†æŠ½å‡º 1000 å€‹æ¨£æœ¬ä¾†é©—è­‰ï¼š
#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
x_val = x_train[:1000]
partial_x_train = x_train[1000:]

y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
#+END_SRC

#+RESULTS:

*** è¨“ç·´æ¨¡å‹
#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=9,
                    batch_size=512,
                    validation_data=(x_val, y_val),
                    verbose=0)
history_dict = history.history
print(history_dict.keys())
#+end_src

#+RESULTS:
: dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])
*** è©•ä¼°æ¨¡å‹
ç¨‹å¼ç¬¬[[(modelEvaluate)]]è¡Œçš„model.evaluate()æœƒå‚³å›å…©å€‹çµæœ:
- loss value
- model.compile()æ™‚æŒ‡å®šçš„metricsï¼Œé€™è£¡æœƒè¨˜éŒ„accuracy


#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
print('loss:', history_dict['loss'])
print('accuracy:', history_dict['accuracy'])
print('val_accuracy:', history_dict['val_accuracy'])
# è©•ä¼°
# Returns the loss value & metrics values for the model in test mode.
results = model.evaluate(x_test, one_hot_test_labels)      (ref:modelEvaluate)
print("è©•ä¼°è³‡æ–™å…§å®¹ï¼š",results)
# é æ¸¬
predictions = model.predict(x_test)
print("é æ¸¬è³‡æ–™æ¶æ§‹ï¼š",predictions[0].shape)
print("é æ¸¬è³‡æ–™å…§å®¹ï¼š",predictions[0])
print("é æ¸¬çµæœ:",np.argmax(predictions[0]))
print("ç­”æ¡ˆ:",one_hot_test_labels[0])
#+END_SRC

#+RESULTS:
#+begin_example
loss: [3.0026934146881104, 1.6911225318908691, 1.232879877090454, 0.995611846446991, 0.8247262835502625, 0.6870928406715393, 0.5740740299224854, 0.4755861163139343, 0.4013058543205261]
accuracy: [0.47619643807411194, 0.6736406683921814, 0.7411676049232483, 0.7872713804244995, 0.8251065015792847, 0.8561763763427734, 0.8801052570343018, 0.9030318260192871, 0.9189426302909851]
val_accuracy: [0.6200000047683716, 0.6959999799728394, 0.7379999756813049, 0.765999972820282, 0.7929999828338623, 0.8069999814033508, 0.8130000233650208, 0.8069999814033508, 0.8130000233650208]
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 839us/step - accuracy: 0.8001 - loss: 0.9160
è©•ä¼°è³‡æ–™å…§å®¹ï¼š [0.9611411094665527, 0.7858415246009827]
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 685us/step
é æ¸¬è³‡æ–™æ¶æ§‹ï¼š (46,)
é æ¸¬è³‡æ–™å…§å®¹ï¼š [1.2854149e-05 3.7789090e-05 4.2292118e-05 9.0718436e-01 8.3002120e-02
 2.3392004e-06 2.9046484e-04 1.1120371e-05 1.7645630e-03 3.6879155e-05
 1.1398656e-06 5.2984012e-04 7.8006480e-05 5.6496664e-04 2.5368774e-05
 1.3207436e-04 7.5159752e-04 2.6923684e-05 1.9250263e-05 4.1414335e-04
 1.8693011e-03 7.0673483e-04 6.4346145e-06 1.2796119e-04 6.4659413e-05
 3.2037435e-05 5.2164037e-06 1.2275139e-04 9.2562705e-06 2.1327383e-04
 5.8351434e-05 1.9944042e-04 3.2126438e-05 2.4959205e-05 8.7677283e-05
 2.4225967e-05 6.1072549e-04 4.1610518e-05 3.6517431e-06 2.3155226e-04
 9.5444564e-05 4.4300844e-04 1.3225984e-05 1.0810289e-05 4.7312778e-07
 3.7070378e-05]
é æ¸¬çµæœ: 3
ç­”æ¡ˆ: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
#+end_example
ä¸Šè¿°ç¨‹å¼åœ¨ç¶“ç”± 9 å€‹ epoch å¾Œç²¾æº–åº¦å·²è¿‘ 80%(0.79)ã€‚
*** è©•ä¼°çµæœè¦–è¦ºåŒ–
#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
# ç•«åœ–
import matplotlib.pyplot as plt

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(loss) + 1)
plt.cla()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.axis([0, 10, 0, 3])
plt.legend()
plt.plot()
plt.savefig("images/reuters-1.png")
#plt.show()

plt.cla()   # clear figure

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.axis([0, 10, 0, 1])
plt.legend()
plt.plot()
plt.savefig("images/reuters-2.png")
# plt.show()
#+end_src

#+RESULTS:

#+CAPTION:Reuters-1
#+LABEL:fig:Reuters-1
#+name: fig:Reuters-1
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/reuters-1.png]]

#+CAPTION:Reuters-2
#+LABEL:fig:Reuters-2
#+name: fig:Reuters-2
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/reuters-2.png]]
*** å„ªåŒ– model
ä¸Šä¾‹ä¸­çš„ä¸­é–“å±¤è‹¥å°‡ç¥ç¶“å…ƒæ•¸(ç¶­åº¦)é™åˆ° 4ï¼Œå‰‡å…¶é©—è­‰æº–ç¢ºç‡æœƒé™è‡³ 71%ï¼Œä¸»è¦åŸå› æ˜¯å› ç‚ºé€™æ¨£æœƒå£“ç¸®å¤§é‡è³‡è¨Šåˆ°ä¸€å€‹ä½ç¶­åº¦çš„ä¸­é–“å±¤è¡¨ç¤ºç©ºé–“ï¼Œé›–ç„¶ç¥ç¶“ç¶²è·¯èƒ½å°‡å¤§éƒ¨ä»½å¿…è¦çš„è³‡è¨Šå¡é€²é€™ 4 ç¶­è¡¨ç¤ºæ³•ä¸­ï¼Œä½†ä»é¡¯ä¸è¶³ã€‚è‹¥å†æå‡ç¶­åº¦ã€å¢åŠ å±¤æ•¸ã€åŠ å…¥ Dropoutï¼Œçµæœä¼¼ä¹æ²’æœ‰é¡¯è‘—æ”¹å–„ï¼Œç‚ºä»€éº¼ï¼Ÿ
#+BEGIN_SRC python -r -n :async :results output :exports both :session reuters
model = models.Sequential()
model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.25))
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(46, activation='softmax'))

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])  (ref:metricsName)

# è¨“ç·´
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=9,
                    batch_size=512,
                    validation_data=(x_val, y_val),
                    verbose=0)

history_dict = history.history
print(history_dict.keys())

# è©•ä¼°
# Returns the loss value & metrics values for the model in test mode.
results = model.evaluate(x_test, one_hot_test_labels)               (ref:modelEvaluate)
print("è©•ä¼°è³‡æ–™å…§å®¹ï¼š",results)

# é æ¸¬
predictions = model.predict(x_test)
print("é æ¸¬è³‡æ–™æ¶æ§‹ï¼š",predictions[0].shape)
print("é æ¸¬è³‡æ–™å…§å®¹ï¼š",predictions[0])
print("é æ¸¬çµæœ:",np.argmax(predictions[0]))
print("ç­”æ¡ˆ:",one_hot_test_labels[0])
# ç•«åœ–

import matplotlib.pyplot as plt

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(loss) + 1)
plt.cla()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.axis([0, 10, 0, 3])
plt.legend()
plt.plot()
plt.savefig("images/reuters-3.png")
#plt.show()

plt.cla()   # clear figure

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.axis([0, 10, 0, 1])
plt.legend()
plt.plot()
plt.savefig("images/reuters-4.png")
# plt.show()
#+END_SRC

#+RESULTS:
#+begin_example
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 2ms/step - accuracy: 0.7549 - loss: 1.2041
è©•ä¼°è³‡æ–™å…§å®¹ï¼š [1.2634036540985107, 0.7471059560775757]
71/71 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 2ms/step
é æ¸¬è³‡æ–™æ¶æ§‹ï¼š (46,)
é æ¸¬è³‡æ–™å…§å®¹ï¼š [8.09684124e-08 9.49222340e-07 5.19393861e-09 9.99711692e-01
 1.80036150e-04 5.10908560e-09 1.91957028e-07 8.43487769e-08
 4.33161113e-05 5.34591793e-09 8.28265286e-07 2.17356887e-06
 1.84676892e-07 6.15979616e-07 5.97942105e-08 6.40554010e-09
 1.57276918e-05 3.67254273e-07 8.75066561e-08 4.16998364e-06
 3.44055552e-05 2.87553036e-07 9.22512200e-09 1.12576892e-07
 4.54701921e-09 1.97374948e-06 1.79199517e-08 2.03319690e-08
 1.43965934e-07 7.99068971e-08 3.35195637e-07 5.80273181e-08
 3.48503910e-08 4.89572605e-09 8.85782299e-07 2.67696922e-08
 3.60888407e-07 1.24438397e-08 2.77553855e-08 3.01288338e-07
 8.20946955e-09 1.16714205e-07 2.22603358e-09 1.22548434e-08
 2.11367723e-09 2.50342702e-09]
é æ¸¬çµæœ: 3
ç­”æ¡ˆ: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
#+end_example

#+CAPTION: Rueter-1
#+LABEL:fig:Rueter-1
#+name: fig:Rueter-1
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/reuters-1.png]]

#+CAPTION: Rueter-2
#+LABEL:fig:Rueter-2
#+name: fig:Rueter-2
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/reuters-2.png]]

#+CAPTION: Rueter-3
#+LABEL:fig:Rueter-3
#+name: fig:Rueter-3
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/reuters-3.png]]

#+CAPTION: Rueter-4
#+LABEL:fig:Rueter-4
#+name: fig:Rueter-4
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/reuters-4.png]]

** è¿´æ­¸å•é¡Œï¼šé æ¸¬æˆ¿åƒ¹
*** æº–å‚™è³‡æ–™
#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
from keras.datasets import boston_housing

(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()

print(train_data.shape)
print(test_data.shape)
#+END_SRC

#+RESULTS:
: (404, 13)
: (102, 13)

**** è³‡æ–™é›†æ¨™æº–åŒ–
#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(axis=0)
train_data /= std

test_data -= mean
test_data /= std
#+END_SRC

#+RESULTS:
*** å»ºç«‹ç¥ç¶“ç¶²è·¯
ç”±æ–¼å¯ç”¨çš„æ¨£æœ¬å¾ˆå°‘ï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€å€‹è¼ƒå°çš„ç¥ç¶“ç¶²è·¯ï¼Œä¸€èˆ¬ä¾†èªªï¼Œè¨“ç·´è³‡æ–™é›†è¶Šå°‘ï¼Œéåº¦é…é©çš„æƒ…æ³æœƒè¶Šåš´é‡ã€‚

#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
from keras import models
from keras import layers

def build_model():
    # Because we will need to instantiate
    # the same model multiple times,
    # we use a function to construct it.
    model = models.Sequential()
    model.add(layers.Dense(64, activation='relu',
                           input_shape=(train_data.shape[1],)))
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(1))      (ref:OneUnitLayer)
    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])
    return model
#+END_SRC

#+RESULTS:

é€™è£¡ä»¥ 1 unit çš„ç¥ç¶“ç¶²è·¯çµæŸè€Œä¸”æ²’æœ‰å•Ÿå‹•å‡½æ•¸(ç¬¬[[(OneUnitLayer)]]è¡Œ)ï¼Œä»£è¡¨ç‚ºç·šæ€§è½‰æ›ï¼Œé€™æ˜¯ç´”é‡è¿´æ­¸çš„åŸºæœ¬è¨­å®šï¼Œæœƒè¼¸å‡ºä¸€å€‹æµ®é»æ•¸å‹åˆ¥çš„æ•¸å€¼(å³è¿´æ­¸å€¼)ï¼Œå¦‚æœä½¿ç”¨å•Ÿå‹•å‡½æ•¸ï¼Œå‰‡åªæœƒè¼¸å‡º 0~1 é–“çš„å€¼ã€‚å¦ï¼Œmse ä¹Ÿæ˜¯è¿´æ­¸å¸¸ç”¨çš„æå¤±å‡½æ•¸ï¼Œåœ¨è©•é‡æŒ‡æ¨™çš„é¸æ“‡æ–¹é¢ï¼Œå‰‡æ¡ç”¨ mae(mean absolute errorï¼Œå³é æ¸¬å€¼èˆ‡ç›®æ¨™å€¼é–“å·®ç•°çš„çµ•å°å€¼)ã€‚
*** é©—è­‰
æœ¬ä¾‹ä¸­ç”±æ–¼è³‡æ–™é»å°‘ï¼Œé©—è­‰é›†ä¹Ÿåªæœ‰ 100 ç­†è³‡æ–™ï¼Œæ•…é©—è­‰åˆ†æ•¸å¯èƒ½æœƒå› é©—è­‰è³‡æ–™é»æˆ–è¨“ç·´è³‡æ–™é»çš„é¸ç”¨è€Œæœ‰å¾ˆå¤§çš„è®ŠåŒ–ï¼Œå› è€Œé˜»ç¤™è©•ä¼° model å„ªåŠ£çš„å¯é æ€§ã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼Œæœ€å¥½çš„æ–¹å¼æ˜¯é¸ç”¨ K-fold corss validationï¼Œåšæ³•å¦‚åœ–[[fig:K-fold-cross-validation]]ï¼ŒåŸç†æ˜¯å°‡è³‡æ–™æ‹†åˆ†ç‚º K å€‹å€åŸŸ(é€šå¸¸ K=4 æˆ– 5)ï¼Œæ¯æ¬¡å–ä¸€å€‹å€åŸŸåšç‚ºé©—è­‰è³‡æ–™é›†ï¼Œæœ€å¾Œæ±‚ K æ¬¡é©—è­‰åˆ†æ•¸çš„å¹³å‡å€¼ã€‚

#+CAPTION:K-fold äº¤å‰é©—è­‰
#+LABEL:fig:K-fold-cross-validation
#+name: fig:K-fold-cross-validation
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/k-fold-validation.png]]

K-fold cross validation çš„ python å¯¦ä½œç¨‹å¼ç¢¼å¦‚ä¸‹ï¼š
#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
import numpy as np

k = 4
num_val_samples = len(train_data) // k
num_epochs = 100
all_scores = []
for i in range(k):
    print('processing fold #', i)
    # Prepare the validation data: data from partition # k
    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]
    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]

    # Prepare the training data: data from all other partitions
    partial_train_data = np.concatenate([train_data[:i * num_val_samples],
         train_data[(i + 1) * num_val_samples:]], axis=0)
    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],
         train_targets[(i + 1) * num_val_samples:]], axis=0)

    # Build the Keras model (already compiled)
    model = build_model()
    # Train the model (in silent mode, verbose=0)
    model.fit(partial_train_data, partial_train_targets,
              epochs=num_epochs, batch_size=1, verbose=0)
    # Evaluate the model on the validation data
    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)
    all_scores.append(val_mae)
#+END_SRC

#+RESULTS:
: processing fold # 0
: processing fold # 1
: processing fold # 2
: processing fold # 3

*** æŸ¥çœ‹çµæœ
#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
print(all_scores)
print(np.mean(all_scores))
#+END_SRC

#+RESULTS:
: [2.2767844200134277, 2.619281053543091, 2.72979474067688, 2.562032461166382]
: 2.546973168849945

ç”±ä¸Šè¿°çµæœçœ‹ä¾†ï¼Œæ‹†æˆ 4 å€çš„é©—è­‰åˆ†æ•¸è‡ª 2.28 åˆ° 2.73ï¼Œç¸½å¹³å‡ç‚º 2.54ï¼Œé€™å€‹å¹³å‡å€¼æ˜¯è¼ƒç‚ºå¯é çš„æŒ‡æ¨™ï¼Œå› ç‚ºç•¶ç›®æ¨™æˆ¿åƒ¹çš„æ•¸å€¼å¾ˆå¤§æ™‚ï¼Œ2.28 åˆ° 2.73 æœƒè®Šæˆå¾ˆå¤§çš„èª¤å·®ã€‚

å¯èƒ½æ˜¯å› ç‚º MAC èˆ‡ Linux ç‰ˆæœ¬çš„ Anaconda ç›¸å®¹æ€§å•é¡Œï¼Œæˆ–æ˜¯ Keras ç‰ˆæœ¬å·®ç•°å•é¡Œï¼ŒMAC ç‰ˆèˆ‡ Linux ä¸‹çš„ history.history æ¶æ§‹ç•¥æœ‰å·®ç•°ï¼š
#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
# Linux with Keras 2.2.5
dict_keys(['val_loss', 'val_mean_absolute_error', 'loss', 'mean_absolute_error'])
# Mac with Keras 2.3.1
dict_keys(['val_loss', 'val_mae', 'loss', 'mae'])
#+END_SRC
**** è©•ä¼°çµæœè¦–è¦ºåŒ–
#+BEGIN_SRC python -r -n :async :results output :exports both :session boston_housing
# Some memory clean-up
k = 4
num_val_samples = len(train_data) // k
num_epochs = 500
all_mae_histories = []
for i in range(k):
    print('processing fold #', i)
    # Prepare the validation data: data from partition # k
    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]
    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]
    # Prepare the training data: data from all other partitions
    partial_train_data = np.concatenate(
        [train_data[:i * num_val_samples],
         train_data[(i + 1) * num_val_samples:]],
        axis=0)
    partial_train_targets = np.concatenate(
        [train_targets[:i * num_val_samples],
         train_targets[(i + 1) * num_val_samples:]],
        axis=0)
    # Build the Keras model (already compiled)
    model = build_model()
    # Train the model (in silent mode, verbose=0)
    history = model.fit(partial_train_data, partial_train_targets,
                        validation_data=(val_data, val_targets),
                        epochs=num_epochs, batch_size=1, verbose=0)
    mae_history = history.history['val_mae']
    all_mae_histories.append(mae_history)

average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]

import matplotlib.pyplot as plt
plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)
plt.xlabel('Epochs')
plt.ylabel('Validation MAE')
plt.plot()
plt.savefig("images/Boston-House-Price.png")

# æ’é™¤æ¯é€±æœŸçš„å‰10å€‹è³‡æ–™é»
def smooth_curve(points, factor=0.9):
  smoothed_points = []
  for point in points:
    if smoothed_points:
      previous = smoothed_points[-1]
      smoothed_points.append(previous * factor + point * (1 - factor))
    else:
      smoothed_points.append(point)
  return smoothed_points

smooth_mae_history = smooth_curve(average_mae_history[10:])
plt.clf()
plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)
plt.xlabel('Epochs')
plt.ylabel('Validation MAE')
plt.plot()
plt.savefig("images/Boston-House-Price-ex10.png")
#+END_SRC

#+RESULTS:
: processing fold # 0
: processing fold # 1
: processing fold # 2
: processing fold # 3

#+CAPTION: Boston House Price Training MAE
#+LABEL:fig:BostonHouseMAE
#+name: fig:BostonHouseMAE
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/Boston-House-Price.png]]

åœ–[[fig:BostonHouseMAE]]æ˜¯ç”±æ¯ä¸€è¨“ç·´é€±æœŸçš„å¹³å‡ MAE åˆ†æ•¸æ‰€ç¹ªå‡ºçš„æŠ˜ç·šåœ–ï¼Œç”±æ–¼å–®ä½åˆ»åº¦èˆ‡ y è»¸åˆ»åº¦å•é¡Œï¼Œæ­¤åœ–å¤±å»äº†éƒ¨ä»½é‡è¦ç´°ç¯€ï¼Œç¶“ç”±ä¸‹åˆ—æ–¹å¼é€²è¡Œä¿®æ­£ï¼š
- çœç•¥å‰ 10 å€‹è³‡æ–™é»ï¼Œ
- æŠŠæ¯å€‹è³‡æ–™é»æ›¿æ›æˆå‰ä¸€é»çš„æŒ‡æ•¸ç§»å‹•å¹³å‡å€¼(exponential moving average, EMA)ï¼Œè®“èª¤å·®è®Šå¹³æ»‘ã€‚

EMA å¸¸æ‡‰ç”¨æ–¼å„é ˜åŸŸçš„è³‡æ–™åˆ†æä¸­ï¼Œå…¶æ ¸å¿ƒæ¦‚å¿µç‚ºï¼šç¾åœ¨çš„è³‡æ–™æœƒè¢«éå»çš„è³‡æ–™æ‰€å½±éŸ¿ï¼Œè€Œæ™‚é–“é»è¶Šè¿‘çš„è³‡æ–™å½±éŸ¿è¶Šå¤§ï¼Œåä¹‹è¶Šå°ï¼Œå¦‚è‚¡ç¥¨çš„æ¼²å¹…ï¼Œå‰ 10 å¹´çš„æ¼²è·Œèˆ‡å‰ 10 æ—¥çš„æ¼²è·Œï¼Œè‡ªç„¶æ˜¯å¾Œè€…å°æœªä¾†çš„å½±éŸ¿æ›´å¤§ã€‚

EMA çš„æ•¸å­¸å‡½å¼å¦‚ä¸‹ï¼š
\( E_t = a \times V_t + (1-a) \times E_{t-1} \)ï¼Œå…¶ä¸­
- \(E_t\)ç‚ºæ™‚é–“é»\(t\)çš„æŒ‡æ•¸ç§»å‹•å¹³å‡å€¼
- \(a\)ç‚ºå¹³æ»‘ä¿‚æ•¸ï¼Œé€šå¸¸ä»‹æ–¼ 0 åˆ° 1 ä¹‹é–“
- \(V_t\)ç‚ºæ™‚é–“é»\(t\)çš„åŸå§‹æ•¸å€¼
- \(E_{t-1}\)ç‚ºæ™‚é–“é»\(t-1\)çš„æŒ‡æ•¸ç§»å‹•å¹³å‡å€¼

ç‚ºä»€éº¼å‰ä¾‹ä¸­å‰ 10 ç­†æ•¸æ“šçš„èˆ‡å…¶ä»–æ•¸æ“šå·®ç•°å¦‚æ­¤å·¨å¤§ï¼Ÿæˆ‘å€‘ä»¥å‰ 10 å¤©çš„è³‡æ–™(ä¸€å¤©ä¸€ç­†)ä¾†çœ‹ï¼Œç¬¬ 10 å¤©çš„ EMA ç‚ºï¼š
\( E_{10} = aV_{10} + (1-a)E_9 \)
å±•é–‹ç¬¬ 9 å¤©çš„\(E_9\)å¾Œ
\( E_{10} = aV_{10} + (1-a)[aV_9 + (1-a)E_8] \)
æ•´ç†å¾Œè®Šæˆ
\( E_{10} = a(V_{10} + (1-a)V_9) + (1-a)^{2}E_8 \)
è‹¥ç¹¼çºŒå±•é–‹æ‰€æœ‰å¤©æ•¸ï¼Œå°‡å¾—åˆ°
\( E_{10} = a(V_{10} + (1-a)V_9) + (1-a)^{2}E_8+ \dots + (1-a)^{9}V_{1}) + (1-a)^{9}E_1 \)
é€šå¸¸ä¸Šå¼çš„æœ€å¾Œä¸€é …æœƒå› ç‚ºæ™‚é–“å¾ˆé•·è€Œè®Šå¤ªå°ï¼Œæ•…å¯å¿½ç•¥ä¸è¨ˆï¼Œè€Œç”±æ­¤ä¹Ÿå¯çœ‹å‡ºï¼Œ\(E_{10}\)çš„å€¼æœƒè¢«æ¯å¤©çš„åŸå§‹è³‡æ–™\((V_{10} \dots V_{1}\))å½±éŸ¿ï¼Œæ¯å¤šä¸€å¤©ï¼ŒåŸå§‹æ•¸å€¼å°±æœƒå¤šä¹˜(1-a)å€ï¼ŒæˆæŒ‡æ•¸é—œä¿‚ï¼Œæ•…æ™‚é–“è¶Šä¹…é çš„äº‹ä»¶ï¼Œå½±éŸ¿è¶Šå°ã€‚

#+CAPTION: Boston House Price Training MAE (æ’é™¤å‰ 10 å€‹è³‡æ–™é»)
#+LABEL:fig:BostonHouseMAE-ex10
#+name: fig:BostonHouseMAE-ex10
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/Boston-House-Price-ex10.png]]

ç”±åœ–[[fig:BostonHouseMAE-ex10]]æ˜¯å¯çœ‹å‡º MAE åœ¨ 80 å€‹é€±æœŸå¾Œå·²åœæ­¢æ”¹å–„ï¼Œç„¶å¾Œé–‹å§‹å¾€ä¸Šå‡ï¼Œå³ï¼Œéäº†é€™é»å°±é–‹å§‹ç™¼ç”Ÿéåº¦é©é…çš„æƒ…æ³ã€‚
*** å°çµ

ç”±æ­¤ç¯„ä¾‹å¯çŸ¥ï¼š
- é€²è¡Œè¿´æ­¸åˆ†ææ™‚ï¼Œå¸¸ä»¥ MSE åšç‚ºæå¤±å‡½æ•¸ã€ä»¥ MAE åšç‚ºè©•ä¼°æŒ‡æ¨™(è€Œé accuracy).
- ç•¶è¼¸å…¥è³‡æ–™çš„ç‰¹å¾µæœ‰ä¸åŒåˆ»åº¦æ™‚ï¼Œæ‡‰å…ˆå°‡æ¯å€‹ç‰¹å¾µé€²è¡Œè½‰æ›ã€‚
- ç•¶å¯ç”¨è³‡æ–™å¾ˆå°‘æ™‚ï¼Œä½¿ç”¨ K-fold é©—è­‰ä¾†è©•ä¼°æ¨¡å¼ã€‚
- ç•¶å¯ç”¨è³‡æ–™å¾ˆå°‘æ™‚ï¼Œæœ€å¥½ä½¿ç”¨éš è—å±¤è¼ƒå°‘(è¼ƒæ·º)çš„å°å‹ç¥ç¶“ç¶²è·¯ï¼Œå¦‚ä¸€å€‹æˆ–å…©å€‹ï¼Œä»¥å…ç”¢ç”Ÿéæ¸¡é…é©ã€‚

** åœ–ç‰‡è­˜åˆ¥: MNIST
æ­¤è™•ä»¥æœ€ç°¡å–®çš„ NN (Neural Network) ä½œç‚ºç¯„ä¾‹ã€‚ä»¥ Keras çš„æ ¸å¿ƒç‚ºæ¨¡å‹ï¼Œæ‡‰ç”¨æœ€å¸¸ä½¿ç”¨ Sequential æ¨¡å‹ã€‚è—‰ç”±.add()æˆ‘å€‘å¯ä»¥ä¸€å±¤ä¸€å±¤çš„å°‡ç¥ç¶“ç¶²è·¯ç–Šèµ·ã€‚åœ¨æ¯ä¸€å±¤ä¹‹ä¸­æˆ‘å€‘åªéœ€è¦ç°¡å–®çš„è¨­å®šæ¯å±¤çš„å¤§å°(units)èˆ‡æ¿€å‹µå‡½æ•¸(activation function)ã€‚éœ€è¦ç‰¹åˆ¥è¨˜å¾—çš„æ˜¯ï¼šç¬¬ä¸€å±¤è¦è¨˜å¾—å¯«è¼¸å…¥çš„å‘é‡å¤§å°ã€æœ€å¾Œä¸€å±¤çš„ units è¦ç­‰æ–¼è¼¸å‡ºçš„å‘é‡å¤§å°ã€‚åœ¨é€™é‚Šæˆ‘å€‘æœ€å¾Œä¸€å±¤ä½¿ç”¨çš„æ¿€æ´»å‡½æ•¸(activation function)ç‚º softmaxã€‚
*** Import Library
#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async
from keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import numpy as np

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# å°‡è¨“ç·´é›†ç‰¹å¾µx_trainæ”¤å¹³æˆä¸€ç¶­å‘é‡
X_train = x_train.reshape(x_train.shape[0], -1)
# å°‡æ¨™ç±¤y_trainé€²è¡Œç¨ç†±ç·¨ç¢¼
Y_train = to_categorical(y_train)

X_test = x_test.reshape(x_test.shape[0], -1)
Y_test = to_categorical(y_test)
#+end_src

#+RESULTS:
*** å»ºç«‹æ¨¡å‹
- Kerasçš„æ¨¡å‹æœ‰Sequentialèˆ‡Modelå…©é¡
- æ±ºå®šå¥½è¦è¨­è¨ˆçš„æ¨¡å‹é¡åˆ¥ï¼Œé‚„è¦æ±ºå®šæ¨¡å‹è£¡çš„layerå¦‚ä½•å åŠ›ï¼Œlayeræœ‰è¨±å¤šé¸æ“‡ï¼Œä¾‹å¦‚[[https://keras.io/api/layers/][Layer]]çš„ç¨®é¡å°±æœ‰Dense layer, Activation layer, Conv1D layer, Dropout layer.....
- æ±ºå®šå¥½layer,é‚„è¦å†é¸activation functionï¼Œå¦‚ relu, sigmoid, softmax.....
- [[https://keras.io/api/layers/activations/][Keras API reference / Layers API / Layer activation functions ]]
#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout

model = Sequential()
#å°‡æ¨¡å‹ç–Šèµ·
model.add(Dense(input_dim=28*28,units=128,activation='relu'))
model.add(Dense(units=64,activation='relu'))
model.add(Dense(units=10,activation='softmax'))
model.summary()
#+end_src

#+RESULTS:
#+begin_example
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         P
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”
â”‚ dense (Dense)                        â”‚ (None, 128)                 â”‚         1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ dense_1 (Dense)                      â”‚ (None, 64)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ dense_2 (Dense)                      â”‚ (None, 10)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total params: 109,386 (427.29 KB)
 Trainable params: 109,386 (427.29 KB)
 Non-trainable params: 0 (0.00 B)
#+end_example

è—‰ç”±model.summary()å¯ä»¥ç°¡ç•¥è¼¸å‡ºæ¨¡å‹çš„å¤§æ¦‚æ¶æ§‹èˆ‡æ‰€ä½¿ç”¨çš„åƒæ•¸ç¸½æ•¸ã€‚

æ­¤ä¾‹ä¸­å äº†ä¸‰å€‹Denseå±¤ï¼Œç¬¬ä¸€å±¤ç‚ºæ¯å¼µåœ–çš„è¼¸å…¥(28*28å€‹é»)ï¼Œæœ‰784å€‹ç¥ç¶“å…ƒ(æˆ–node)ï¼Œç¬¬äºŒå±¤æœ‰64å€‹ç¥ç¶“å…ƒï¼Œé€™æ˜¯éš±è—å±¤ï¼Œæœ€å¾Œä¸€å±¤æœ‰10ç¥ç¶“å…ƒï¼Œåˆ†åˆ¥ä»£è¡¨10ç¨®æ•¸å­—çš„å¯èƒ½æ€§ã€‚

*** è¨“ç·´æ¨¡å‹
è¨“ç·´æ¨¡å‹æ™‚è¦æ±ºå®šä½¿ç”¨ä½•ç¨®loss functionã€ä½¿ç”¨ä½•ç¨®optimizerï¼Œå¯ä»¥åˆ°å®˜ç¶²([[https://keras.io/api/models/model_training_apis/][Model training APIs]])æŸ¥çœ‹æœ‰å“ªäº›é¸é …å¯ä½¿ç”¨ä»¥åŠä½•ç¨®é¸é …é©åˆå“ªäº›é¡å‹çš„è³‡æ–™é›†èˆ‡å•é¡Œã€‚
#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async

model.compile(loss='categorical_crossentropy',
              optimizer='adam', metrics=['accuracy'])

train_history = model.fit(x=X_train, y=Y_train, validation_split=0.2,
                          epochs=50, batch_size=1000, verbose=2)
#+end_src

#+RESULTS:
#+begin_example
Epoch 1/50
48/48 - 1s - 27ms/step - accuracy: 0.9686 - loss: 0.1297 - val_accuracy: 0.9424 - val_loss: 0.4813
...ç•¥...
Epoch 50/50
48/48 - 1s - 12ms/step - accuracy: 0.9961 - loss: 0.0137 - val_accuracy: 0.9631 - val_loss: 0.4587
#+end_example
*** æŸ¥çœ‹è¨“ç·´éç¨‹
çœ‹ä¸€ä¸‹historyçš„çµæ§‹
#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async
print(train_history.history.keys())
#+end_src

#+RESULTS:
: dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])

#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async
import matplotlib.pyplot as plt
def show_train_history(ylabel,train,test,fn):
    plt.cla()
    plt.plot(train_history.history[train])
    plt.plot(train_history.history[test])
    plt.title('Train History')
    plt.ylabel(ylabel)
    plt.xlabel('Epoch')
    plt.legend(['train', 'test'], loc='center left')
    plt.savefig("images/"+fn, dpi=300)
    ##plt.show()

show_train_history('Accuracy', 'accuracy','val_accuracy','mnist-acc-val.png')
show_train_history('Loss', 'loss','val_loss','mnist-loss-val.png')
#+end_src

#+RESULTS:

è¨“ç·´å®Œå°±å¯ä»¥é€éaccuracyèˆ‡lossä¾†è©•ä¼°æ¨¡å‹çš„æ•ˆèƒ½ï¼Œå¯ä»¥ç²—ç•¥çœ‹å‡ºéš¨è‘—epochçš„å¢åŠ ï¼Œç²¾ç¢ºåº¦ä¹Ÿéš¨ä¹‹æå‡ã€losså‰‡éš¨ä¹‹ä¸‹é™ã€‚
#+RESULTS:
#+CAPTION: Accuracy
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/mnist-acc-val.png]]

#+CAPTION: Loss
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 300
#+ATTR_ORG: :width 300
#+ATTR_HTML: :width 500
[[file:images/mnist-loss-val.png]]
*** è©•ä¼°æ¨¡å‹æº–ç¢ºç‡
#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async
score = model.evaluate(X_train, Y_train, batch_size = 200)
print ('\nTrain Acc:', score[1])
score = model.evaluate(X_test, Y_test, batch_size = 200)
print ('\nTest Acc:', score[1])
#+end_src

#+RESULTS:
: 300/300 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 1ms/step - accuracy: 0.9955 - loss: 0.0254
:
: Train Acc: 0.9897500276565552
: [1m50/50[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 1ms/step - accuracy: 0.9575 - loss: 0.5729
:
: Test Acc: 0.9627000093460083
*** å¯¦éš›é æ¸¬çµæœ
#+BEGIN_SRC python -r -n :results output :exports both :session mnistX
prediction=model.predict(X_test)
print(prediction.shape)
print(prediction[:2])
#+end_src

#+RESULTS:
: 313/313 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 519us/step
: (10000, 10)
: [[0.0000000e+00 4.8615205e-32 4.4841320e-31 5.9096544e-32 9.9364236e-38
:   5.8718204e-37 0.0000000e+00 1.0000000e+00 0.0000000e+00 3.7505548e-29]
:  [1.0376822e-33 4.1142359e-27 1.0000000e+00 6.7152534e-21 0.0000000e+00
:   0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6477517e-24 0.0000000e+00]]

#+BEGIN_SRC python -r -n :results output :exports both :session mnistX :async
import matplotlib.pyplot as plt
import numpy as np
def oneHotDecode(number):
    return np.argmax(number)
def plot_images_labels_prediction(images, labels, prediction, num, fn):
    plt.cla()
    fig = plt.gcf()

    fig.set_size_inches(10, 14)

    idx = 0
    for i in range(0, num):
        ax=plt.subplot(5, 5, 1+i)
        ax.imshow(images[idx].reshape(28, 28), cmap='binary')

        ax.set_title("label=" +str(oneHotDecode(labels[idx]))+
                     ",\npredict="+str(np.argmax(prediction[idx]))
                     ,fontsize=10)
        idx+=1
    plt.savefig("images/"+fn, dpi=300, bbox_inches='tight',pad_inches = 0.2)
plot_images_labels_prediction(x_test, y_test, prediction, 20, 'mnist-predic-perf.png')

#+end_src

#+RESULTS:

æœ€å¾Œè¼¸å‡ºæ¸¬è©¦è³‡æ–™é›†çš„å‰20ç­†è³‡æ–™çš„åœ–ã€labelä»¥åŠé æ¸¬çµæœ
#+RESULTS:
#+CAPTION: å‰20ç­†æ¸¬è©¦é›†é æ¸¬çµæœ
#+LABEL:fig:Labl
#+name: fig:Name
#+ATTR_LATEX: :width 500
#+ATTR_ORG: :width 500
#+ATTR_HTML: :width 500
[[file:images/mnist-predic-perf.png]]

** åœ–ç‰‡è­˜åˆ¥ç‰ˆæœ¬2: MNIST
*** å¦ä¸€ç‰ˆæœ¬
#+BEGIN_SRC python -r -n :results output :exports both :noeval
# è¼‰å…¥è³‡æ–™
from keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

def load_data():
    # è¼‰å…¥minstçš„è³‡æ–™
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    # å°‡åœ–ç‰‡è½‰æ›ç‚ºä¸€å€‹60000*784çš„å‘é‡ï¼Œä¸¦ä¸”æ¨™æº–åŒ–
    x_train = x_train.reshape(x_train.shape[0], 28*28)
    x_test = x_test.reshape(x_test.shape[0], 28*28)
    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')
    x_train = x_train/255
    x_test = x_test/255
    # å°‡yè½‰æ›æˆone-hot encoding
    y_train = to_categorical(y_train, 10)
    y_test = to_categorical(y_test, 10)
    # å›å‚³è™•ç†å®Œçš„è³‡æ–™
    return (x_train, y_train), (x_test, y_test)

import numpy as np
from keras import layers
from keras import models

def build_model():#å»ºç«‹æ¨¡å‹
    model = models.Sequential()
    #å°‡æ¨¡å‹ç–Šèµ·
    model.add(layers.Dense(input_dim=28*28,units=128,activation='relu'))
    model.add(layers.Dense(units=64,activation='relu'))
    model.add(layers.Dense(units=10,activation='softmax'))
    model.summary()
    return model

# é–‹å§‹è¨“ç·´æ¨¡å‹ï¼Œæ­¤è™•ä½¿ç”¨äº†Adamåšç‚ºæˆ‘å€‘çš„å„ªåŒ–å™¨ï¼Œloss functioné¸ç”¨äº†categorical_crossentropyã€‚
(x_train,y_train),(x_test,y_test)=load_data()
model = build_model()
#é–‹å§‹è¨“ç·´æ¨¡å‹
model.compile(loss='categorical_crossentropy',optimizer="adam",metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=100, epochs=5, verbose=0)
#é¡¯ç¤ºè¨“ç·´çµæœ
score = model.evaluate(x_train, y_train)
print ('\nTrain Acc:', score[1])
score = model.evaluate(x_test,y_test)
print ('\nTest Acc:', score[1])

### é€²è¡Œé æ¸¬
prediction = model.predict(x_test)
print(prediction[:10])

import pandas as pd
# å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾
predicted_labels = np.argmax(prediction, axis=1)
# å°†çœŸå®æ ‡ç­¾è½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾
true_labels = np.argmax(y_test, axis=1)

p = pd.crosstab(true_labels, predicted_labels, rownames=['label'], colnames=['predict'])
print(p)

#+END_SRC

#+RESULTS:
#+begin_example
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ dense (Dense)                   â”‚ (None, 128)            â”‚       100,480 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 64)             â”‚         8,256 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (None, 10)             â”‚           650 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 109,386 (427.29 KB)
 Trainable params: 109,386 (427.29 KB)
 Non-trainable params: 0 (0.00 B)
[1m   1/1875[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:11[0m 38ms/step - accuracy: 1.0000 - loss: 0.0060[1m 119/1875[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 426us/step - accuracy: 0.9900 - loss: 0.0408 [1m 266/1875[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 379us/step - accuracy: 0.9910 - loss: 0.0376[1m 406/1875[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 372us/step - accuracy: 0.9909 - loss: 0.0371[1m 553/1875[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 364us/step - accuracy: 0.9909 - loss: 0.0365[1m 691/1875[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 364us/step - accuracy: 0.9908 - loss: 0.0361[1m 838/1875[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 360us/step - accuracy: 0.9907 - loss: 0.0359[1m 975/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 361us/step - accuracy: 0.9906 - loss: 0.0358[1m1115/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 360us/step - accuracy: 0.9904 - loss: 0.0358[1m1261/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 358us/step - accuracy: 0.9903 - loss: 0.0358[1m1410/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 356us/step - accuracy: 0.9903 - loss: 0.0358[1m1554/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 355us/step - accuracy: 0.9902 - loss: 0.0359[1m1686/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 357us/step - accuracy: 0.9901 - loss: 0.0360[1m1801/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 362us/step - accuracy: 0.9900 - loss: 0.0361[1m1875/1875[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 364us/step - accuracy: 0.9900 - loss: 0.0361

Train Acc: 0.9893333315849304
[1m  1/313[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m14s[0m 45ms/step - accuracy: 1.0000 - loss: 0.0102[1m144/313[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 350us/step - accuracy: 0.9736 - loss: 0.0826[1m279/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 361us/step - accuracy: 0.9729 - loss: 0.0823[1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 359us/step - accuracy: 0.9733 - loss: 0.0810

Test Acc: 0.9764999747276306
[1m  1/313[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 17ms/step[1m139/313[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 364us/step[1m288/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 350us/step[1m313/313[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 378us/step
[[1.58942123e-06 4.56630090e-07 1.44183810e-04 7.96658918e-04
  4.83289035e-08 5.57914291e-07 8.43276837e-12 9.98949349e-01
  7.18311139e-06 9.99482872e-05]
 [9.20066245e-11 8.16951651e-05 9.99909282e-01 7.55548444e-06
  9.96026872e-11 2.12249276e-07 8.12293024e-08 3.26049777e-11
  1.17174454e-06 2.21182258e-14]
 [1.82215524e-06 9.96792972e-01 3.96484742e-04 1.60194541e-04
  1.02035912e-04 1.21604295e-04 6.79323348e-05 8.09717865e-04
  1.49104348e-03 5.62478417e-05]
 [9.99915719e-01 5.35815747e-09 4.51234046e-05 5.88590240e-07
  1.43257850e-07 3.82396547e-06 1.11071859e-05 1.55277394e-06
  2.66697526e-08 2.18579280e-05]
 [4.33285859e-05 1.10104907e-06 1.34856982e-05 1.56399324e-06
  9.93066788e-01 4.01588704e-06 4.50718362e-05 1.48709762e-04
  9.48531579e-06 6.66645123e-03]
 [6.66389894e-08 9.97991085e-01 3.08640438e-06 4.88619798e-06
  1.13685437e-05 2.65808126e-07 6.75553053e-08 1.93838566e-03
  2.31987287e-05 2.76108785e-05]
 [7.66120678e-08 4.94036567e-06 2.84373783e-07 6.58262920e-08
  9.98910308e-01 1.59385650e-06 7.10860562e-08 8.05889431e-06
  4.70556435e-04 6.04005065e-04]
 [6.92483184e-07 7.98684960e-06 4.36144364e-05 3.25308600e-03
  4.72561878e-05 9.02633201e-06 8.00792588e-09 1.29608334e-05
  2.07478279e-05 9.96604562e-01]
 [1.25154367e-08 2.27490159e-06 1.40500115e-03 6.09770814e-06
  4.96629109e-05 8.98099899e-01 9.85215753e-02 2.18058993e-08
  1.91533507e-03 1.61481594e-07]
 [6.98578688e-08 2.19913043e-09 5.58190187e-08 9.24819687e-06
  1.30430009e-04 7.13636261e-09 4.16892909e-12 4.35012007e-05
  2.02734009e-06 9.99814689e-01]]
predict    0     1     2    3    4    5    6     7    8    9
label
0        960     0     6    0    2    0    7     1    4    0
1          0  1128     3    0    0    0    1     0    3    0
2          2     4  1015    2    1    0    1     4    2    1
3          0     0    11  979    0    9    0     4    2    5
4          0     1     1    0  955    0    6     4    2   13
5          2     0     0   14    1  860    4     1    7    3
6          3     3     2    1    1    3  942     1    2    0
7          0     4     7    1    1    0    0  1004    0   11
8          5     1     4    7    3    2    3     5  938    6
9          3     2     2    6    6    1    2     3    0  984
#+end_example

* Footnotes

[fn:1][[https://kknews.cc/zh-tw/tech/b4zkbom.html][ä¸»æµçš„æ·±åº¦å­¸ç¿’æ¨¡å‹æœ‰å“ªäº›ï¼Ÿ]]

[fn:2] [[https://medium.com/nerd-for-tech/vgg-16-easiest-explanation-12453b599526][VGG 16 Easiest Explanation]]

[fn:3] [[https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0][Extract Features, Visualize Filters and Feature Maps in VGG16 and VGG19 CNN Models]]

[fn:4] [[https://medium.com/image-processing-and-ml-note/inception-v1-googlenet-winner-of-ilsvrc-2014-image-classification-15b1ea62cc11][Inception-v1 (GoogLeNet) â€” Winner of ILSVRC 2014 (Image Classification)]]

[fn:5] [[https://medium.com/ai-blog-tw/deep-learning-residual-leaning-%E8%AA%8D%E8%AD%98resnet%E8%88%87%E4%BB%96%E7%9A%84%E5%86%A0%E5%90%8D%E5%BE%8C%E7%B9%BC%E8%80%85resnext-resnest-6bedf9389ce][Residual Leaning: èªè­˜ResNetèˆ‡ä»–çš„å† åå¾Œç¹¼è€…ResNeXtã€ResNeSt]]

[fn:6][[https://medium.com/@rossleecooloh/%E7%9B%B4%E8%A7%80%E7%90%86%E8%A7%A3resnet-%E7%B0%A1%E4%BB%8B-%E8%A7%80%E5%BF%B5%E5%8F%8A%E5%AF%A6%E4%BD%9C-python-keras-8d1e2e057de2][ç›´è§€ç†è§£ResNet â€”ç°¡ä»‹ã€ è§€å¿µåŠå¯¦ä½œ(Python Keras)]]

[fn:7] [[https://arxiv.org/pdf/1512.03385.pdf][Deep Residual Learning for Image Recognition]]

[fn:8] [[http://tkdbooks.com/PC14110][å°ç§‘å¤§è³‡è¨Šç§‘æŠ€]]

[fn:9] [[https://www.baeldung.com/cs/cost-vs-loss-vs-objective-function][Difference Between the Cost, Loss, and the Objective Function]]

[fn:18][[https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-09-l1l2regularization/][L1 / L2 æ­£è¦åŒ–]]

[fn:17][[https://ithelp.ithome.com.tw/articles/10219648?sc=rss.iron][Google MLèª²ç¨‹ç­†è¨˜ - Overfitting èˆ‡ L1 /L2 Regularization ]]

[fn:16][[https://www.itread01.com/content/1549579879.html][æ©Ÿå™¨å­¸ç¿’åå¤§æ¼”ç®—æ³•---8. éš¨æ©Ÿæ£®æ—æ¼”ç®—æ³•]]

[fn:15][[https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8-%E7%B5%B1%E8%A8%88%E5%AD%B8%E7%BF%92-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-principle-component-analysis-pca-58229cd26e71][æ©Ÿå™¨/çµ±è¨ˆå­¸ç¿’:ä¸»æˆåˆ†åˆ†æ(Principal Component Analysis, PCA)]]

[fn:14][[https://blog.csdn.net/dongyanwen6036/article/details/78311071][LDAèˆ‡PCAéƒ½æ˜¯å¸¸ç”¨çš„é™ç¶­æ–¹æ³•ï¼ŒäºŒè€…çš„å€åˆ¥]]

[fn:13][[https://keras-cn.readthedocs.io/en/latest/models/model/][å‡½æ•¸å¼æ¨¡å‹æ¥å£]]

[fn:12][[https://keras.io/zh/getting-started/sequential-model-guide/][Sequential é †åºæ¨¡å‹æŒ‡å¼•]]

[fn:11][[https://medium.com/yiyi-network/transfer-learning-1f87d4f1886f][Kaggle Learn | Deep Learning æ·±åº¦å­¸ç¿’ | å­¸ç¿’è³‡æºä»‹ç´¹ (Part 2)]]

[fn:10] Goodfello, Ian J., Oriol Vinyals & Andrew M. Saxe, Qualitatively characterizing neural ntwork optimization problems, arXiv preprint arXiv: 1412.6544 (2014).
