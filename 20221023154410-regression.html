<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-12-23 Sat 10:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>迴歸</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">迴歸</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org7bca0e0">1. 簡介</a>
<ul>
<li><a href="#org273e8fb">1.1. 迴歸類型</a></li>
<li><a href="#org771599f">1.2. 迴歸原理</a></li>
<li><a href="#orgfe7cc21">1.3. 迴歸預測流程(以波士頓房價預測為例)</a></li>
</ul>
</li>
<li><a href="#org667b751">2. 線性迴歸:年齡身高預測#1</a>
<ul>
<li><a href="#org8de31e2">2.1. 資料生成</a></li>
<li><a href="#org306ca0e">2.2. 查看資料</a></li>
<li><a href="#orgef1672b">2.3. 直線模型</a></li>
<li><a href="#org83ee065">2.4. 損失函數</a></li>
<li><a href="#org4e79d9f">2.5. 窮舉所有的可能性</a></li>
<li><a href="#org60d89a1">2.6. 快速求出最佳解</a></li>
<li><a href="#org54ded58">2.7. 逐步找出最佳解</a></li>
</ul>
</li>
<li><a href="#orgf62972d">3. 保持距離以測安全</a>
<ul>
<li><a href="#orgbaf6c09">3.1. 模型的目的</a></li>
<li><a href="#orgabf4705">3.2. 沿著曲線上下爬</a></li>
<li><a href="#org1f7a2d4">3.3. 確定方向</a></li>
<li><a href="#orgf94f8fb">3.4. 確定移動距離與重複次數</a></li>
<li><a href="#orga7bf1d6">3.5. 斜率與微分</a></li>
</ul>
</li>
<li><a href="#org0780830">4. 線性迴歸:年齡身高預測#2</a></li>
</ul>
</div>
</div>
<a href="https://letranger.github.io/AI/20221023154410-regression.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023154410-regression.html.svg"/></a>
<div id="outline-container-org7bca0e0" class="outline-2">
<h2 id="org7bca0e0"><span class="section-number-2">1.</span> 簡介</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org273e8fb" class="outline-3">
<h3 id="org273e8fb"><span class="section-number-3">1.1.</span> 迴歸類型</h3>
<div class="outline-text-3" id="text-1-1">
<p>
即，根據一組預測特徵（predictor，如里程數、車齡、品牌）來預測目標數值（如二手車車價）<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>，這個目標數值也叫label。
</p>

<p>
部份迴歸演算法也可以用來分類，例如Logistic，它可以輸出一個數值，以這個數值來表示對應到特定類別的機率，例如，某封email為垃圾郵件的機率為20%、某張圖片為狗的機率為70%。
</p>

<p>
迴歸問題可分為兩類：
</p>
<ul class="org-ul">
<li>Linear regression:
<ul class="org-ul">
<li>假設輸入變量(x)與單一輸出變量(y)間存在線性關係，並以此建立模型。</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時會導致低度擬合</li>
<li>例: 身高與體重間的關係</li>
</ul></li>
<li>Logistic regression
<ul class="org-ul">
<li>也是線性方法，但使用logist function轉換輸出的預測結果，其輸出結果為類別機率(class probabilities)</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時無法處理分類問題</li>
</ul></li>
</ul>

<p>
典型迴歸案例: Boston Housing Data
</p>
</div>
</div>
<div id="outline-container-org771599f" class="outline-3">
<h3 id="org771599f"><span class="section-number-3">1.2.</span> 迴歸原理</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-orgbc459f8" class="outline-4">
<h4 id="orgbc459f8"><span class="section-number-4">1.2.1.</span> Step 1</h4>
<div class="outline-text-4" id="text-1-2-1">
<ol class="org-ol">
<li>Model: \(y = w*x+b\)</li>
<li>Data: 找一堆現成的資料</li>
</ol>
</div>
</div>
<div id="outline-container-org92050bd" class="outline-4">
<h4 id="org92050bd"><span class="section-number-4">1.2.2.</span> Step 2: Goodness of Function</h4>
<div class="outline-text-4" id="text-1-2-2">
<ol class="org-ol">
<li>Training Data</li>
<li>Loss function L: 越小越好
input: a function / output: how bad it is</li>
<li>Pick the &ldquo;Best: Function
\(f* = arg min L(f)\)
上述可以微分來求最佳解，即求 function L 的最小值</li>
<li>數值最佳解: Gradient Descent(找拋物面最低點)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgfe7cc21" class="outline-3">
<h3 id="orgfe7cc21"><span class="section-number-3">1.3.</span> 迴歸預測流程(以波士頓房價預測為例)</h3>
<div class="outline-text-3" id="text-1-3">
<ol class="org-ol">
<li>Import the required module</li>
<li>Load and configure the Boston housing data set</li>
<li>Chekc the relation between the variable, using pairplot and correlation graph</li>
<li>Descriptive statistics: central tendency and dispersion</li>
<li>Select the required columns</li>
<li>Train the test split</li>
<li>Normalize the data</li>
<li>Build the input pipeline for the TensorFlow model</li>
<li>Model tranining</li>
<li>Predictions</li>
<li>Validation</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org667b751" class="outline-2">
<h2 id="org667b751"><span class="section-number-2">2.</span> 線性迴歸:年齡身高預測#1</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org8de31e2" class="outline-3">
<h3 id="org8de31e2"><span class="section-number-3">2.1.</span> 資料生成</h3>
<div class="outline-text-3" id="text-2-1">
<p>
這是當初上帝創造人類時決定人類身高的規則，我們也可以將之視為這組資料的模型，這個規則或模型是很神祕的，等一下我們要假裝我們不知道這個模型的存在，而迴歸的目的就在於想辦法猜出這個規則或模型。
</p>
<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt

<span style="color: #dcaeea;">n</span> = <span style="color: #da8548; font-weight: bold;">10</span>                               <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36039;&#26009;&#31558;&#25976;</span>
<span style="color: #dcaeea;">year</span> = <span style="color: #da8548; font-weight: bold;">5</span> + <span style="color: #da8548; font-weight: bold;">25</span> * np.random.rand(n)  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24180;&#32000;</span>
<span style="color: #dcaeea;">height</span> = <span style="color: #da8548; font-weight: bold;">170</span> - <span style="color: #da8548; font-weight: bold;">108</span> * np.exp(-<span style="color: #da8548; font-weight: bold;">0.2</span> * year) + <span style="color: #da8548; font-weight: bold;">4</span> * np.random.randn(n)
<span style="color: #c678dd;">print</span>(year)
<span style="color: #c678dd;">print</span>(height)
</pre>
</div>
<pre class="example">
[13.3, 16.2, 10.9, 28.7, 19.8, 14.2, 11.7, 26.6, 22.4, 18.3, 19.4]
[163.61, 168.53, 155.06, 171.3 , 166.69, 160.98, 158.23, 165.27, 170.83,  161.31, 163.58]
</pre>
</div>
</div>
<div id="outline-container-org306ca0e" class="outline-3">
<h3 id="org306ca0e"><span class="section-number-3">2.2.</span> 查看資料</h3>
<div class="outline-text-3" id="text-2-2">
<p>
對於平凡的人類而言，他們只能看到身邊的人們隨著年齡增長而出現身高的變化，也就是由神袐模型所生成的數字：年齡和身高(如圖<a href="#org23da423">1</a>)。
</p>

<div id="org23da423" class="figure">
<p><img src="images/yearHeight.png" alt="yearHeight.png" width="500" />
</p>
<p><span class="figure-number">Figure 1: </span>年齡與身高的資料分佈</p>
</div>

<p>
但那些一身反骨的數學家則不甘於當平凡人，他們想透過統計、分析、思考、通靈等方式對這個既有現象進行逆向工程，去推估這個現象背後的神祕規則，藉此窺探上帝的意志。
這些規則也許是如圖<a href="#orgbea8d02">2</a>中的各種線段。一但找到了規則，我們就能根據這些規則進行 <b>預測</b> ，例如，由某人的年齡來合理推估他的身高。
</p>

<div id="orgbea8d02" class="figure">
<p><img src="images/yearHeightModel.png" alt="yearHeightModel.png" width="500" />
</p>
<p><span class="figure-number">Figure 2: </span>隱藏在年齡與身高資料背後的規則(模型)</p>
</div>
</div>
</div>
<div id="outline-container-orgef1672b" class="outline-3">
<h3 id="orgef1672b"><span class="section-number-3">2.3.</span> 直線模型</h3>
<div class="outline-text-3" id="text-2-3">
<p>
我們可以在圖<a href="#orgbea8d02">2</a>中畫上無數條線，但，最能代表年齡和身高關係的線應該只有一條，我們要如何找出這條線？
</p>

<p>
首先，既然我們想以 <b>直線</b> 來表示我們想找的模型或規則，那我們就先把這條直線以下列數學示表示出來:
\[y=ax+b\] 或 \[f(x)=ax+b\]
這樣的直線 \(y\) 或函數 \(f(x)\) 有無限多個，迴歸的目的就是要為函數 \(f(x)\) 找出一組最好的參數 \(a,b\)，或是為直線 \(y\) 找到最適合的斜率 \(a\) 和截距 \(b\)。這也是現今許多AI模型的基本精神：找到一組最好的參數，或者說：從無數個可能的模型中挑出最好的一個。
</p>

<p>
為了從無限多個備選模型中找出最佳的，我們需要有一個評估機制。
</p>
</div>
</div>
<div id="outline-container-org83ee065" class="outline-3">
<h3 id="org83ee065"><span class="section-number-3">2.4.</span> 損失函數</h3>
<div class="outline-text-3" id="text-2-4">
<p>
損失函數(loss function)也稱為成本函數(cost function)，就是最常用來定義、衡量模型誤差的方法。以圖<a href="#org0d5cebb">3</a>為例，我們可以計算所有原始資料\((x_0, y_0) \dots (x_9, y_9)\) 離這條預測線的距離(預測結果為 \(\hat{y_0} \dots \hat{y_9}\))，這些距離( \(y_0 - \hat{y_0} \dots y_9 - \hat{y_9}\) )的總和越小，表示預測線離每一點越近，也就是說這個模型越準確。
</p>


<div id="org0d5cebb" class="figure">
<p><img src="images/yearHeightLoss.png" alt="yearHeightLoss.png" width="600" />
</p>
<p><span class="figure-number">Figure 3: </span>直線模型的均方誤差</p>
</div>

<p>
圖<a href="#org0d5cebb">3</a>中的 \(y_i\) 為實際資料 \(x_i\) 對應的結果， 而 \(\hat{y_i}\) 則是將每個實際資料 \(x_i\) 丟入模型後的預測結果，計算 \(y_i\) 與 \(\hat{y_i}\) 誤差的方法稱為 <b>殘差平方和</b> (Residual Sum of Squares, RSS)，計算公式為
\[ RSS = \sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
把RSS再除以n就或是 <b>均方差</b> (Mean Square Error, MSE)，即
\[ MSE = \frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
迴歸的任務就是把RSS或MSE最小化。
</p>

<p>
如何讓RSS/MSE最小化呢？
</p>
</div>
</div>
<div id="outline-container-org4e79d9f" class="outline-3">
<h3 id="org4e79d9f"><span class="section-number-3">2.5.</span> 窮舉所有的可能性</h3>
<div class="outline-text-3" id="text-2-5">
<p>
為了找出哪一組參數 \(a,b\) 可以讓模型 \(y=ax+b\) 的預測誤差達到最小，我們可以將一些合理的a,b值可能組合都列出來，如圖<a href="#org97b9047">4</a>，我們列出了由參數 \(a\) (-40~40)、參數 \(b\) (40~160)的所有可能模型，圖中的 \(z\) 軸代表每一種模型產生的誤差(RSS)。由圖<a href="#org97b9047">4</a>可以看出兩件事:
</p>
<ol class="org-ol">
<li>參數 \(a\) 對模型誤差的影響遠大於參數 \(b\)</li>
<li>當參數 \(a\) 的值接近0時，所生成的模型會有較低的MSE，也就是模型預測能力較好</li>
</ol>


<div id="org97b9047" class="figure">
<p><img src="images/SSELossA.png" alt="SSELossA.png" width="500" />
</p>
<p><span class="figure-number">Figure 4: </span>不同a,b情況下的均方差</p>
</div>

<p>
讓我們回憶一下等高線這個東西，如果我們把圖<a href="#org97b9047">4</a>當成某個山谷的地形圖(z軸為高度)，那我們就可以畫出這個區域的等高線圖<a href="#orga560647">5</a>(先別管我是怎麼畫出來的)，從等高線圖<a href="#orga560647">5</a>就能大概看出來當a的值約等於0、b的值約等於150時會有最低的SSE(如圖<a href="#orga560647">5</a>中的紅點，這是我透過觀落音得到的訊息)。
</p>


<div id="orga560647" class="figure">
<p><img src="images/SSELossB.png" alt="SSELossB.png" width="500" />
</p>
<p><span class="figure-number">Figure 5: </span>不同a,b情況下的MSE(俯視/等高線)</p>
</div>

<p>
總之，看起來是有辦法找到最佳的模型的(只是有點麻煩)，這個方法稱為梯度下降，在這裡我們先知道有這麼個方法、知道這個方法可以找出最佳模型就好，至於深入探討這個方法是如何運作這件事，等我搞清楚了再說吧(或是等你們上大學再自己去研究)&#x2026;
</p>
</div>
</div>
<div id="outline-container-org60d89a1" class="outline-3">
<h3 id="org60d89a1"><span class="section-number-3">2.6.</span> 快速求出最佳解</h3>
<div class="outline-text-3" id="text-2-6">
<p>
雖然從無數組 \((a,b)\) 中找出最好的一組看似困難，不過其實許多現成的相關模組已經有了這些功能，例如<a href="https://scikit-learn.org/stable/">scikit-learn</a>。以底下的程式為例：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">year</span> = np.array([<span style="color: #da8548; font-weight: bold;">13.3</span>, <span style="color: #da8548; font-weight: bold;">16.2</span>, <span style="color: #da8548; font-weight: bold;">10.9</span>, <span style="color: #da8548; font-weight: bold;">28.7</span>, <span style="color: #da8548; font-weight: bold;">14.2</span>, <span style="color: #da8548; font-weight: bold;">11.7</span>, <span style="color: #da8548; font-weight: bold;">26.6</span>, <span style="color: #da8548; font-weight: bold;">22.4</span>, <span style="color: #da8548; font-weight: bold;">18.3</span>, <span style="color: #da8548; font-weight: bold;">20.4</span>]).reshape([-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 5: </span><span style="color: #dcaeea;">height</span> = np.array([<span style="color: #da8548; font-weight: bold;">163.61</span>, <span style="color: #da8548; font-weight: bold;">168.53</span>, <span style="color: #da8548; font-weight: bold;">155.06</span>, <span style="color: #da8548; font-weight: bold;">168.3</span> ,<span style="color: #da8548; font-weight: bold;">158.98</span>, <span style="color: #da8548; font-weight: bold;">158.23</span>, <span style="color: #da8548; font-weight: bold;">165.27</span>, <span style="color: #da8548; font-weight: bold;">170.83</span>,  <span style="color: #da8548; font-weight: bold;">161.31</span>, <span style="color: #da8548; font-weight: bold;">163.58</span>])
<span class="linenr"> 6: </span>
<span id="coderef-modelRegression" class="coderef-off"><span class="linenr"> 7: </span><span style="color: #dcaeea;">model</span> = LinearRegression()</span>
<span id="coderef-modelFit" class="coderef-off"><span class="linenr"> 8: </span>model.fit(year, height)</span>
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #dcaeea;">slope</span> = model.coef_
<span class="linenr">11: </span><span style="color: #dcaeea;">intercept</span> = model.intercept_
<span class="linenr">12: </span><span style="color: #dcaeea;">heightHat</span> = year * slope + intercept
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#26012;&#29575;/Slope:'</span>, slope)
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#25130;&#36317;/Intercept:'</span>, intercept)
</pre>
</div>

<pre class="example">
斜率/Slope: [0.58182444]
截距/Intercept: 152.74006747354875
</pre>


<p>
在上述程式碼中，真正與計算迴歸有關的只有第<a href="#coderef-modelRegression" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-modelRegression');" onmouseout="CodeHighlightOff(this, 'coderef-modelRegression');">7</a>行(利用scikit-learn建立一個線性迴歸模型)與第<a href="#coderef-modelFit" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-modelFit');" onmouseout="CodeHighlightOff(this, 'coderef-modelFit');">8</a>行(把手上的10組 \((a,b)\) 資料丟進模型訓練)，
夠簡單吧，這樣我們就能畫出一條斜率約為0.58、截距約為152.74的最佳迴歸線(如圖<a href="#orgc7c03da">6</a>):
</p>

<div id="orgc7c03da" class="figure">
<p><img src="images/yearHeightModelHat.png" alt="yearHeightModelHat.png" width="500" />
</p>
<p><span class="figure-number">Figure 6: </span>線性迴歸求解</p>
</div>
</div>
</div>
<div id="outline-container-org54ded58" class="outline-3">
<h3 id="org54ded58"><span class="section-number-3">2.7.</span> 逐步找出最佳解</h3>
<div class="outline-text-3" id="text-2-7">
<p>
<a id="org6d8970a"></a>
雖然我們可以快速的利用如<a href="https://scikit-learn.org/">scikit-learn</a>這類第三方模組求出最佳解，但是相信對於有志投入AI領域的你來說，光知道如何快速求解顯然遠遠不夠，讓我們來搞清楚這到底是怎麼完成的。
</p>
</div>
<div id="outline-container-orga074fb4" class="outline-4">
<h4 id="orga074fb4"><span class="section-number-4">2.7.1.</span> 隨機的力量</h4>
<div class="outline-text-4" id="text-2-7-1">
<p>
萬事起頭難，要找出最佳的參數組合 \((a,b)\) ，最合理的方式就是我們 <b>閉上眼睛</b> 在圖<a href="#org97b9047">4</a>中隨意點圈出一個點b \((a_0, b_0)\)，這就是我們的第一步，其結果就如圖<a href="#orgcae8440">7</a>所示。有了這個開頭，我們接下來要做的事就是：
</p>
<ol class="org-ol">
<li>找出 <b>一個方法</b> 來判斷要由點 \((a_0, b_0)\) 點沿著這個曲面的 <b>哪一個方向</b> 前進 <b>多遠</b> ，來到下一點 \((a_1, b_1)\)。也許是沿著曲面往上移一小段(如圖<a href="#orgcae8440">7</a>中的藍色線段)、也許是沿著曲面往下移一小段(如圖<a href="#orgcae8440">7</a>中的紅色線段)。</li>
<li>利用 <b>同一個方法</b> 來判斷接下來要由點 \((a_1, b_1)\) 點沿著這個曲面的 <b>哪一個方向</b> 繼續前進 <b>多遠</b> ，來到下一點 \((a_2, b_2)\)</li>
<li>重複同樣的步驟，直到找到最佳的點 \((a_n, b_n)\) ，也就是這一點 \((a_n, b_n)\) 能使整個模型的SSE來到最小，讓模型具備最佳的預測效能。</li>
</ol>

<div id="orgcae8440" class="figure">
<p><img src="images/SSELossC.png" alt="SSELossC.png" width="500" />
</p>
<p><span class="figure-number">Figure 7: </span>找出最佳a,b組合的方法</p>
</div>
</div>
</div>
<div id="outline-container-org70f0067" class="outline-4">
<h4 id="org70f0067"><span class="section-number-4">2.7.2.</span> 何去何從</h4>
<div class="outline-text-4" id="text-2-7-2">
<p>
發現了嗎？其實AI的本質就是在解數學問題，我們在求某個方程式的最小值。
</p>

<p>
到這裡我想你一定會發現上面那個方法的幾個漏洞：
</p>
<ul class="org-ul">
<li>我怎麼知道要往哪個方向移呢？</li>
<li>我怎麼知道要移動多長的距離呢?</li>
<li>我怎麼知道移動後的新位置比原來的位置好呢？</li>
</ul>

<p>
好吧，我也不知道。不如我們先跳過這個看起來太複雜的問題，先換個簡單點的來強化自信。
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf62972d" class="outline-2">
<h2 id="orgf62972d"><span class="section-number-2">3.</span> 保持距離以測安全</h2>
<div class="outline-text-2" id="text-3">
<p>
讓我們先來看一個更簡單的例子。
</p>

<p>
這是一組從<a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html">R語言資料集</a>偷來的資料，這個資料集有七百多組教學用的資料集，其中有一組簡單的資料集cars，裡面有50筆資料，每筆資料只有兩個欄位：
</p>
<ul class="org-ul">
<li>speed: 車速</li>
<li>dist: 所需剎車距離</li>
</ul>
<p>
資料分佈如圖<a href="#org2804a3b">8</a>所示
</p>

<div id="org2804a3b" class="figure">
<p><img src="images/carsScatter.png" alt="carsScatter.png" width="500" />
</p>
<p><span class="figure-number">Figure 8: </span>車速與剎車距離關係分佈圖</p>
</div>

<p>
我們為了這組簡單的資料分佈建了一個如下的模型
\[dist=w*speed\]
建立這組模型的最終目的當然是希望輸入 <b>車速</b> (\(speed\)) 後就能得到 <b>預測的剎車距離</b> ( \(dist\) ) 。我們也可以用更常見的數學表示法( \(x\) 為車速、\(y_{predicted}\) 為預測的剎車距離) ：
\[ y_{predicted} = w * x \]
或是更常見的寫法( \(\hat{y}\) 為預測的剎車距離)：
\[ \hat{y} = w * x \]
同時，為了評估不同 \(w\) 值下模型的優劣，我們當也要提出相對應的損失函數( \(y_{predicted}\) 為模型預測的剎車距離、 \(y_{actual}\) 為實際資料的剎車距離)：
\[ Loss = \frac{1}{n}\sum_{1}^{n}(y_{predicted} - y_{actual})^2 \]
例如：
</p>
<ul class="org-ul">
<li>當 \(w\) 為-15時，Loss值為85113.26</li>
<li>當 \(w\) 為-10時，Loss值為44346.86</li>
<li>當 \(w\) 為 -5時，Loss值為16808.46</li>
<li>當 \(w\) 為  0時，Loss為2498.06</li>
<li>當 \(w\) 為  5時，Loss為1415.66</li>
<li>當 \(w\) 為 10時，Loss為17152.28</li>
</ul>

<p>
在這個例子中，我們的任務就變成：提出一個假設模型( \(y=w*x\) )，然後找出最理想的參數( \(w\) )，讓這個模型可以俱備最好的預測能力(Loss值最小)。
</p>
</div>
<div id="outline-container-orgbaf6c09" class="outline-3">
<h3 id="orgbaf6c09"><span class="section-number-3">3.1.</span> 模型的目的</h3>
<div class="outline-text-3" id="text-3-1">
<p>
顯然，對於如何解出方程式(或是說找到最佳模型) ，一開始當然沒啥頭緒，那，不如就暴力一點吧，弄個窮舉法：試試從 \(w=-20\) try到 \(w=+20\) 吧，觀察一下損失函數Loss的變化：
</p>

<div id="orgf0df7e9" class="figure">
<p><img src="images/carsLoss.png" alt="carsLoss.png" width="500" />
</p>
<p><span class="figure-number">Figure 9: </span>不同參數w下的損失函數Loss分佈圖</p>
</div>

<p>
現在我們可以想辦法找出最好的 \(w\) 在哪裡了。
</p>
</div>
</div>
<div id="outline-container-orgabf4705" class="outline-3">
<h3 id="orgabf4705"><span class="section-number-3">3.2.</span> 沿著曲線上下爬</h3>
<div class="outline-text-3" id="text-3-2">
<p>
雖然我們從圖<a href="#orgf0df7e9">9</a>大概可以看出來模型大概在參數 \(w\) 介於0和5之間會有最小的Loss，也就是模型會最準確，但身為嚴謹的學術研究者，我們不能這樣蠻幹，這是土匪的行為，我們要用最科學的方法：既然不知道從哪裡著手，就閉著眼睛隨意給個 \(w\) 好了，例如：-15，如圖<a href="#orgd81f25d">10</a>。
</p>

<p>
你看，我們這不就邁出成功的第一步了?
</p>

<p>
隨機就是這麼美而有力!!
</p>


<div id="orgd81f25d" class="figure">
<p><img src="images/carsLoss1.png" alt="carsLoss1.png" width="500" />
</p>
<p><span class="figure-number">Figure 10: </span>先隨機假設一個數(-15)為最佳參數w的值</p>
</div>

<p>
有了出發點(我們估且稱之為 \(w_0\) 好了，如圖<a href="#orgd81f25d">10</a>)，接下來就只要決定下一個「較好的下一個 \(w_1\) 」是在 \(w_0\) 的左邊還是右邊(根據Loss值來判斷)，然後繼續往左或往右移(如圖<a href="#org790215f">11</a>。
</p>

<p>
總之，我們只要決定以下兩個因素，就可以利用python把模型的最佳參數 \(w\) 找出來了。
</p>
<ol class="org-ol">
<li>每次要往左或往右移多少距離?</li>
<li>這樣的修正動作要重複幾次？（或，結束的條件為何？)</li>
</ol>


<div id="org790215f" class="figure">
<p><img src="images/carsLoss2.png" alt="carsLoss2.png" width="500" />
</p>
<p><span class="figure-number">Figure 11: </span>決定w應往哪個方向移動</p>
</div>
</div>
</div>
<div id="outline-container-org1f7a2d4" class="outline-3">
<h3 id="org1f7a2d4"><span class="section-number-3">3.3.</span> 確定方向</h3>
<div class="outline-text-3" id="text-3-3">
<p>
BUT，相信學過幾何學的你一定有想到另一種策略：切線。既然 \(w\) 與 Loss的關係是如圖<a href="#org790215f">11</a>的曲線，我們應該可以找出 \(w_0\) 這個點的 <b>切線</b> 。如果我們從點 \(w_0\) 的 \(x\) 軸各向左、右移動一段很小的距離(例如0.0000001)，所連接的這條線(如圖<a href="#orgf77aac8">12</a>)就很接近點 \(w_0\) 沿曲線的切線了。
</p>

<p>
根據斜率的計算公式(或是以肉眼觀察這條切線)，我們發現這條切線的斜率是負的。這表示
</p>
<ol class="org-ol">
<li>曲線的最低點應該是出現在點 \(w_0\) 的右側</li>
<li>下一點 \(w_1\) 要往右邊找</li>
</ol>


<div id="orgf77aac8" class="figure">
<p><img src="images/carsLoss3.png" alt="carsLoss3.png" width="500" />
</p>
<p><span class="figure-number">Figure 12: </span>決定w應往哪個方向移動</p>
</div>

<p>
問題是：該往右邊移動多少距離呢？要移動幾次？
</p>
</div>
</div>
<div id="outline-container-orgf94f8fb" class="outline-3">
<h3 id="orgf94f8fb"><span class="section-number-3">3.4.</span> 確定移動距離與重複次數</h3>
<div class="outline-text-3" id="text-3-4">
<p>
<a id="orgb422c05"></a>
由圖<a href="#orgf77aac8">12</a>的 \(w\) 與Loss分佈，不難發現可以逐步往右移動w，Loss的值就會慢慢降下來，所以我們可以先這麼計畫：
</p>
<ul class="org-ul">
<li>每次由 \(w0\) 的 \(x\) 軸往右邊加0.5、直到Loss不再變小。</li>
</ul>
<p>
或換另一種說法：
</p>
<ul class="org-ul">
<li>每次往右邊加0.5、直到Loss開始變大(因為越過了曲線最低點)。</li>
</ul>

<p>
上述的Python實作程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> pydataset <span style="color: #51afef;">import</span> data
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#36039;&#26009;&#38598;</span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">cars</span> = data(<span style="color: #98be65;">'cars'</span>)
<span class="linenr"> 6: </span><span style="color: #dcaeea;">speed</span> = np.array(cars[<span style="color: #98be65;">'speed'</span>])
<span class="linenr"> 7: </span><span style="color: #dcaeea;">dist</span> = np.array(cars[<span style="color: #98be65;">'dist'</span>])
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639;Loss&#29992;&#30340;function</span>
<span class="linenr">10: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">loss_func</span>(y_true, y_predict):
<span class="linenr">11: </span>    <span style="color: #51afef;">return</span> y_true - y_predict
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #dcaeea;">w</span> = np.arange(-<span style="color: #da8548; font-weight: bold;">20</span>,<span style="color: #da8548; font-weight: bold;">21</span>,<span style="color: #da8548; font-weight: bold;">0.5</span>)
<span class="linenr">14: </span><span style="color: #dcaeea;">loss</span> = []
<span class="linenr">15: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> w:
<span class="linenr">16: </span>    <span style="color: #dcaeea;">yHat</span> =  i * speed
<span class="linenr">17: </span>    loss.append(np.mean(loss_func(dist, yHat)**<span style="color: #da8548; font-weight: bold;">2</span>))
<span class="linenr">18: </span>
<span class="linenr">19: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25214;&#26368;&#20339;w&#20540;, &#36889;&#35041;&#20197;x&#20195;&#34920;w&#20540;</span>
<span class="linenr">20: </span><span style="color: #dcaeea;">x</span>, <span style="color: #dcaeea;">y</span> = -<span style="color: #da8548; font-weight: bold;">15</span>, loss[np.where(w == -<span style="color: #da8548; font-weight: bold;">15</span>)[<span style="color: #da8548; font-weight: bold;">0</span>][<span style="color: #da8548; font-weight: bold;">0</span>]]
<span id="coderef-keepIncrease" class="coderef-off"><span class="linenr">21: </span><span style="color: #51afef;">while</span> <span style="color: #a9a1e1;">True</span>:</span>
<span class="linenr">22: </span>    <span style="color: #dcaeea;">loss</span> = np.mean(loss_func(dist, x*speed)**<span style="color: #da8548; font-weight: bold;">2</span>)
<span id="coderef-increaseX" class="coderef-off"><span class="linenr">23: </span>    <span style="color: #dcaeea;">x</span> += <span style="color: #da8548; font-weight: bold;">0.5</span></span>
<span class="linenr">24: </span>    <span style="color: #dcaeea;">newLoss</span> = np.mean(loss_func(dist, x*speed)**<span style="color: #da8548; font-weight: bold;">2</span>)
<span id="coderef-breakWhile" class="coderef-off"><span class="linenr">25: </span>    <span style="color: #51afef;">if</span> newLoss &gt;= loss:</span>
<span class="linenr">26: </span>        <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'STOP: w&#20540;:</span>{x-0.5}<span style="color: #98be65;">, Loss:</span>{loss}<span style="color: #98be65;">'</span>)
<span class="linenr">27: </span>        <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'NEXT: w&#20540;:</span>{x}<span style="color: #98be65;">, Loss:</span>{newLoss}<span style="color: #98be65;">'</span>)
<span class="linenr">28: </span>        <span style="color: #51afef;">break</span>
<span id="coderef-monitorW" class="coderef-off"><span class="linenr">29: </span>    <span style="color: #51afef;">if</span> <span style="color: #c678dd;">int</span>(x) % <span style="color: #da8548; font-weight: bold;">5</span> == <span style="color: #da8548; font-weight: bold;">0</span>:</span>
<span class="linenr">30: </span>        <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'w&#20540;:</span>{x}<span style="color: #98be65;">, Loss:</span>{newLoss}<span style="color: #98be65;">'</span>)
</pre>
</div>
<p>
逐步右移的控制主要由第<a href="#coderef-keepIncrease" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-keepIncrease');" onmouseout="CodeHighlightOff(this, 'coderef-keepIncrease');">21</a>行的while負責，\(w\) 每次右移0.5，直到Loss值不再變小就停止(第<a href="#coderef-breakWhile" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-breakWhile');" onmouseout="CodeHighlightOff(this, 'coderef-breakWhile');">25</a>行)，為簡化輸出，每移動10次 \(w\) 我們就把對應的 \(w\) 和Loss輸出來觀察一下（第<a href="#coderef-monitorW" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-monitorW');" onmouseout="CodeHighlightOff(this, 'coderef-monitorW');">29</a>行)。輸出結果如下：
</p>

<pre class="example">
w值:-10.5, Loss:47828.24
w值:-10.0, Loss:44346.86
w值:-5.5, Loss:18967.04
w值:-5.0, Loss:16808.46
w值:-0.5, Loss:3333.84
w值:0.0, Loss:2498.06
w值:0.5, Loss:1794.56
STOP: w值:3.0, Loss:261.26
NEXT: w值:3.5, Loss:351.44
</pre>


<p>
由執行結果可發現隨著 \(w\) 值的增加，Loss值也隨之減少，直到 \(w\) 值為3時可以得到最低的Loss值(261.26)，過了這一點，Loss值便又開始增加。圖<a href="#orgdb63cb4">14</a>為w值持續修正的模擬結果，圖<a href="#org484f915">13</a>則為假設\(w\) 值為3所畫出的預測線(模型)。
</p>


<div id="org484f915" class="figure">
<p><img src="images/carsLine.png" alt="carsLine.png" width="500" />
</p>
<p><span class="figure-number">Figure 13: </span>車速與剎車距離關係分佈及預測模型</p>
</div>


<p>
然而，這個 \(w=3\) 的模型就是最佳模型嗎？你有什麼可以更快找到更精確的「使Loss最低的 \(w\) 值」的修正方案嗎？
</p>


<div id="orgdb63cb4" class="figure">
<p><img src="images/carsLoss4.png" alt="carsLoss4.png" width="500" />
</p>
<p><span class="figure-number">Figure 14: </span>決定w應往哪個方向移動</p>
</div>
</div>
</div>
<div id="outline-container-orga7bf1d6" class="outline-3">
<h3 id="orga7bf1d6"><span class="section-number-3">3.5.</span> 斜率與微分</h3>
<div class="outline-text-3" id="text-3-5">
<p>
在前節中我們計算圖<a href="#orgdb63cb4">14</a>中 \(w_0\) 的斜率方法是由 \(w=-15\) 這點各往左、右移動0.0000001，這個方法當然不太準確，最好的方法是各往左、右移動 <b>無限小</b> 的距離，這樣畫出來的就是點 \(w_0\) 的切線，而這條切線的斜率也就是 \(w_0\) 的斜率。為什麼 <b>找出曲線上各點的斜率</b> 這件事如此重要呢？原因有二
</p>
<ul class="org-ul">
<li>在第<a href="#orgb422c05">3.4</a>中，我們據以移動 \(w\) 值的依據是 &ldquo; <b>每次往右邊加0.5、直到Loss開始變大(因為越過了曲線最低點)</b>&rdquo; ，其實我們有另一種更方便的判斷方式：在曲線最低點左側所有點的斜率均為負、在曲線最低點右側所有點的斜率均為正，知道了某點的斜率為正或負，我們就知道該往左側或右側去移動，找出最低點的位置。</li>
<li>曲線最低點的斜率為0，我們只要能找到斜率為0的這一點，就能找到模型的最佳參數。</li>
</ul>

<p>
事實上，如果我們知道曲線 \(y=f(x)\) 的實際內容，我們就能用<a href="20221126112514-基礎數學for_ai.html#ID-3ce884c1-cd16-4310-b757-37cdd1ddcdef">微分</a>來找到曲線上的最低點。
</p>
</div>
<div id="outline-container-org64e278f" class="outline-4">
<h4 id="org64e278f"><span class="section-number-4">3.5.1.</span> 頂點公式求函數解</h4>
<div class="outline-text-4" id="text-3-5-1">
<p>
如假設損失函數L為 \[ Loss = MSE = \frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
其中
</p>
<ul class="org-ul">
<li>\(n=50\)(實際有50筆資料)</li>
<li>\(\hat{y_i}\)為用模型\(y=wx\)所預測出來的剎車距離</li>
<li>\(y_i\)為當實測車速為\(x_i\)時所對應的剎車距離</li>
</ul>
<p>
故
</p>
\begin{align}

Loss=\frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \\
=\frac{1}{n}\sum_{i=1}^{n}(wx_i - y_i)^2 \\
=\frac{1}{n}\sum_{i=1}^{n}(w^2x_i^2 -2wx_iy_i + y_i^2) \\
=\frac{1}{n}(w^2\sum_{i=1}^{n}x_i^2 -2w\sum_{i=1}^{n}x_iy_i + ny_i^2) \\
\end{align}
<p>
雖然可以用微分來解，但是這個一元二次函數也可以用頂點公式來找出曲線頂點(模型最小值)，求出的最小Loss會出現在
\[ w=\frac{\sum_{i=1}^{n}x_iy_i}{\sum_{i=1}^{n}x_i^2} \]
因為當 \(a>0\)
\[ ax^2+bx+c = a(x+\frac{b}{2a})+\frac{4ac-b^2}{4a} \]
故 函數在 \(x=\frac{-b}{2a}\) 時有最小值
</p>

<p>
以程式驗證如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> pydataset <span style="color: #51afef;">import</span> data
<span class="linenr">2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #dcaeea;">cars</span> = data(<span style="color: #98be65;">'cars'</span>)
<span class="linenr">5: </span><span style="color: #dcaeea;">speed</span> = np.array(cars[<span style="color: #98be65;">'speed'</span>])
<span class="linenr">6: </span><span style="color: #dcaeea;">dist</span> = np.array(cars[<span style="color: #98be65;">'dist'</span>])
<span class="linenr">7: </span>
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#26368;&#23567;Loss&#30340;&#21443;&#25976;w&#20540;:'</span>,<span style="color: #c678dd;">sum</span>(speed*dist) / <span style="color: #c678dd;">sum</span>(speed*speed))
</pre>
</div>

<pre class="example">
最小Loss的參數w值: 2.909132143937103
</pre>
</div>
</div>
<div id="outline-container-orgb10c59e" class="outline-4">
<h4 id="orgb10c59e"><span class="section-number-4">3.5.2.</span> 微分求函數頂點</h4>
<div class="outline-text-4" id="text-3-5-2">
<p>
當 \(a>0\)
</p>
\begin{align}
f(x)=ax^2+bx+c \\
f'(x)=2ax+b
\end{align}
<p>
找曲線最低點、令函式為0
\[2ax+b=0\]
故 \(x=\frac{-b}{2a}\) 時有最小值
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org0780830" class="outline-2">
<h2 id="org0780830"><span class="section-number-2">4.</span> 線性迴歸:年齡身高預測#2</h2>
<div class="outline-text-2" id="text-4">
<p>
回到第<a href="#org6d8970a">2.7</a>節，我們提及要找出最佳的參數組合 \((a,b)\) ，最合理的方式是在圖<a href="#org97b9047">4</a>中隨意點圈出一個點b \((a_0, b_0)\) (如圖<a href="#orgcae8440">7</a>)。接下來：
</p>
<ol class="org-ol">
<li>找出 <b>一個方法</b> 來判斷要由點 \((a_0, b_0)\) 點沿著這個曲面的 <b>哪一個方向</b> 前進 <b>多遠</b> ，來到下一點 \((a_1, b_1)\)。也許是沿著曲面往上移一小段(如圖<a href="#orgcae8440">7</a>中的藍色線段)、也許是沿著曲面往下移一小段(如圖<a href="#orgcae8440">7</a>中的紅色線段)。</li>
<li>利用 <b>同一個方法</b> 來判斷接下來要由點 \((a_1, b_1)\) 點沿著這個曲面的 <b>哪一個方向</b> 繼續前進 <b>多遠</b> ，來到下一點 \((a_2, b_2)\)</li>
<li>重複同樣的步驟，直到找到最佳的點 \((a_n, b_n)\) ，也就是這一點 \((a_n, b_n)\) 能使整個模型的SSE來到最小，讓模型具備最佳的預測效能。</li>
</ol>

<p>
假設損失函數L為 \[ L = MSE = \frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
因為 \(\hat{y_i}\) 代表直線模型
實際的做法就變成：
</p>
<ol class="org-ol">
<li>計算點 \((a_0, b_0)\) 的斜率，然後朝著 <b>使Loss(MSE)減小得最快的方向</b> 稍微移動 \(a, b\)</li>
<li>重複步驟1</li>
</ol>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Hands-On Machine Learning with Scikit-Learn: Aurelien Geron
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2023-12-23 Sat 10:32</p>
</div>
</body>
</html>