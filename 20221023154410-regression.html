<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-03-09 Thu 15:49 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Regression</title>
<meta name="author" content="Yung Chin, Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Regression</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgf287606">1. 迴歸原理</a>
<ul>
<li><a href="#org5cf72d5">1.1. Step 1</a></li>
<li><a href="#org48404cd">1.2. Step 2: Goodness of Function</a></li>
<li><a href="#org683e47a">1.3. 迴歸實作</a></li>
<li><a href="#org552dbca">1.4. sklear版solution</a></li>
</ul>
</li>
<li><a href="#org603abe3">2. 簡單線性迴歸</a>
<ul>
<li><a href="#org2875734">2.1. Pizza</a></li>
</ul>
</li>
<li><a href="#orgd4f375b">3. BOOK</a></li>
</ul>
</div>
</div>
<p>
即，根據一組預測特徵（predictor，如里程數、車齡、品牌）來預測目標數值（如二手車車價）<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>，這個目標數值也是label。
</p>

<p>
有些迴歸演算法也可以用來分類，例如Logistic，它可以輸出一個數值，以這個數值來表示對應到特定類別的機率，例如，某封email為垃圾郵件的機率為20%、某張圖片為狗的機率為70%。
</p>

<p>
迴歸問題可再細分為兩類：
</p>
<ul class="org-ul">
<li>Linear regression:
<ul class="org-ul">
<li>假設輸入變量(x)與單一輸出變量(y)間存在線性關係，並以此建立模型。</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時會導致低度擬合</li>
<li>例: 身高與體重間的關係</li>
</ul></li>
<li>Logistic regression
<ul class="org-ul">
<li>也是線性方法，但使用logist function轉換輸出的預測結果，其輸出結果為類別機率(class probabilities)</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時無法處理分類問題</li>
</ul></li>
</ul>

<p>
典型迴歸案例: Boston Housing Data
</p>

<div id="outline-container-orgf287606" class="outline-2">
<h2 id="orgf287606"><span class="section-number-2">1.</span> 迴歸原理</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org5cf72d5" class="outline-3">
<h3 id="org5cf72d5"><span class="section-number-3">1.1.</span> Step 1</h3>
<div class="outline-text-3" id="text-1-1">
<ol class="org-ol">
<li>Model: \(y = w*x+b\)</li>
<li>Data: 找一堆現成的資料</li>
</ol>
</div>
</div>
<div id="outline-container-org48404cd" class="outline-3">
<h3 id="org48404cd"><span class="section-number-3">1.2.</span> Step 2: Goodness of Function</h3>
<div class="outline-text-3" id="text-1-2">
<ol class="org-ol">
<li>Training Data</li>
<li>Loss function L: 越小越好
input: a function / output: how bad it is</li>
<li>Pick the &ldquo;Best: Function
\(f* = arg min L(f)\)
上述可以微分來求最佳解，即求 function L 的最小值</li>
<li>數值最佳解: Gradient Descent(找拋物面最低點)</li>
</ol>
</div>
</div>
<div id="outline-container-org683e47a" class="outline-3">
<h3 id="org683e47a"><span class="section-number-3">1.3.</span> 迴歸實作</h3>
<div class="outline-text-3" id="text-1-3">
<p>
<a href="https://tree.rocks/deep-learning-from-scratch-by-linear-regression-e42f5dcdb024">手刻 Deep Learning — 第零章 — 線性回歸</a>
原始資料:
</p>

<div id="org9d322c8" class="figure">
<p><img src="images/Xyh-1.png" alt="Xyh-1.png" width="500" />
</p>
<p><span class="figure-number">Figure 1: </span>Caption</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">gen_data</span>(X, a, b):
<span class="linenr"> 5: </span>    <span style="color: #51afef;">return</span> X * a + b
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #5B6268;">## </span><span style="color: #5B6268;">&#37325;&#26032;&#29986;&#29983;X, y&#65292;&#36611;&#21512;&#29702;&#65292;&#32780;&#38750;&#24050;&#23384;&#22312;&#19968;&#26781;&#32218;</span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">X</span> = np.array(<span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">10</span>))
<span class="linenr">10: </span><span style="color: #dcaeea;">y</span> = np.array([<span style="color: #da8548; font-weight: bold;">27</span>, <span style="color: #da8548; font-weight: bold;">35</span>, <span style="color: #da8548; font-weight: bold;">40</span>, <span style="color: #da8548; font-weight: bold;">50</span>, <span style="color: #da8548; font-weight: bold;">66</span>, <span style="color: #da8548; font-weight: bold;">60</span>, <span style="color: #da8548; font-weight: bold;">76</span>, <span style="color: #da8548; font-weight: bold;">88</span>, <span style="color: #da8548; font-weight: bold;">90</span>])
<span class="linenr">11: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">y = gen_data(X, a=8, b=20)</span>
<span class="linenr">12: </span>
<span class="linenr">13: </span>plt.scatter(X, y, color=<span style="color: #98be65;">'black'</span>)
<span class="linenr">14: </span>plt.plot(X, <span style="color: #da8548; font-weight: bold;">1</span> * X + <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr">15: </span>plt.plot(X, <span style="color: #da8548; font-weight: bold;">4</span> * X + <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">16: </span>plt.plot(X, <span style="color: #da8548; font-weight: bold;">4</span> * X + <span style="color: #da8548; font-weight: bold;">10</span>)
<span class="linenr">17: </span>plt.plot(X, <span style="color: #da8548; font-weight: bold;">8</span> * X + <span style="color: #da8548; font-weight: bold;">30</span>)
<span class="linenr">18: </span>plt.ylim(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">121</span>)
<span class="linenr">19: </span>plt.legend([<span style="color: #98be65;">'Raw Data'</span>, <span style="color: #98be65;">'Line 1'</span>, <span style="color: #98be65;">'Line 2'</span>, <span style="color: #98be65;">'Line 3'</span>])
<span class="linenr">20: </span>plt.savefig(<span style="color: #98be65;">"images/Xyh-1.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">21: </span>
<span class="linenr">22: </span><span style="color: #dcaeea;">a</span> = <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">23: </span><span style="color: #dcaeea;">b</span> = <span style="color: #da8548; font-weight: bold;">1</span>
<span class="linenr">24: </span><span style="color: #dcaeea;">yh</span> = a * X + b <span style="color: #5B6268;">#</span><span style="color: #5B6268;">y hat</span>
<span class="linenr">25: </span>
<span class="linenr">26: </span>
<span class="linenr">27: </span>plt.plot(X, yh)
<span class="linenr">28: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig("images/Xyh.png", dpi=300)</span>
<span class="linenr">29: </span>
<span class="linenr">30: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">loss_func</span>(y_true, y_predict):
<span class="linenr">31: </span>    <span style="color: #51afef;">return</span> y_true - y_predict
<span class="linenr">32: </span>
<span class="linenr">33: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">optimizer</span>(d, loss):
<span class="linenr">34: </span>    <span style="color: #51afef;">return</span> np.mean(d * loss * <span style="color: #da8548; font-weight: bold;">0.01</span>)
<span class="linenr">35: </span>
<span class="linenr">36: </span><span style="color: #dcaeea;">N</span> = <span style="color: #da8548; font-weight: bold;">1000</span>
<span class="linenr">37: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(N):
<span class="linenr">38: </span>    <span style="color: #dcaeea;">p_y</span> = a * X + b
<span class="linenr">39: </span>    <span style="color: #dcaeea;">loss</span> = loss_func(y, p_y)
<span class="linenr">40: </span>    <span style="color: #dcaeea;">a</span> -= optimizer(-<span style="color: #da8548; font-weight: bold;">2</span> * X, loss)
<span class="linenr">41: </span>    <span style="color: #dcaeea;">b</span> -= optimizer(-<span style="color: #da8548; font-weight: bold;">2</span>, loss)
<span class="linenr">42: </span>    <span style="color: #51afef;">if</span> i % <span style="color: #c678dd;">int</span>(N/<span style="color: #da8548; font-weight: bold;">10</span>) == <span style="color: #da8548; font-weight: bold;">0</span>:
<span class="linenr">43: </span>        <span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#35492;&#24046;: {:.2f}'</span>.<span style="color: #c678dd;">format</span>(np.mean(loss)), <span style="color: #98be65;">'&#30446;&#21069; a: {:.2f}, b: {:.2f}'</span>.<span style="color: #c678dd;">format</span>(a, b))
<span class="linenr">44: </span>
<span class="linenr">45: </span>yh = a * X + b <span style="color: #5B6268;">#</span><span style="color: #5B6268;">y hat</span>
<span class="linenr">46: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.plot(X, yh)</span>
<span class="linenr">47: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.legend(['Target', 'Initialization', 'Optimization'])</span>
<span class="linenr">48: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.savefig("images/Xyh.png", dpi=300)</span>
</pre>
</div>

<pre class="example" id="org73f055b">
[[1]
 [2]
 [3]
 [4]
 [5]
 [6]
 [7]
 [8]
 [9]]
誤差: 53.11 目前 a: 7.27, b: 2.06
誤差: 2.11 目前 a: 9.84, b: 7.81
誤差: 1.40 目前 a: 9.29, b: 11.26
誤差: 0.93 目前 a: 8.93, b: 13.54
誤差: 0.61 目前 a: 8.69, b: 15.05
誤差: 0.41 目前 a: 8.53, b: 16.06
誤差: 0.27 目前 a: 8.42, b: 16.72
誤差: 0.18 目前 a: 8.35, b: 17.16
誤差: 0.12 目前 a: 8.31, b: 17.45
誤差: 0.08 目前 a: 8.28, b: 17.65
</pre>



<div id="orgbcb141a" class="figure">
<p><img src="images/Xyh.png" alt="Xyh.png" width="500" />
</p>
<p><span class="figure-number">Figure 2: </span>Caption</p>
</div>

<p>
開始 Linear Regression (線性回歸)
</p>

<p>
練習投藍的時後，我們需要知道籃筐位置，誤差多少，做出丟球的修正；做 Machine Learning 也是一樣道理，我們需要 :
</p>
<ol class="org-ol">
<li>找出誤差</li>
<li>做出修正</li>
</ol>

<p>
所以我們這邊帶入兩個觀念:
</p>
<ol class="org-ol">
<li>loss function (誤差計算，找出誤差)</li>
<li>optimizer (最佳化方法，做出修正)</li>
</ol>

<p>
我們用程式碼來看
loss function: 其中 loss_func 的 y_true 表示商店的真實價格，y_predict 是我們預測的價格，我們這邊採用 真實價格 減去 預測價格，就是預測的誤差
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">loss_func</span>(y_true, y_predict):
<span class="linenr">2: </span>    <span style="color: #51afef;">return</span> y_true - y_predict
</pre>
</div>
<p>
optimizer: 這邊有個參數叫做 d ，其實他是 partial derivative ，這是微積分的概念。optimizer的修正並非最佳，可以自行修正找出最佳參數
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">optimizer</span>(d, loss):
<span class="linenr">2: </span>    <span style="color: #51afef;">return</span> np.mean(d * loss * <span style="color: #da8548; font-weight: bold;">0.01</span>)
</pre>
</div>

<p>
上面就是我們的訓練用程式碼，跑 1000 次訓練，每 100 次 ( N/10 ) 我們印出一次誤差讓我們看看過程
其中：
a -= optimizer(-2 * X, loss)
b -= optimizer(-2, loss)
這邊就是每次的訓練我們都在調整 a 與 b，就像是我們投籃丟歪球了，每次練習都在調整力道
</p>

<p>
各位可以試看看將 a 與 b 改成任意數值 ( 不要太過極端以免 overflow )，在這個訓練過程中，不管 a, b 初始是多少，都會逐漸往我們正確答案靠近，為什麼會這樣呢？
</p>

<p>
這就是微積分的力量
</p>

<p>
大多的 Machine Learning 也是類似這種方法，不停的 Training ( 訓練 ) 找到答案，微積分這部分日後有空再來解說 XD
</p>

<p>
微分: <a href="https://tree.rocks/deep-learning-from-scratch-introduce-differential-91f5b4400d1a">https://tree.rocks/deep-learning-from-scratch-introduce-differential-91f5b4400d1a</a>
</p>
</div>
</div>

<div id="outline-container-org552dbca" class="outline-3">
<h3 id="org552dbca"><span class="section-number-3">1.4.</span> sklear版solution</h3>
<div class="outline-text-3" id="text-1-4">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #dcaeea;">X</span> = np.arange(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">10</span>).reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>) <span style="color: #5B6268;">#</span><span style="color: #5B6268;">&#36681;&#25563;&#30697;&#38499;&#24418;&#29376;&#20197;&#31526;&#21512;sklearn&#35201;&#27714;</span>
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y</span> = [<span style="color: #da8548; font-weight: bold;">27</span>, <span style="color: #da8548; font-weight: bold;">35</span>, <span style="color: #da8548; font-weight: bold;">40</span>, <span style="color: #da8548; font-weight: bold;">50</span>, <span style="color: #da8548; font-weight: bold;">66</span>, <span style="color: #da8548; font-weight: bold;">60</span>, <span style="color: #da8548; font-weight: bold;">76</span>, <span style="color: #da8548; font-weight: bold;">88</span>, <span style="color: #da8548; font-weight: bold;">90</span>]
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 6: </span><span style="color: #dcaeea;">model</span> = LinearRegression()
<span class="linenr"> 7: </span>model.fit(X, y)
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Slope:'</span>, model.coef_)
<span class="linenr">10: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'Intercept:'</span>, model.intercept_)
</pre>
</div>

<pre class="example">
Slope: [8.21666667]
Intercept: 18.02777777777777
</pre>
</div>
</div>
</div>

<div id="outline-container-org603abe3" class="outline-2">
<h2 id="org603abe3"><span class="section-number-2">2.</span> 簡單線性迴歸</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org2875734" class="outline-3">
<h3 id="org2875734"><span class="section-number-3">2.1.</span> Pizza</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Let&rsquo;s assume that you have recorded the diameters and prices of pizzas that you have previously eaten in your pizza journal. These observations comprise our training data:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">Diameter in inches</th>
<th scope="col" class="org-right">Price in dollars</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">6</td>
<td class="org-right">7</td>
</tr>

<tr>
<td class="org-right">8</td>
<td class="org-right">9</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-right">13</td>
</tr>

<tr>
<td class="org-right">14</td>
<td class="org-right">17.5</td>
</tr>

<tr>
<td class="org-right">18</td>
<td class="org-right">18</td>
</tr>
</tbody>
</table>
</div>
<div id="outline-container-org004a926" class="outline-4">
<h4 id="org004a926"><span class="section-number-4">2.1.1.</span> 觀察數據</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
We can visualize our training data by plotting it on a graph using matplotlib:
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">"np" and "plt" are common aliases for NumPy and Matplotlib, respectively.</span>
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">X represents the features of our training data, the diameters of the pizzas.</span>
<span class="linenr"> 6: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">A scikit&#8211;learn convention is to name the matrix of feature vectors X.</span>
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Uppercase letters indicate matrices, and lowercase letters indicate vectors.</span>
<span class="linenr"> 8: </span><span style="color: #dcaeea;">X</span> = np.array([[<span style="color: #da8548; font-weight: bold;">6</span>], [<span style="color: #da8548; font-weight: bold;">8</span>], [<span style="color: #da8548; font-weight: bold;">10</span>], [<span style="color: #da8548; font-weight: bold;">14</span>], [<span style="color: #da8548; font-weight: bold;">18</span>]]).reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #dcaeea;">y</span> = [<span style="color: #da8548; font-weight: bold;">7</span>, <span style="color: #da8548; font-weight: bold;">9</span>, <span style="color: #da8548; font-weight: bold;">13</span>, <span style="color: #da8548; font-weight: bold;">17.5</span> , <span style="color: #da8548; font-weight: bold;">18</span>]
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">y is a vector representing the prices of the pizzas.</span>
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.figure()</span>
<span class="linenr">14: </span>plt.title(<span style="color: #98be65;">'Pizza price plotted against diameter'</span>)
<span class="linenr">15: </span>plt.xlabel(<span style="color: #98be65;">'Diameter in inches'</span>)
<span class="linenr">16: </span>plt.ylabel(<span style="color: #98be65;">'Price in dollars'</span>)
<span class="linenr">17: </span>plt.plot(X, y, <span style="color: #98be65;">'k.'</span>)
<span class="linenr">18: </span>plt.axis([<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">25</span>, <span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">25</span>])
<span class="linenr">19: </span>plt.grid(<span style="color: #a9a1e1;">True</span>)
<span class="linenr">20: </span>plt.savefig(<span style="color: #98be65;">'images/pizza-1.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<p width="500">
<img src="images/pizza-1.png" alt="pizza-1.png" width="500" />
We can see from the plot of the training data that there is a positive relationship between the diameter of a pizza and its price, which should be corroborated by our own pizza-eating experience.
</p>
</div>
</div>
<div id="outline-container-org6e33614" class="outline-4">
<h4 id="org6e33614"><span class="section-number-4">2.1.2.</span> 建模: LinearRegression</h4>
<div class="outline-text-4" id="text-2-1-2">
<p>
The following pizza price predictor program models this relationship using simple linear regression.
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #dcaeea;">X</span> = np.array([[<span style="color: #da8548; font-weight: bold;">6</span>], [<span style="color: #da8548; font-weight: bold;">8</span>], [<span style="color: #da8548; font-weight: bold;">10</span>], [<span style="color: #da8548; font-weight: bold;">14</span>], [<span style="color: #da8548; font-weight: bold;">18</span>]]).reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y</span> = [<span style="color: #da8548; font-weight: bold;">7</span>, <span style="color: #da8548; font-weight: bold;">9</span>, <span style="color: #da8548; font-weight: bold;">13</span>, <span style="color: #da8548; font-weight: bold;">17.5</span> , <span style="color: #da8548; font-weight: bold;">18</span>]
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #c678dd;">print</span>(X.shape)
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 8: </span><span style="color: #dcaeea;">model</span> = LinearRegression()
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create an instance of the estimator</span>
<span class="linenr">10: </span>model.fit(X, y)
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Fit the model on the training data</span>
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Predict the price of a pizza with a diameter that has never been seen before</span>
<span class="linenr">14: </span><span style="color: #dcaeea;">test_pizza</span> = np.array([[<span style="color: #da8548; font-weight: bold;">12</span>]])
<span class="linenr">15: </span><span style="color: #dcaeea;">predicted_price</span> = model.predict(test_pizza)[<span style="color: #da8548; font-weight: bold;">0</span>]
<span class="linenr">16: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'A 12" pizza should cost: $%.2f'</span> % predicted_price)
</pre>
</div>

<pre class="example">
(5, 1)
A 12" pizza should cost: $13.68
</pre>


<ul class="org-ul">
<li>The LinearRegression class is an <b>estimator</b>. Estimators predict a value based on observed data.</li>
<li>In scikit-learn, all estimators implement the fit methods and predict.</li>
<li>The fit method of LinearRegression learns the parameters of the following model for simple linear regression:\[y=\alpha+\beta x\]</li>
<li>\(y\) is the predicted value of the response variable; in this example, it is the predicted price of the pizza.</li>
<li>\(x\) is the explanatory variable.</li>
<li>The intercept term \(\alpha\) and the coefficient \(\beta\) are parameters of the model that are learned by the learning algorithm.</li>
<li>The hyperplane plotted in the following figure models the relationship between the size of a pizza and its price.</li>
<li>Using training data to learn the values of the parameters for simple linear regression that produce the best fitting model is called ordinary least squares (OLS) or linear least squares.</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #dcaeea;">X</span> = np.array([[<span style="color: #da8548; font-weight: bold;">6</span>], [<span style="color: #da8548; font-weight: bold;">8</span>], [<span style="color: #da8548; font-weight: bold;">10</span>], [<span style="color: #da8548; font-weight: bold;">14</span>], [<span style="color: #da8548; font-weight: bold;">18</span>]]).reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y</span> = [<span style="color: #da8548; font-weight: bold;">7</span>, <span style="color: #da8548; font-weight: bold;">9</span>, <span style="color: #da8548; font-weight: bold;">13</span>, <span style="color: #da8548; font-weight: bold;">17.5</span> , <span style="color: #da8548; font-weight: bold;">18</span>]
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 6: </span><span style="color: #dcaeea;">model</span> = LinearRegression()
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create an instance of the estimator</span>
<span class="linenr"> 8: </span>model.fit(X, y)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Fit the model on the training data</span>
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #51afef;">from</span> matplotlib <span style="color: #51afef;">import</span> pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">12: </span>plt.scatter(X, y, color = <span style="color: #98be65;">'k'</span>)
<span class="linenr">13: </span>plt.plot(X, model.predict(X), color=<span style="color: #98be65;">'g'</span>)
<span class="linenr">14: </span>plt.title(<span style="color: #98be65;">'Pizza price plotted against diameter'</span>)
<span class="linenr">15: </span>plt.xlabel(<span style="color: #98be65;">'Diameter in inches'</span>)
<span class="linenr">16: </span>plt.ylabel(<span style="color: #98be65;">'Price in dollars'</span>)
<span class="linenr">17: </span>plt.savefig(<span style="color: #98be65;">'images/pizza-2.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="org861da68" class="figure">
<p><img src="images/pizza-2.png" alt="pizza-2.png" width="500" />
</p>
<p><span class="figure-number">Figure 3: </span>Pizza regression 2</p>
</div>
</div>
</div>
<div id="outline-container-org8e3470a" class="outline-4">
<h4 id="org8e3470a"><span class="section-number-4">2.1.3.</span> Evaluating the fitness of the model with a cost function</h4>
<div class="outline-text-4" id="text-2-1-3">
<p>
Regression lines produced by several sets of parameter values are plotted in the following figure. How can we assess which parameters produced the best-fitting regression line?
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #dcaeea;">X</span> = np.array([[<span style="color: #da8548; font-weight: bold;">6</span>], [<span style="color: #da8548; font-weight: bold;">8</span>], [<span style="color: #da8548; font-weight: bold;">10</span>], [<span style="color: #da8548; font-weight: bold;">14</span>], [<span style="color: #da8548; font-weight: bold;">18</span>]]).reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y</span> = [<span style="color: #da8548; font-weight: bold;">7</span>, <span style="color: #da8548; font-weight: bold;">9</span>, <span style="color: #da8548; font-weight: bold;">13</span>, <span style="color: #da8548; font-weight: bold;">17.5</span> , <span style="color: #da8548; font-weight: bold;">18</span>]
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 6: </span><span style="color: #dcaeea;">model</span> = LinearRegression()
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create an instance of the estimator</span>
<span class="linenr"> 8: </span>model.fit(X, y)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Fit the model on the training data</span>
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #51afef;">from</span> matplotlib <span style="color: #51afef;">import</span> pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">12: </span>plt.scatter(X, y, color = <span style="color: #98be65;">'k'</span>)
<span class="linenr">13: </span>plt.plot(X, model.predict(X), color=<span style="color: #98be65;">'g'</span>)
<span class="linenr">14: </span>plt.plot(X, model.predict(X)+.<span style="color: #da8548; font-weight: bold;">5</span>, color=<span style="color: #98be65;">'c'</span>, linestyle=<span style="color: #98be65;">'--'</span>)
<span class="linenr">15: </span>plt.plot(X, model.predict(X)*.<span style="color: #da8548; font-weight: bold;">9</span>, color=<span style="color: #98be65;">'m'</span>, linestyle=<span style="color: #98be65;">'-.'</span>)
<span class="linenr">16: </span>plt.title(<span style="color: #98be65;">'Pizza price plotted against diameter'</span>)
<span class="linenr">17: </span>plt.xlabel(<span style="color: #98be65;">'Diameter in inches'</span>)
<span class="linenr">18: </span>plt.ylabel(<span style="color: #98be65;">'Price in dollars'</span>)
<span class="linenr">19: </span>plt.savefig(<span style="color: #98be65;">'images/pizza-3.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">20: </span>
</pre>
</div>


<div id="orgc6ba488" class="figure">
<p><img src="images/pizza-3.png" alt="pizza-3.png" width="500" />
</p>
<p><span class="figure-number">Figure 4: </span>Pizza regression 3</p>
</div>
</div>
<ol class="org-ol">
<li><a id="orged7d1cd"></a>cost function<br />
<div class="outline-text-5" id="text-2-1-3-1">
<p>
A cost function, also called a loss function, is used to define and measure the error of a model. The differences between the prices predicted by the model and the observed prices of the pizzas in the training set are called residuals, or training errors. The differences between the predicted and observed values in the test data are called prediction errors, or test errors.
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #dcaeea;">X</span> = np.array([[<span style="color: #da8548; font-weight: bold;">6</span>], [<span style="color: #da8548; font-weight: bold;">8</span>], [<span style="color: #da8548; font-weight: bold;">10</span>], [<span style="color: #da8548; font-weight: bold;">14</span>], [<span style="color: #da8548; font-weight: bold;">18</span>]]).reshape(-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 3: </span><span style="color: #dcaeea;">y</span> = [<span style="color: #da8548; font-weight: bold;">7</span>, <span style="color: #da8548; font-weight: bold;">9</span>, <span style="color: #da8548; font-weight: bold;">13</span>, <span style="color: #da8548; font-weight: bold;">17.5</span> , <span style="color: #da8548; font-weight: bold;">18</span>]
<span class="linenr"> 4: </span>
<span class="linenr"> 5: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 6: </span><span style="color: #dcaeea;">model</span> = LinearRegression()
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Create an instance of the estimator</span>
<span class="linenr"> 8: </span>model.fit(X, y)
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Fit the model on the training data</span>
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #51afef;">from</span> matplotlib <span style="color: #51afef;">import</span> pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #dcaeea;">dy</span> = (model.predict(X)-y)/<span style="color: #da8548; font-weight: bold;">2</span>
<span class="linenr">14: </span><span style="color: #51afef;">for</span> x, y1, y2 <span style="color: #51afef;">in</span> <span style="color: #c678dd;">zip</span>(X, y, model.predict(X)):
<span class="linenr">15: </span>    <span style="color: #dcaeea;">xs</span> = [x, x]
<span class="linenr">16: </span>    <span style="color: #dcaeea;">ys</span> = [y1, y2]
<span class="linenr">17: </span>    plt.plot(xs, ys, color=<span style="color: #98be65;">'orange'</span>)
<span class="linenr">18: </span>plt.scatter(X, y, color = <span style="color: #98be65;">'k'</span>)
<span class="linenr">19: </span>plt.plot(X, model.predict(X), color=<span style="color: #98be65;">'g'</span>)
<span class="linenr">20: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">plt.errorbar(X, model.predict(X)-dy, yerr=dy, fmt='.')</span>
<span class="linenr">21: </span>plt.title(<span style="color: #98be65;">'Pizza price plotted against diameter'</span>)
<span class="linenr">22: </span>plt.xlabel(<span style="color: #98be65;">'Diameter in inches'</span>)
<span class="linenr">23: </span>plt.ylabel(<span style="color: #98be65;">'Price in dollars'</span>)
<span class="linenr">24: </span>plt.savefig(<span style="color: #98be65;">'images/pizza-4.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>
<p width="500">
<img src="images/pizza-4.png" alt="pizza-4.png" width="500" />
This measure of the model&rsquo;s fitness is called the residual sum of squares (RSS) cost function. Formally, this function assesses the fitness of a model by summing the squared residuals for all of our training examples. The RSS is calculated with the formula in the following equation, where \(y_i\) is the observed value and \(f(x_i\) is the predicted value:\[SS_{res}=\sum_{i=1}^{n}(y_i-f(x_i))^2\]
</p>



<div class="org-src-container">
<pre class="src src-emacs-lisp"><span style="color: #51afef;">(</span><span style="color: #c678dd;">add-to-list</span> <span style="color: #51afef;">'</span><span style="color: #dcaeea;">package-archives</span> <span style="color: #51afef;">'</span><span style="color: #c678dd;">(</span><span style="color: #98be65;">"melpa"</span> . <span style="color: #98be65;">"https://melpa.org/packages/"</span><span style="color: #c678dd;">)</span><span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span><span style="color: #51afef;">setq</span> <span style="color: #dcaeea;">python-shell-interpreter</span> <span style="color: #98be65;">"/usr/bin/python3"</span><span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span><span style="color: #51afef;">setq</span> python-shell-interpreter-arg <span style="color: #98be65;">"-i"</span><span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span><span style="color: #51afef;">setq</span> py-use-current-dir-when-execute-p t<span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span><span style="color: #51afef;">setq</span> <span style="color: #dcaeea;">python-shell-prompt-detect-enabled</span> nil<span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span><span style="color: #51afef;">setq</span> <span style="color: #dcaeea;">python-shell-interpreter</span> <span style="color: #98be65;">"ipython"</span><span style="color: #51afef;">)</span>
<span style="color: #51afef;">(</span><span style="color: #51afef;">setq</span> python-shell-interpreter-interactive-args <span style="color: #98be65;">"-i --simple-prompt"</span><span style="color: #51afef;">)</span>
</pre>
</div>


<div class="org-src-container">
<pre class="src src-emacs-lisp"><span style="color: #51afef;">(</span><span style="color: #c678dd;">add-to-list</span> <span style="color: #51afef;">'</span><span style="color: #dcaeea;">package-archives</span> <span style="color: #51afef;">'</span><span style="color: #c678dd;">(</span><span style="color: #98be65;">"melpa"</span> . <span style="color: #98be65;">"https://melpa.org/packages/"</span><span style="color: #c678dd;">)</span><span style="color: #51afef;">)</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd

<span style="color: #dcaeea;">a</span> = <span style="color: #da8548; font-weight: bold;">3</span>
<span style="color: #c678dd;">print</span>(a)
<span style="color: #dcaeea;">data</span> = [[<span style="color: #da8548; font-weight: bold;">1</span>,<span style="color: #da8548; font-weight: bold;">2</span>], [<span style="color: #da8548; font-weight: bold;">3</span>,<span style="color: #da8548; font-weight: bold;">4</span>]]
pd.DataFrame(data, columns=[<span style="color: #98be65;">"Foo"</span>, <span style="color: #98be65;">"Bar"</span>])
</pre>
</div>

<pre class="example" id="org35f38d3">
  Foo  Bar
  0    1    2
  1    3    4
</pre>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #51afef;">from</span> ipywidgets <span style="color: #51afef;">import</span>  interact, interactive, fixed, interact_manual
<span style="color: #51afef;">import</span> ipywidgets <span style="color: #51afef;">as</span> widgets
<span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span style="color: #c678dd;">print</span>(data)
<span style="color: #51afef;">def</span> <span style="color: #c678dd;">f</span>(x):
    plt.plot(np.arange(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">10</span>), x*np.arange(<span style="color: #da8548; font-weight: bold;">0</span>, <span style="color: #da8548; font-weight: bold;">10</span>))
    plt.ylim(-<span style="color: #da8548; font-weight: bold;">30</span>, <span style="color: #da8548; font-weight: bold;">30</span>)
<span style="color: #5B6268;">#</span><span style="color: #5B6268;">interact(f, x=10)</span>
f(<span style="color: #da8548; font-weight: bold;">10</span>)
</pre>
</div>


<div id="orgf922f1c" class="figure">
<p><img src=".ob-ipython-resrcnqInND.png" alt=".ob-ipython-resrcnqInND.png" />
</p>
</div>

<p>
:end:
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp"><span style="color: #51afef;">(</span><span style="color: #a9a1e1;">require</span> <span style="color: #51afef;">'</span><span style="color: #a9a1e1;">jupyter</span><span style="color: #51afef;">)</span>
</pre>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orgd4f375b" class="outline-2">
<h2 id="orgd4f375b"><span class="section-number-2">3.</span> BOOK</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>Title: Mastering Machine Learning with scikit-learn</li>
<li>Author: Gavin Hackeling</li>
</ul>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Hands-On Machine Learning with Scikit-Learn: Aurelien Geron
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung Chin, Yen</p>
<p class="date">Created: 2023-03-09 Thu 15:49</p>
</div>
</body>
</html>
