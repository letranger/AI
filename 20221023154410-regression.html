<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-02-10 Sat 17:05 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>迴歸</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">迴歸</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0552e37">1. 關於迴歸</a>
<ul>
<li><a href="#org0b9493a">1.1. 迴歸類型</a></li>
</ul>
</li>
<li><a href="#orgc198cfd">2. 迴歸原理</a>
<ul>
<li><a href="#org74b3259">2.1. Step 1: Model, Data</a></li>
<li><a href="#orgb0599b0">2.2. Step 2: Goodness of Function</a></li>
<li><a href="#org147fa3d">2.3. 迴歸預測流程(以波士頓房價預測為例)</a></li>
</ul>
</li>
<li><a href="#orge88d5ad">3. 線性迴歸:年齡身高預測#1</a>
<ul>
<li><a href="#org31ed4e8">3.1. 資料生成</a></li>
<li><a href="#org900b4ad">3.2. 查看資料</a></li>
<li><a href="#org8e9312c">3.3. 直線模型</a></li>
<li><a href="#orge2f4884">3.4. 損失函數</a></li>
<li><a href="#org79c6771">3.5. 方法一：暴力求解</a></li>
<li><a href="#org86e13fa">3.6. 方法二: 站在巨人的頭頂</a></li>
<li><a href="#org04b46bc">3.7. 逐步找出最佳解</a></li>
</ul>
</li>
<li><a href="#org162407a">4. 保持距離以測安全</a>
<ul>
<li><a href="#org4fc2b05">4.1. 模型的目的</a></li>
<li><a href="#org4a7271f">4.2. 沿著曲線上下爬</a></li>
<li><a href="#org4581a0a">4.3. 確定方向</a></li>
<li><a href="#orge959d82">4.4. 確定移動距離與重複次數</a></li>
<li><a href="#org2b907e7">4.5. 斜率與微分</a></li>
</ul>
</li>
<li><a href="#org5a89cfd">5. 線性迴歸:年齡身高預測#2</a>
<ul>
<li><a href="#org3e00da3">5.1. 梯度(Gradient)</a></li>
<li><a href="#orgc2deaae">5.2. 實作</a></li>
</ul>
</li>
<li><a href="#org0e87834">6. 線性迴歸實作: 波士頓房價預測</a>
<ul>
<li><a href="#org0760f1c">6.1. 下載資料</a></li>
<li><a href="#orgfa2c280">6.2. 大概觀察一下資料集</a></li>
<li><a href="#org97e2342">6.3. 資料預處理</a></li>
<li><a href="#org212864d">6.4. 觀察資料</a></li>
<li><a href="#org1b0cef0">6.5. 分割訓練集與測試集</a></li>
<li><a href="#org4519c8e">6.6. 建立模型</a></li>
<li><a href="#org012c164">6.7. 測試效能</a></li>
<li><a href="#org1cf9b6b">6.8. 找出線性模型</a></li>
</ul>
</li>
<li><a href="#orgbe57fb8">7. [作業]依據期中考成績預測期末考成績&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></a>
<ul>
<li><a href="#org6ed016b">7.1. Data</a></li>
<li><a href="#org4a3e0a7">7.2. Task</a></li>
</ul>
</li>
</ul>
</div>
</div>
<a href="https://letranger.github.io/AI/20221023154410-regression.html"><img align="right" alt="Hits" src="https://hits.sh/letranger.github.io/AI/20221023154410-regression.html.svg"/></a>
<div id="outline-container-org0552e37" class="outline-2">
<h2 id="org0552e37"><span class="section-number-2">1.</span> 關於迴歸</h2>
<div class="outline-text-2" id="text-1">
<p>
即，根據一組預測特徵（predictor，如里程數、車齡、品牌）來預測目標數值（如二手車車價）<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>、根據歷史股價來預測明天股價、根據路況來預測方向盤轉向及車速。
</p>

<p>
部份迴歸演算法也可以用來分類，例如Logistic，它可以輸出一個數值，以這個數值來表示對應到特定類別的機率，例如，某封email為垃圾郵件的機率為20%、某張圖片為狗的機率為70%。
</p>
</div>
<div id="outline-container-org0b9493a" class="outline-3">
<h3 id="org0b9493a"><span class="section-number-3">1.1.</span> 迴歸類型</h3>
<div class="outline-text-3" id="text-1-1">
<p>
迴歸問題可分為兩類：
</p>
<ul class="org-ul">
<li>Linear regression:</li>
<li>Logistic regression</li>
</ul>
</div>
<div id="outline-container-orga0cd592" class="outline-4">
<h4 id="orga0cd592"><span class="section-number-4">1.1.1.</span> Linear regression:</h4>
<div class="outline-text-4" id="text-1-1-1">
<ul class="org-ul">
<li>假設輸入變量(x)與單一輸出變量(y)間存在線性關係，並以此建立模型。</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時會導致低度擬合</li>
<li>例: 身高與體重間的關係</li>
</ul>
<p>
Linear regression可再細分為
</p>
</div>
<ol class="org-ol">
<li><a id="org6c391f5"></a>Simple Linear regression (簡單線性迴歸):<br />
<div class="outline-text-5" id="text-1-1-1-1">
<ul class="org-ul">
<li>討論兩個變數間的關係(輸入變量(x)與單一輸出變量(y)間)</li>
<li>在統計中:
x為Independent Variables: 自變數
y為Dependent Variables: 應變數</li>
<li>在機器學習中
x叫Features: 特徵值
y叫Label: 標籤</li>
</ul>
</div>
</li>
<li><a id="orga4b2588"></a>Multiple Linear regression (複線性迴歸)<br />
<div class="outline-text-5" id="text-1-1-1-2">
<p>
討論多個變數間的關係
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgf2e830f" class="outline-4">
<h4 id="orgf2e830f"><span class="section-number-4">1.1.2.</span> Logistic regression</h4>
<div class="outline-text-4" id="text-1-1-2">
<ul class="org-ul">
<li>也是線性方法，但使用logist function轉換輸出的預測結果，其輸出結果為類別機率(class probabilities)</li>
<li>優點: 簡單、容易解釋</li>
<li>缺點: 輸入與輸出變量關係為線性時無法處理分類問題</li>
</ul>
</div>
</div>
<div id="outline-container-org6c45e0c" class="outline-4">
<h4 id="org6c45e0c"><span class="section-number-4">1.1.3.</span> 迴歸的目的</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
建立迴歸的目的在於從現有資料中找出規則，然後依此規則來對後續的新進資料進行預測。如圖<a href="#org7fbb1a7">1</a>中有一些資料分佈，x、y軸為資料的兩個特徵值。
</p>

<div id="org7fbb1a7" class="figure">
<p><img src="images/關於迴歸/2024-02-07_15-18-38_2024-02-07_15-18-19.png" alt="2024-02-07_15-18-38_2024-02-07_15-18-19.png" width="400" />
</p>
<p><span class="figure-number">Figure 1: </span>原始資料分佈</p>
</div>

<p>
我們可以畫出幾條直線來代表這些資料的趨勢，問題是：
</p>
<ul class="org-ul">
<li>怎麼畫</li>
<li>怎麼知道哪一條最有代表性</li>
</ul>

<div id="orgd7bf47e" class="figure">
<p><img src="images/關於迴歸/2024-02-07_15-19-44_2024-02-07_15-18-27.png" alt="2024-02-07_15-19-44_2024-02-07_15-18-27.png" width="400" />
</p>
<p><span class="figure-number">Figure 2: </span>根據原始資料畫出的幾條迴歸線</p>
</div>

<p>
典型迴歸案例: Boston Housing Data
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgc198cfd" class="outline-2">
<h2 id="orgc198cfd"><span class="section-number-2">2.</span> 迴歸原理</h2>
<div class="outline-text-2" id="text-2">
<p>
練習投藍的時後，我們需要知道籃筐位置，誤差多少，做出丟球的修正。
做 Machine Learning 也是一樣道理，我們需要 :
</p>
<ul class="org-ul">
<li>建立模型</li>
<li>計算誤差: 在<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>中，我們用loss function來計算</li>
<li>做出修正: 在<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>中，我們用optimizer來不斷對模型進行修正</li>
</ul>
</div>
<div id="outline-container-org74b3259" class="outline-3">
<h3 id="org74b3259"><span class="section-number-3">2.1.</span> Step 1: Model, Data</h3>
<div class="outline-text-3" id="text-2-1">
<ol class="org-ol">
<li>Model: \(y = w*x+b\)</li>
<li>Data: 找一堆現成的資料</li>
</ol>
</div>
</div>
<div id="outline-container-orgb0599b0" class="outline-3">
<h3 id="orgb0599b0"><span class="section-number-3">2.2.</span> Step 2: Goodness of Function</h3>
<div class="outline-text-3" id="text-2-2">
<ol class="org-ol">
<li>Training Data</li>
<li>Loss function L: 越小越好
input: a function / output: how bad it is</li>
<li>Pick the <b>Best Function</b> :
\(f* = arg min L(f)\)
上述可以微分來求最佳解，即求 function L 的最小值</li>
<li>數值最佳解: Gradient Descent(找拋物線/面最低點)</li>
</ol>
</div>
</div>
<div id="outline-container-org147fa3d" class="outline-3">
<h3 id="org147fa3d"><span class="section-number-3">2.3.</span> 迴歸預測流程(以波士頓房價預測為例)</h3>
<div class="outline-text-3" id="text-2-3">
<ol class="org-ol">
<li>Import the required module</li>
<li>Load and configure the Boston housing data set</li>
<li>Chekc the relation between the variable, using pairplot and correlation graph</li>
<li>Descriptive statistics: central tendency and dispersion</li>
<li>Select the required columns</li>
<li>Train the test split</li>
<li>Normalize the data</li>
<li>Build the input pipeline for the TensorFlow model</li>
<li>Model tranining</li>
<li>Predictions</li>
<li>Validation</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orge88d5ad" class="outline-2">
<h2 id="orge88d5ad"><span class="section-number-2">3.</span> 線性迴歸:年齡身高預測#1</h2>
<div class="outline-text-2" id="text-3">
<p>
<a id="orgacaa1b2"></a>
</p>
</div>
<div id="outline-container-org31ed4e8" class="outline-3">
<h3 id="org31ed4e8"><span class="section-number-3">3.1.</span> 資料生成</h3>
<div class="outline-text-3" id="text-3-1">
<p>
這是當初上帝創造人類時決定人類身高的規則，我們也可以將之視為這組資料的模型，這個規則或模型是很神祕的，等一下我們要假裝我們不知道這個模型的存在，而迴歸的目的就在於想辦法猜出這個規則或模型。
</p>
<div class="org-src-container">
<pre class="src src-ipython"><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt

<span style="color: #dcaeea;">n</span> = <span style="color: #da8548; font-weight: bold;">10</span>                             <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36039;&#26009;&#31558;&#25976;</span>
<span style="color: #dcaeea;">year</span> = <span style="color: #da8548; font-weight: bold;">5</span> + <span style="color: #da8548; font-weight: bold;">25</span> * np.random.rand(n)  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24180;&#32000;</span>
<span style="color: #dcaeea;">height</span> = <span style="color: #da8548; font-weight: bold;">170</span> - <span style="color: #da8548; font-weight: bold;">108</span> * np.exp(-<span style="color: #da8548; font-weight: bold;">0.2</span> * year) + <span style="color: #da8548; font-weight: bold;">4</span> * np.random.randn(n)
<span style="color: #c678dd;">print</span>(year)
<span style="color: #c678dd;">print</span>(height)
</pre>
</div>
<pre class="example">
[13.3, 16.2, 10.9, 28.7, 19.8, 14.2, 11.7, 26.6, 22.4, 18.3, 19.4]
[163.61, 168.53, 155.06, 171.3 , 166.69, 160.98, 158.23, 165.27, 170.83,  161.31, 163.58]
</pre>
</div>
</div>
<div id="outline-container-org900b4ad" class="outline-3">
<h3 id="org900b4ad"><span class="section-number-3">3.2.</span> 查看資料</h3>
<div class="outline-text-3" id="text-3-2">
<p>
對於平凡的人類而言，他們只能看到身邊的人們隨著年齡增長而出現身高的變化，也就是由神袐模型所生成的數字：年齡和身高(如圖<a href="#org09f04b9">3</a>)。
</p>

<div id="org09f04b9" class="figure">
<p><img src="images/yearHeight.png" alt="yearHeight.png" width="500" />
</p>
<p><span class="figure-number">Figure 3: </span>年齡與身高的資料分佈</p>
</div>

<p>
但那些一身反骨的數學家則不甘於當平凡人，他們想透過統計、分析、思考、通靈等方式對這個既有現象進行逆向工程，去推估這個現象背後的神祕規則，藉此窺探上帝的意志。
這些規則也許是如圖<a href="#org29c1259">4</a>中的各種線段。一但找到了規則，我們就能根據這些規則進行 <b>預測</b> ，例如，由某人的年齡來合理推估他的身高。
</p>

<div id="org29c1259" class="figure">
<p><img src="images/yearHeightModel.png" alt="yearHeightModel.png" width="500" />
</p>
<p><span class="figure-number">Figure 4: </span>隱藏在年齡與身高資料背後的規則(模型)</p>
</div>
</div>
</div>
<div id="outline-container-org8e9312c" class="outline-3">
<h3 id="org8e9312c"><span class="section-number-3">3.3.</span> 直線模型</h3>
<div class="outline-text-3" id="text-3-3">
<p>
我們可以在圖<a href="#org29c1259">4</a>中畫上無數條線，但，最能代表年齡和身高關係的線應該只有一條，我們要如何找出這條線？
</p>

<p>
首先，既然我們想以 <b>直線</b> 來表示我們想找的模型或規則，那我們就先把這條直線以下列數學示表示出來:
\[y=ax+b\] 或 \[f(x)=ax+b\]
這樣的直線 \(y\) 或函數 \(f(x)\) 有無限多個，例如：
</p>
<ul class="org-ul">
<li>\(f_1(x)=3x+2\)</li>
<li>\(f_2(x)=4.5x-3.12\)</li>
<li>\(...\)</li>
<li>\(f_n(x)=-3x+50\)</li>
</ul>
<p>
迴歸的目的就是要從上述無限多個函數中找出一個最好的 \(f_?(x)\) ，這組函數擁有最好的參數 \(a,b\)(你也可以看成為直線 \(y\) 找到最適合的斜率 \(a\) 和截距 \(b\))。這也是現今許多<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>模型的基本精神：找到一個擁有最佳參數的函數，或者說：從無數個可能的模型中挑出最好的一個。
</p>

<p>
為了從無限多個備選模型中找出最佳的，我們需要有一個評估機制。
</p>
</div>
</div>
<div id="outline-container-orge2f4884" class="outline-3">
<h3 id="orge2f4884"><span class="section-number-3">3.4.</span> 損失函數</h3>
<div class="outline-text-3" id="text-3-4">
<p>
損失函數(loss function)也稱為成本函數(cost function)，就是最常用來定義、衡量模型誤差的方法。以圖<a href="#org020cb96">5</a>為例，我們可以計算所有原始資料\((x_0, y_0) \dots (x_9, y_9)\) 離這條預測線的距離(預測結果為 \(\hat{y_0} \dots \hat{y_9}\))，這些距離( \(y_0 - \hat{y_0} \dots y_9 - \hat{y_9}\) )的總和越小，表示預測線離每一點越近，也就是說這個模型越準確。
</p>


<div id="org020cb96" class="figure">
<p><img src="images/yearHeightLoss.png" alt="yearHeightLoss.png" width="600" />
</p>
<p><span class="figure-number">Figure 5: </span>直線模型的均方誤差</p>
</div>

<p>
圖<a href="#org020cb96">5</a>中的 \(y_i\) 為實際資料 \(x_i\) 對應的結果， 而 \(\hat{y_i}\) 則是將每個實際資料 \(x_i\) 丟入模型後的預測結果，計算 \(y_i\) 與 \(\hat{y_i}\) 誤差的方法稱為 <b>殘差平方和</b> (Residual Sum of Squares, RSS)，計算公式為
\[ RSS = \sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
把RSS再除以n就或是 <b>均方差</b> (Mean Square Error, MSE)，即
\[ MSE = \frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
迴歸的任務就是把RSS或MSE最小化。
</p>

<p>
如何讓RSS/MSE最小化呢？
</p>
</div>
</div>
<div id="outline-container-org79c6771" class="outline-3">
<h3 id="org79c6771"><span class="section-number-3">3.5.</span> 方法一：暴力求解</h3>
<div class="outline-text-3" id="text-3-5">
<p>
為了找出哪一組參數 \(a,b\) 可以讓模型 \(y=ax+b\) 的預測誤差達到最小，我們可以將一些合理的a,b值可能組合都列出來，如圖<a href="#org81c6a80">6</a>，我們列出了由參數 \(a\) (-40~40)、參數 \(b\) (40~160)的所有可能模型，圖中的 \(z\) 軸代表每一種模型產生的誤差(RSS)。由圖<a href="#org81c6a80">6</a>可以看出兩件事:
</p>
<ol class="org-ol">
<li>參數 \(a\) 對模型誤差的影響遠大於參數 \(b\)</li>
<li>當參數 \(a\) 的值接近0時，所生成的模型會有較低的MSE，也就是模型預測能力較好</li>
</ol>


<div id="org81c6a80" class="figure">
<p><img src="images/SSELossA.png" alt="SSELossA.png" width="500" />
</p>
<p><span class="figure-number">Figure 6: </span>不同a,b情況下的均方差</p>
</div>

<p>
讓我們回憶一下等高線這個東西，如果我們把圖<a href="#org81c6a80">6</a>當成某個山谷的地形圖(z軸為高度)，那我們就可以畫出這個區域的等高線圖<a href="#org5eeaee9">7</a>(先別管我是怎麼畫出來的)，從等高線圖<a href="#org5eeaee9">7</a>就能大概看出來當a的值約等於0、b的值約等於150時會有最低的SSE(如圖<a href="#org5eeaee9">7</a>中的紅點，這是我透過觀落陰得到的訊息)。
</p>


<div id="org5eeaee9" class="figure">
<p><img src="images/SSELossB.png" alt="SSELossB.png" width="500" />
</p>
<p><span class="figure-number">Figure 7: </span>不同a,b情況下的MSE(俯視/等高線)</p>
</div>

<p>
總之，看起來是有辦法找到最佳的模型的(只是有點麻煩)，這個方法稱為梯度下降，在這裡我們先知道有這麼個方法、知道這個方法可以找出最佳模型就好，至於深入探討這個方法是如何運作這件事，等我搞清楚了再說吧(或是等你們上大學再自己去研究)&#x2026;
</p>
</div>
</div>
<div id="outline-container-org86e13fa" class="outline-3">
<h3 id="org86e13fa"><span class="section-number-3">3.6.</span> 方法二: 站在巨人的頭頂</h3>
<div class="outline-text-3" id="text-3-6">
<p>
雖然從無數組 \((a,b)\) 中找出最好的一組看似困難，不過其實許多現成的相關模組已經有了這些功能，例如<a href="https://scikit-learn.org/stable/">scikit-learn</a>。以底下的程式為例：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #dcaeea;">year</span> = np.array([<span style="color: #da8548; font-weight: bold;">13.3</span>, <span style="color: #da8548; font-weight: bold;">16.2</span>, <span style="color: #da8548; font-weight: bold;">10.9</span>, <span style="color: #da8548; font-weight: bold;">28.7</span>, <span style="color: #da8548; font-weight: bold;">14.2</span>, <span style="color: #da8548; font-weight: bold;">11.7</span>, <span style="color: #da8548; font-weight: bold;">26.6</span>, <span style="color: #da8548; font-weight: bold;">22.4</span>, <span style="color: #da8548; font-weight: bold;">18.3</span>, <span style="color: #da8548; font-weight: bold;">20.4</span>]).reshape([-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 5: </span><span style="color: #dcaeea;">height</span> = np.array([<span style="color: #da8548; font-weight: bold;">163.61</span>, <span style="color: #da8548; font-weight: bold;">168.53</span>, <span style="color: #da8548; font-weight: bold;">155.06</span>, <span style="color: #da8548; font-weight: bold;">168.3</span> ,<span style="color: #da8548; font-weight: bold;">158.98</span>, <span style="color: #da8548; font-weight: bold;">158.23</span>, <span style="color: #da8548; font-weight: bold;">165.27</span>, <span style="color: #da8548; font-weight: bold;">170.83</span>,  <span style="color: #da8548; font-weight: bold;">161.31</span>, <span style="color: #da8548; font-weight: bold;">163.58</span>])
<span class="linenr"> 6: </span>
<span id="coderef-modelRegression" class="coderef-off"><span class="linenr"> 7: </span><span style="color: #dcaeea;">model</span> = LinearRegression()</span>
<span id="coderef-modelFit" class="coderef-off"><span class="linenr"> 8: </span>model.fit(year, height)</span>
<span class="linenr"> 9: </span>
<span class="linenr">10: </span><span style="color: #dcaeea;">slope</span> = model.coef_
<span class="linenr">11: </span><span style="color: #dcaeea;">intercept</span> = model.intercept_
<span class="linenr">12: </span><span style="color: #dcaeea;">heightHat</span> = year * slope + intercept
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#26012;&#29575;/Slope:'</span>, slope)
<span class="linenr">15: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#25130;&#36317;/Intercept:'</span>, intercept)
</pre>
</div>

<pre class="example">
斜率/Slope: [0.58182444]
截距/Intercept: 152.74006747354875
</pre>


<p>
在上述程式碼中，真正與計算迴歸有關的只有第<a href="#coderef-modelRegression" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-modelRegression');" onmouseout="CodeHighlightOff(this, 'coderef-modelRegression');">7</a>行(利用scikit-learn建立一個線性迴歸模型)與第<a href="#coderef-modelFit" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-modelFit');" onmouseout="CodeHighlightOff(this, 'coderef-modelFit');">8</a>行(把手上的10組 \((a,b)\) 資料丟進模型訓練)，
夠簡單吧，這樣我們就能畫出一條斜率約為0.58、截距約為152.74的最佳迴歸線(如圖<a href="#org7a46dc1">8</a>)，其模型為
\(f(x)=0.58x+152.74\)
</p>

<div id="org7a46dc1" class="figure">
<p><img src="images/yearHeightModelHat.png" alt="yearHeightModelHat.png" width="500" />
</p>
<p><span class="figure-number">Figure 8: </span>線性迴歸求解</p>
</div>

<p>
根據這個模型，一個18歲的人，我們可以預測其身高為
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">year</span> = <span style="color: #da8548; font-weight: bold;">18</span>
<span class="linenr">2: </span><span style="color: #dcaeea;">height</span> = <span style="color: #da8548; font-weight: bold;">0.58</span>*year+<span style="color: #da8548; font-weight: bold;">152.74</span>
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'&#26681;&#25818;&#27169;&#22411;&#38928;&#28204;&#65292;&#19968;&#20491;18&#27506;&#30340;&#20154;&#20854;&#36523;&#39640;&#28858;:</span>{height}<span style="color: #98be65;">&#20844;&#20998;'</span>)
</pre>
</div>

<pre class="example">
根據模型預測，一個18歲的人其身高為:163.18公分
</pre>
</div>
</div>
<div id="outline-container-org04b46bc" class="outline-3">
<h3 id="org04b46bc"><span class="section-number-3">3.7.</span> 逐步找出最佳解</h3>
<div class="outline-text-3" id="text-3-7">
<p>
<a id="org1e10fcc"></a>
雖然我們可以快速的利用如<a href="https://scikit-learn.org/">scikit-learn</a>這類第三方模組求出最佳解，但是相信對於有志投入AI領域的你來說，光知道如何快速求解顯然遠遠不夠，讓我們來搞清楚這到底是怎麼完成的。
</p>
</div>
<div id="outline-container-org3189345" class="outline-4">
<h4 id="org3189345"><span class="section-number-4">3.7.1.</span> 隨機的力量</h4>
<div class="outline-text-4" id="text-3-7-1">
<p>
萬事起頭難，要找出最佳的參數組合 \((a,b)\) ，最合理的方式就是我們 <b>閉上眼睛</b> 在圖<a href="#org81c6a80">6</a>中隨意點圈出一個點 \((a_0, b_0)\)，這就是我們的第一步，其結果就如圖<a href="#org3462fd5">9</a>所示。有了這個開頭，我們接下來要做的事就是：
</p>
<ol class="org-ol">
<li>找出 <b>一個方法</b> 來判斷要由點 \((a_0, b_0)\) 點沿著這個曲面的 <b>哪一個方向</b> 前進 <b>多遠</b> ，來到下一點 \((a_1, b_1)\)。也許是沿著曲面往上移一小段(如圖<a href="#org3462fd5">9</a>中的藍色線段)、也許是沿著曲面往下移一小段(如圖<a href="#org3462fd5">9</a>中的紅色線段)。</li>
<li>利用 <b>同一個方法</b> 來判斷接下來要由點 \((a_1, b_1)\) 點沿著這個曲面的 <b>哪一個方向</b> 繼續前進 <b>多遠</b> ，來到下一點 \((a_2, b_2)\)</li>
<li>重複同樣的步驟，直到找到最佳的點 \((a_n, b_n)\) ，也就是這一點 \((a_n, b_n)\) 能使整個模型的SSE來到最小，讓模型具備最佳的預測效能。</li>
</ol>

<div id="org3462fd5" class="figure">
<p><img src="images/SSELossC.png" alt="SSELossC.png" width="500" />
</p>
<p><span class="figure-number">Figure 9: </span>找出最佳a,b組合的方法</p>
</div>
</div>
</div>
<div id="outline-container-org0c66459" class="outline-4">
<h4 id="org0c66459"><span class="section-number-4">3.7.2.</span> 何去何從</h4>
<div class="outline-text-4" id="text-3-7-2">
<p>
發現了嗎？其實我們就只是在求某個方程式的最小值。
</p>

<p>
到這裡我想你一定會發現上面那個方法的幾個漏洞：
</p>
<ul class="org-ul">
<li>我怎麼知道要往哪個方向移呢？</li>
<li>我怎麼知道要移動多長的距離呢?</li>
<li>我怎麼知道移動後的新位置比原來的位置好呢？</li>
</ul>

<p>
好吧，我也不知道。不如我們先跳過這個看起來太複雜的問題，先換個簡單點的來強化自信。
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org162407a" class="outline-2">
<h2 id="org162407a"><span class="section-number-2">4.</span> 保持距離以測安全</h2>
<div class="outline-text-2" id="text-4">
<p>
讓我們先來看一個更簡單的例子。
</p>

<p>
這是一組從<a href="https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html">R語言資料集</a>偷來的資料，這個資料集有七百多組教學用的資料集，其中有一組簡單的資料集cars，裡面有50筆資料，每筆資料只有兩個欄位：
</p>
<ul class="org-ul">
<li>speed: 車速</li>
<li>dist: 所需剎車距離</li>
</ul>
<p>
資料分佈如圖<a href="#orgc1c3cef">10</a>所示
</p>

<div id="orgc1c3cef" class="figure">
<p><img src="images/carsScatter.png" alt="carsScatter.png" width="500" />
</p>
<p><span class="figure-number">Figure 10: </span>車速與剎車距離關係分佈圖</p>
</div>

<p>
我們為了這組簡單的資料分佈建了一個如下的模型
\[dist=w*speed\]
建立這組模型的最終目的當然是希望輸入 <b>車速</b> (\(speed\)) 後就能得到 <b>預測的所需剎車距離</b> ( \(dist\) ) 。我們也可以用常見的數學表示法( \(x\) 為車速、\(y_{predicted}\) 為預測的剎車距離)：
\[ y_{predicted} = w * x \]
或是更常見的寫法( \(\hat{y}\) 為預測的剎車距離)：
\[ \hat{y} = w * x \]
我們的任務就是找到一個最佳的 \(w\) 值，也就是這個模型的參數。同時，為了評估不同 \(w\) 值下模型的優劣，我們當也要提出相對應的損失函數( \(\hat{y}\) 為模型預測的剎車距離、 \(y_i\) 為實際資料的剎車距離，\(n\) 為資料筆數，共有50筆資料)：
\[ Loss = \frac{1}{n}\sum_{i=1}^{n}(\hat{y} - y_i)^2 \]
例如：
</p>
<ul class="org-ul">
<li>當 \(w\) 為-15時，Loss值為85113.26</li>
<li>當 \(w\) 為-10時，Loss值為44346.86</li>
<li>當 \(w\) 為 -5時，Loss值為16808.46</li>
<li>當 \(w\) 為  0時，Loss為2498.06</li>
<li>當 \(w\) 為  5時，Loss為1415.66</li>
<li>當 \(w\) 為 10時，Loss為17152.28</li>
</ul>

<p>
在這個例子中，我們的任務就變成：提出一個假設模型 \(f(x)=w*x\)，然後找出最理想的參數 \(w\)，讓這個模型可以俱備最好的預測能力(Loss值最小)。
</p>
</div>
<div id="outline-container-org4fc2b05" class="outline-3">
<h3 id="org4fc2b05"><span class="section-number-3">4.1.</span> 模型的目的</h3>
<div class="outline-text-3" id="text-4-1">
<p>
顯然，對於如何解出方程式(或是說找到最佳模型) ，一開始當然沒啥頭緒，那，不如就暴力一點吧，弄個窮舉法：試試從 \(w=-20\) try到 \(w=+20\) 吧，觀察一下損失函數Loss的變化：
</p>

<div id="org7efa90f" class="figure">
<p><img src="images/carsLoss.png" alt="carsLoss.png" width="500" />
</p>
<p><span class="figure-number">Figure 11: </span>不同參數w下的損失函數Loss分佈圖</p>
</div>

<p>
從圖<a href="#org7efa90f">11</a>可以看出來，最低的loss值應該是介於20到-20沒錯的，現在我們來想辦法找出最好的 \(w\) 在哪裡。
</p>
</div>
</div>
<div id="outline-container-org4a7271f" class="outline-3">
<h3 id="org4a7271f"><span class="section-number-3">4.2.</span> 沿著曲線上下爬</h3>
<div class="outline-text-3" id="text-4-2">
<p>
雖然我們從圖<a href="#org7efa90f">11</a>大概可以看出來模型大概在參數 \(w\) 介於0和5之間會有最小的Loss，也就是模型會最準確，但身為嚴謹的學術研究者，我們不能這樣蠻幹，這是土匪的行徑。面對未知的困難，我們要有嚴格的解題SOP，也就是要遵循「科學、理性、務實」的精神：閉著眼睛隨便給個 \(w\)。例如：-15，如圖<a href="#orgf7b0687">12</a>。
</p>

<p>
你看，我們這不就邁出成功的第一步了?
</p>

<p>
隨機就是這麼美而有力!!
</p>


<div id="orgf7b0687" class="figure">
<p><img src="images/carsLoss1.png" alt="carsLoss1.png" width="500" />
</p>
<p><span class="figure-number">Figure 12: </span>先隨機假設一個數(-15)為最佳參數w的值</p>
</div>

<p>
有了出發點(我們估且稱之為 \(w_0\) 好了，如圖<a href="#orgf7b0687">12</a>)，接下來就只要決定下一個「較好的下一個 \(w\) 」是在 \(w_0\) 的左邊還是右邊(根據Loss值來判斷)，然後繼續往左或往右移(如圖<a href="#org0c2d353">13</a>。
</p>

<p>
總之，我們只要決定以下兩個因素，就可以利用<a href="https://letranger.github.io/PythonCourse/">Python</a>把模型的最佳參數 \(w\) 找出來了。
</p>
<ol class="org-ol">
<li>每次要往左或往右移多少距離?</li>
<li>這樣的修正動作要重複幾次？或者說，程式結束的條件為何？</li>
</ol>


<div id="org0c2d353" class="figure">
<p><img src="images/carsLoss2.png" alt="carsLoss2.png" width="500" />
</p>
<p><span class="figure-number">Figure 13: </span>決定w應往哪個方向移動</p>
</div>
</div>
</div>
<div id="outline-container-org4581a0a" class="outline-3">
<h3 id="org4581a0a"><span class="section-number-3">4.3.</span> 確定方向</h3>
<div class="outline-text-3" id="text-4-3">
<p>
相信學過幾何學的你一定有想到一種策略：切線。既然 \(w\) 與  \(Loss\) 的關係是如圖<a href="#org0c2d353">13</a>的曲線，我們應該可以找出 \(w_0\) 這個點的 <b>切線</b> ，根據這條切線的斜率(也就是點 \(w_0\) 的斜率)為正或負來判斷要往哪個方向移動，如果切線是負的，也就是一條左上右下的線，那我們就知道曲線的最低點應該是在這個點的右側。
</p>

<p>
讓我們從點 \(w_0\) 的 \(x\) 軸向左移動一段距離(例如5)，就會在曲線上找到 \(w_1\) 對應的 \(Loss_1\) ，然後連接點\((w_0, Loss_0)\) 、點\((w_1, Loss_1)\) ，就會得到一條經過點\((w_0, Loss_0)\) 的割線。
</p>


<div id="org493f065" class="figure">
<p><img src="images/carsLoss30.png" alt="carsLoss30.png" width="500" />
</p>
<p><span class="figure-number">Figure 14: </span>決定w應往哪個方向移動#1</p>
</div>

<p>
這條割線的斜率計算方式為 \[ Slope = \frac{\Delta Loss}{\Delta x} = \frac{Loss_0-Loss_1}{x_0-x_1} \]
讓我們進一步把 <b>移動距離</b> 縮到無限小，也就是把割線斜率中的 \(\Delta x\) 逼近於0，就能得到一條點 \((w_0, Loss_0)\) 的在曲線上的切線，其斜率計算方式為：
\[f'(w_0)=lim_{w_1 \rightarrow w_0}\frac{f(w_1)-f(w_0)}{w_1-w_0}\]
</p>


<div id="orgbdc170f" class="figure">
<p><img src="images/carsLoss31.png" alt="carsLoss31.png" width="500" />
</p>
<p><span class="figure-number">Figure 15: </span>決定w應往哪個方向移動#2</p>
</div>

<p>
以程式計算斜率的方式也很簡單，甚至不需要懂微分，所謂把 <b>移動距離</b> 縮到無限小，我們可以用作弊的方式，直接將 \(\Delta x\) 設為一個很小的值，例如 0.5。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> pydataset <span style="color: #51afef;">import</span> data
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#36039;&#26009;&#38598;</span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">cars</span> = data(<span style="color: #98be65;">'cars'</span>)
<span class="linenr"> 6: </span><span style="color: #dcaeea;">speed</span> = np.array(cars[<span style="color: #98be65;">'speed'</span>])
<span class="linenr"> 7: </span><span style="color: #dcaeea;">dist</span> = np.array(cars[<span style="color: #98be65;">'dist'</span>])
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639;Loss&#29992;&#30340;function</span>
<span class="linenr">10: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">loss_func</span>(y_true, y_predict):
<span class="linenr">11: </span>    <span style="color: #51afef;">return</span> y_true - y_predict
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #dcaeea;">w</span> = np.arange(-<span style="color: #da8548; font-weight: bold;">20</span>,<span style="color: #da8548; font-weight: bold;">21</span>,<span style="color: #da8548; font-weight: bold;">0.5</span>)
<span class="linenr">14: </span><span style="color: #dcaeea;">loss</span> = []
<span class="linenr">15: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> w:
<span class="linenr">16: </span>    <span style="color: #dcaeea;">yHat</span> =  i * speed
<span class="linenr">17: </span>    loss.append(np.mean(loss_func(dist, yHat)**<span style="color: #da8548; font-weight: bold;">2</span>))
<span class="linenr">18: </span>
<span class="linenr">19: </span>
<span class="linenr">20: </span><span style="color: #dcaeea;">x</span>, <span style="color: #dcaeea;">y</span> = -<span style="color: #da8548; font-weight: bold;">5</span>, loss[np.where(w == -<span style="color: #da8548; font-weight: bold;">5</span>)[<span style="color: #da8548; font-weight: bold;">0</span>][<span style="color: #da8548; font-weight: bold;">0</span>]]
<span class="linenr">21: </span><span style="color: #dcaeea;">x1</span>, <span style="color: #dcaeea;">y1</span> = -<span style="color: #da8548; font-weight: bold;">4.5</span>, loss[np.where(w == -<span style="color: #da8548; font-weight: bold;">4.5</span>)[<span style="color: #da8548; font-weight: bold;">0</span>][<span style="color: #da8548; font-weight: bold;">0</span>]]
<span class="linenr">22: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639;&#20999;&#32218;&#26012;&#29575;</span>
<span class="linenr">23: </span><span style="color: #c678dd;">print</span>((y-y1)/(x-x1))
</pre>
</div>

<pre class="example">
-4052.5999999999985
</pre>


<p>
計算結果 \(Slope<0\) ，表示這是條左上右下的切線，顯然接下來該往右側去找到最低點。問題是：該往右邊移動多少距離呢？要移動幾次？
</p>
</div>
</div>
<div id="outline-container-orge959d82" class="outline-3">
<h3 id="orge959d82"><span class="section-number-3">4.4.</span> 確定移動距離與重複次數</h3>
<div class="outline-text-3" id="text-4-4">
<p>
<a id="org23bd067"></a>
由圖<a href="#orgbdc170f">15</a>中點 \((w_0, Loss_0)\) 的斜率可知應逐步往右移動w，Loss的值就會慢慢降下來，所以我們可以先這麼計畫：
</p>
<ul class="org-ul">
<li>每次由 \(w0\) 的 \(x\) 軸往右邊加0.5、直到Loss不再變小。</li>
</ul>
<p>
或換另一種說法：
</p>
<ul class="org-ul">
<li>每次往右邊加0.5、直到Loss開始變大(因為越過了曲線最低點)。</li>
</ul>

<p>
上述的Python實作程式碼如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">from</span> pydataset <span style="color: #51afef;">import</span> data
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21462;&#24471;&#36039;&#26009;&#38598;</span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">cars</span> = data(<span style="color: #98be65;">'cars'</span>)
<span class="linenr"> 6: </span><span style="color: #dcaeea;">speed</span> = np.array(cars[<span style="color: #98be65;">'speed'</span>])
<span class="linenr"> 7: </span><span style="color: #dcaeea;">dist</span> = np.array(cars[<span style="color: #98be65;">'dist'</span>])
<span class="linenr"> 8: </span>
<span class="linenr"> 9: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639;Loss&#29992;&#30340;function</span>
<span class="linenr">10: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">loss_func</span>(y_true, y_predict):
<span class="linenr">11: </span>    <span style="color: #51afef;">return</span> y_true - y_predict
<span class="linenr">12: </span>
<span class="linenr">13: </span><span style="color: #dcaeea;">w</span> = np.arange(-<span style="color: #da8548; font-weight: bold;">20</span>,<span style="color: #da8548; font-weight: bold;">21</span>,<span style="color: #da8548; font-weight: bold;">0.5</span>)
<span class="linenr">14: </span><span style="color: #dcaeea;">loss</span> = []
<span class="linenr">15: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> w:
<span class="linenr">16: </span>    <span style="color: #dcaeea;">yHat</span> =  i * speed
<span class="linenr">17: </span>    loss.append(np.mean(loss_func(dist, yHat)**<span style="color: #da8548; font-weight: bold;">2</span>))
<span class="linenr">18: </span>
<span class="linenr">19: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25214;&#26368;&#20339;w&#20540;, &#36889;&#35041;&#20197;x&#20195;&#34920;w&#20540;</span>
<span class="linenr">20: </span><span style="color: #dcaeea;">x</span>, <span style="color: #dcaeea;">y</span> = -<span style="color: #da8548; font-weight: bold;">15</span>, loss[np.where(w == -<span style="color: #da8548; font-weight: bold;">15</span>)[<span style="color: #da8548; font-weight: bold;">0</span>][<span style="color: #da8548; font-weight: bold;">0</span>]]
<span id="coderef-keepIncrease" class="coderef-off"><span class="linenr">21: </span><span style="color: #51afef;">while</span> <span style="color: #a9a1e1;">True</span>:</span>
<span class="linenr">22: </span>    <span style="color: #dcaeea;">loss</span> = np.mean(loss_func(dist, x*speed)**<span style="color: #da8548; font-weight: bold;">2</span>)
<span id="coderef-increaseX" class="coderef-off"><span class="linenr">23: </span>    <span style="color: #dcaeea;">x</span> += <span style="color: #da8548; font-weight: bold;">0.5</span></span>
<span class="linenr">24: </span>    <span style="color: #dcaeea;">newLoss</span> = np.mean(loss_func(dist, x*speed)**<span style="color: #da8548; font-weight: bold;">2</span>)
<span id="coderef-breakWhile" class="coderef-off"><span class="linenr">25: </span>    <span style="color: #51afef;">if</span> newLoss &gt;= loss:</span>
<span class="linenr">26: </span>        <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'STOP: w&#20540;:</span>{x-0.5}<span style="color: #98be65;">, Loss:</span>{loss}<span style="color: #98be65;">'</span>)
<span class="linenr">27: </span>        <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'NEXT: w&#20540;:</span>{x}<span style="color: #98be65;">, Loss:</span>{newLoss}<span style="color: #98be65;">'</span>)
<span class="linenr">28: </span>        <span style="color: #51afef;">break</span>
<span id="coderef-monitorW" class="coderef-off"><span class="linenr">29: </span>    <span style="color: #51afef;">if</span> <span style="color: #c678dd;">int</span>(x) % <span style="color: #da8548; font-weight: bold;">5</span> == <span style="color: #da8548; font-weight: bold;">0</span>:</span>
<span class="linenr">30: </span>        <span style="color: #c678dd;">print</span>(f<span style="color: #98be65;">'w&#20540;:</span>{x}<span style="color: #98be65;">, Loss:</span>{newLoss}<span style="color: #98be65;">'</span>)
</pre>
</div>

<p>
逐步右移的控制主要由第<a href="#coderef-keepIncrease" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-keepIncrease');" onmouseout="CodeHighlightOff(this, 'coderef-keepIncrease');">21</a>行的while負責，\(w\) 每次右移0.5，直到Loss值不再變小就停止(第<a href="#coderef-breakWhile" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-breakWhile');" onmouseout="CodeHighlightOff(this, 'coderef-breakWhile');">25</a>行)，為簡化輸出，每移動10次 \(w\) 我們就把對應的 \(w\) 和Loss輸出來觀察一下（第<a href="#coderef-monitorW" class="coderef" onmouseover="CodeHighlightOn(this, 'coderef-monitorW');" onmouseout="CodeHighlightOff(this, 'coderef-monitorW');">29</a>行)。輸出結果如下：
</p>

<pre class="example">
w值:-10.5, Loss:47828.24
w值:-10.0, Loss:44346.86
w值:-5.5, Loss:18967.04
w值:-5.0, Loss:16808.46
w值:-0.5, Loss:3333.84
w值:0.0, Loss:2498.06
w值:0.5, Loss:1794.56
STOP: w值:3.0, Loss:261.26
NEXT: w值:3.5, Loss:351.44
</pre>


<p>
由執行結果可發現隨著 \(w\) 值的增加，Loss值也隨之減少，直到 \(w\) 值為3時可以得到最低的Loss值(261.26)，過了這一點，Loss值便又開始增加。圖<a href="#org0bd55da">17</a>為w值持續修正的模擬結果，圖<a href="#orga91aaab">16</a>則為假設\(w\) 值為3所畫出的預測線(模型)。
</p>


<div id="orga91aaab" class="figure">
<p><img src="images/carsLine.png" alt="carsLine.png" width="500" />
</p>
<p><span class="figure-number">Figure 16: </span>車速與剎車距離關係分佈及預測模型</p>
</div>


<p>
然而，這個 \(w=3\) 的模型就是最佳模型嗎？你有什麼可以更快找到更精確的「使Loss最低的 \(w\) 值」的修正方案嗎？
</p>


<div id="org0bd55da" class="figure">
<p><img src="images/carsLoss4.png" alt="carsLoss4.png" width="500" />
</p>
<p><span class="figure-number">Figure 17: </span>決定w應往哪個方向移動</p>
</div>
</div>
</div>
<div id="outline-container-org2b907e7" class="outline-3">
<h3 id="org2b907e7"><span class="section-number-3">4.5.</span> 斜率與微分</h3>
<div class="outline-text-3" id="text-4-5">
<p>
為什麼 <b>找出曲線上各點的斜率</b> 這件事如此重要呢？原因有二
</p>
<ul class="org-ul">
<li>在第<a href="#org23bd067">4.4</a>中，我們據以移動 \(w\) 值的依據是 <b>「每次往右邊加0.5、直到Loss開始變大(因為越過了曲線最低點)」</b> ，其實我們有另一種更方便的判斷方式：在曲線最低點左側所有點的斜率均為負、在曲線最低點右側所有點的斜率均為正，知道了某點的斜率為正或負，我們就知道該往左側或右側去移動，找出最低點的位置。理解這件事，我們可以用程式來求出接近的最低點。</li>
<li>曲線最低點的斜率為0，我們只要能找到斜率為0的這一點，就能找到模型的最佳參數。理解這件事，我們就能用數學的方式求出最低點的位置。 事實上，如果我們知道曲線 \(y=f(x)\) 的實際內容，我們就能用<a href="20221126112514-基礎數學for_ai.html#ID-3ce884c1-cd16-4310-b757-37cdd1ddcdef">微分</a>來找到曲線上的最低點。</li>
</ul>
</div>
<div id="outline-container-org34e9708" class="outline-4">
<h4 id="org34e9708"><span class="section-number-4">4.5.1.</span> 頂點公式求函數解</h4>
<div class="outline-text-4" id="text-4-5-1">
<p>
如假設損失函數L為 \[ Loss = MSE = \frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
其中
</p>
<ul class="org-ul">
<li>\(n=50\)(實際有50筆資料)</li>
<li>\(\hat{y_i}\)為用模型\(y=wx\)所預測出來的剎車距離</li>
<li>\(y_i\)為當實測車速為\(x_i\)時所對應的剎車距離</li>
</ul>
<p>
故
</p>
\begin{align}
Loss=\frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \\
=\frac{1}{n}\sum_{i=1}^{n}(wx_i - y_i)^2 \\
=\frac{1}{n}\sum_{i=1}^{n}(w^2x_i^2 -2wx_iy_i + y_i^2) \\
=\frac{1}{n}(w^2\sum_{i=1}^{n}x_i^2 -2w\sum_{i=1}^{n}x_iy_i + ny_i^2) \\
\end{align}
<p>
現在我們就得到一個一元二次方程式:\(ax^2+bx+c\)
</p>

<p>
雖然可以用微分來解，但是這個一元二次函數也可以用頂點公式來找出曲線頂點(模型最小值)，求出的最小Loss會出現在
\[ w=\frac{\sum\limits_{i=1}^{n}x_iy_i}{\sum\limits_{i=1}^{n}x_i^2} \]
因為當 \(a>0\)
\[ ax^2+bx+c = a(x+\frac{b}{2a})+\frac{4ac-b^2}{4a} \]
故 函數在 \(x=\frac{-b}{2a}\) 時有最小值
</p>

<p>
以程式驗證如下：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">from</span> pydataset <span style="color: #51afef;">import</span> data
<span class="linenr">2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">3: </span>
<span class="linenr">4: </span><span style="color: #dcaeea;">cars</span> = data(<span style="color: #98be65;">'cars'</span>)
<span class="linenr">5: </span><span style="color: #dcaeea;">speed</span> = np.array(cars[<span style="color: #98be65;">'speed'</span>])
<span class="linenr">6: </span><span style="color: #dcaeea;">dist</span> = np.array(cars[<span style="color: #98be65;">'dist'</span>])
<span class="linenr">7: </span>
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#26368;&#23567;Loss&#30340;&#21443;&#25976;w&#20540;:'</span>,<span style="color: #c678dd;">sum</span>(speed*dist) / <span style="color: #c678dd;">sum</span>(speed*speed))
</pre>
</div>

<pre class="example">
最小Loss的參數w值: 2.909132143937103
</pre>
</div>
</div>
<div id="outline-container-org8bac0d2" class="outline-4">
<h4 id="org8bac0d2"><span class="section-number-4">4.5.2.</span> 微分求函數頂點</h4>
<div class="outline-text-4" id="text-4-5-2">
<p>
當 \(a>0\)
</p>
\begin{align}
f(x)=ax^2+bx+c \\
f'(x)=2ax+b
\end{align}
<p>
找曲線最低點、令函式為0
\[2ax+b=0\]
故 \(x=\frac{-b}{2a}\) 時有最小值
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org5a89cfd" class="outline-2">
<h2 id="org5a89cfd"><span class="section-number-2">5.</span> 線性迴歸:年齡身高預測#2</h2>
<div class="outline-text-2" id="text-5">
<p>
回到第<a href="#org1e10fcc">3.7</a>節<a href="#orgacaa1b2">以年齡預測身高</a>的例子，我們提及要找出最佳的參數組合 \((a,b)\) ，最合理的方式是在圖<a href="#org81c6a80">6</a>中隨意點圈出一個點 \((a_0, b_0)\) (如圖<a href="#org3462fd5">9</a>)。接下來：
</p>
<ol class="org-ol">
<li>找出 <b>一個方法</b> 來判斷要由點 \((a_0, b_0)\) 點沿著這個曲面的 <b>哪一個方向</b> 前進 <b>多遠</b> ，來到下一點 \((a_1, b_1)\)。也許是沿著曲面往上移一小段(如圖<a href="#org3462fd5">9</a>中的藍色線段)、也許是沿著曲面往下移一小段(如圖<a href="#org3462fd5">9</a>中的紅色線段)。</li>
<li>利用 <b>同一個方法</b> 來判斷接下來要由點 \((a_1, b_1)\) 點沿著這個曲面的 <b>哪一個方向</b> 繼續前進 <b>多遠</b> ，來到下一點 \((a_2, b_2)\)</li>
<li>重複同樣的步驟，直到找到最佳的點 \((a_n, b_n)\) ，也就是這一點 \((a_n, b_n)\) 能使整個模型的SSE來到最小，讓模型具備最佳的預測效能。</li>
</ol>

<p>
假設損失函數L為 \[ L = MSE = \frac{1}{n}\sum_{i=1}^{n}(\hat{y_i}-y_i)^2 \]
因為 \(\hat{y_i}\) 代表直線模型 \(y=ax+b\) 的預測結果。
</p>

<p>
實際的做法就變成：
</p>
<ol class="org-ol">
<li>計算點 \((a_0, b_0)\) 的斜率，然後朝著 <b>使Loss(MSE)減小得最快的方向</b> 稍微移動 \(a, b\)</li>
<li>重複步驟1</li>
</ol>
</div>
<div id="outline-container-org3e00da3" class="outline-3">
<h3 id="org3e00da3"><span class="section-number-3">5.1.</span> 梯度(Gradient)</h3>
<div class="outline-text-3" id="text-5-1">
<p>
為了符合機器學習的表達習慣，我們稍微修正一下上面的式子，將 \(a,b\) 改為 \(w_0, w_1\) ，因為對機器學習來說， \(a,b\) 都是模型的權重(weight) ，訓練模型的目的就是找出最佳的權重，讓模型的預測最準確，所以上述式子就變成了 \(y=w_0x+w_1\) 。
</p>

<p>
假設我們就站在下圖(圖<a href="#orgc973a77">18</a>)中的點 \((w_0, w_1)\) 上，環顧四周，由這點往上的方向可以用 \(L\) 對 \(w_0,w_1\) 的偏導數向量
\(
\begin{bmatrix}
\frac{\delta L}{\delta w_0} \frac{\delta L}{\delta w_1}
\end{bmatrix}^T
\)
，也稱之為 <b>梯度(gradient)</b> ，以符號 \(\nabla_wL\) 表示。為了使 \(L\) 最小，我們要朝著著 \(L\) 梯度的反方向前進，也就是
\(
-\nabla_wL =
-\begin{bmatrix}
\frac{\delta L}{\delta w_0} \frac{\delta L}{\delta w_1}
\end{bmatrix}^T
\)
</p>


<div id="orgc973a77" class="figure">
<p><img src="images/SSELossD.png" alt="SSELossD.png" width="500" />
</p>
<p><span class="figure-number">Figure 18: </span>隨意於曲面指定一點(a,b)</p>
</div>

<p>
確定移動方向後，我們就要來研究出一個適當的移動距離。我們先定義幾個表達式：
</p>
<ul class="org-ul">
<li>\(\nabla_wL\) 為 \(w\) 的函數</li>
<li>\(w(\tau)\) 代表目前的 \((w_0, w_1)\) 所在位置</li>
<li>\(w(\tau+1)\) 代表下一次移動的新 \((w_0, w_1)\) 所在位置</li>
<li>\(\alpha\) 為一個大於0的數，稱為學習率，用來控制調整權重的步幅，其值越大，調整的幅度就越大。典型的值可能為 \(0.001\)</li>
<li>\(y_i\) 為實際由第i個年齡 <b>對應</b> 到的身高</li>
<li>\(\hat y_i\) 為模型由第i個年齡 <b>預測出來</b> 的身高</li>
</ul>
<p>
兩個權重的下一步的調整步幅為：
</p>
<ul class="org-ul">
<li>\(w_0(\tau+1) = w_0(\tau)-\alpha\frac{\partial L}{\partial w_0}\)</li>
<li>\(w_1(\tau+1) = w_0(\tau)-\alpha\frac{\partial L}{\partial w_1}\)</li>
</ul>
<p>
因為 \[L=\frac{1}{n}\sum\limits_{i=1}^{n}(\hat y_i - y_i)^2 = \frac{1}{n}\sum\limits_{i=1}^{n}(w_0x_i + w_1 - y_i)^2\]
對 \(w_0\) 求偏導數：
\[\frac{\partial L}{\partial w_0} = \frac{2}{n}\sum\limits_{i=1}^{n}(w_0x_i + w_1 - y_i)x_i = \frac{2}{n}\sum\limits_{i=1}^{n}(\hat y_i - y_i)x_i\]
對 \(w_1\) 求偏導數：
\[\frac{\partial L}{\partial w_1} = \frac{2}{n}\sum\limits_{i=1}^{n}(w_0x_i + w_1 - y_i)= \frac{2}{n}\sum\limits_{i=1}^{n}(\hat y_i - y_i)\]
即 \((w_0, w_1)\) 的下一次移動距離為：
</p>
<ul class="org-ul">
<li>\(w_0(\tau+1) = w_0(\tau)-\alpha\frac{\partial L}{\partial w_0} = \frac{2}{n}\sum\limits_{i=1}^{n}(\hat y_i - y_i)x_i\)</li>
<li>\(w_1(\tau+1) = w_0(\tau)-\alpha\frac{\partial L}{\partial w_1} = \frac{2}{n}\sum\limits_{i=1}^{n}(\hat y_i - y_i)\)</li>
</ul>
<p>
上面數學式中貌似有很複雜的計算，但是如果我們以Numpy的array來儲存 \(x_i, y_i, \hat y_i\)，就能利用Numpy的矩陣運算np.mean()輕易求出結果，例如當 \((w_0, w_1) = (-20, 70)\) (如圖<a href="#orgc973a77">18</a>)，則下一個點梯度的計算方式為
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 2: </span><span style="color: #dcaeea;">year</span> = np.array([<span style="color: #da8548; font-weight: bold;">13.3</span>, <span style="color: #da8548; font-weight: bold;">16.2</span>, <span style="color: #da8548; font-weight: bold;">10.9</span>, <span style="color: #da8548; font-weight: bold;">28.7</span>, <span style="color: #da8548; font-weight: bold;">14.2</span>, <span style="color: #da8548; font-weight: bold;">11.7</span>, <span style="color: #da8548; font-weight: bold;">26.6</span>, <span style="color: #da8548; font-weight: bold;">22.4</span>, <span style="color: #da8548; font-weight: bold;">18.3</span>, <span style="color: #da8548; font-weight: bold;">20.4</span>]).reshape([-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr"> 3: </span><span style="color: #dcaeea;">height</span> = np.array([<span style="color: #da8548; font-weight: bold;">163.61</span>, <span style="color: #da8548; font-weight: bold;">168.53</span>, <span style="color: #da8548; font-weight: bold;">155.06</span>, <span style="color: #da8548; font-weight: bold;">168.3</span> ,<span style="color: #da8548; font-weight: bold;">158.98</span>, <span style="color: #da8548; font-weight: bold;">158.23</span>, <span style="color: #da8548; font-weight: bold;">165.27</span>, <span style="color: #da8548; font-weight: bold;">170.83</span>,  <span style="color: #da8548; font-weight: bold;">161.31</span>, <span style="color: #da8548; font-weight: bold;">163.58</span>])
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22343;&#26041;&#24046;&#30340;&#26799;&#24230;</span>
<span class="linenr"> 5: </span><span style="color: #51afef;">def</span> <span style="color: #c678dd;">dw</span>(x, y, w):
<span class="linenr"> 6: </span>    <span style="color: #dcaeea;">yhat</span> = w[<span style="color: #da8548; font-weight: bold;">0</span>]*x + w[<span style="color: #da8548; font-weight: bold;">1</span>]
<span class="linenr"> 7: </span>    <span style="color: #dcaeea;">d_w0</span> = <span style="color: #da8548; font-weight: bold;">2</span>*np.mean((yhat-y)*x)
<span class="linenr"> 8: </span>    <span style="color: #dcaeea;">d_w1</span> = <span style="color: #da8548; font-weight: bold;">2</span>*np.mean(yhat-y)
<span class="linenr"> 9: </span>    <span style="color: #51afef;">return</span> d_w0, d_w1
<span class="linenr">10: </span><span style="color: #dcaeea;">w</span> = dw(year, height, [-<span style="color: #da8548; font-weight: bold;">20</span>, <span style="color: #da8548; font-weight: bold;">70</span>])
<span class="linenr">11: </span><span style="color: #c678dd;">print</span>(w)
</pre>
</div>

<pre class="example">
(-18134.659799999998, -917.54)
</pre>

<p>
結果分別是 \(w_0, w_1\) 方向的斜率，可以看出斜率都非常小，且 \(w_0\) 斜率比 \(w_1\) 方向的斜度更大，這與由圖<a href="#orgc973a77">18</a>觀察結果一致。
</p>
</div>
</div>
<div id="outline-container-orgc2deaae" class="outline-3">
<h3 id="orgc2deaae"><span class="section-number-3">5.2.</span> 實作</h3>
<div class="outline-text-3" id="text-5-2">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span style="color: #dcaeea;">year</span> = np.array([<span style="color: #da8548; font-weight: bold;">13.3</span>, <span style="color: #da8548; font-weight: bold;">16.2</span>, <span style="color: #da8548; font-weight: bold;">10.9</span>, <span style="color: #da8548; font-weight: bold;">28.7</span>, <span style="color: #da8548; font-weight: bold;">14.2</span>, <span style="color: #da8548; font-weight: bold;">11.7</span>, <span style="color: #da8548; font-weight: bold;">26.6</span>, <span style="color: #da8548; font-weight: bold;">22.4</span>, <span style="color: #da8548; font-weight: bold;">18.3</span>, <span style="color: #da8548; font-weight: bold;">20.4</span>]).reshape([-<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>])
<span style="color: #dcaeea;">height</span> = np.array([<span style="color: #da8548; font-weight: bold;">163.61</span>, <span style="color: #da8548; font-weight: bold;">168.53</span>, <span style="color: #da8548; font-weight: bold;">155.06</span>, <span style="color: #da8548; font-weight: bold;">168.3</span> ,<span style="color: #da8548; font-weight: bold;">158.98</span>, <span style="color: #da8548; font-weight: bold;">158.23</span>, <span style="color: #da8548; font-weight: bold;">165.27</span>, <span style="color: #da8548; font-weight: bold;">170.83</span>,  <span style="color: #da8548; font-weight: bold;">161.31</span>, <span style="color: #da8548; font-weight: bold;">163.58</span>])

<span style="color: #51afef;">def</span> <span style="color: #c678dd;">mse</span>(x, t, w):
    <span style="color: #dcaeea;">y</span> = w[<span style="color: #da8548; font-weight: bold;">0</span>] * x + w[<span style="color: #da8548; font-weight: bold;">1</span>]
    <span style="color: #dcaeea;">mse</span> = np.mean((y - t)**<span style="color: #da8548; font-weight: bold;">2</span>)
    <span style="color: #51afef;">return</span> mse

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#22343;&#26041;&#24046;&#30340;&#26799;&#24230;</span>
<span style="color: #51afef;">def</span> <span style="color: #c678dd;">dw</span>(x, y, w):
    <span style="color: #dcaeea;">yhat</span> = w[<span style="color: #da8548; font-weight: bold;">0</span>]*x + w[<span style="color: #da8548; font-weight: bold;">1</span>]
    <span style="color: #dcaeea;">d_w0</span> = <span style="color: #da8548; font-weight: bold;">2</span>*np.mean((yhat-y)*x)
    <span style="color: #dcaeea;">d_w1</span> = <span style="color: #da8548; font-weight: bold;">2</span>*np.mean(yhat-y)
    <span style="color: #51afef;">return</span> d_w0, d_w1

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#26799;&#24230;&#27861; ------------------------------------</span>
<span style="color: #51afef;">def</span> <span style="color: #c678dd;">fit_gd</span>(x, y):
    <span style="color: #dcaeea;">w_init</span> = [-<span style="color: #da8548; font-weight: bold;">20</span>, <span style="color: #da8548; font-weight: bold;">70</span>]  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21021;&#22987;&#21443;&#25976;</span>
    <span style="color: #dcaeea;">alpha</span> = <span style="color: #da8548; font-weight: bold;">0.001</span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23416;&#32722;&#29575;</span>
    <span style="color: #dcaeea;">tau_max</span> = <span style="color: #da8548; font-weight: bold;">100000</span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#37325;&#35079;&#30340;&#26368;&#22823;&#27425;&#25976;</span>
    <span style="color: #dcaeea;">eps</span> = <span style="color: #da8548; font-weight: bold;">0.1</span>  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20572;&#27490;&#37325;&#35079;&#30340;&#26799;&#24230;&#32085;&#23565;&#20540;&#30340;&#38309;&#20540;</span>
    <span style="color: #dcaeea;">w_hist</span> = np.zeros([tau_max, <span style="color: #da8548; font-weight: bold;">2</span>])
    <span style="color: #dcaeea;">w_hist</span>[<span style="color: #da8548; font-weight: bold;">0</span>, :] = w_init
    <span style="color: #51afef;">for</span> tau <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(<span style="color: #da8548; font-weight: bold;">1</span>, tau_max):
        <span style="color: #dcaeea;">dmse</span> = dw(x, y, w_hist[tau - <span style="color: #da8548; font-weight: bold;">1</span>])
        <span style="color: #dcaeea;">w_hist</span>[tau, <span style="color: #da8548; font-weight: bold;">0</span>] = w_hist[tau - <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">0</span>] - alpha * dmse[<span style="color: #da8548; font-weight: bold;">0</span>]
        <span style="color: #dcaeea;">w_hist</span>[tau, <span style="color: #da8548; font-weight: bold;">1</span>] = w_hist[tau - <span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #da8548; font-weight: bold;">1</span>] - alpha * dmse[<span style="color: #da8548; font-weight: bold;">1</span>]
        <span style="color: #51afef;">if</span> <span style="color: #c678dd;">max</span>(np.absolute(dmse)) &lt; eps: <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32080;&#26463;&#21028;&#26039;</span>
            <span style="color: #51afef;">break</span>
    <span style="color: #dcaeea;">w0</span> = w_hist[tau, <span style="color: #da8548; font-weight: bold;">0</span>]
    <span style="color: #dcaeea;">w1</span> = w_hist[tau, <span style="color: #da8548; font-weight: bold;">1</span>]
    <span style="color: #dcaeea;">w_hist</span> = w_hist[:tau, :]
    <span style="color: #51afef;">return</span> w0, w1, dmse, w_hist

<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35519;&#29992;&#26799;&#24230;&#27861;</span>
<span style="color: #dcaeea;">W0</span>, <span style="color: #dcaeea;">W1</span>, <span style="color: #dcaeea;">dMSE</span>, <span style="color: #dcaeea;">W_history</span> = fit_gd(year, height)
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'&#37325;&#35079;&#27425;&#25976; {0}'</span>.<span style="color: #c678dd;">format</span>(W_history.shape[<span style="color: #da8548; font-weight: bold;">0</span>]))
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'W=[{0:.6f}, {1:.6f}]'</span>.<span style="color: #c678dd;">format</span>(W0, W1))
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'dMSE=[{0:.6f}, {1:.6f}]'</span>.<span style="color: #c678dd;">format</span>(dMSE[<span style="color: #da8548; font-weight: bold;">0</span>], dMSE[<span style="color: #da8548; font-weight: bold;">1</span>]))
<span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'MSE={0:.6f}'</span>.<span style="color: #c678dd;">format</span>(mse(year, height, [W0, W1])))
</pre>
</div>

<pre class="example">
重複次數 27678
W=[0.026711, 162.832008]
dMSE=[0.004964, -0.099983]
MSE=22.955476
</pre>
</div>
</div>
</div>
<div id="outline-container-org0e87834" class="outline-2">
<h2 id="org0e87834"><span class="section-number-2">6.</span> 線性迴歸實作: 波士頓房價預測</h2>
<div class="outline-text-2" id="text-6">
<p>
本例中部份程式碼及文字來自<a href="https://medium.com/li-ting-liao-tiffany/python-%E5%BF%AB%E9%80%9F%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-boston-housing%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9-9c535fb7ceb7">What impacts Boston Housing Prices</a>
</p>
</div>
<div id="outline-container-org0760f1c" class="outline-3">
<h3 id="org0760f1c"><span class="section-number-3">6.1.</span> 下載資料</h3>
<div class="outline-text-3" id="text-6-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">housing</span> = pd.read_csv(<span style="color: #98be65;">'https://raw.githubusercontent.com/letranger/AI/gh-pages/Downloads/boston_housing.csv'</span>)
</pre>
</div>

<p>
也可以用tensorflow的load_data()直接下載，但這組沒有column title
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #51afef;">from</span> tensorflow.keras.datasets <span style="color: #51afef;">import</span> boston_housing
<span class="linenr">3: </span>
<span class="linenr">4: </span>(train_x, train_y), (<span style="color: #dcaeea;">test_x</span>, <span style="color: #dcaeea;">test_y</span>) = boston_housing.load_data()
</pre>
</div>
</div>
</div>
<div id="outline-container-orgfa2c280" class="outline-3">
<h3 id="orgfa2c280"><span class="section-number-3">6.2.</span> 大概觀察一下資料集</h3>
<div class="outline-text-3" id="text-6-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(housing))
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(housing.shape)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(housing.iloc[<span style="color: #da8548; font-weight: bold;">0</span>])
</pre>
</div>

<pre class="example" id="org4a20117">
&lt;class 'pandas.core.frame.DataFrame'&gt;
(506, 14)
crim         0.00632
zn          18.00000
indus        2.31000
chas         0.00000
nox          0.53800
rm           6.57500
age         65.20000
dis          4.09000
rad          1.00000
tax        296.00000
ptratio     15.30000
b          396.90000
lstat        4.98000
medv        24.00000
Name: 0, dtype: float64
</pre>
<p>
這個資料集共有506筆資料，前13個為特徵值，最後一個medv為房價。其他特徵值分別代表:
</p>
<ul class="org-ul">
<li>CRIM: per capita crime rate by town</li>
<li>ZN: proportion of residential land zoned for lots over 25,000 sq.ft.</li>
<li>INDUS: proportion of non-retail business acres per town</li>
<li>CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li>
<li>NOX: nitric oxides concentration (parts per 10 million)</li>
<li>RM: average number of rooms per dwelling</li>
<li>AGE: proportion of owner-occupied units built prior to 1940</li>
<li>DIS: weighted distances to five Boston employment centres</li>
<li>RAD: index of accessibility to radial highways</li>
<li>TAX: full-value property-tax rate per $10,000</li>
<li>PTRATIO: pupil-teacher ratio by town</li>
<li>B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town</li>
<li>LSTAT: % lower status of the population</li>
<li>MEDV: Median value of owner-occupied homes in $1000&rsquo;s</li>
</ul>
</div>
</div>
<div id="outline-container-org97e2342" class="outline-3">
<h3 id="org97e2342"><span class="section-number-3">6.3.</span> 資料預處理</h3>
<div class="outline-text-3" id="text-6-3">
</div>
<div id="outline-container-orga9aa801" class="outline-4">
<h4 id="orga9aa801"><span class="section-number-4">6.3.1.</span> 處理缺漏值</h4>
<div class="outline-text-4" id="text-6-3-1">
<p>
快速檢查是否有缺漏值
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(housing.isnull().<span style="color: #c678dd;">sum</span>())
</pre>
</div>
<pre class="example" id="orga4367a2">
crim        0
zn          0
indus       0
chas        0
nox         0
rm          0
age         0
dis         0
rad         0
tax         0
ptratio     0
b           0
lstat       0
medv       54
dtype: int64
</pre>
<p>
刪掉有缺失值的資料
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span>housing.dropna(axis=<span style="color: #da8548; font-weight: bold;">0</span>, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(housing.isnull().<span style="color: #c678dd;">sum</span>())
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(housing.shape)
</pre>
</div>

<pre class="example" id="org0e9b58c">
crim       0
zn         0
indus      0
chas       0
nox        0
rm         0
age        0
dis        0
rad        0
tax        0
ptratio    0
b          0
lstat      0
medv       0
dtype: int64
(452, 14)
</pre>
</div>
</div>
<div id="outline-container-orge45d573" class="outline-4">
<h4 id="orge45d573"><span class="section-number-4">6.3.2.</span> 資料標準化</h4>
<div class="outline-text-4" id="text-6-3-2">
<p>
由第一筆訓練資料特徵housing.iloc[0]可以看出，每項特徵值的差異甚大，我們可以先對這些資料特徵進行標準化：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(housing.iloc[<span style="color: #da8548; font-weight: bold;">0</span>,:-<span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">mean</span> = housing.iloc[:,:-<span style="color: #da8548; font-weight: bold;">1</span>].mean(axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">4: </span>housing.<span style="color: #dcaeea;">iloc</span>[:,:-<span style="color: #da8548; font-weight: bold;">1</span>] -= mean
<span class="linenr">5: </span><span style="color: #dcaeea;">std</span> = housing.iloc[:,:-<span style="color: #da8548; font-weight: bold;">1</span>].std(axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">6: </span>housing.<span style="color: #dcaeea;">iloc</span>[:,:-<span style="color: #da8548; font-weight: bold;">1</span>] /= std
<span class="linenr">7: </span>
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(housing.iloc[<span style="color: #da8548; font-weight: bold;">0</span>,:-<span style="color: #da8548; font-weight: bold;">1</span>])
</pre>
</div>

<pre class="example" id="orgb4cc171">
crim         0.00632
zn          18.00000
indus        2.31000
chas         0.00000
nox          0.53800
rm           6.57500
age         65.20000
dis          4.09000
rad          1.00000
tax        296.00000
ptratio     15.30000
b          396.90000
lstat        4.98000
Name: 0, dtype: float64
&lt;string&gt;:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0     -6.823009
1     -5.823009
2     -5.823009
3     -4.823009
4     -4.823009
         ...
501   -6.823009
502   -6.823009
503   -6.823009
504   -6.823009
505   -6.823009
Name: rad, Length: 452, dtype: float64' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
crim      -0.566733
zn         0.217000
indus     -1.176220
chas      -0.289391
nox       -0.024739
rm         0.347120
age       -0.012727
dis        0.022210
rad       -0.904489
tax       -0.538187
ptratio   -1.339563
b          0.394920
lstat     -1.049614
Name: 0, dtype: float64
</pre>
</div>
</div>
</div>
<div id="outline-container-org212864d" class="outline-3">
<h3 id="org212864d"><span class="section-number-3">6.4.</span> 觀察資料</h3>
<div class="outline-text-3" id="text-6-4">
</div>
<div id="outline-container-org2eb75ee" class="outline-4">
<h4 id="org2eb75ee"><span class="section-number-4">6.4.1.</span> 初步看一下房價的分佈</h4>
<div class="outline-text-4" id="text-6-4-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span class="linenr">3: </span>
<span class="linenr">4: </span>sns.histplot(housing[<span style="color: #98be65;">'medv'</span>])
<span class="linenr">5: </span>plt.savefig(<span style="color: #98be65;">"images/housing-price.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="orge2e6b0d" class="figure">
<p><img src="images/housing-price.png" alt="housing-price.png" width="500" />
</p>
<p><span class="figure-number">Figure 19: </span>房價分佈概況</p>
</div>
</div>
</div>
<div id="outline-container-org1cd57f2" class="outline-4">
<h4 id="org1cd57f2"><span class="section-number-4">6.4.2.</span> 各特徵值間的關係</h4>
<div class="outline-text-4" id="text-6-4-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">correlation_matrix</span> = housing.corr().<span style="color: #c678dd;">round</span>(<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">annot = True &#35731;&#25105;&#20497;&#21487;&#20197;&#25226;&#25976;&#23383;&#27161;&#36914;&#27599;&#20491;&#26684;&#23376;&#35041;</span>
<span class="linenr">3: </span>sns.heatmap(data=correlation_matrix, annot = <span style="color: #a9a1e1;">True</span>)
<span class="linenr">4: </span>plt.savefig(<span style="color: #98be65;">"images/housing-corr.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="org4d0b08f" class="figure">
<p><img src="images/housing-corr.png" alt="housing-corr.png" width="500" />
</p>
<p><span class="figure-number">Figure 20: </span>特徵值間的闗係</p>
</div>

<p>
由圖<a href="#org4d0b08f">20</a>可以看出：
</p>
<ul class="org-ul">
<li>跟MEDV（房價）高度相關的是LSTAT（中低收入戶佔當地居住人口的比例）和RM（房子有幾間房間）這兩個變數。</li>
<li>此外也看到DIS（到波士頓商業中心的距離）和AGE（屋齡），INDUS（非零售業土地使用比例）和ZN（居住使用土地比例）這兩組變數有多元共線性問題，所以未來如果要做其他模型，避免同時使用這兩組中的變數。</li>
</ul>

<p>
所以目前可以用LSTAT和RM來做出預測MEDV的模型。再次把這兩個變數跟房價變數的關係畫出來，可以看到兩者和房價變數都接近線性關係：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35373;&#23450;&#25972;&#24373;&#22294;&#30340;&#38263;&#23532;</span>
<span class="linenr"> 2: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">20</span>, <span style="color: #da8548; font-weight: bold;">10</span>))
<span class="linenr"> 3: </span><span style="color: #dcaeea;">features</span> = [<span style="color: #98be65;">'lstat'</span>, <span style="color: #98be65;">'rm'</span>]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">target</span> = housing[<span style="color: #98be65;">'medv'</span>]
<span class="linenr"> 5: </span><span style="color: #51afef;">for</span> i, col <span style="color: #51afef;">in</span> <span style="color: #c678dd;">enumerate</span>(features):
<span class="linenr"> 6: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25490;&#29256;1 row, 2 columns, nth plot&#65306;&#22312;jupyter notebook&#19978;&#20841;&#24373;&#20006;&#25490;</span>
<span class="linenr"> 7: </span>    plt.subplot(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(features) , i+<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 8: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">add data column into plot</span>
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">x</span> = housing[col]
<span class="linenr">10: </span>    <span style="color: #dcaeea;">y</span> = target
<span class="linenr">11: </span>    plt.scatter(x, y, marker=<span style="color: #98be65;">'o'</span>)
<span class="linenr">12: </span>    plt.title(col)
<span class="linenr">13: </span>    plt.xlabel(col)
<span class="linenr">14: </span>    plt.ylabel(<span style="color: #98be65;">'medv'</span>)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">'images/housing-2var.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="orgaca10ee" class="figure">
<p><img src="images/housing-2var.png" alt="housing-2var.png" width="600" />
</p>
<p><span class="figure-number">Figure 21: </span>Caption</p>
</div>
</div>
</div>
<div id="outline-container-org664bf38" class="outline-4">
<h4 id="org664bf38"><span class="section-number-4">6.4.3.</span> 準備訓練用的資料</h4>
<div class="outline-text-4" id="text-6-4-3">
<p>
先拿兩項特徵值來試一下水溫: lstat和rm
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">2: </span><span style="color: #dcaeea;">X</span> = housing[[<span style="color: #98be65;">'lstat'</span>, <span style="color: #98be65;">'rm'</span>]]
<span class="linenr">3: </span><span style="color: #dcaeea;">Y</span> = housing[<span style="color: #98be65;">'medv'</span>]
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(X)
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(Y)
</pre>
</div>

<pre class="example" id="org737810c">
        lstat        rm
0   -1.049614  0.347120
1   -0.373898  0.116169
2   -1.203924  1.261927
3   -1.380974  0.981486
4   -0.992763  1.204939
..        ...       ...
501 -0.287809  0.374115
502 -0.383644 -0.335236
503 -0.942409  0.948493
504 -0.805966  0.675551
505 -0.578562 -0.470207

[452 rows x 2 columns]
0      24.0
1      21.6
2      34.7
3      33.4
4      36.2
       ...
501    22.4
502    20.6
503    23.9
504    22.0
505    11.9
Name: medv, Length: 452, dtype: float64
</pre>
</div>
</div>
</div>
<div id="outline-container-org1b0cef0" class="outline-3">
<h3 id="org1b0cef0"><span class="section-number-3">6.5.</span> 分割訓練集與測試集</h3>
<div class="outline-text-3" id="text-6-5">
<p>
訓練集佔80%、測試集佔20%
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">train_test_split</span>
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span class="linenr">3: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">Y_train</span>, <span style="color: #dcaeea;">Y_test</span> = train_test_split(X, Y, test_size = <span style="color: #da8548; font-weight: bold;">0.2</span>, random_state=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20877;&#29992;.shape&#30475;&#20999;&#20986;&#20358;&#30340;&#36039;&#26009;&#30340;&#38263;&#30456;&#65288;&#21015;, &#27396;&#65289;</span>
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(X_train.shape)
<span class="linenr">6: </span><span style="color: #c678dd;">print</span>(X_test.shape)
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(Y_train.shape)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(Y_test.shape)
</pre>
</div>

<pre class="example">
(361, 2)
(91, 2)
(361,)
(91,)
</pre>
</div>
</div>
<div id="outline-container-org4519c8e" class="outline-3">
<h3 id="org4519c8e"><span class="section-number-3">6.6.</span> 建立模型</h3>
<div class="outline-text-3" id="text-6-6">
<p>
new出一個LinearRegression的物件後，用特徵變數的訓練資料和目標變數的訓練資料產生一個模型。接著將特徵變數的測試資料倒進這個新產生的模型當中，得到預測的目標變數資料<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Modeling</span>
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr">3: </span><span style="color: #dcaeea;">reg</span> = LinearRegression()<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23416;&#32722;/&#35347;&#32244;Fitting linear model</span>
<span class="linenr">4: </span>reg.fit(X_train,Y_train)
</pre>
</div>
</div>
</div>
<div id="outline-container-org012c164" class="outline-3">
<h3 id="org012c164"><span class="section-number-3">6.7.</span> 測試效能</h3>
<div class="outline-text-3" id="text-6-7">
<p>
將這個預測的目標變數資料（預測結果）和目標變數的測試資料（真實結果）做R2-score：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38928;&#28204;&#32080;&#26524;Predicting using the linear model</span>
<span class="linenr">2: </span>reg.predict(X_test)<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30495;&#23526;&#32080;&#26524;&#65306;Y_test# &#28204;&#35430;&#28310;&#30906;&#24230;&#65306;</span>
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'R2:'</span>, reg.score(X_test, Y_test))
</pre>
</div>

<pre class="example">
R2: 0.6048366146231109
</pre>

<p>
得到的這個R2-score讓我們可以知道特徵變數對於目標變數的解釋程度為何，而越接近1代表越準確。這裡大約是66%，解釋程度算是相當好的<sup><a id="fnr.2.100" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>。
</p>
</div>
<div id="outline-container-org1abec41" class="outline-4">
<h4 id="org1abec41"><span class="section-number-4">6.7.1.</span> 模型效能視覺化</h4>
<div class="outline-text-4" id="text-6-7-1">
<p>
把剛剛的預測的目標變數資料和測試的目標變數資料畫成散佈圖
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">plotting the y_test vs y_pred</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">Y_pred</span> = reg.predict(X_test)
<span class="linenr"> 3: </span>plt.cla()
<span class="linenr"> 4: </span>plt.tight_layout()
<span class="linenr"> 5: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">10</span>,<span style="color: #da8548; font-weight: bold;">8</span>))
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span>plt.scatter(Y_pred, Y_test)
<span class="linenr"> 8: </span>plt.xlabel(<span style="color: #98be65;">'Y_pred'</span>)
<span class="linenr"> 9: </span>plt.ylabel(<span style="color: #98be65;">'Y_test'</span>)
<span class="linenr">10: </span>plt.savefig(<span style="color: #98be65;">'images/boston-perf.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="org767cca1" class="figure">
<p><img src="images/boston-perf.png" alt="boston-perf.png" width="500" />
</p>
<p><span class="figure-number">Figure 22: </span>Caption</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org1cf9b6b" class="outline-3">
<h3 id="org1cf9b6b"><span class="section-number-3">6.8.</span> 找出線性模型</h3>
<div class="outline-text-3" id="text-6-8">
<p>
由LinearRegression()找出線性模型的intercept和coefficient
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'intercept:'</span>,reg.intercept_)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'coefficient::'</span>,reg.coef_)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'lstat:'</span>,reg.coef_[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'rm:'</span>,reg.coef_[<span style="color: #da8548; font-weight: bold;">1</span>])
</pre>
</div>

<pre class="example">
intercept: 23.662167506495486
coefficient:: [-3.2284783   4.66331239]
lstat: -3.228478297753095
rm: 4.663312387946355
</pre>

<p>
線性模型為：\(medv=23.66 + -3.22 \times lstat + 4.66 \times rm + error\)
</p>
</div>
</div>
</div>
<div id="outline-container-orgbe57fb8" class="outline-2">
<h2 id="orgbe57fb8"><span class="section-number-2">7.</span> [作業]依據期中考成績預測期末考成績&#xa0;&#xa0;&#xa0;<span class="tag"><span class="TNFSH">TNFSH</span></span></h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org6ed016b" class="outline-3">
<h3 id="org6ed016b"><span class="section-number-3">7.1.</span> Data</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>線上資料: <a href="https://letranger.github.io/AI/2023A-CS-Data.csv">https://letranger.github.io/AI/PythonScores.csv</a></li>
<li>資料中有424筆記錄，每筆記錄分別為學生的
<ol class="org-ol">
<li>id: 學號</li>
<li>class: 平時成績</li>
<li>task: 作業成績</li>
<li>mid: 期中考成績</li>
<li>final: 期末考成績</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org4a3e0a7" class="outline-3">
<h3 id="org4a3e0a7"><span class="section-number-3">7.2.</span> Task</h3>
<div class="outline-text-3" id="text-7-2">
<p>
你的任務是建立一個模型，輸入一個或多個特徵值(class, task, mid)來預測期末考成績(final)，其他相關任務包括:
</p>
<ol class="org-ol">
<li>部份學生的期中、期末考有缺考行為，請將這些缺考記錄填入0分</li>
<li>畫出所有特徵資料的分佈狀況(直方圖)</li>
<li>將所有分數間的相關以視覺化方式表現出來</li>
<li>將資料集分割為訓練集(70%)及測試集(30%)</li>
<li>請自行決定你要用多少個特徵值來預測，並以測試集來評估模型效能，輸出分數(R2-score)</li>
<li>列出你找出的模型方程式</li>
</ol>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Hands-On Machine Learning with Scikit-Learn: Aurelien Geron
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/li-ting-liao-tiffany/python-%E5%BF%AB%E9%80%9F%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-boston-housing%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9-9c535fb7ceb7">What impacts Boston Housing Prices</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2024-02-10 Sat 17:05</p>
</div>
</body>
</html>
