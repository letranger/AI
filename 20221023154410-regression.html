<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-02-21 Fri 11:08 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>迴歸</title>
<meta name="author" content="Yung-Chin Yen" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="../css/muse.css" />
<script src="../css/copy_code.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">迴歸</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org2a13792">1. 迴歸原理</a>
<ul>
<li><a href="#org53691e4">1.1. Step 1: Model, Data</a></li>
<li><a href="#org6df016f">1.2. Step 2: Goodness of Function</a></li>
</ul>
</li>
<li><a href="#org5b638c4">2. 線性迴歸: 學期成績預估</a>
<ul>
<li><a href="#org06a2695">2.1. 函數: AI的本質</a></li>
<li><a href="#org70706bc">2.2. 逐步找出最佳的a</a></li>
<li><a href="#orge093652">2.3. 兩項成績推估</a></li>
<li><a href="#org171c720">2.4. 神經網路的視角</a></li>
</ul>
</li>
<li><a href="#orgc7a4bdc">3. 線性迴歸實作: 波士頓房價預測</a>
<ul>
<li><a href="#orgeee5228">3.1. 下載資料</a></li>
<li><a href="#orgc40a4c4">3.2. 大概觀察一下資料集</a></li>
<li><a href="#orgc4a2248">3.3. 資料預處理</a></li>
<li><a href="#orge6a16cf">3.4. 觀察資料</a></li>
<li><a href="#orge3affc9">3.5. 分割訓練集與測試集</a></li>
<li><a href="#org6a77f57">3.6. 建立模型</a></li>
<li><a href="#org3562daf">3.7. 測試效能</a></li>
<li><a href="#org49af693">3.8. 找出線性模型</a></li>
</ul>
</li>
<li><a href="#org82ccafb">4. 關於迴歸模型的特徵選擇</a>
<ul>
<li><a href="#org0913509">4.1. 前向選擇法(Forward Selection)</a></li>
<li><a href="#org0d9e354">4.2. 後向選擇法(Backward Selection)</a></li>
<li><a href="#org458506d">4.3. 特徵選擇的注意事項</a></li>
<li><a href="#org803c498">4.4. 多重共線性(Multicollinearity)</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org2a13792" class="outline-2">
<h2 id="org2a13792"><span class="section-number-2">1.</span> 迴歸原理</h2>
<div class="outline-text-2" id="text-1">
<p>
練習投藍的時後，我們需要知道籃筐位置，誤差多少，1做出丟球的修正。
做 Machine Learning 也是一樣道理，我們需要 :
</p>
<ul class="org-ul">
<li>建立模型</li>
<li>計算誤差: 在<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>中，我們用loss function來計算</li>
<li>做出修正: 在<a href="20221023101456-機器學習.html#ID-20221023T101456.955364">機器學習</a>中，我們用optimizer來不斷對模型進行修正</li>
</ul>
</div>
<div id="outline-container-org53691e4" class="outline-3">
<h3 id="org53691e4"><span class="section-number-3">1.1.</span> Step 1: Model, Data</h3>
<div class="outline-text-3" id="text-1-1">
<ol class="org-ol">
<li>Model: \(y = w*x+b\)</li>
<li>Data: 找一堆現成的資料</li>
</ol>
</div>
</div>
<div id="outline-container-org6df016f" class="outline-3">
<h3 id="org6df016f"><span class="section-number-3">1.2.</span> Step 2: Goodness of Function</h3>
<div class="outline-text-3" id="text-1-2">
<ol class="org-ol">
<li>Training Data</li>
<li>Loss function L: 越小越好
input: a function / output: how bad it is</li>
<li>Pick the <b>Best Function</b> :
\(f* = \arg\min L(f)\)
上述可以微分來求最佳解，即求 function L 的最小值</li>
<li>數值最佳解: Gradient Descent(找拋物線/面最低點)</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org5b638c4" class="outline-2">
<h2 id="org5b638c4"><span class="section-number-2">2.</span> 線性迴歸: 學期成績預估</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org06a2695" class="outline-3">
<h3 id="org06a2695"><span class="section-number-3">2.1.</span> 函數: AI的本質</h3>
<div class="outline-text-3" id="text-2-1">
<p>
人工智慧本質上就是在找出一個特定函數。例如，我們想利用人工智慧來預估自己這個學期的資訊科成績，其實相當於在找一個類似這樣的函數：
\[f(期中考成績,期末考成績)→學期總成績\]
有了這個函數，只要我們輸入這學期的兩次段成績，就能算出自己的學期總成績。但像這樣的函數f有無限多個，其中一種可能的計算方式如下：
\[期末成績=0.4×期中考成績+0.6×期末考成績\]
，此處的0.4, 0.6就稱為這個函數的參數（parameter）。
</p>

<p>
為了找出這個函數，我們首先應蒐集歷屆學長姐的成績資料（包括兩次段考平均成績與學期總成績），這些資料稱之為訓練資料（training data）。在將訓練資料視覺化後，我們發現x與y的分佈如圖<a href="#org9c74842">1</a>所示（假設我們詢問了10位學長姐、收集了10筆訓練資料），初步猜測二者可能存在線性關係。接下來的任務就是畫出一條能儘量接近圖上所有資料點的線，也就是找出最佳的參數a（即這條迴歸線的斜率）。
</p>


<div id="org9c74842" class="figure">
<p><img src="images/2scores.png" alt="2scores.png" width="500" />
</p>
<p><span class="figure-number">Figure 1: </span>兩次段考平均與學期總成績關係</p>
</div>
</div>
</div>
<div id="outline-container-org70706bc" class="outline-3">
<h3 id="org70706bc"><span class="section-number-3">2.2.</span> 逐步找出最佳的a</h3>
<div class="outline-text-3" id="text-2-2">
<p>
雖然在此例中最佳的a可以很快用數學公式求出，但此處我們打算介紹另一種逐步找出最佳a的方式，步驟詳列如下：
</p>
</div>
<div id="outline-container-org8df16f8" class="outline-4">
<h4 id="org8df16f8"><span class="section-number-4">2.2.1.</span> a=0.5</h4>
<div class="outline-text-4" id="text-2-2-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'cc'</span>)
</pre>
</div>

<pre class="example">
cc
</pre>


<p>
首先，面對未知的困難，我們要有嚴格的解題SOP，也就是要遵循「科學、理性、務實」的精神：閉著眼睛隨便給個 \(a\)。例如：a=0.5，畫出的迴歸線結果如圖<a href="#orgae5fd25">2</a>。
</p>

<div id="orgae5fd25" class="figure">
<p><img src="images/2scores_with_regression.png" alt="2scores_with_regression.png" width="500" />
</p>
<p><span class="figure-number">Figure 2: </span>a=0.5的迴歸線</p>
</div>

<p>
有了這條線，我們就可以找出這10筆資料與這條線有多遠。理想狀況下我們希望每個點都離線越近越好，把所有點與迴歸線的距離（圖<a href="#orgae5fd25">2</a>中的橘色線段）加總起來，我們把它稱為誤差。此處以均方差（Mean Squared Error, MSE）來計算，誤差值為367.76。MSE公式如下：
\[MSE=\frac{1}{n}\sum_{i=1}^{n}{(y_i-\widehat{y_i})}^2\]
，這裡的MSE就是這個模型的損失函數（Loss Function） 。
</p>
</div>
</div>
<div id="outline-container-orgdec3474" class="outline-4">
<h4 id="orgdec3474"><span class="section-number-4">2.2.2.</span> a=0.4, a=0.6</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
但是目前的a(0.5)是最好的嗎？我們可以試著調整a值，對它各加、減0.1，再來觀察誤差的變化，結果如圖<a href="#org3ecab49">3</a>，可以發現a再大一些結果似乎會更好。
</p>

<div id="org3ecab49" class="figure">
<p><img src="images/2scores_with_regression12.png" alt="2scores_with_regression12.png" width="800" />
</p>
<p><span class="figure-number">Figure 3: </span>a=0.4 v.s. a=0.6</p>
</div>
</div>
</div>
<div id="outline-container-org86aca4c" class="outline-4">
<h4 id="org86aca4c"><span class="section-number-4">2.2.3.</span> 全部的a</h4>
<div class="outline-text-4" id="text-2-2-3">
<p>
當我們把全部合理的  a  值（如\(0.3 \le a \le 1.4\)）對應的損失函數逐一計算出來後，就可以將這些結果畫成一條如圖<a href="#orga3fdd72">4</a>的曲線，這就是這個模型的損失函數曲線（Loss Function Curve）。不難看出：只要將a逐步往損失函數較小的方向調整，這個模型的預測效果就會更好。另一種調整a值的方式是透過資料點在曲線上的切線（圖中綠色虛線）斜率來判斷該往左或右移動a值，直到找到切線斜率為0的點，這便是曲線的最低點，也是最佳a值。此函數如下，也是我們用來預估分數的模型：
\[y=f\left(x\right)=0.84x\]
</p>


<div id="orga3fdd72" class="figure">
<p><img src="images/scoreLoss.png" alt="scoreLoss.png" width="500" />
</p>
<p><span class="figure-number">Figure 4: </span>合理a值畫出的誤差函數</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orge093652" class="outline-3">
<h3 id="orge093652"><span class="section-number-3">2.3.</span> 兩項成績推估</h3>
<div class="outline-text-3" id="text-2-3">
<p>
如果老師的計分是針對期中期末考給予不同權重呢？那我們新的目標函數就要改成如下式子，此時的任務在求出最佳的參數a, b。
\[y=f\left(x\right)=ax_1+bx_2\]
，其中 \(x_1\) 為兩次段考平均成績, \(x_2\) 為學期總成績。
</p>

<p>
比照上述步驟的做法，我們可以求出所有合理的a, b值（0～1）及其所對應的損失函數，將結果畫成如圖 ‎2.2 5的曲面。實際求解時，一樣先隨機指定一組權重值a, b（圖<a href="#org933e2a4">5</a>藍色點），依該點在曲面上的斜率（此處稱為梯度，Gradient） ，沿著梯度的反方向往下找，就能找到這個曲面的最低點（圖<a href="#orga3fdd72">4</a>紅色點），該點便是函數的最佳參數。此種做法也就是神經網路中找出模型最佳參數的核心思想：梯度下降法（Gradient Descent）。
</p>


<div id="org933e2a4" class="figure">
<p><img src="images/3dScoreLoss.png" alt="3dScoreLoss.png" width="500" />
</p>
<p><span class="figure-number">Figure 5: </span>兩個參數時的誤差函數</p>
</div>
</div>
</div>
<div id="outline-container-org171c720" class="outline-3">
<h3 id="org171c720"><span class="section-number-3">2.4.</span> 神經網路的視角</h3>
<div class="outline-text-3" id="text-2-4">
<p>
從神經網路的角度來看，上述函數也可以視為如圖 ‎2.2 6的模型，模型中只有一層隱藏層，裡面只有一個神經元，輸出結果為期末成績，這便是一個能進行迴歸計算的神經網路。
</p>

<div id="org2438d0e" class="figure">
<p><img src="images/datapreprocessing.png" alt="datapreprocessing.png" />
</p>
</div>



<div id="org24b3300" class="figure">
<p><img src="images/scoreNN.png" alt="scoreNN.png" width="300" />
</p>
<p><span class="figure-number">Figure 6: </span>以兩項成績預估學期成績的神經網路</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgc7a4bdc" class="outline-2">
<h2 id="orgc7a4bdc"><span class="section-number-2">3.</span> 線性迴歸實作: 波士頓房價預測</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>本例中部份程式碼及文字來自<a href="https://medium.com/li-ting-liao-tiffany/python-%E5%BF%AB%E9%80%9F%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-boston-housing%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9-9c535fb7ceb7">What impacts Boston Housing Prices</a></li>
<li>本例使用資料集為 1970 年中期 Boston 郊區資料，包含犯罪率、當地財產稅等，用以預測某郊區房價中位數，本例有 506 筆資料，分為 404 個訓練樣本和 102 個測試樣本，但每個 feature 的單位不同，故須先進行資料預調整。</li>
</ul>
</div>
<div id="outline-container-orgeee5228" class="outline-3">
<h3 id="orgeee5228"><span class="section-number-3">3.1.</span> 下載資料</h3>
<div class="outline-text-3" id="text-3-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">housing</span> = pd.read_csv(<span style="color: #98be65;">'https://raw.githubusercontent.com/letranger/AI/gh-pages/Downloads/boston_housing.csv'</span>)
</pre>
</div>

<p>
也可以用tensorflow的load_data()直接下載，但這組沒有column title
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #51afef;">from</span> tensorflow.keras.datasets <span style="color: #51afef;">import</span> boston_housing
<span class="linenr">3: </span>
<span class="linenr">4: </span>(train_x, train_y), (<span style="color: #dcaeea;">test_x</span>, <span style="color: #dcaeea;">test_y</span>) = boston_housing.load_data()
</pre>
</div>
</div>
</div>
<div id="outline-container-orgc40a4c4" class="outline-3">
<h3 id="orgc40a4c4"><span class="section-number-3">3.2.</span> 大概觀察一下資料集</h3>
<div class="outline-text-3" id="text-3-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #c678dd;">type</span>(housing))
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(housing.shape)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(housing.iloc[<span style="color: #da8548; font-weight: bold;">0</span>])
</pre>
</div>

<pre class="example" id="orgc1aa52b">
&lt;class 'pandas.core.frame.DataFrame'&gt;
(506, 14)
crim         0.00632
zn          18.00000
indus        2.31000
chas         0.00000
nox          0.53800
rm           6.57500
age         65.20000
dis          4.09000
rad          1.00000
tax        296.00000
ptratio     15.30000
b          396.90000
lstat        4.98000
medv        24.00000
Name: 0, dtype: float64
</pre>

<p>
這個資料集共有506筆資料，前13個為特徵值，最後一個medv為房價。其他特徵值分別代表:
</p>
<ul class="org-ul">
<li>CRIM: 每個城鎮的人均犯罪率</li>
<li>ZN: 佔地超過 25,000 平方英尺的住宅用地比例</li>
<li>INDUS: 每個城鎮的非零售業商業用地比例(工業區)</li>
<li>CHAS: 查爾斯河虛擬變量（= 1 如果地段邊界是河流；否則為 0）</li>
<li>NOX: 一氧化氮濃度（每 1000 萬分之一）</li>
<li>RM: 每套住宅的平均房間數</li>
<li>AGE: 1940 年前建成的自有住宅單位比例</li>
<li>DIS: 到五個波士頓就業中心的加權距離</li>
<li>RAD: 徑向公路可達性指數</li>
<li>TAX: 每 $10,000 的全價房產稅率</li>
<li>PTRATIO: 每個城鎮的師生比例</li>
<li>B: 1000(Bk - 0.63)^2，其中 Bk 是每個城鎮的黑人比例</li>
<li>LSTAT: 低社會地位人口的百分比</li>
<li>MEDV: 房值（以 $1000 為單位）</li>
</ul>
</div>
</div>
<div id="outline-container-orgc4a2248" class="outline-3">
<h3 id="orgc4a2248"><span class="section-number-3">3.3.</span> 資料預處理</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<div id="outline-container-org3bb358f" class="outline-4">
<h4 id="org3bb358f"><span class="section-number-4">3.3.1.</span> 處理缺漏值</h4>
<div class="outline-text-4" id="text-3-3-1">
<p>
快速檢查是否有缺漏值
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(housing.isnull().<span style="color: #c678dd;">sum</span>())
</pre>
</div>
<pre class="example" id="orgb78f2ac">
crim        0
zn          0
indus       0
chas        0
nox         0
rm          0
age         0
dis         0
rad         0
tax         0
ptratio     0
b           0
lstat       0
medv       54
dtype: int64
</pre>
<p>
刪掉有缺失值的資料
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span>housing.dropna(axis=<span style="color: #da8548; font-weight: bold;">0</span>, inplace=<span style="color: #a9a1e1;">True</span>)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(housing.isnull().<span style="color: #c678dd;">sum</span>())
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(housing.shape)
</pre>
</div>

<pre class="example" id="org8e10899">
crim       0
zn         0
indus      0
chas       0
nox        0
rm         0
age        0
dis        0
rad        0
tax        0
ptratio    0
b          0
lstat      0
medv       0
dtype: int64
(452, 14)
</pre>
</div>
</div>
<div id="outline-container-orgce93c16" class="outline-4">
<h4 id="orgce93c16"><span class="section-number-4">3.3.2.</span> 資料標準化</h4>
<div class="outline-text-4" id="text-3-3-2">
<p>
由第一筆訓練資料特徵housing.iloc[0]可以看出，每項特徵值的差異甚大，我們可以先對這些資料特徵進行標準化：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(housing.iloc[<span style="color: #da8548; font-weight: bold;">0</span>,:-<span style="color: #da8548; font-weight: bold;">1</span>])
<span class="linenr">2: </span>
<span class="linenr">3: </span><span style="color: #dcaeea;">mean</span> = housing.iloc[:,:-<span style="color: #da8548; font-weight: bold;">1</span>].mean(axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">4: </span>housing.<span style="color: #dcaeea;">iloc</span>[:,:-<span style="color: #da8548; font-weight: bold;">1</span>] -= mean
<span class="linenr">5: </span><span style="color: #dcaeea;">std</span> = housing.iloc[:,:-<span style="color: #da8548; font-weight: bold;">1</span>].std(axis=<span style="color: #da8548; font-weight: bold;">0</span>)
<span class="linenr">6: </span>housing.<span style="color: #dcaeea;">iloc</span>[:,:-<span style="color: #da8548; font-weight: bold;">1</span>] /= std
<span class="linenr">7: </span>
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(housing.iloc[<span style="color: #da8548; font-weight: bold;">0</span>,:-<span style="color: #da8548; font-weight: bold;">1</span>])
</pre>
</div>

<pre class="example" id="orgaf7c35a">
crim         0.00632
zn          18.00000
indus        2.31000
chas         0.00000
nox          0.53800
rm           6.57500
age         65.20000
dis          4.09000
rad          1.00000
tax        296.00000
ptratio     15.30000
b          396.90000
lstat        4.98000
Name: 0, dtype: float64
&lt;string&gt;:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0     -6.823009
1     -5.823009
2     -5.823009
3     -4.823009
4     -4.823009
         ...
501   -6.823009
502   -6.823009
503   -6.823009
504   -6.823009
505   -6.823009
Name: rad, Length: 452, dtype: float64' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
crim      -0.566733
zn         0.217000
indus     -1.176220
chas      -0.289391
nox       -0.024739
rm         0.347120
age       -0.012727
dis        0.022210
rad       -0.904489
tax       -0.538187
ptratio   -1.339563
b          0.394920
lstat     -1.049614
Name: 0, dtype: float64
</pre>
</div>
</div>
</div>
<div id="outline-container-orge6a16cf" class="outline-3">
<h3 id="orge6a16cf"><span class="section-number-3">3.4.</span> 觀察資料</h3>
<div class="outline-text-3" id="text-3-4">
</div>
<div id="outline-container-orgec3fa4c" class="outline-4">
<h4 id="orgec3fa4c"><span class="section-number-4">3.4.1.</span> 初步看一下房價的分佈</h4>
<div class="outline-text-4" id="text-3-4-1">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr">2: </span><span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span class="linenr">3: </span>
<span class="linenr">4: </span>sns.histplot(housing[<span style="color: #98be65;">'medv'</span>])
<span class="linenr">5: </span>plt.savefig(<span style="color: #98be65;">"images/housing-price.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="org54f9e8c" class="figure">
<p><img src="images/housing-price.png" alt="housing-price.png" width="500" />
</p>
<p><span class="figure-number">Figure 7: </span>房價分佈概況</p>
</div>
</div>
</div>
<div id="outline-container-orga2b7aa3" class="outline-4">
<h4 id="orga2b7aa3"><span class="section-number-4">3.4.2.</span> 各特徵值間的關係</h4>
<div class="outline-text-4" id="text-3-4-2">
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #dcaeea;">correlation_matrix</span> = housing.corr().<span style="color: #c678dd;">round</span>(<span style="color: #da8548; font-weight: bold;">2</span>)
<span class="linenr">2: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">annot = True &#35731;&#25105;&#20497;&#21487;&#20197;&#25226;&#25976;&#23383;&#27161;&#36914;&#27599;&#20491;&#26684;&#23376;&#35041;</span>
<span class="linenr">3: </span>sns.heatmap(data=correlation_matrix, annot = <span style="color: #a9a1e1;">True</span>)
<span class="linenr">4: </span>plt.savefig(<span style="color: #98be65;">"images/housing-corr.png"</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>

<div id="org6f05fe6" class="figure">
<p><img src="images/housing-corr.png" alt="housing-corr.png" width="500" />
</p>
<p><span class="figure-number">Figure 8: </span>特徵值間的闗係</p>
</div>

<p>
由圖<a href="#org6f05fe6">8</a>可以看出：
</p>
<ul class="org-ul">
<li>跟MEDV（房價）高度相關的是LSTAT（中低收入戶佔當地居住人口的比例）和RM（房子有幾間房間）這兩個變數。</li>
<li>此外也看到DIS（到波士頓商業中心的距離）和AGE（屋齡），INDUS（非零售業土地使用比例）和ZN（居住使用土地比例）這兩組變數有多元共線性問題，所以未來如果要做其他模型，避免同時使用這兩組中的變數。</li>
</ul>

<p>
所以我們 <b>直覺的想法</b> 是：應該可以用LSTAT和RM來做出預測MEDV的模型。再次把這兩個變數跟房價變數的關係畫出來，可以看到兩者和房價變數都接近線性關係：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35373;&#23450;&#25972;&#24373;&#22294;&#30340;&#38263;&#23532;</span>
<span class="linenr"> 2: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">20</span>, <span style="color: #da8548; font-weight: bold;">10</span>))
<span class="linenr"> 3: </span><span style="color: #dcaeea;">features</span> = [<span style="color: #98be65;">'lstat'</span>, <span style="color: #98be65;">'rm'</span>]
<span class="linenr"> 4: </span><span style="color: #dcaeea;">target</span> = housing[<span style="color: #98be65;">'medv'</span>]
<span class="linenr"> 5: </span><span style="color: #51afef;">for</span> i, col <span style="color: #51afef;">in</span> <span style="color: #c678dd;">enumerate</span>(features):
<span class="linenr"> 6: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#25490;&#29256;1 row, 2 columns, nth plot&#65306;&#22312;jupyter notebook&#19978;&#20841;&#24373;&#20006;&#25490;</span>
<span class="linenr"> 7: </span>    plt.subplot(<span style="color: #da8548; font-weight: bold;">1</span>, <span style="color: #c678dd;">len</span>(features) , i+<span style="color: #da8548; font-weight: bold;">1</span>)
<span class="linenr"> 8: </span>    <span style="color: #5B6268;"># </span><span style="color: #5B6268;">add data column into plot</span>
<span class="linenr"> 9: </span>    <span style="color: #dcaeea;">x</span> = housing[col]
<span class="linenr">10: </span>    <span style="color: #dcaeea;">y</span> = target
<span class="linenr">11: </span>    plt.scatter(x, y, marker=<span style="color: #98be65;">'o'</span>)
<span class="linenr">12: </span>    plt.title(col)
<span class="linenr">13: </span>    plt.xlabel(col)
<span class="linenr">14: </span>    plt.ylabel(<span style="color: #98be65;">'medv'</span>)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">'images/housing-2var.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="orgc1311d6" class="figure">
<p><img src="images/housing-2var.png" alt="housing-2var.png" width="600" />
</p>
<p><span class="figure-number">Figure 9: </span>LSTAT和RM與房價的關係</p>
</div>
</div>
</div>
<div id="outline-container-org1f43662" class="outline-4">
<h4 id="org1f43662"><span class="section-number-4">3.4.3.</span> 準備訓練用的資料</h4>
<div class="outline-text-4" id="text-3-4-3">
<p>
先拿兩項特徵值來試一下水溫: lstat和rm
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr">2: </span><span style="color: #dcaeea;">X</span> = housing[[<span style="color: #98be65;">'lstat'</span>, <span style="color: #98be65;">'rm'</span>]]
<span class="linenr">3: </span><span style="color: #dcaeea;">Y</span> = housing[<span style="color: #98be65;">'medv'</span>]
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(X)
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(Y)
</pre>
</div>

<pre class="example" id="org992f6ae">
        lstat        rm
0   -1.049614  0.347120
1   -0.373898  0.116169
2   -1.203924  1.261927
3   -1.380974  0.981486
4   -0.992763  1.204939
..        ...       ...
501 -0.287809  0.374115
502 -0.383644 -0.335236
503 -0.942409  0.948493
504 -0.805966  0.675551
505 -0.578562 -0.470207

[452 rows x 2 columns]
0      24.0
1      21.6
2      34.7
3      33.4
4      36.2
       ...
501    22.4
502    20.6
503    23.9
504    22.0
505    11.9
Name: medv, Length: 452, dtype: float64
</pre>
</div>
</div>
</div>
<div id="outline-container-orge3affc9" class="outline-3">
<h3 id="orge3affc9"><span class="section-number-3">3.5.</span> 分割訓練集與測試集</h3>
<div class="outline-text-3" id="text-3-5">
<p>
訓練集佔80%、測試集佔20%
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">train_test_split</span>
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.model_selection <span style="color: #51afef;">import</span> train_test_split
<span class="linenr">3: </span><span style="color: #dcaeea;">X_train</span>, <span style="color: #dcaeea;">X_test</span>, <span style="color: #dcaeea;">Y_train</span>, <span style="color: #dcaeea;">Y_test</span> = train_test_split(X, Y, test_size = <span style="color: #da8548; font-weight: bold;">0.2</span>, random_state=<span style="color: #da8548; font-weight: bold;">5</span>)
<span class="linenr">4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20877;&#29992;.shape&#30475;&#20999;&#20986;&#20358;&#30340;&#36039;&#26009;&#30340;&#38263;&#30456;&#65288;&#21015;, &#27396;&#65289;</span>
<span class="linenr">5: </span><span style="color: #c678dd;">print</span>(X_train.shape)
<span class="linenr">6: </span><span style="color: #c678dd;">print</span>(X_test.shape)
<span class="linenr">7: </span><span style="color: #c678dd;">print</span>(Y_train.shape)
<span class="linenr">8: </span><span style="color: #c678dd;">print</span>(Y_test.shape)
</pre>
</div>

<pre class="example">
(361, 2)
(91, 2)
(361,)
(91,)
</pre>
</div>
</div>
<div id="outline-container-org6a77f57" class="outline-3">
<h3 id="org6a77f57"><span class="section-number-3">3.6.</span> 建立模型</h3>
<div class="outline-text-3" id="text-3-6">
<p>
new出一個LinearRegression的物件後，用特徵變數的訓練資料和目標變數的訓練資料產生一個模型。接著將特徵變數的測試資料倒進這個新產生的模型當中，得到預測的目標變數資料<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">Modeling</span>
<span class="linenr">2: </span><span style="color: #51afef;">from</span> sklearn.linear_model <span style="color: #51afef;">import</span> LinearRegression
<span class="linenr">3: </span><span style="color: #dcaeea;">reg</span> = LinearRegression()<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23416;&#32722;/&#35347;&#32244;Fitting linear model</span>
<span class="linenr">4: </span>reg.fit(X_train,Y_train)
</pre>
</div>
</div>
</div>
<div id="outline-container-org3562daf" class="outline-3">
<h3 id="org3562daf"><span class="section-number-3">3.7.</span> 測試效能</h3>
<div class="outline-text-3" id="text-3-7">
<p>
將這個預測的目標變數資料（預測結果）和目標變數的測試資料（真實結果）做R2-score：
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#38928;&#28204;&#32080;&#26524;Predicting using the linear model</span>
<span class="linenr">2: </span>reg.predict(X_test)<span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30495;&#23526;&#32080;&#26524;&#65306;Y_test# &#28204;&#35430;&#28310;&#30906;&#24230;&#65306;</span>
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'R2:'</span>, reg.score(X_test, Y_test))
</pre>
</div>

<pre class="example">
R2: 0.6048366146231109
</pre>

<p>
得到的這個R2-score讓我們可以知道特徵變數對於目標變數的解釋程度為何，而越接近1代表越準確。這裡大約是66%，解釋程度算是相當好的<sup><a id="fnr.1.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>。
</p>
</div>
<div id="outline-container-org98c1aa9" class="outline-4">
<h4 id="org98c1aa9"><span class="section-number-4">3.7.1.</span> 模型效能視覺化</h4>
<div class="outline-text-4" id="text-3-7-1">
<p>
把剛剛的預測的目標變數資料和測試的目標變數資料畫成散佈圖
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">plotting the y_test vs y_pred</span>
<span class="linenr"> 2: </span><span style="color: #dcaeea;">Y_pred</span> = reg.predict(X_test)
<span class="linenr"> 3: </span>plt.cla()
<span class="linenr"> 4: </span>plt.tight_layout()
<span class="linenr"> 5: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">10</span>,<span style="color: #da8548; font-weight: bold;">8</span>))
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span>plt.scatter(Y_pred, Y_test)
<span class="linenr"> 8: </span>plt.xlabel(<span style="color: #98be65;">'Y_pred'</span>)
<span class="linenr"> 9: </span>plt.ylabel(<span style="color: #98be65;">'Y_test'</span>)
<span class="linenr">10: </span>plt.savefig(<span style="color: #98be65;">'images/boston-perf.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
</pre>
</div>


<div id="orgcf6d35e" class="figure">
<p><img src="images/boston-perf.png" alt="boston-perf.png" width="500" />
</p>
<p><span class="figure-number">Figure 10: </span>Caption</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org49af693" class="outline-3">
<h3 id="org49af693"><span class="section-number-3">3.8.</span> 找出線性模型</h3>
<div class="outline-text-3" id="text-3-8">
<p>
由LinearRegression()找出線性模型的intercept和coefficient
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr">1: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'intercept:'</span>,reg.intercept_)
<span class="linenr">2: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'coefficient::'</span>,reg.coef_)
<span class="linenr">3: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'lstat:'</span>,reg.coef_[<span style="color: #da8548; font-weight: bold;">0</span>])
<span class="linenr">4: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">'rm:'</span>,reg.coef_[<span style="color: #da8548; font-weight: bold;">1</span>])
</pre>
</div>

<pre class="example">
intercept: 23.662167506495486
coefficient:: [-3.2284783   4.66331239]
lstat: -3.228478297753095
rm: 4.663312387946355
</pre>

<p>
線性模型為：\(medv=23.66 + -3.22 \times lstat + 4.66 \times rm + error\)
</p>
</div>
</div>
</div>
<div id="outline-container-org82ccafb" class="outline-2">
<h2 id="org82ccafb"><span class="section-number-2">4.</span> 關於迴歸模型的特徵選擇</h2>
<div class="outline-text-2" id="text-4">
<p>
在進行迴歸分析時，我們可以選擇不同的特徵來建立模型，這裡介紹兩種方法：
</p>
<ol class="org-ol">
<li>前向選擇法(Forward Selection)</li>
<li>後向選擇法(Backward Selection)</li>
</ol>
</div>
<div id="outline-container-org0913509" class="outline-3">
<h3 id="org0913509"><span class="section-number-3">4.1.</span> 前向選擇法(Forward Selection)</h3>
<div class="outline-text-3" id="text-4-1">
<p>
前向選擇法是一種逐步選擇特徵的方法，它從空模型開始，然後逐步添加特徵，直到達到某個標準為止。這種方法的優點是可以減少過擬合的風險，但是需要注意的是，如果特徵之間存在 <b>多重共線性(Multicollinearity)</b> ，則可能會導致模型不穩定。
</p>
</div>
</div>
<div id="outline-container-org0d9e354" class="outline-3">
<h3 id="org0d9e354"><span class="section-number-3">4.2.</span> 後向選擇法(Backward Selection)</h3>
<div class="outline-text-3" id="text-4-2">
<p>
後向選擇法是一種逐步刪除特徵的方法，它從包含所有特徵的模型開始，然後逐步刪除特徵，直到達到某個標準為止。這種方法的優點是可以減少過擬合的風險，但是需要注意的是，如果特徵之間存在多重共線性，則可能會導致模型不穩定。
</p>
</div>
</div>
<div id="outline-container-org458506d" class="outline-3">
<h3 id="org458506d"><span class="section-number-3">4.3.</span> 特徵選擇的注意事項</h3>
<div class="outline-text-3" id="text-4-3">
<p>
在進行特徵選擇時，需要注意以下幾點：
</p>
</div>
<div id="outline-container-org41278f4" class="outline-4">
<h4 id="org41278f4"><span class="section-number-4">4.3.1.</span> 特徵之間的相關性</h4>
<div class="outline-text-4" id="text-4-3-1">
<p>
特徵之間的相關性可能會導致模型不穩定，因此在進行特徵選擇時，需要注意特徵之間的相關性，避免選擇相關性較高的特徵。
</p>

<p>
以lstat, rm, indus, ptratio這四個特徵為例，我們可以使用 皮爾遜相關係數（Pearson Correlation） 來衡量 lstat 與 rm、indus、ptratio 的線性關係。
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 3: </span>
<span class="linenr"> 4: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639; lstat &#33287;&#20854;&#20182;&#35722;&#25976;&#30340;&#30456;&#38364;&#24615;</span>
<span class="linenr"> 5: </span><span style="color: #dcaeea;">lstat_corr</span> = housing[[<span style="color: #98be65;">'lstat'</span>, <span style="color: #98be65;">'rm'</span>, <span style="color: #98be65;">'indus'</span>, <span style="color: #98be65;">'ptratio'</span>]].corr()
<span class="linenr"> 6: </span>
<span class="linenr"> 7: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#30456;&#38364;&#20418;&#25976;&#34920;</span>
<span class="linenr"> 8: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"lstat &#33287;&#20854;&#20182;&#35722;&#25976;&#30340;&#30456;&#38364;&#24615;&#65306;"</span>)
<span class="linenr"> 9: </span><span style="color: #c678dd;">print</span>(lstat_corr)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#32362;&#35069;&#30456;&#38364;&#20418;&#25976;&#29105;&#22294;</span>
<span class="linenr">12: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">8</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">13: </span>sns.heatmap(lstat_corr, annot=<span style="color: #a9a1e1;">True</span>, cmap=<span style="color: #98be65;">"coolwarm"</span>, fmt=<span style="color: #98be65;">".2f"</span>)
<span class="linenr">14: </span>plt.title(<span style="color: #98be65;">"lstat correlation with other variables"</span>)
<span class="linenr">15: </span>plt.savefig(<span style="color: #98be65;">'images/lstat-corr.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">16: </span>
</pre>
</div>

<pre class="example">
lstat 與其他變數的相關性：
            lstat        rm     indus   ptratio
lstat    1.000000 -0.607289  0.565402  0.303043
rm      -0.607289  1.000000 -0.364895 -0.334164
indus    0.565402 -0.364895  1.000000  0.317336
ptratio  0.303043 -0.334164  0.317336  1.000000
</pre>


<div id="orgeeee798" class="figure">
<p><img src="images/lstat-corr.png" alt="lstat-corr.png" width="500" />
</p>
<p><span class="figure-number">Figure 11: </span>lstat 與其他變數的相關性</p>
</div>
</div>
</div>
<div id="outline-container-orgf23b32e" class="outline-4">
<h4 id="orgf23b32e"><span class="section-number-4">4.3.2.</span> 如何解讀相關性？</h4>
<div class="outline-text-4" id="text-4-3-2">
<p>
相關係數範圍：-1（完全負相關）到 +1（完全正相關）
</p>
<ul class="org-ul">
<li>|r| &gt; 0.8：高度相關（可能有多重共線性）</li>
<li>0.5 &lt; |r| &lt; 0.8：中等相關（可能需要進一步檢查）</li>
<li>|r| &lt; 0.5：低相關（通常不會造成共線性問題）</li>
</ul>
</div>
</div>
<div id="outline-container-org5f0ed8f" class="outline-4">
<h4 id="org5f0ed8f"><span class="section-number-4">4.3.3.</span> 為什麼變數之間的共變（高相關性）會影響迴歸結果？</h4>
<div class="outline-text-4" id="text-4-3-3">
<ol class="org-ol">
<li><p>
變數之間高共變影響迴歸模型
當兩個變數彼此高度相關時（例如 rm 和 lstat 相關性 -0.73）：
</p>

<p>
這兩個變數都能解釋目標變數 MEDV（房價）。
但因為它們彼此也高度相關，回歸模型無法區分到底是哪個變數真正影響房價，所以模型可能會：
</p>
<ul class="org-ul">
<li>讓其中一個變數的迴歸係數變得極端大或極端小，以補償另一個變數。</li>
</ul></li>
<li><p>
多重共線性會影響模型泛化能力
</p>
<ul class="org-ul">
<li>假設我們的模型發現： \(x_1\) （房屋面積）和 \(x_2\)（房間數）高度相關</li>
<li>由於數據集的特性，模型可能學到：
<ul class="org-ul">
<li>\(x_1\)影響比較大，\(x_2\) 影響比較小</li>
<li>但換一組數據集時，模型可能學到 \(x_2\) 影響比較大，\(x_1\)影響比較小</li>
</ul></li>
</ul>
<p>
這會導致：
</p>
<ul class="org-ul">
<li>在不同的測試集上，模型預測結果不穩定。</li>
<li>當我們遇到新數據時，模型的預測結果可能變化很大。</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-orgf97a4ce" class="outline-4">
<h4 id="orgf97a4ce"><span class="section-number-4">4.3.4.</span> 如何解決？</h4>
<div class="outline-text-4" id="text-4-3-4">
</div>
<div id="outline-container-org7de642f" class="outline-5">
<h5 id="org7de642f">方法 1：刪除其中一個變數</h5>
<div class="outline-text-5" id="text-org7de642f">
<p>
如果 \(x_1\) 和 \(x_2\) 高度相關（相關係數 &gt; 0.8），可以考慮刪除其中一個。例如：
</p>
<ul class="org-ul">
<li>刪除 \(x_2\)（房間數），只保留 \(x_1\)（房屋面積）。</li>
<li>選擇一個對 MEDV 影響更大的變數（透過 corr() 和 VIF 來選擇）。</li>
</ul>
</div>
</div>
<div id="outline-container-org536fb28" class="outline-5">
<h5 id="org536fb28">方法 2：合併變數</h5>
<div class="outline-text-5" id="text-org536fb28">
<p>
有時候可以建立一個新變數，代表這些高度相關變數的組合資訊。例如：
</p>
<ul class="org-ul">
<li>用「每平方公尺的房間數」(\(x_2\) / \(x_1\) 來替代 \(x_1\) 和 \(x_2\)，這樣就避免兩個變數的高度相關性。</li>
</ul>
</div>
</div>
<div id="outline-container-org1e078ef" class="outline-5">
<h5 id="org1e078ef">方法 3：使用 Ridge Regression（L2 正則化）</h5>
<div class="outline-text-5" id="text-org1e078ef">
<ul class="org-ul">
<li>Ridge 迴歸會對回歸係數加上一個懲罰，使它們不會變得過大，從而減少共線性的影響。</li>
<li>適合當 VIF 在 5~10 之間的變數，因為它不會直接移除變數，而是調整其影響力。</li>
</ul>
</div>
</div>
<div id="outline-container-org66dbb56" class="outline-5">
<h5 id="org66dbb56">方法 4：使用 PCA（主成分分析）降維</h5>
<div class="outline-text-5" id="text-org66dbb56">
<ul class="org-ul">
<li>透過 PCA 將高度相關的變數轉換為不相關的新特徵（如 PC1、PC2）。</li>
<li>這樣可以讓回歸模型使用的變數之間不會有多重共線性問題。</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org803c498" class="outline-3">
<h3 id="org803c498"><span class="section-number-3">4.4.</span> 多重共線性(Multicollinearity)</h3>
<div class="outline-text-3" id="text-4-4">
<p>
多重共線性是指特徵之間存在高度相關性的情況，這種情況下，模型的參數估計可能會變得不穩定，並且可能會導致模型的預測能力下降。因此，在進行特徵選擇時，需要注意特徵之間的相關性，避免多重共線性的問題。
</p>

<p>
當我們檢查 lstat（低收入族群比例）與其他變數的相關性時，指的是 lstat 與 其餘三個變數 (rm, indus, ptratio) 的 共變關係（即相關係數, Correlation Coefficient）。
</p>
</div>
<div id="outline-container-org65cd28b" class="outline-4">
<h4 id="org65cd28b"><span class="section-number-4">4.4.1.</span> 檢查多重共線性（VIF, Variance Inflation Factor）</h4>
<div class="outline-text-4" id="text-4-4-1">
<ul class="org-ul">
<li>若兩個或多個變數之間的相關性過高，可能會影響迴歸模型的穩定性。</li>
<li>VIF &gt; 5 通常表示該變數與其他變數的相關性過高，應考慮移除。</li>
</ul>
<div class="org-src-container">
<pre class="src src-python"><span class="linenr"> 1: </span><span style="color: #51afef;">import</span> pandas <span style="color: #51afef;">as</span> pd
<span class="linenr"> 2: </span><span style="color: #51afef;">import</span> numpy <span style="color: #51afef;">as</span> np
<span class="linenr"> 3: </span><span style="color: #51afef;">import</span> seaborn <span style="color: #51afef;">as</span> sns
<span class="linenr"> 4: </span><span style="color: #51afef;">import</span> matplotlib.pyplot <span style="color: #51afef;">as</span> plt
<span class="linenr"> 5: </span><span style="color: #51afef;">from</span> sklearn.preprocessing <span style="color: #51afef;">import</span> StandardScaler
<span class="linenr"> 6: </span><span style="color: #51afef;">from</span> statsmodels.stats.outliers_influence <span style="color: #51afef;">import</span> variance_inflation_factor
<span class="linenr"> 7: </span>
<span class="linenr"> 8: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35712;&#21462; Boston Housing &#36039;&#26009;</span>
<span class="linenr"> 9: </span><span style="color: #dcaeea;">housing</span> = pd.read_csv(<span style="color: #98be65;">'https://raw.githubusercontent.com/letranger/AI/gh-pages/Downloads/boston_housing.csv'</span>)
<span class="linenr">10: </span>
<span class="linenr">11: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30446;&#27161;&#35722;&#25976;</span>
<span class="linenr">12: </span><span style="color: #dcaeea;">target_column</span> = <span style="color: #98be65;">'medv'</span>
<span class="linenr">13: </span>
<span class="linenr">14: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639;&#30456;&#38364;&#20418;&#25976;</span>
<span class="linenr">15: </span><span style="color: #dcaeea;">correlation_matrix</span> = housing.corr()
<span class="linenr">16: </span>
<span class="linenr">17: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21482;&#39023;&#31034;&#33287;&#30446;&#27161;&#35722;&#25976;&#30340;&#30456;&#38364;&#24615;</span>
<span class="linenr">18: </span><span style="color: #dcaeea;">corr_target</span> = correlation_matrix[target_column].drop(target_column).sort_values(ascending=<span style="color: #a9a1e1;">False</span>)
<span class="linenr">19: </span>
<span class="linenr">20: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35373;&#23450;&#30456;&#38364;&#24615;&#38334;&#20540;&#65288;&#20363;&#22914;&#65306;0.4 &#20197;&#19978;&#28858;&#36611;&#24375;&#30456;&#38364;&#65289;</span>
<span class="linenr">21: </span><span style="color: #dcaeea;">threshold</span> = <span style="color: #da8548; font-weight: bold;">0.4</span>
<span class="linenr">22: </span><span style="color: #dcaeea;">selected_features</span> = corr_target[<span style="color: #c678dd;">abs</span>(corr_target) &gt; threshold].index.tolist()
<span class="linenr">23: </span>
<span class="linenr">24: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#36942;&#28670;&#24460;&#30340;&#29305;&#24501;</span>
<span class="linenr">25: </span><span style="color: #dcaeea;">filtered_data</span> = housing[selected_features + [target_column]]
<span class="linenr">26: </span>
<span class="linenr">27: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034;&#30456;&#38364;&#24615;&#36611;&#39640;&#30340;&#29305;&#24501;</span>
<span class="linenr">28: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"&#33287;&#30446;&#27161;&#35722;&#25976;&#30456;&#38364;&#24615;&#36611;&#39640;&#30340;&#29305;&#24501;&#65306;"</span>)
<span class="linenr">29: </span><span style="color: #c678dd;">print</span>(filtered_data.head())
<span class="linenr">30: </span>
<span class="linenr">31: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#30059;&#20986;&#30456;&#38364;&#20418;&#25976;&#29105;&#22294;</span>
<span class="linenr">32: </span>plt.figure(figsize=(<span style="color: #da8548; font-weight: bold;">10</span>, <span style="color: #da8548; font-weight: bold;">6</span>))
<span class="linenr">33: </span>sns.heatmap(filtered_data.corr(), annot=<span style="color: #a9a1e1;">True</span>, cmap=<span style="color: #98be65;">"coolwarm"</span>, fmt=<span style="color: #98be65;">".2f"</span>)
<span class="linenr">34: </span>plt.title(<span style="color: #98be65;">"The correlation heatmap of features related to MEDV"</span>)
<span class="linenr">35: </span>plt.savefig(<span style="color: #98be65;">'images/boston-heatmap.png'</span>, dpi=<span style="color: #da8548; font-weight: bold;">300</span>)
<span class="linenr">36: </span>
<span class="linenr">37: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639; VIF&#65288;&#35722;&#30064;&#33192;&#33081;&#22240;&#23376;&#65289;</span>
<span class="linenr">38: </span><span style="color: #dcaeea;">X</span> = housing[selected_features]
<span class="linenr">39: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">vif_data = pd.DataFrame()</span>
<span class="linenr">40: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">vif_data["Feature"] = X.columns</span>
<span class="linenr">41: </span><span style="color: #5B6268;">#</span><span style="color: #5B6268;">vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]</span>
<span class="linenr">42: </span>
<span class="linenr">43: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#24314;&#31435; VIF DataFrame(&#31777;&#26131;&#29256;)</span>
<span class="linenr">44: </span><span style="color: #dcaeea;">vif_data</span> = pd.DataFrame()
<span class="linenr">45: </span><span style="color: #dcaeea;">vif_data</span>[<span style="color: #98be65;">"Feature"</span>] = X.columns  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35352;&#37636;&#35722;&#25976;&#21517;&#31281;</span>
<span class="linenr">46: </span><span style="color: #dcaeea;">vif_values</span> = []  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23384;&#25918;&#27599;&#20491;&#35722;&#25976;&#30340; VIF &#20540;</span>
<span class="linenr">47: </span>
<span class="linenr">48: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#20351;&#29992; for &#36852;&#22280;&#36880;&#20491;&#35722;&#25976;&#35336;&#31639; VIF</span>
<span class="linenr">49: </span><span style="color: #51afef;">for</span> i <span style="color: #51afef;">in</span> <span style="color: #c678dd;">range</span>(X.shape[<span style="color: #da8548; font-weight: bold;">1</span>]):
<span class="linenr">50: </span>    <span style="color: #dcaeea;">vif</span> = variance_inflation_factor(X.values, i)  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#35336;&#31639; VIF</span>
<span class="linenr">51: </span>    vif_values.append(vif)  <span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#21152;&#20837;&#21015;&#34920;</span>
<span class="linenr">52: </span>
<span class="linenr">53: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#23559; VIF &#20540;&#23384;&#20837; DataFrame</span>
<span class="linenr">54: </span><span style="color: #dcaeea;">vif_data</span>[<span style="color: #98be65;">"VIF"</span>] = vif_values
<span class="linenr">55: </span>
<span class="linenr">56: </span><span style="color: #5B6268;"># </span><span style="color: #5B6268;">&#39023;&#31034; VIF &#32080;&#26524;</span>
<span class="linenr">57: </span><span style="color: #c678dd;">print</span>(<span style="color: #98be65;">"</span><span style="color: #a9a1e1;">\n</span><span style="color: #98be65;">&#35722;&#30064;&#33192;&#33081;&#22240;&#23376;&#65288;VIF&#65289;&#27298;&#28204;&#32080;&#26524;&#65306;"</span>)
<span class="linenr">58: </span><span style="color: #c678dd;">print</span>(vif_data)
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
<a href="https://medium.com/li-ting-liao-tiffany/python-%E5%BF%AB%E9%80%9F%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-boston-housing%E6%B3%A2%E5%A3%AB%E9%A0%93%E6%88%BF%E5%83%B9-9c535fb7ceb7">What impacts Boston Housing Prices</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Yung-Chin Yen</p>
<p class="date">Created: 2025-02-21 Fri 11:08</p>
</div>
</body>
</html>
